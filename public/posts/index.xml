<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Jiekun&#39;s Blog</title>
		<link>https://jiekun.dev/posts/</link>
		<description>Recent content in Posts on Jiekun&#39;s Blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>cn-zh</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Fri, 21 Mar 2025 21:48:21 +0800</lastBuildDate>
		<atom:link href="https://jiekun.dev/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>2024 Annual Review: My New Role At VictoriaMetrics</title>
			<link>https://jiekun.dev/posts/2024-summary/</link>
			<pubDate>Fri, 21 Mar 2025 21:48:21 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2024-summary/</guid>
			<description>This blog post is written before my trip to KubeCon London. Exactly one year ago, I met with the VictoriaMetrics team in Paris for the first time. So, this review is about what I have been doing during this past year and how these things have changed my life.
 Contributing Without Pull Requests: Learning Through Action At first, I didn&amp;rsquo;t know much about VictoriaMetrics. We were using Prometheus and Thanos, well-recognized metrics monitoring solutions.</description>
			<content type="html"><![CDATA[<blockquote>
<p>This blog post is written before my trip to <a href="https://kccnceu2025.sched.com/">KubeCon London</a>. Exactly one year ago, I met with the VictoriaMetrics team in Paris for the first time. So, this review is about what I have been doing during this past year and how these things have changed my life.</p>
</blockquote>
<h2 id="contributing-without-pull-requests-learning-through-action">Contributing Without Pull Requests: Learning Through Action</h2>
<p>At first, I didn&rsquo;t know much about VictoriaMetrics. We were using Prometheus and Thanos, well-recognized metrics monitoring solutions. Like everyone else, we had performance and other issues, so we started looking for alternatives.</p>
<p>At that time, there were already some companies using VictoriaMetrics at a large scale in China, with some case study blog posts. We saw them and started a PoC(proof of concept). It took months, and I, as the one in charge of the PoC, asked some questions in Slack and GitHub. Everything up to now has nothing special, every developer would do the same.</p>
<p>I noticed that many questions were duplicated and already explained in the document. Therefore, in order to reduce the pressure on the VictoriaMetrics engineers (so they would have time to help with my questions), I started to answer questions based on my limited knowledge or the information available in the document.</p>
<p><img src="../202503-2024-summary/comment_trend.png" alt=""></p>
<p>By doing so, I looked through many documents and sometimes read the source code to find the answer. It&rsquo;s very helpful, both for the community and me:</p>
<ol>
<li>Open-source community always lack first-line supporter, not matter how good the document is. Most people are asking questions, while only a few are answering. The vast majority of these few are core developers because they understand everything, and a very small number are some interested users who try to help each other.</li>
<li>Questions force me to read and learn. That&rsquo;s a good first step to get familiar with a open-source project. Sometimes it could be the only way, because you may not have a chance to work with it in your day job (e.g., a Go developer maintaining a payment service trying to learn about Kubernetes).</li>
</ol>
<p>I am very grateful that these supporting things are receiving attention and sometimes I can see comments like &ldquo;thank you, this solved my issue&rdquo;. At least it proves that (sometimes) my comments are helpful.</p>
<p>Everything happens for a reason. The documentation and source code of VictoriaMetrics are well-organized; at least they didn&rsquo;t give me too much trouble while reading them.</p>
<p>I&rsquo;m not sure if this &ldquo;learn by answering&rdquo; approach would work in other projects. For example, take a look at the issue list of Kubernetes: If the answer is available in the documentation, that would be ideal. If you need to delve into the code, I believe that would be much more challenging.</p>
<p>In summary, if you want to learn and contribute to open-source projects, choosing a good project and starting by addressing real user issues is a good approach, especially for developers who may not have chance to use it in their day job.</p>
<h2 id="my-new-role-at-victoriametrics">My New Role At VictoriaMetrics</h2>
<p>I really like this scene in the movie &ldquo;Catch Me If You Can&rdquo;, but I want to make a slight modification to it.</p>
<p><img src="../202503-2024-summary/interview.webp" alt=""></p>
<p>I actually failed the technical interview. But, fortunately, I am not bothered by that and continue my &ldquo;unofficial&rdquo; support within the VictoriaMetrics community. Because it helps me gain knowledge and sometimes a simple word of thanks.</p>
<p>Even more fortunate, the team was willing to accept someone who didn&rsquo;t pass the interview, giving me the opportunity to turn supporting into an official role.</p>
<h2 id="how-my-life-was-changed">How My Life Was Changed</h2>
<p>It&rsquo;s a remote job, so every day I find myself sitting at home in front of the laptop. Meetings, tasks, everything is conducted virtually online.</p>
<p>Without a commute, I can take time to play sports in the mornings or after work. On the flip side, without a company canteen, I now have to cook for myself or order delivery.</p>
]]></content>
		</item>
		
		<item>
			<title>OpenTelemetry, Prometheus, and More: 谁是采集监控指标的最佳选择?</title>
			<link>https://jiekun.dev/posts/otlp-remote-write/</link>
			<pubDate>Sat, 21 Dec 2024 01:22:23 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/otlp-remote-write/</guid>
			<description>Medium This blog post is also available in English: OpenTelemetry, Prometheus, and More: Which Is Better for Metrics Collection and Propagation? Prometheus and Remote Write Prometheus 是云原生指标监控领域的事实标准。它的工作模式很简单：应用提供 /metrics HTTP API，以文本格式暴露指</description>
			<content type="html"><![CDATA[
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="https://victoriametrics.com/blog/opentelemetry-prometheus-and-more/">OpenTelemetry, Prometheus, and More: Which Is Better for Metrics Collection and Propagation?</a></li>
</ul>
</div>
    </aside>
<h2 id="prometheus-and-remote-write">Prometheus and Remote Write</h2>
<p>Prometheus 是云原生指标监控领域的事实标准。它的工作模式很简单：应用提供 <code>/metrics</code> HTTP API，以文本格式暴露指标数据；Prometheus 访问这些 API，将数据采集，然后提供查询 API 进行展示。</p>
<p>虽然 Prometheus 的生态发展出了很丰富的组件，它的核心 Prometheus Server（下称 Prometheus）仍然保持 All-in-One 的设计，提供一个可执行文件，无需任何依赖即可运行，这使得它的安装和部署更加简单。</p>
<p>但是，这也使得 Prometheus 不易扩展。想象一下，一开始的时候，你在一台 2 CPU，4GiB 内存的机器上运行 Prometheus，用它来监控 100 个应用程序，这很容易。很快你需要用它监控 10000 个、100000 个应用程序，Prometheus 需要更多的机器资源，但是单台机器的配置总是有限的；另外，这些应用可能部署于不同的集群，不同的可用区，用单个 Prometheus 来四处收集数据并不高效。</p>
<p>所以，Prometheus 也提供了两个重要功能：</p>
<ol>
<li>Remote Write：将指标数据发送给<strong>远端存储</strong>，例如 Thanos，Cortex，Mimir 和 VictoriaMetrics。</li>
<li>Agent Mode：省略查询、告警、本地存储功能，降低 Prometheus 仅用作数据采集 Agent 时的成本。</li>
</ol>
<p>有了这些功能，面对大量应用时，监控架构可能是如下图这样：</p>
<p><img src="../202412-otlp-remote-write/metrics_monitoring.png" alt=""></p>
<h2 id="opentelemetry-and-otlp">OpenTelemetry and OTLP</h2>
<p>2019 年，OpenTelemetry 诞生，它提供了统一、开源的可观测性标准，避免用户因依赖特定供应商或者协议而难以更换、迁移到新的技术服务上。</p>
<p>OpenTelemetry 定义了一系列的概念，例如 Signal，即一类 Telemetry，包括 Tracing Signal、Metric Signal、Log Signal 等。而在不同组件间传输这些 Telemetry 数据需要遵循的协议就是 OpenTelemetry 协议（OpenTelemetry Protocol，OTLP）。</p>
<h2 id="prometheus-and-opentelemetry">Prometheus and OpenTelemetry</h2>
<p>那么当谈及 Metrics 时，似乎很容易将 OpenTelemetry 与 Prometheus 进行类比：</p>
<table>
<thead>
<tr>
<th></th>
<th>Prometheus</th>
<th>OpenTelemetry</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Model</td>
<td>Metrics</td>
<td>Metrics Signal</td>
</tr>
<tr>
<td>Protocol of Data Propagation</td>
<td>Remote Write</td>
<td>OTLP</td>
</tr>
</tbody>
</table>
<p>不知道大家是否有过这样的疑问：<strong>Prometheus 既然已经是云原生指标监控领域的事实标准，大多数供应商、项目也支持它的 Data Model 和 Remote Write Protocol，那为什么要考虑 OpenTelemetry 呢？</strong></p>
<p>假设你已经在使用 Kubernetes，这个生态里的许多组件都是以 HTTP API 的形式暴露 Prometheus 文本格式的指标数据：</p>
<ol>
<li><a href="https://kubernetes.io/docs/reference/instrumentation/metrics/">Kubernetes</a>.</li>
<li><a href="https://istio.io/latest/docs/reference/config/metrics/">Istio</a>.</li>
<li><a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics</a>.</li>
<li>&hellip;</li>
</ol>
<p>当这些基础设施都不可改变的时候，前面的问题就变成了：<strong>抓取指标数据并将他发送给 Remote Storage，Prometheus 还是 OpenTelemetry 更好？</strong></p>
<p>不妨来做一下性能测试。</p>
<h2 id="benchmark">Benchmark</h2>
<h3 id="setup">Setup</h3>
<p>我们分别运行 <a href="https://github.com/prometheus/prometheus">Prometheus</a>（Agent Mode）、<a href="https://github.com/open-telemetry/opentelemetry-collector">OpenTelemetry Collector</a> 和 <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/tree/master">vmagent</a> 抓取 1200 个分散在 3 个 Region 的 <a href="https://github.com/prometheus/node_exporter">Node exporter</a>，并将数据以不同协议发送给 Receiver。这个 Receiver 会对数据进行 Decompress 和 Unmarshal，并且记录一些统计信息，但没有实际的数据持久化操作。</p>
<p>相关组件的信息如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>Version</th>
<th>Machine Type</th>
<th>vCPUs</th>
<th>Memory (GB)</th>
<th>Standard persistent disk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Prometheus</td>
<td>2.53.3</td>
<td>e2-highcpu-2</td>
<td>2</td>
<td>2</td>
<td>Standard persistent disk(HDD)</td>
</tr>
<tr>
<td>Prometheus</td>
<td>3.0.1</td>
<td>e2-highcpu-2</td>
<td>2</td>
<td>2</td>
<td>Standard persistent disk(HDD)</td>
</tr>
<tr>
<td>OpenTelemetry Collector</td>
<td>v0.115.0</td>
<td>e2-highcpu-2</td>
<td>2</td>
<td>2</td>
<td>Standard persistent disk(HDD)</td>
</tr>
<tr>
<td>vmagent</td>
<td>v1.108.0</td>
<td>e2-highcpu-2</td>
<td>2</td>
<td>2</td>
<td>Standard persistent disk(HDD)</td>
</tr>
<tr>
<td>Node exporter</td>
<td>1.8.2</td>
<td>e2-micro</td>
<td>2(0.25)</td>
<td>1</td>
<td>Standard persistent disk(HDD)</td>
</tr>
<tr>
<td>No-op Receiver</td>
<td>N/A</td>
<td>n2d-highcpu-4</td>
<td>4</td>
<td>4</td>
<td>Balanced persistent disk(SSD)</td>
</tr>
</tbody>
</table>
<p>整体的 Benchmark 架构如下：</p>
<p><img src="../202412-otlp-remote-write/benchmark_setup.png" alt=""></p>
<h3 id="result-1">Result #1</h3>
<p>首次 Benchmark 主要了解不同组件的资源使用情况，为后续测试提供参考基准。在运行了数天后，我们得到了一些监控数据。</p>
<p><img src="../202412-otlp-remote-write/benchmark-1-resource.png" alt=""></p>
<p>看起来<strong>从 Prometheus 2.x 升级到 Prometheus 3.x 并不会给你额外的节约 CPU 和内存资源</strong>。它是测试组件中<strong>使用内存最多</strong>的，这可能与 WAL 的存在有关。<strong>OpenTelemetry Collector</strong> 如果用作数据采集的 Agent，<strong>CPU 开销似乎太高了</strong>，同时在没有 WAL 的情况下，内存的使用量也处在较高的水平。</p>
<p><img src="../202412-otlp-remote-write/benchmark-1-traffic.png" alt=""></p>
<p>网络流量的情况反映的是不同协议的数据传输效率。由于采集的是相同的目标，In-Traffic 是几乎一致的。而 Out-Traffic 告诉我们，Prometheus 3.x 使用的 <strong>Remote Write 2.0 相比 Remote Write 1.0 能节约 40% 的带宽</strong>，而 OpenTelemetry Collector 使用的 OTLP 似乎在这方面不太占优势。vmagent 使用的是 Remote Write 1.0，但是压缩算法从 Prometheus 规范中指定的 <a href="https://github.com/google/snappy">Snappy</a> 变成了 <a href="https://github.com/valyala/gozstd">zstd</a>，这为它节约了大量的带宽。</p>
<p><img src="../202412-otlp-remote-write/benchmark-1-disk.png" alt=""></p>
<p>在磁盘使用量方面，因为 Benchmark 并没有关注 Remote Storage 不可用时的情况，所以 OpenTelemetry Collector 和 vmagent 几乎都没有使用额外的存储空间。Prometheus 由于 WAL 的存在，尽管处于 Agent Mode，WAL 仍然需要正常写入以提供 Remote Write 支持。这些 WAL 数据每隔 2 小时清理，因此在磁盘用量的监控上图线呈现锯齿状。</p>
<p>在简单总结之后，我们发现了一些值得继续探讨的问题：</p>
<ol>
<li><strong>为什么 OpenTelemetry Collector 的 CPU 使用率远高于其它 Agent？</strong></li>
<li>vmagent 仅修改了 Remote Write 1.0 的压缩算法就能使带宽用量降低这么多，那 <strong>Remote Write 2.0 使用 zstd 压缩算法有用吗？</strong></li>
</ol>
<h3 id="profiling-opentelemetry-collector">Profiling OpenTelemetry Collector</h3>
<p>我们使用到的 OpenTelemetry Collector 配置非常简洁：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">service</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">pipelines</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">receivers</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="l">prometheus]</span><span class="w">
</span><span class="w">      </span><span class="nt">processors</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="l">batch]</span><span class="w">
</span><span class="w">      </span><span class="nt">exporters</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="l">otlp]</span><span class="w">
</span></code></pre></div><p>所以问题无非出在 Prometheus Receiver 或 OTLP Exporter 上。</p>
<p>因此，我们通过增加 <code>extensions: [pprof]</code>，收集了它的 <a href="../202412-otlp-remote-write/otel-profile.prof">profile</a> 样本。从中可以看出，OpenTelemetry Collector 在 Scrape 操作花费的时间较多，所以基本可以确定是 <strong>Prometheus Receiver</strong> 带来的开销。</p>
<p><img src="../202412-otlp-remote-write/otel-profile.jpg" alt=""></p>
<p>考虑到抓取 Prometheus 文本格式的指标并不算是 OpenTelemetry Collector 的“本职工作”，这些性能上的瑕疵似乎可以理解。对它进行优化会是个很有趣的过程，但这不是本文讨论的重点。</p>
<p><strong>假若未来各类基础设施（例如 Node exporter）可以提供 OTLP 支持，这个问题能否得到改善呢？</strong> 我们重新设计了 OpenTelemetry Collector 的数据采集流程，考察其在 Push 模式下收集数据的资源使用情况。架构修改如下：</p>
<p><img src="../202412-otlp-remote-write/otel_setup.png" alt=""></p>
<p>其中，OpenTelemetry Collector Helper 仍然使用 Prometheus Receiver 来主动采集 Node exporter 指标，移除 Batch Processor，然后借助 OTLP Exporter 将数据推送给 OpenTelemetry Collector。在这种场景下，被测的 OpenTelemetry Collector 收到请求速率大约为 40 req/s。</p>
<p>通过对比，我们发现这种工作模式下 OpenTelemetry Collector 的 <strong>CPU 使用率降低了 35%</strong>，<strong>内存使用率降低了 70%</strong>。</p>
<p><img src="../202412-otlp-remote-write/benchmark-otel-receiver.png" alt=""></p>
<h3 id="zstd-silver-bullet">zstd: Silver Bullet?</h3>
<p>在惊讶于 vmagent 定制版 Remote Write 1.0 的超低带宽使用量之余，我们尝试让 Remote Write 2.0 也与 zstd 进行结合。通过对 Prometheus 3.x 进行简单调整，我们观测到了如下的结果：</p>
<p><img src="../202412-otlp-remote-write/benchmark-prometheus-vmagent-zstd.png" alt=""></p>
<p>借助 zstd，Remote Write 2.0 的带宽使用降低了 30%。压缩算法的变更影响最大的是 CPU 使用率，但是在测试的负载下，CPU 使用率仅上升了 4%，并不明显。因此，有理由认为 zstd 对于关注带宽使用的用户（例如多云商部署，需要跨 Available Zone 传输数据）有不错的使用价值。</p>
<h3 id="result-full">Result (Full)</h3>
<p><img src="../202412-otlp-remote-write/benchmark-full.png" alt=""></p>
<p>现在，你还可以在 <a href="https://snapshots.raintank.io/dashboard/snapshot/HS3eUWxbt8sjwyOByd6WclWElEAyUUMv?orgId=0">snapshots.raintank.io</a> 上查看这份监控数据 Snapshot。</p>
<h2 id="conclusion">Conclusion</h2>
<p>我们最初提出的问题是：<strong>Prometheus 既然已经是云原生指标监控领域的事实标准，大多数供应商、项目也支持它的 Data Model 和 Remote Write Protocol，那为什么要考虑 OpenTelemetry 呢？</strong></p>
<p>通过前文的比较，我们认为，<strong>在大部分 Exporter</strong>（特别是 <a href="https://istio.io/latest/docs/reference/config/metrics/">Istio</a>、<a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics</a> 这种数据量庞大的 Exporter）<strong>能提供完善的 OTLP 支持之前，使用 OpenTelemetry 是需要不小的代价的</strong>，在数据采集、转换所需要的 CPU 资源上体现尤为明显。</p>
<p>而关注到 Prometheus 生态内部，<strong>Prometheus 3.x 的全新 Remote Write 协议直接减少了 40% 的带宽使用</strong>，若进一步加入 zstd 压缩算法的选项，用户甚至可以得到一张 4 折的带宽账单。但其他资源使用上，因为 Prometheus 2.x 仍在继续开发迭代，所以也会收到性能优化 Patch，相比之下，<strong>两个大版本间的资源使用差距似乎不太明显</strong>。</p>
<p>而 <strong>vmagent</strong> 作为众多比较对象中较为特殊的存在，相比 OpenTelemetry Collector 和 Prometheus 3.x，它以能<strong>以极低的 CPU（相比前两者降低 70% / 39%）和内存（相比前两者降低 64% / 67%）开销</strong>直接采集 Prometheus 文本格式的 Exporter。同时，借助 Remote Write 1.0 及 zstd 压缩算法的组合，它又能最小化带宽需求，<strong>即使对比 Remote Write 2.0 仍能节约 46% 的网络带宽</strong>，算得上是用户的极致性价比之选。</p>
<p>随着 OpenTelemetry 和 Prometheus 不断推动新的标准，未来若有能更好利用 OTLP 和 Remote Write 2.0 标准的 Exporter，或许新的协议会体现出更多的优势。但是就目前而言，用户似乎仍有理由坚守在现存的版本，毕竟，伴随每次迁移升级的不止有收益，也有很多不可忽视的成本。</p>
]]></content>
		</item>
		
		<item>
			<title>社区报障案例：没有新的 Time Series，为什么 Churn Rate 升高？</title>
			<link>https://jiekun.dev/posts/churn-rate-in-victoriametrics/</link>
			<pubDate>Sat, 03 Aug 2024 14:59:00 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/churn-rate-in-victoriametrics/</guid>
			<description>Medium This blog post is also available in English: Question From Community: High Churn Rate Without New Time Series? 上周，我在 Slack 看到一位用户求助： 我的 VictoriaMetrics 集群在每天 0 点都有很高的 Churn Rate。但是当我开启 -logNewSe</description>
			<content type="html"><![CDATA[
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="">Question From Community: High Churn Rate Without New Time Series?</a></li>
</ul>
</div>
    </aside>
<p>上周，我在 <a href="https://victoriametrics.slack.com/archives/CGZF1H6L9/p1722389004202069">Slack</a> 看到一位用户求助：</p>
<blockquote>
<p>我的 VictoriaMetrics 集群在每天 0 点都有很高的 Churn Rate。但是当我开启 <code>-logNewSeries</code>，我发现这些“新” Time Series 其实都已经存在过，这是为什么呢？</p>
</blockquote>
<p><img src="../202408-high-churn-rate/high_churn_rate_at_0.png" alt=""></p>
<h2 id="what-is-churn-rate">What Is Churn Rate</h2>
<p><a href="https://docs.victoriametrics.com/faq/#what-is-high-churn-rate">Churn Rate</a>，也就是新 Time Series 出现的速率。</p>
<p>如果旧的 Time Series 一直在被新 Time Series 所替代，我们称之为 High Churn Rate。High Churn Rate 对 TSDB 有以下的不良影响：</p>
<ul>
<li>使得 TSDB 中总的 Time Series 数量增加；</li>
<li>使得 TSDB 中的倒排索引（Inverted Index）体积增加；</li>
<li>使得范围查询的性能下降，因为需要聚合更多的 Time Series。</li>
</ul>
<p>在 VictoriaMetrics 中，你可以用这个语句来查询它：</p>
<pre tabindex="0"><code>sum(rate(vm_new_timeseries_created_total))
</code></pre><p><img src="../202408-high-churn-rate/churn_rate.gif" alt=""></p>
<p>那么回到用户的问题，<strong>如果真的没有新的 Time Series 出现，Churn Rate 难道不应该是 0 吗？</strong></p>
<p>理论上，是的。为了解答这个问题，我们需要先了解 Churn Rate 是如何计算的。</p>
<h2 id="how-churn-rate-is-calculated-in-victoriametrics">How Churn Rate is Calculated in VictoriaMetrics</h2>
<p>如果我们需要知道哪些 Time Series 已经出现过，我们必须要先将它（及相关索引）记录到磁盘中。当有 Time Series 到来，我们从磁盘（的倒排索引）中查询是否有相同的 Time Series 存在。</p>
<p>在此基础上，最常见的查询优化是使用<strong>内存缓存</strong>。所以我们可以得到如下的流程图：</p>
<p><img src="../202408-high-churn-rate/time_series_exist.png" alt=""></p>
<h2 id="root-cause">Root Cause</h2>
<p>根据这些知识，我们继续思考用户的问题，如果一个 Time Series 被判定为“新”，说明它既不存在于 Cache 中，也不存在于倒排索引中。</p>
<p>我们仔细观察倒排索引的查询，看看能不能有新的收获：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go">        <span class="c1">// Search for TSID for the given mr.MetricNameRaw in the indexdb.
</span><span class="c1"></span>        <span class="k">if</span> <span class="nx">is</span><span class="p">.</span><span class="nf">getTSIDByMetricName</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">genTSID</span><span class="p">,</span> <span class="nx">metricNameBuf</span><span class="p">,</span> <span class="nx">date</span><span class="p">)</span> <span class="p">{</span>
            <span class="c1">// Slower path - the TSID has been found in indexdb.
</span><span class="c1"></span>            <span class="o">...</span>
        <span class="p">}</span>

        <span class="c1">// Slowest path - the TSID for the given mr.MetricNameRaw isn&#39;t found in indexdb. Create it.
</span><span class="c1"></span>        <span class="o">...</span>
</code></pre></div><p>其中，<code>date</code> 参数非常容易引起注意，这说明数据是按天查找的，如果真的是这样，那相当于每日凌晨所有的 Time Series 都是“新” Time Series，和用户描述的现象就能对得上了。</p>
<p>所以，更准确的数据写入流程图应该是：</p>
<p><img src="../202408-high-churn-rate/time_series_create.png" alt=""></p>
<p>为了验证这个情况，我又查看了我们内部的 VictoriaMetrics 集群面板，奇怪的是，Churn Rate 还是相对平稳的，并没有在每日凌晨暴涨。</p>
<p><img src="../202408-high-churn-rate/healthy_churn_rate.png" alt=""></p>
<p>“Aha，因为还有 <strong>Cache</strong>”，我突然想起来。现在已经离 Root Cause 很接近了，那为什么用户的 Time Series 不在 Cache 中呢？</p>
<p>我再次查看用户提供的信息，发现了以下内容：</p>
<blockquote>
<p>我的（有问题的）VictoriaMetrics Cluster 主要用于存放 Downsampling 的数据，它们是<strong>每隔 1 小时生成一次</strong>的。</p>
</blockquote>
<p>这是个很重要的信息，如果缓存有 TTL，1 小时可能会超过 TTL 的时间。通过简单的搜索，我发现 TTL 是由 <code>cacheExpireDuration</code> 参数控制的，默认值为 30 分钟。</p>
<p>那么问题原因到这里就已经明确了：</p>
<ol>
<li>用户每次 Downsampling 生成数据被记录到缓存和倒排索引中，其中缓存 TTL 30 分钟；</li>
<li>30 分钟后，缓存过期；1 小时后，用户再次生成新的 Downsampling 数据，无法命中缓存，转而命中倒排索引；</li>
<li>因为查询使用的倒排索引是当日的数据，所以每日凌晨时无法命中，数据被视为新的 Time Series，表现为 High Churn Rate。</li>
</ol>
<p>为了最终确认，我让用户查看缓存使用率的情况，是否每次生成数据时上升，过了 30 分钟后降低。果然：</p>
<p><img src="../202408-high-churn-rate/cache_usage.png" alt=""></p>
<h2 id="how-to-fix-it">How To Fix It</h2>
<p>非常简单，根据实际数据生成的间隔，将 <code>cacheExpireDuration</code> 修改至合适的时长。</p>
<h2 id="conclusion">Conclusion</h2>
<p>在这篇博客中，我们通过 Churn Rate 问题的排查，介绍了 Churn Rate 的概念，以及它在 VictoriaMetrics 中的统计规则。</p>
<p>实际上，每个 Time Series 在 VictoriaMetrics 中的处理更加复杂，例如在每次 IndexDB 滚动之前 1 小时需要进行预热（Prefill），详细实现请阅读：<a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/bdc0e688e8eda34f1afd3f9061d3158b052c44cb/lib/storage/storage.go#L1773">add</a>。</p>
<h2 id="bonus-section">Bonus Section</h2>
<p>在用户将 <code>cacheExpireDuration</code> 调整至 90 分钟后，理论上能够覆盖 Downsampling 数据的生成间隔，所以 Cache 使用率似乎应该保持稳定。但是实际上，Cache 使用率如下图所示，你知道为什么吗？</p>
<p><img src="../202408-high-churn-rate/cache_usage_2.png" alt=""></p>
<p>提示：<a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/7e1dd8ab9d792b9c6250e0bf4c5b9cbadaeaf529/lib/workingsetcache/cache.go#L135">expirationWatcher</a>。</p>
]]></content>
		</item>
		
		<item>
			<title>监控数据问题排查：我的指标去哪儿了？</title>
			<link>https://jiekun.dev/posts/troubleshooting-victoriametrics/</link>
			<pubDate>Thu, 18 Jul 2024 15:12:00 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/troubleshooting-victoriametrics/</guid>
			<description>Medium This blog post is also available in English: Troubleshooting Time Series Database: Where Did My Metrics Go? 问题 复杂的现代应用离不开可观测性，而指标监控是可观测性中非常重要的一环。最常见的指标监控采集、处理、存储</description>
			<content type="html"><![CDATA[
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="">Troubleshooting Time Series Database: Where Did My Metrics Go?</a></li>
</ul>
</div>
    </aside>
<h2 id="问题">问题</h2>
<p>复杂的现代应用离不开可观测性，而指标监控是可观测性中非常重要的一环。最常见的指标监控采集、处理、存储、展示流程可以概括为下图：</p>
<p><img src="../202407-troubleshooting-tsdb/pipeline.png" alt=""></p>
<p>如果它出了问题，例如，我们经常被用户问道：“<strong>我已经在应用中记录了指标，为什么我的指标不能在 Grafana 上查到？</strong>”，应该怎么进行排查呢？今天我们以 VictoriaMetrics 为例，借助其内置的工具排查一下这个问题。当然，你可以在 Prometheus 上套用一样的排查思路，他们是高度兼容的。</p>
<h2 id="数据采集">数据采集</h2>
<p>数据采集通常问题只出现在这 3 处：应用、vmagent、它们之间的网络。</p>
<p>对应用来说，首先应该检查监控指标是否有正常暴露，可以通过访问指标的 HTTP 接口（如 <code> curl http://IP:Port/metrics</code>）查看，如果一切正常，你应该能看到如下的内容：</p>
<pre tabindex="0"><code># HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile=&quot;0&quot;} 0
go_gc_duration_seconds{quantile=&quot;0.25&quot;} 0
go_gc_duration_seconds{quantile=&quot;0.5&quot;} 0
go_gc_duration_seconds{quantile=&quot;0.75&quot;} 0
go_gc_duration_seconds{quantile=&quot;1&quot;} 0
go_gc_duration_seconds_sum 0
go_gc_duration_seconds_count 0
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 7
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
go_info{version=&quot;go1.22.5&quot;} 1
...
</code></pre><p>如果你没能看到这些监控数据，则需要对应用进行调试，通常可以参考 <a href="https://prometheus.io/docs/instrumenting/clientlibs/">Prometheus SDK 的文档</a>，或者这个简单的 <a href="https://gist.github.com/jiekun/57114fb9552b6d180bca50cc36882be9">Go 语言示例</a>。</p>
<p>好，那么应用一切正常后，我们要检查 vmagent 是否进行了数据采集。vmagent 提供了非常方便的 WebUI（如 <code>http://&lt;vmagent&gt;:8429/</code>）来协助，从 <code>target</code> 页面可以找到所有采集任务，正常情况下，它应该像这样：</p>
<p><img src="../202407-troubleshooting-tsdb/vmagent_1.gif" alt=""></p>
<p>到这一步，最常见的问题可能是：</p>
<ol>
<li>找不到对应的 Target（无论它是 Healthy 还是 Unhealthy 的）；</li>
<li>对应的 Target 处在 Unhealthy 状态。</li>
</ol>
<p>如果没有找到 Target，它可能没有被服务发现，也可能是在服务发现后被 Relabeling Rule 所丢弃，vmagent 自带的 <a href="https://docs.victoriametrics.com/vmagent/index.html#relabel-debug">Relabel Debug</a> 功能可以有效地帮助你确认问题（见下图）。</p>
<p><img src="../202407-troubleshooting-tsdb/vmagent_2.gif" alt=""></p>
<p>如果对应 Target 处在 Unhealthy，原因可能是：</p>
<ul>
<li>vmagent 与应用间的网络不通；</li>
<li>应用暴露的指标过于庞大导致访问超时。</li>
</ul>
<p>通常你可以在 vmagent 的 WebUI 上观察到具体的错误原因：</p>
<p><img src="../202407-troubleshooting-tsdb/vmagent_3.png" alt=""></p>
<p>我常常建议用户<strong>从 vmagent 所在的环境</strong>（例如 vmagent 所在的 Container / Pod / Node）手动访问抓取目标，观察网络情况是否与错误原因相匹配，如果匹配，则需要对网络问题进行（<code>iptables</code> / Kubernetes <code>Service</code> / &hellip;）调试。</p>
<h2 id="数据传输">数据传输</h2>
<p>当你没能在数据采集端找到问题时，你一定会想，数据是否真的发送到了存储端（VictoriaMetrics Single-Node / Cluster）。</p>
<p>首先考虑的是 vmagent 的 Remote Write 是否正常，我们需要借助一些 vmagent 暴露的指标来观察，以下截图来自于 VictoriaMetrics 提供的 <a href="https://grafana.com/grafana/dashboards/12683"><strong>Grafana Dashboard</strong></a>，它描述了对每个 Remote-Write Target 的数据传输情况：</p>
<p><img src="../202407-troubleshooting-tsdb/vmagent_4.png" alt=""></p>
<p>如果你还没有配置 VictoriaMetrics Grafana Dashboard，也可以尝试以下语句：</p>
<pre tabindex="0"><code>sum(rate(vmagent_remotewrite_requests_total{}[1m])) by(url, status_code) &gt; 0
sum(rate(vmagent_remotewrite_conn_bytes_written_total{}[1m]))&gt; 0
</code></pre>
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Grafana Dashboard</b>
        </div>
        <div class="admonition-content">我仍然建议在搭建好 VictoriaMetrics 后第一时间导入 Grafana Dashboard，因为它上面包含针对 VictoriaMetrics 各个组件的监控指标，可以最大程度减少定位问题所需的时间。本文后续提及的监控指标也会基于 Grafana Dashboard 进行介绍。</div>
    </aside>
<p>另一个可能出现在 vmagent 侧的问题是 Remote Write 队列堵塞，同样，可以通过观察 <code>vmagent_remotewrite_pending_data_bytes</code> 指标发现：</p>
<p><img src="../202407-troubleshooting-tsdb/vmagent_5.png" alt=""></p>
<p>这种情况会导致 vmagent 采集的数据无法及时发往 Remote Write Target，因此用户不能马上查询到他们的指标。可能原因包括：</p>
<ol>
<li>Remote Write Target 性能不足以支撑当前的数据摄取；</li>
<li>vmagent 与 Remote Write Target 之间的网络带宽不足。</li>
</ol>
<p>其中，第一种情况可以很容易通过 vmstorage 暴露的指标观察，通常 Slow Insert 应该维持在 10% 以内：</p>
<pre tabindex="0"><code>max(
    rate(vm_slow_row_inserts_total{}[1m]) 
    / rate(vm_rows_added_to_storage_total{}[1m])
)
</code></pre><p>我同样推荐直接在 Grafana Dashboard 上将它可视化，这些指标已经集成在了 VictoriaMetrics Cluster 的 <a href="https://grafana.com/grafana/dashboards/11176">Dashboard</a> 中：</p>
<p><img src="../202407-troubleshooting-tsdb/vmcluster_1.png" alt=""></p>
<p>如果没有从 VictoriaMetrics Cluster 的监控中发现太多问题，那么或许可以考虑第二种情况，也就是网络带宽是否充足了。</p>
<h2 id="数据查询">数据查询</h2>
<p>假设前面的步骤都没有发现问题，那么恭喜你，数据很有可能已经存储在了 TSDB 中。这时，数据查询不到结果通常是因为 PromQL/MetricsQL、变量等问题引起的。</p>
<p>在 VictoriaMetrics Cluster 中，首先建议从最底层的 vmselect 对 vmstorage 进行查询，并去除语句中的所有变量和函数，例如：</p>
<pre tabindex="0"><code>// 原始语句
rate(vm_slow_row_inserts_total{job=~&quot;$job_storage&quot;}[$__rate_interval]) 

// 排查时所用语句
vm_slow_row_inserts_total
</code></pre><p>这样可以确保你的 TSDB 中已经存有了这个指标，然后可以逐步将 Label 条件、变量、函数加上，检查是哪一步的查询结果不符合预期。</p>
<p>如果都没有问题，那原因应该出在更上层的查询路径中，例如 <code>Grafana -&gt; vmauth -&gt; vmselect_level_1 -&gt; ... vmselect_level_n -&gt; vmstorage</code>，这时应该逐层向上排查。</p>
<h2 id="总结">总结</h2>
<p>通过上面的介绍，相信你已经对在指标监控体系中排查问题有了一定的思路。我将这些思路总结成了一张图，希望方便你记忆。</p>
<p><img src="../202407-troubleshooting-tsdb/conclusion.png" alt=""></p>
<p>由于篇幅有限，本文能覆盖的内容不过是日常问题中的冰山一角。如果你有遇到更复杂的问题，我推荐：</p>
<ol>
<li>善用对 VictoriaMetrics 的监控，<a href="https://grafana.com/orgs/victoriametrics/dashboards"><strong>Grafana Dashboard</strong></a> 是你最好的工具；</li>
<li>来到 <a href="https://github.com/VictoriaMetrics/VictoriaMetrics"><strong>VictoriaMetrics 的社区</strong></a>进行提问，我们很乐意解答用户的问题和实现新的功能。</li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>[翻译] 聚焦 VictoriaMetrics：一家乌克兰初创企业的故事</title>
			<link>https://jiekun.dev/posts/one-to-watch-victoriametrics/</link>
			<pubDate>Sun, 23 Jun 2024 15:32:11 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/one-to-watch-victoriametrics/</guid>
			<description>Medium This blog post is originally posted by The Stack on: One to Watch: VictoriaMetrics - The story of a startup from Ukraine 这是一个初创公司追寻成功的故事，虽然不管从哪个方面看，这个故事都耳熟能详： 一群聪明人有一个填补</description>
			<content type="html"><![CDATA[<p><img src="../202406-one-to-watch-victoriametrics/cover.jpg" alt=""></p>

    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is originally posted by <strong>The Stack</strong> on:</p>
<ul>
<li><a href="https://www.thestack.technology/one-to-watch-victoriametrics-the-story-of-a-startup-from-ukraine/">One to Watch: VictoriaMetrics - The story of a startup from Ukraine</a></li>
</ul>
</div>
    </aside>
<p>这是一个初创公司追寻成功的故事，虽然不管从哪个方面看，这个故事都耳熟能详：</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 一群聪明人有一个填补市场空白的创意；</li>
<li><input checked="" disabled="" type="checkbox"> 他们成立了一家自力更生（Bootstrapped）的公司；</li>
<li><input checked="" disabled="" type="checkbox"> 他们花时间编码实现这个创意；</li>
<li><input checked="" disabled="" type="checkbox"> 他们对外宣传并展示 POC（Proof Of Concept）；</li>
<li><input checked="" disabled="" type="checkbox"> 最终出现了愿意买单的用户；</li>
<li><input checked="" disabled="" type="checkbox"> 然后他们继续努力将其发展成为一个更大的项目。</li>
</ul>
<p>但是 <a href="https://victoriametrics.com/">VictoriaMetrics</a> 有一点不同：它是一家乌克兰公司，尽管现在总部设在旧金山，它曾受到过战争的严重打击。</p>
<p>让我们先来聊下公司本身。它的客户包括阿迪达斯（Adidas）、Grammarly 和欧洲粒子物理实验室（CERN）等，并被 <a href="https://thestack.technology">The Stack</a> 收录在最新一期“值得关注公司”名单中。VictoriaMetrics 提供时序数据库和监控软件服务，它们的口号是 “We make monitoring simple &amp; reliable for everyone”。</p>
<h2 id="victoriametrics-具体是做什么的">VictoriaMetrics 具体是做什么的？</h2>
<p>这家公司聚焦的场景是：业务扩张与其带来的海量事件（Events），两者之间的脱节问题。例如，VictoriaMetrics 专注于指标（Metrics），指标代表的是系统的表现（译注：表现包括且不限于性能、业务量等），掌握这些指标，就能够构建监控面板并预测走势。但是指标数量随着业务规模增长，对计算和存储提出了实际的需求。</p>
<p><img src="../202406-one-to-watch-victoriametrics/roman.jpg" alt=""></p>
<p>“当业务增长了10%，需要追踪的指标就可能会增长 100 倍甚至 1000 倍，这时企业就会开始寻找（现有指标监控的）替代方案。” Co-Founder Roman Khavronenko 说道。</p>
<p>“他们从简单的解决方案开始，碰到扩展上的瓶颈，但要想办法满足未来的增长。VictoriaMetrics 就是专门为处理这种海量数据的场景而诞生的。”</p>
<p>该公司采用了一套很标准的商业产品开源模式：“99% 的功能对所有人免费开源，1% 的功能针对企业需求、安全性和租户管理闭源，仅向企业用户提供。企业服务的另一个重要部分是提供支持，帮助和指导客户管理指标。大公司希望保证一切正常运行，而监控是非常复杂的，他们需要专家来回答系统设计等方面的问题。”</p>
<p>VictoriaMetrics 拒绝就营收问题作出评论，但表示已经有大约 1.2 亿次下载，并且有像网站构建工具 Wix、游戏平台 Roblox 和写作插件 <a href="https://www.grammarly.com/">Grammarly</a> 这些公司的使用案例。Grammarly 表示，与之前的监控解决方案相比，它降低了 10 倍的成本。其他用户还包括 CERN（用于大型强子对撞机的 CMS 通用探测器系统）和阿迪达斯（Adidas）等公司。</p>
<h2 id="victoriametrics-与众不同的发展路线">VictoriaMetrics: 与众不同的发展路线</h2>
<p>该公司有机地进行招聘，仅依靠 10 至 20 名员工运作，并广泛使用 Contractors。与硅谷一些热门的初创公司不同，它目前没有计划寻求大规模的融资。</p>
<p>“我们对来自企业业务的收入感到满意，” Khavronenko 说道。“这足以支持我们的团队扩张、发展和开发新的解决方案。”</p>
<p>那为什么不像大多数初创公司那样迫切向前发展呢？</p>
<p>“（如果融资）你会向投资者承诺份额，这是 OK 的，但这意味着你正在失去公司的一部分。 设想一下，你已经拥有了足够的资金，那么为什么还需要额外的融资呢？我并不是说融资是件坏事，这只是一个愿不愿意的权衡。”</p>
<p>Khavronenko 强调并不是说绝对不会接受第三方资金，尽管目前还没有从外部筹集到任何资金。他的言辞中透露出，如果存在一个与众不同的提议，他可能会考虑接受第三方资金。</p>
<p>“我坚持认为，筹集资金可以带来快速发展，并在市场上获得时间上的优势，就如人们所说的先行者优势。”</p>
<p>他说道：“你可以更快地前进，但速度并不等同于质量。”</p>
<p>“在许多情况下，这会带来压力并导致错误。”</p>
<p>目前，该公司“不愿意为了投资者的 KPI 而牺牲自身”，但“如果未来有需要大量资金的机遇，这也会发生改变。一切都取决于 Oportunity、Cost 和 Cost of Opportunity”。</p>
<p>并且，只要数据的规模足够大，机遇就无处不在。这个领域非常广阔，因为“如果你拥有巨大的数据规模，就需要收集所有这些数据的指标”。数据可以来自一个应用、你的汽车，甚至是你的冰箱，关键是观察正在发生的事情，然后窥探未来。</p>
<p>因此，有很多机会扩展指标，然后对应调整市场上的操作。</p>
<p>Khavronenko 表示：“日志与指标有所不同，但仍然是可观测性的三大支柱之一。我们正在努力研究这个领域，并对今年有很大的期望。”第三个支柱是追踪，VictoriaMetrics 似乎希望在日志之后构建一个完整的可观察性堆栈，这是一个很自然的发展方向。但他们还有很多其他的事情要考虑，比如在支持 AWS 和本地部署之后，增加对 Google 和 Microsoft 云的支持。</p>
<h2 id="code-of-war">Code of war</h2>
<p>因此，VictoriaMetrics 知道如何发展并扩展其影响力，追随着无数人遵循古老的创新智慧（“build a better mousetrap and the world will beat a path to your door”）和诗歌（“a man’s reach should exceed his grasp/Or what’s a heaven for?”）。</p>
<p>但该公司拥有与大多数其他公司不同的视角，它曾经经历过一段战争。</p>
<p>Khavronenko 以他特有的轻描淡写的方式说：“它确实对我们的工作地点和生活产生了影响。”</p>
<p>他在疫情爆发前半年离开了伦敦 Cloudflare，他曾经在那里担任工程师，然后前往基辅加入了 VictoriaMetrics：“我买了一套公寓，我的儿子就在那里出生，然后战争开始了；那是一段可怕的经历，”他回忆道。“有些人留在了 VictoriaMetrics，有些人离开了。但这并没有影响公司的增长。我和其他同事在工作中找到了拯救。当你无法左右局势时，你只能去左右你能控制的事情&hellip;你可以控制自己写什么样的代码。”</p>
<p>确实，在第一次危机期间，代码量出现了激增，比过往任何时候都多。</p>
<p>如今，Khavronenko 表示他很平静，VictoriaMetrics 的员工们也安全。他提到，另一种不同类型的危机，即新冠疫情和随后的 Lockdown，燃起了在物理隔离的环境下合作工作的苗头。目前，VictoriaMetrics 是一家现代化的、成员分散在各地的初创公司，没有固定的工作时间，并通过线上渠道运作，如使用 GitHub 跟进工单等。“我们不遵循传统的 9 点到 5 点的工作时间，如果有人想多睡一会，也完全没问题，这是为了让你找到最适合的工作方式。”</p>
<p>毕竟，还有更重要的事情需要考虑，Khavronenko 表示他对欧盟、对那些向他的同胞伸出援手并帮助他们重新开始生活的国家和公司“非常感激”。</p>
<p>他目前居住在奥地利，另外两位联合创始人分别在美国和波兰。</p>
<p>“每个人想象过的成功的样子，而这种想象又人人不同。”，他思考着说，“我们在 VictoriaMetrics 中打造的实际上是人和团队：喜欢相互合作的人在一起构建一个被成千上万人使用的产品。即使这个产品消失了，那些参与构建它的人仍然会在，他们可以构建更好的产品并解决更重要的问题。对我来说，这就是成功：人们解决真实问题。”</p>
]]></content>
		</item>
		
		<item>
			<title>用 Interface 扩展 Go 应用：以 VictoriaMetrics 实现 Redis 缓存为例</title>
			<link>https://jiekun.dev/posts/extending-go-application-with-interface/</link>
			<pubDate>Tue, 21 May 2024 23:16:21 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/extending-go-application-with-interface/</guid>
			<description>Medium This blog post is also available in English: Extending Go Application with Interface: Implementing Redis Caching for VictoriaMetrics VictoriaMetrics 的缓存问题 VictoriaMetrics 是一个 Metrics 监控的解决方案，它由几个关键组件构成： vmagent 负责数据采集，并发往 vminsert； vminsert</description>
			<content type="html"><![CDATA[
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="https://medium.com/p/4fe4a3fbe7b3">Extending Go Application with Interface: Implementing Redis Caching for VictoriaMetrics</a></li>
</ul>
</div>
    </aside>
<h2 id="victoriametrics-的缓存问题">VictoriaMetrics 的缓存问题</h2>
<p>VictoriaMetrics 是一个 Metrics 监控的解决方案，它由几个关键组件构成：</p>
<ul>
<li>vmagent 负责数据采集，并发往 vminsert；</li>
<li>vminsert 负责解码数据，并根据一致性哈希发往不同 vmstorage 节点；</li>
<li>vmstorage 负责将数据写入磁盘，并提供查询功能；</li>
<li>vmselect 负责向多个 vmstorage 节点查询数据，并聚合它们的返回结果提供给用户。</li>
</ul>
<p>vmselect 处于负载均衡之后，每个 vmselect 的节点都是平等的，相同的查询请求可能会被不同的 vmselect 处理。vmselect 中存在一些缓存机制，在这种场景下，每个 vmselect 节点的缓存都有可能保存相同的内容，因此内存资源使用并不是最优的。</p>
<p>我曾经在 Issue <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/issues/5056">#5056</a> 与 @<a href="https://github.com/hagen1778">hagen1778</a>（VictoriaMetrics 的 Maintainer）聊过，大家给出了不同的方案：</p>
<ul>
<li>在 LoadBalancer 实现定制化的负载均衡策略，使得不同的查询语句由不同的 vmselect 节点负责；</li>
<li>让多个 vmselect 节点共享相同的外部缓存（例如 Redis、Memcached）；</li>
<li>既然 vmselect 节点互相知道对方的存在，那就让 vmselect 转发请求，从相邻的 vmselect 节点获取缓存（这和 Redis 中的 <code>ASK</code> 和 <code>MOVED</code> 有点像）。</li>
</ul>
<p>尽管上游尚未对解决方案达成一致，我们还是基于优化资源使用的目的为内部的 vmselect 实现了 Redis 缓存支持。我想在这里分享一下完整实现的过程，以及 Go 语言中的 Interface 是怎样减少改动量的。</p>
<h2 id="观察">观察</h2>
<p>在上一篇<a href="https://jiekun.dev/posts/vmselect-data-structures/">博客</a>，我介绍过 vmselect 中的 Rollup Result Cache，对于一个在时间范围 [a, b] 上的查询，vmselect 将其结果（Rollup Result）缓存，如果未来相同查询需要获取重叠的时间范围数据，例如 [a+5, b+5] 中 [a+5, b] 是与之前缓存重叠的，那么这部分数据就无需再次查询。</p>
<p>我们的目标是将 Rollup Result Cache 从进程内缓存变为外部缓存（Redis），所以观察 Rollup Result Cache 的调用情况：</p>
<p><img src="../202405-extending-go-application/rollup_result_cache_usage.png" alt=""></p>
<p>非常棒，看起来只有几个方法被使用到了，他们分别是：<code>Get</code>、<code>Set</code>、<code>GetBig</code>、<code>SetBig</code>、<code>Stop</code>、<code>UpdateStats</code>、<code>Save</code>。我的扩展的思路是：</p>
<ol>
<li>设计一个包含这些方法的 Interface，叫 <code>rollupResultCacheClient</code>；</li>
<li>将原有对 <code>*workingsetcache.Cache</code> 实例的调用修改为对 <code>rollupResultCacheClient</code> Interface 的调用；</li>
<li>为 <code>rollupResultCacheClient</code> Interface 提供新的实现；</li>
<li>启动时按照配置选择 <code>rollupResultCacheClient</code> 使用哪种实现。</li>
</ol>
<h2 id="开发">开发</h2>
<h3 id="定义-interface">定义 Interface</h3>
<p>定义 Interface 非常简单，只需要将使用到的方法签名收集起来：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">rollupResultCacheClient</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nf">Get</span><span class="p">(</span><span class="nx">dst</span><span class="p">,</span> <span class="nx">key</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">[]</span><span class="kt">byte</span>
    <span class="nf">Set</span><span class="p">(</span><span class="nx">key</span><span class="p">,</span> <span class="nx">value</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span>
    <span class="nf">GetBig</span><span class="p">(</span><span class="nx">dst</span><span class="p">,</span> <span class="nx">key</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">[]</span><span class="kt">byte</span>
    <span class="nf">SetBig</span><span class="p">(</span><span class="nx">key</span><span class="p">,</span> <span class="nx">value</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span>
    <span class="nf">Save</span><span class="p">(</span><span class="nx">filePath</span> <span class="kt">string</span><span class="p">)</span> <span class="kt">error</span>
    <span class="nf">Stop</span><span class="p">()</span>
    <span class="nf">UpdateStats</span><span class="p">(</span><span class="nx">fcs</span> <span class="o">*</span><span class="nx">fastcache</span><span class="p">.</span><span class="nx">Stats</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div><p>我们可以看到其中一些方法可能不是每种扩展实现都需要的，例如 <code>Save</code>、<code>Stop</code>，这没关系，我们先将它保留。</p>
<p>有了 Interface，原有对 <code>*workingsetcache.Cache</code> 的使用就可以变成对 Interface 的使用了：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">rollupResultCache</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="c1">//c *workingsetcache.Cache
</span><span class="c1"></span>    <span class="nx">c</span> <span class="nx">rollupResultCacheClient</span>
<span class="p">}</span>
</code></pre></div><p>如果担心改动有问题，我们可以在这时编译运行 vmselect，看看是否一切正常。</p>
<h3 id="添加-redis-的实现">添加 Redis 的实现</h3>
<p>接下来按照接口的定义，实现对应的 Redis 调用方法。</p>
<p>首先初始化 Redis Client：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">RedisRollupResultCacheClient</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">c</span> <span class="nx">redis</span><span class="p">.</span><span class="nx">UniversalClient</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">NewRedisClient</span><span class="p">()</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">&amp;</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">{</span>
        <span class="nx">c</span><span class="p">:</span> <span class="nx">redis</span><span class="p">.</span><span class="nf">NewUniversalClient</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">redis</span><span class="p">.</span><span class="nx">UniversalOptions</span><span class="p">{</span>
            <span class="nx">Addrs</span><span class="p">:</span> <span class="p">[]</span><span class="kt">string</span><span class="p">{</span><span class="s">&#34;127.0.0.1:6379&#34;</span><span class="p">},</span>
        <span class="p">}),</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>我们可以观察到，<code>Get/Set</code> 和 <code>GetBig/SetBig</code> 显然是在做相同的动作，只是 <code>GetBig/SetBig</code> 是针对更大（超过 64KiB）的对象。所以我们先屏蔽一定的复杂度，在 Redis 实现中只实现简单的 <code>Get/Set</code>，让 <code>GetBig/SetBig</code> 调用 <code>Get/Set</code> 即可。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="c1">// Get 使用 Redis GetEX 查询缓存, 如果命中, TTL 会被重置到 1 分钟
</span><span class="c1"></span><span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">Get</span><span class="p">(</span><span class="nx">dst</span><span class="p">,</span> <span class="nx">key</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">[]</span><span class="kt">byte</span> <span class="p">{</span>
    <span class="nx">dst</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">rc</span><span class="p">.</span><span class="nx">c</span><span class="p">.</span><span class="nf">GetEx</span><span class="p">(</span><span class="nx">context</span><span class="p">.</span><span class="nf">TODO</span><span class="p">(),</span> <span class="nb">string</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Minute</span><span class="p">).</span><span class="nf">Bytes</span><span class="p">()</span>
    <span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="o">&amp;&amp;</span> <span class="p">!</span><span class="nx">errors</span><span class="p">.</span><span class="nf">Is</span><span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">redis</span><span class="p">.</span><span class="nx">Nil</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">logger</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;get rollup result cache from redis failed: %v&#34;</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="nx">dst</span>
<span class="p">}</span>

<span class="c1">// Set 使用 Redis Set 创建/覆盖缓存, 并设置 1 分钟 TTL 时间
</span><span class="c1"></span><span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">Set</span><span class="p">(</span><span class="nx">key</span><span class="p">,</span> <span class="nx">value</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">rc</span><span class="p">.</span><span class="nx">c</span><span class="p">.</span><span class="nf">Set</span><span class="p">(</span><span class="nx">context</span><span class="p">.</span><span class="nf">TODO</span><span class="p">(),</span> <span class="nb">string</span><span class="p">(</span><span class="nx">key</span><span class="p">),</span> <span class="nx">value</span><span class="p">,</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Minute</span><span class="p">).</span><span class="nf">Err</span><span class="p">();</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
        <span class="nx">logger</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;set rollup result cache to redis failed: %v&#34;</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="k">return</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">GetBig</span><span class="p">(</span><span class="nx">dst</span><span class="p">,</span> <span class="nx">key</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">[]</span><span class="kt">byte</span> <span class="p">{</span>
    <span class="k">return</span> <span class="nx">rc</span><span class="p">.</span><span class="nf">Get</span><span class="p">(</span><span class="nx">dst</span><span class="p">,</span> <span class="nx">key</span><span class="p">)</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">SetBig</span><span class="p">(</span><span class="nx">key</span><span class="p">,</span> <span class="nx">value</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">rc</span><span class="p">.</span><span class="nf">Set</span><span class="p">(</span><span class="nx">key</span><span class="p">,</span> <span class="nx">value</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1">// 下面的方法先不关注
</span><span class="c1"></span><span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">Save</span><span class="p">(</span><span class="nx">filePath</span> <span class="kt">string</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span> <span class="k">return</span> <span class="kc">nil</span> <span class="p">}</span>
<span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">Stop</span><span class="p">()</span> <span class="p">{}</span>
<span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">UpdateStats</span><span class="p">(</span><span class="nx">fcs</span> <span class="o">*</span><span class="nx">fastcache</span><span class="p">.</span><span class="nx">Stats</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="p">}</span>
</code></pre></div><p>可以注意到，这些实现非常的粗糙，例如使用硬编码的 Redis 地址、<code>Set</code> 超时时间等。没关系，这些都会在后续进行整理。</p>
<p>现在，我们需要验证一下这些简易的实现是否可行。修改初始化内存缓存的代码，让它直接变成使用 Redis Client：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go">    <span class="nx">rollupResultCacheV</span> <span class="p">=</span> <span class="o">&amp;</span><span class="nx">rollupResultCache</span><span class="p">{</span>
        <span class="c1">// c: c,
</span><span class="c1"></span>        <span class="nx">c</span><span class="p">:</span> <span class="nx">rediscache</span><span class="p">.</span><span class="nf">NewRedisClient</span><span class="p">(),</span>
    <span class="p">}</span>
</code></pre></div><p>然后编译运行 vmselect，看看是否一切功能都完好：</p>
<ul>
<li>运行：<code>go run ./app/vmselect/ --storageNode=10.**.**.***:8401</code>；</li>
<li>访问 <code>http://127.0.0.1:8481/select/0/vmui</code>，打开 Trace query 并尝试重复查询一个语句；</li>
<li>访问 Redis 查看是否有缓存。</li>
</ul>
<p><img src="../202405-extending-go-application/trace_query.png" alt=""></p>
<p>可以看到第二次查询时耗时从 4.384 秒降低到了 1.706 秒，并且 Redis 中也出现了一些 Item。很好，看起来一切都是正常的。</p>
<h3 id="整理代码">整理代码</h3>
<p>前文的修改是为了快速实现核心功能，而很多旁路功能还要进行完善：</p>
<ul>
<li>用户配置、Flags、初始化逻辑、优雅退出逻辑；</li>
<li>Rollup Result Cache 监控指标。</li>
</ul>
<p>我们先来为新的 Cache 设计对应参数。参考 Thanos 的参数命名，我们为 vmselect 提供两个新的参数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go">    <span class="nx">cacheType</span>      <span class="p">=</span> <span class="nx">flag</span><span class="p">.</span><span class="nf">String</span><span class="p">(</span><span class="s">&#34;cacheType&#34;</span><span class="p">,</span> <span class="s">&#34;in-memory&#34;</span><span class="p">,</span> <span class="s">&#34;Cache type for rollup result. Available options: in-memory(default), redis.&#34;</span><span class="p">)</span>
    <span class="nx">cacheRedisAddr</span> <span class="p">=</span> <span class="nx">flag</span><span class="p">.</span><span class="nf">String</span><span class="p">(</span><span class="s">&#34;cacheRedisAddr&#34;</span><span class="p">,</span> <span class="s">&#34;&#34;</span><span class="p">,</span> <span class="s">&#34;Address for redis cache. It&#39;s only available when `cacheType` is set to `redis`. Usage: -cacheRedisAddr=127.0.0.1:6379&#34;</span><span class="p">)</span>
    <span class="nx">cacheRedisTTL</span>  <span class="p">=</span> <span class="nx">flag</span><span class="p">.</span><span class="nf">Duration</span><span class="p">(</span><span class="s">&#34;cacheRedisTTL&#34;</span><span class="p">,</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Minute</span><span class="p">,</span> <span class="s">&#34;TTL for redis cache items. It&#39;s only available when `cacheType` is set to `redis`. Usage: -cacheRedisTTL=1m (default)&#34;</span><span class="p">)</span>

</code></pre></div><p>同样地，在 <code>InitRollupResultCache</code> 和 <code>StopRollupResultCache</code> 方法中，接收这些参数，并且 switch-case 处理：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">InitRollupResultCache</span><span class="p">(</span><span class="nx">cacheType</span><span class="p">,</span> <span class="nx">cachePath</span><span class="p">,</span> <span class="nx">cacheRedisAddr</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">cacheRedisTTL</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Duration</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="nx">c</span> <span class="nx">rollupResultCacheClient</span>

    <span class="k">switch</span> <span class="nx">cacheType</span> <span class="p">{</span>
    <span class="k">case</span> <span class="s">&#34;in-memory&#34;</span><span class="p">:</span>
        <span class="c1">// 将原有的初始化代码移到这里
</span><span class="c1"></span>        <span class="o">...</span> 
    <span class="k">case</span> <span class="s">&#34;redis&#34;</span><span class="p">:</span>
        <span class="nx">c</span> <span class="p">=</span> <span class="nx">rediscache</span><span class="p">.</span><span class="nf">NewRedisClient</span><span class="p">(</span><span class="nx">cacheRedisAddr</span><span class="p">,</span> <span class="nx">cacheRedisTTL</span><span class="p">)</span> <span class="c1">// NewRedisClient 也修改为传入地址参数
</span><span class="c1"></span>    <span class="p">}</span>

    <span class="nx">rollupResultCacheV</span> <span class="p">=</span> <span class="o">&amp;</span><span class="nx">rollupResultCache</span><span class="p">{</span>
        <span class="nx">c</span><span class="p">:</span> <span class="nx">c</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">StopRollupResultCache</span><span class="p">(</span><span class="nx">cacheType</span> <span class="kt">string</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">switch</span> <span class="nx">cacheType</span> <span class="p">{</span>
    <span class="k">case</span> <span class="s">&#34;in-memory&#34;</span><span class="p">:</span>
        <span class="c1">// 将原有的初始化代码移到这里
</span><span class="c1"></span>        <span class="o">...</span>
    <span class="k">case</span> <span class="s">&#34;redis&#34;</span><span class="p">:</span>
        <span class="c1">// 与 in-memory Cache 不同, Redis 的 Stop 方法实际上不进行任何操作.
</span><span class="c1"></span>        <span class="nx">rollupResultCacheV</span><span class="p">.</span><span class="nx">c</span><span class="p">.</span><span class="nf">Stop</span><span class="p">()</span>
        <span class="nx">rollupResultCacheV</span><span class="p">.</span><span class="nx">c</span> <span class="p">=</span> <span class="kc">nil</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>现在代码看起来整洁多了。</p>
<p>那么接下来处理缓存相关的指标。Rollup Result Cache 原有的监控指标主要由 <code>fastcache.Stats</code> 提供，包括 Item 数量、体积、缓存命中率等。对于 Redis 实例，通常认为使用者会有额外的监控，因此不需要提供资源使用情况的指标，仅需要记录缓存命中率。</p>
<p>首先我们给 <code>RedisRollupResultCacheClient</code> 添加统计字段，并且在 <code>Get</code> 方法中记录它们：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">RedisRollupResultCacheClient</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">c</span>   <span class="nx">redis</span><span class="p">.</span><span class="nx">UniversalClient</span>
    <span class="nx">ttl</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Duration</span>

    <span class="c1">// 统计字段
</span><span class="c1"></span>    <span class="nx">calls</span>  <span class="kt">uint64</span>
    <span class="nx">misses</span> <span class="kt">uint64</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">Get</span><span class="p">(</span><span class="nx">dst</span><span class="p">,</span> <span class="nx">key</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">[]</span><span class="kt">byte</span> <span class="p">{</span>
    <span class="nx">rc</span><span class="p">.</span><span class="nx">calls</span><span class="o">++</span>  <span class="c1">// 记录调用次数
</span><span class="c1"></span>    
    <span class="o">...</span>
    <span class="k">if</span> <span class="nx">errors</span><span class="p">.</span><span class="nf">Is</span><span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">redis</span><span class="p">.</span><span class="nx">Nil</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">rc</span><span class="p">.</span><span class="nx">misses</span><span class="o">++</span> <span class="c1">// 如果没有读取到结果，记录未命中次数
</span><span class="c1"></span>    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
        <span class="o">...</span>
    <span class="p">}</span>

    <span class="o">...</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">GetCalls</span><span class="p">()</span> <span class="kt">uint64</span>  <span class="p">{</span> <span class="k">return</span> <span class="nx">rc</span><span class="p">.</span><span class="nx">calls</span> <span class="p">}</span>
<span class="kd">func</span> <span class="p">(</span><span class="nx">rc</span> <span class="o">*</span><span class="nx">RedisRollupResultCacheClient</span><span class="p">)</span> <span class="nf">GetMisses</span><span class="p">()</span> <span class="kt">uint64</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">rc</span><span class="p">.</span><span class="nx">misses</span> <span class="p">}</span>
</code></pre></div><p>最后参考指标暴露的方法，在 <code>InitRollupResultCache</code> 中修改：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">InitRollupResultCache</span><span class="p">(</span><span class="nx">cacheType</span><span class="p">,</span> <span class="nx">cachePath</span><span class="p">,</span> <span class="nx">cacheRedisAddr</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">cacheRedisTTL</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Duration</span><span class="p">)</span> <span class="p">{</span>
    <span class="o">...</span>

    <span class="k">switch</span> <span class="nx">cacheType</span> <span class="p">{</span>
    <span class="k">case</span> <span class="s">&#34;in-memory&#34;</span><span class="p">:</span>
        <span class="o">...</span>
    <span class="k">case</span> <span class="s">&#34;redis&#34;</span><span class="p">:</span>
        <span class="o">...</span>
        <span class="nx">metrics</span><span class="p">.</span><span class="nf">GetOrCreateGauge</span><span class="p">(</span><span class="s">`vm_cache_requests_total{type=&#34;promql/rollupResult&#34;}`</span><span class="p">,</span> <span class="kd">func</span><span class="p">()</span> <span class="kt">float64</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nb">float64</span><span class="p">(</span><span class="nx">redisClient</span><span class="p">.</span><span class="nf">GetCalls</span><span class="p">())</span>
        <span class="p">})</span>
        <span class="nx">metrics</span><span class="p">.</span><span class="nf">GetOrCreateGauge</span><span class="p">(</span><span class="s">`vm_cache_misses_total{type=&#34;promql/rollupResult&#34;}`</span><span class="p">,</span> <span class="kd">func</span><span class="p">()</span> <span class="kt">float64</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nb">float64</span><span class="p">(</span><span class="nx">redisClient</span><span class="p">.</span><span class="nf">GetMisses</span><span class="p">())</span>
        <span class="p">})</span>
        <span class="o">...</span>
    <span class="p">}</span>

    <span class="o">...</span>
<span class="p">}</span>
</code></pre></div><h2 id="效果对比">效果对比</h2>
<p>现在让我们来看看最终效果，用户需要怎样使用不同的缓存。</p>
<p>In-memory 缓存依然与原来的使用方式一致：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># 使用内存缓存, 退出时缓存数据不持久化</span>
./vmselect -storageNode<span class="o">=</span>127.0.0.1:8401

<span class="c1"># 使用内存缓存, 指定退出时缓存数据的持久化路径</span>
./vmselect -storageNode<span class="o">=</span>127.0.0.1:8401 -cacheDataPath<span class="o">=</span>/my/tmp/dir

<span class="c1"># (新) 使用内存缓存, 指定退出时缓存数据的持久化路径</span>
./vmselect -storageNode<span class="o">=</span>127.0.0.1:8401 -cacheType<span class="o">=</span>in-memory -cacheDataPath<span class="o">=</span>/my/tmp/dir
</code></pre></div><p>Redis 缓存与参数使用：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># (新) 使用外部缓存</span>
./vmselect -storageNode<span class="o">=</span>127.0.0.1:8401 -cacheType<span class="o">=</span>redis -cacheRedisAddr<span class="o">=</span>127.0.0.1:6379

<span class="c1"># (新) 使用外部缓存, 指定 Item 的过期时间</span>
./vmselect -storageNode<span class="o">=</span>127.0.0.1:8401 -cacheType<span class="o">=</span>redis -cacheRedisAddr<span class="o">=</span>127.0.0.1:6379 -cacheRedisTTL<span class="o">=</span>5m
</code></pre></div><p>在进行一些查询后，可以从 vmselect 暴露的指标观察缓存使用情况：
<img src="../202405-extending-go-application/metrics.png" alt=""></p>
<h2 id="总结">总结</h2>
<p>这篇博客以最近为公司内的 VictoriaMetrics 开发缓存功能的实践为基础，介绍了 Go Interface 在抽象、扩展上的基础用法。你可以通过以下链接查看完整代码与改动部分：</p>
<ul>
<li><a href="https://github.com/jiekun/VictoriaMetrics/tree/feature/vmselect-ext-cache">feature/vmselect-ext-cache</a> 分支；</li>
<li><a href="https://github.com/jiekun/VictoriaMetrics/compare/cluster...feature/vmselect-ext-cache">diff</a> 代码。</li>
</ul>

    <aside class="admonition tip">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg></div><b>什么时候能合并？</b>
        </div>
        <div class="admonition-content"><p>这个功能是否可以合并到 VictoriaMetrics 呢？暂时还不行。</p>
<p>首先，代码中有几个错误——既有特意留下的，也有出于时间原因没有深入完善的。如果读者有兴趣的话可以尝试通过 Code Review 找出来。以下是对应的提示：</p>
<ul>
<li>在记录缓存命中率时，我们使用到了 <code>uint64</code> 进行自增，这种数据类型是线程安全的吗？</li>
<li><code>rollupResultCacheClient</code> 中 <code>Save</code>、<code>UpdateStats</code> 方法是所有 Cache 都需要的吗？</li>
<li><code>InitRollupResultCache</code> 需要接收许多参数，如果未来有更多类型的 Cache，或者 Redis Cache 需要更多控制参数，应该怎样设计得更优雅？</li>
</ul>
<p>其次，当前的代码分支中缺少了 Pull Request 必须具备的内容：</p>
<ul>
<li>文档；</li>
<li>单元测试。</li>
</ul>
<p>最后，如<a href="#victoriametrics-%E7%9A%84%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98">第一章</a>所说，上游还在针对以何种方式提供更好的缓存进行讨论。</p>
</div>
    </aside>
<p>VictoriaMetrics 的社区非常活跃，对 Issue 的答复和处理也比较及时，希望这篇博客可以鼓励更多的 <a href="https://go.dev/blog/gopher">Gopher</a> 探索和参与到 VictoriaMetrics 社区中。</p>
]]></content>
		</item>
		
		<item>
			<title>VictoriaMetrics 中的持久化数据结构 (Part 2): vmselect</title>
			<link>https://jiekun.dev/posts/vmselect-data-structures/</link>
			<pubDate>Wed, 15 May 2024 23:37:23 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/vmselect-data-structures/</guid>
			<description>Medium This blog post is also available in English: Persistent Data Structures in VictoriaMetrics (Part 2): vmselect Series Introduction VictoriaMetrics 是一个开源的高性能时序数据库，作为 Prometheus 及其长期存储方案（如：Thanos、Cortex）的平替，有很多</description>
			<content type="html"><![CDATA[
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="https://medium.com/@jiekun/persistent-data-structures-in-victoriametrics-part-2-vmselect-9e3de39a4d20">Persistent Data Structures in VictoriaMetrics (Part 2): vmselect</a></li>
</ul>
</div>
    </aside>

    <aside class="admonition info">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-info"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg></div><b>Series Introduction</b>
        </div>
        <div class="admonition-content"><p>VictoriaMetrics 是一个开源的高性能时序数据库，作为 Prometheus 及其长期存储方案（如：Thanos、Cortex）的平替，有很多企业已经将它大规模部署在生产环境。尽管 VictoriaMetrics 有非常详细的使用文档和示例，关于它的数据是如何存在于磁盘上的讨论却非常少。</p>
<p>鉴于社区中的活跃的成员越来越多，一份介于使用说明和源代码之间的文档可以更好地帮助他们过渡到贡献者。</p>
<p>这个系列旨在让读者了解 VictoriaMetrics 的磁盘数据是如何组织的。读者不需要具备任何 Go 语言的知识，但是最好对 VictoriaMetrics 的组件有简单的了解。</p>
</div>
    </aside>
<h2 id="vmselect-简介">vmselect 简介</h2>
<p><strong>vmselect</strong> 是 VictoriaMetrics 的查询组件，通常位于 Load Balancer 后面，负责向多个 vmstorage 节点发送查询请求，并将数据聚合、缓存、返回给用户。</p>
<p><img src="../202405-vm-series/vmselect.png" alt=""></p>
<h2 id="rollup-result-cache">Rollup Result Cache</h2>
<p>在一次时序数据库的查询中，通常会涉及许多时间序列和大量数据点，这些数据点必须先聚合才能展示。<strong>Rollup</strong> 通常指的是一个按照时间维度聚合好的时间序列，形成一个 Rollup 除了数据点，还需要 <strong>Interval</strong> 和 <strong>Aggregation 方法</strong>，例如 <code>sum</code>、<code>max</code>。</p>
<p>在 vmselect 中，Rollup Result 会被缓存到 RollupResultCache 中。以查询时间范围 [a, b] 的 PromQL 为例，如果在 [a+5, b+5] 的时间范围上再次查询相同的 PromQL：</p>
<ol>
<li>RollupResultCache 可以用于填充部分时间范围（[a+5, b]）上的结果；</li>
<li>时间不重叠的部分（[b+1, b+5]）继续向 vmstorage 查询。</li>
</ol>
<p>vmselect 会收集、聚合多个 vmstorage 返回的结果，并将结果与 RollupResultCache 进行合并，最终形成新的 Rollup Result 返回，并更新 RollupResultCache。</p>
<p><img src="../202405-vm-series/rollup_result_cache.png" alt=""></p>
<p>虽然文章的标题是“持久化数据结构”，但是我们还是会简单介绍部分内存中的数据结构。RollUpCacheResult 通常存在于<strong>内存</strong>中，它的特点主要为：</p>
<ol>
<li>由 2 个 Key-Value 数据结构组成，分别代表热数据和冷数据；</li>
<li>冷数据会定期（过去 60 秒内访问概率低于 10%）被清空，热数据定期降级为冷数据；</li>
<li>冷数据中被查询到的内容可以回到热数据中。</li>
</ol>
<h2 id="fastcache">FastCache</h2>
<p>如果 vmselect 需要退出，RollupCacheResult 中的<strong>热数据</strong>会被持久化到磁盘中。代表热数据的 Key-Value 数据结构名叫 <strong>FastCache</strong>，本节介绍它的持久化。</p>
<p>FastCache 由多个 Bucket 组成，每个 Bucket 由一个 Ring Buffer 和一个 Hash Index 组成。Ring Buffer 负责存储 Key-Value Pairs，而 Hash Index 则记录了 Key 对应的数据在 Ring Buffer 中的位置，作为索引。</p>
<p><img src="../202405-vm-series/fast_cache.png" alt=""></p>
<p>在持久化时：</p>
<ol>
<li>所有的 Ring Buffer 通过 <strong>Snappy</strong> 压缩后写入 <code>data.n.bin</code> 文件；</li>
<li>Buckets[0] 的 Ring Buffer 长度（也代表所有 Bucket 的 Ring Buffer 长度）存入 <code>metadata.bin</code> 文件，用于在下次启动时验证持久化数据是否完整。</li>
</ol>
<p>最终持久化到磁盘的文件目录格式如下：</p>
<pre tabindex="0"><code>./rollupResult
├── data.0.bin
├── data.1.bin
├── data.2.bin
├── data.3.bin
└── metadata.bin
</code></pre>
    <aside class="admonition Tip">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" class="feather feather-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></div><b>加餐</b>
        </div>
        <div class="admonition-content"><p>在（非缓存的）数据查询的过程中，由于需要向多个 vmstorage 节点获取大量数据并合并，这些数据会以 tmpBlocksFile 的结构存放在磁盘。tmpBlocksFile 拥有一个根据内存大小设置的 Buffer <code>[]byte</code>，以及指向临时文件的 <code>*os.File</code>。获取到的数据首先写入 Buffer 中，并不断地持久化到临时文件。</p>
<pre tabindex="0"><code>./tmp
└──searchResults
   └──2400906475
</code></pre><p>这些临时文件在收集完后将会被并发地读取、合并成向 vmstorage 查询的 Rollup Result，最终与 RollupResultCache 的数据再次合并形成返回给用户的 Rollup Result。</p>
</div>
    </aside>
<h2 id="further-reading">Further Reading</h2>
<p>你可以在以下位置找到关键的代码：</p>
<ul>
<li>Search RollupResultCache: <a href="https://bit.ly/3ylPXiC">https://bit.ly/3ylPXiC</a></li>
<li>Query vmstorage for missing results: <a href="https://bit.ly/3wDZUrb">https://bit.ly/3wDZUrb</a></li>
<li>Merge cached result and vmstorage results: <a href="https://bit.ly/4becexo">https://bit.ly/4becexo</a></li>
<li>Save RollupResultCache to disk: <a href="https://bit.ly/4bk1PQX">https://bit.ly/4bk1PQX</a></li>
<li>Write vmstorage temporary data to disk: <a href="https://bit.ly/3WHnHB1">https://bit.ly/3WHnHB1</a></li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>VictoriaMetrics 中的持久化数据结构 (Part 1): vmagent</title>
			<link>https://jiekun.dev/posts/vmagent-data-structures/</link>
			<pubDate>Fri, 03 May 2024 11:33:36 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/vmagent-data-structures/</guid>
			<description>Medium This blog post is also available in English: Persistent Data Structures in VictoriaMetrics (Part 1): vmagent Series Introduction VictoriaMetrics 是一个开源的高性能时序数据库，作为 Prometheus 及其长期存储方案（如：Thanos、Cortex）的平替，有很多</description>
			<content type="html"><![CDATA[
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="https://medium.com/@jiekun/persistent-data-structures-in-victoriametrics-part-1-vmagent-2e9c7681a6f0">Persistent Data Structures in VictoriaMetrics (Part 1): vmagent</a></li>
</ul>
</div>
    </aside>

    <aside class="admonition info">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-info"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg></div><b>Series Introduction</b>
        </div>
        <div class="admonition-content"><p>VictoriaMetrics 是一个开源的高性能时序数据库，作为 Prometheus 及其长期存储方案（如：Thanos、Cortex）的平替，有很多企业已经将它大规模部署在生产环境。尽管 VictoriaMetrics 有非常详细的使用文档和示例，关于它的数据是如何存在于磁盘上的讨论却非常少。</p>
<p>鉴于社区中的活跃的成员越来越多，一份介于使用说明和源代码之间的文档可以更好地帮助他们过渡到贡献者。</p>
<p>这个系列旨在让读者了解 VictoriaMetrics 的磁盘数据是如何组织的。读者不需要具备任何 Go 语言的知识，但是最好对 VictoriaMetrics 的组件有简单的了解。</p>
</div>
    </aside>
<h2 id="vmagnet-简介">vmagnet 简介</h2>
<p><strong>vmagent</strong> 是一个轻量的 Agent，用于像 Prometheus 一样<strong>采集</strong>应用暴露的指标，或者作为 Receiver <strong>接收</strong> Remote-Write Compatible、InfluxDB line 协议的数据推送。</p>
<p>vmagent 可以对数据进行加工，例如 Relabeling、Sorting。最后将数据 remote write 至 VictoriaMetrics 或其他协议兼容的目标。</p>
<p><img src="../202405-vm-series/vmagent.png" alt=""></p>
<h2 id="fastqueue">FastQueue</h2>
<p>现在让我们关注 vmagent 内部，采集到的数据首先会在内存中不断追加给各个 Remote-Write 的对象（图中未画出）。等到积累了一定的数据量或者等待一定的时间间隔（默认 1 秒）后，它们会被 Flush 到一个 Remote-Write 对象持有的 FastQueue。每个 Remote-Write 对象还会持有多个 worker，负责消费 FastQueue 中的数据，推送至 Remote-Write 的地址。</p>
<p><img src="../202405-vm-series/fast_queue.png" alt=""></p>
<p>FastQueue 在理想情况下通过 <code>channel</code> 数据结构将数据传递给 worker（这是 Go 语言中很典型的协程间通信），这是完全基于内存的。但 <code>channel</code> 能够缓冲的数据是有限的，如果网络异常，或者 Remote-Write 的目标没有足够能力处理数据，<code>channel</code> 很快就会被填满。</p>
<p>这时候 FastQueue 会选择将数据写入磁盘进行缓冲。</p>
<p><img src="../202405-vm-series/fast_queue_2.png" alt=""></p>
<p>基于这些介绍，我们可以很容易总结出以下要点：</p>
<ul>
<li>一个 Remote-Write 配置对应一个 Remote-Write 对象；</li>
<li>一个 Remote-Write 对象持有 1 个 FastQueue 和多个 workers；</li>
<li>一个 FastQueue 对应一个 <code>channel</code> 和一个磁盘文件（目录）。</li>
</ul>
<h2 id="on-disk-data-structure">On-Disk Data Structure</h2>
<p>如果你在本地运行过 vmagent，你可以很容易查看到它为每个 Remote-Write 生成的文件目录。例如：</p>
<pre tabindex="0"><code>./vmagent-remotewrite-data
└── persistent-queue
    ├── 1_E3C1E1E1733E59E4
    │   ├── 0000000000000000
    │   ├── flock.lock
    │   └── metainfo.json
    └── 2_740390E5C841CCAC
        ├── 0000000000000000
        ├── flock.lock
        └── metainfo.json
</code></pre><p>vmagent 根据 Remote-Write 的<strong>配置顺序</strong>以及 URL 生成目录名：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go">	<span class="o">...</span>
	<span class="c1">// Hash value of `URL`. e.g.: E3C1E1E1733E59E4
</span><span class="c1"></span>	<span class="nx">h</span> <span class="o">:=</span> <span class="nx">xxhash</span><span class="p">.</span><span class="nf">Sum64</span><span class="p">([]</span><span class="nb">byte</span><span class="p">(</span><span class="nx">URL</span><span class="p">.</span><span class="nf">String</span><span class="p">()))</span>

	<span class="c1">// Index + Hash value. e.g.: 1_E3C1E1E1733E59E4
</span><span class="c1"></span>	<span class="nx">queuePath</span> <span class="o">:=</span> <span class="nx">filepath</span><span class="p">.</span><span class="nf">Join</span><span class="p">(</span><span class="s">&#34;./vmagent-remotewrite-data&#34;</span><span class="p">,</span> <span class="s">&#34;persistent-queue&#34;</span><span class="p">,</span> <span class="nx">fmt</span><span class="p">.</span><span class="nf">Sprintf</span><span class="p">(</span><span class="s">&#34;%d_%016X&#34;</span><span class="p">,</span> <span class="nx">argIdx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nx">h</span><span class="p">))</span>
	<span class="o">...</span>
</code></pre></div><p>如果在磁盘上有待消费的数据，且 vmagent 意外退出，那么它在重启时仍然能够读取相同的目录继续进行消费。</p>

    <aside class="admonition danger">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-alert-triangle"><path d="M10.29 3.86L1.82 18a2 2 0 0 0 1.71 3h16.94a2 2 0 0 0 1.71-3L13.71 3.86a2 2 0 0 0-3.42 0z"></path><line x1="12" y1="9" x2="12" y2="13"></line><line x1="12" y1="17" x2="12.01" y2="17"></line></svg></div><b>思考题 1</b>
        </div>
        <div class="admonition-content"><ol>
<li>如果意外退出后，修改了其中一个 Remote-Write 的 URL 再启动，会发生什么？</li>
<li>问题 1 如果将 “修改” 换成 “移除” 会有什么不同的结果？</li>
<li>问题 2 中 “移除” 第一个 Remote-Write 配置和最后一个 Remote-Write 配置会有差别吗？</li>
</ol>
</div>
    </aside>
<p>每个 Remote-Write 的目录下有 3 个文件，分别是数据文件（<code>0000000000000000</code>）、元数据文件（<code>metainfo.json</code>）和锁（<code>flock.lock</code>）。</p>
<p>其中，元数据文件记录了数据文件的读写偏移量：</p>
<pre tabindex="0"><code>{&quot;Name&quot;:&quot;2:secret-url&quot;,&quot;ReaderOffset&quot;:0,&quot;WriterOffset&quot;:0}
</code></pre><p>而数据文件中的存放了等待 remote write 的 <code>[]byte</code>。要注意的是，他们并不是 Time-Series 数据经过序列化后得到的 <code>[]byte</code>。</p>
<p>vmagent 支持 Prometheus 使用的 Snappy 压缩算法，也支持 zstd 压缩算法。vmagent 在<strong>启动时</strong>会根据启动参数或自动协商确认每个 Remote-Write 需要使用的压缩算法。Remote-Write 数据进入 FastQueue 前，需要：</p>
<ol>
<li>按照 Remote-Write Protocol 序列化成二进制 <code>[]byte</code>；</li>
<li>使用 Snappy 或 zstd 算法将其压缩成新的 <code>[]byte</code></li>
</ol>
<p><img src="../202405-vm-series/data_compression.png" alt=""></p>
<p>最后才会被发送出去或写入本地数据文件。</p>

    <aside class="admonition danger">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-alert-triangle"><path d="M10.29 3.86L1.82 18a2 2 0 0 0 1.71 3h16.94a2 2 0 0 0 1.71-3L13.71 3.86a2 2 0 0 0-3.42 0z"></path><line x1="12" y1="9" x2="12" y2="13"></line><line x1="12" y1="17" x2="12.01" y2="17"></line></svg></div><b>思考题 2</b>
        </div>
        <div class="admonition-content"><p>假设 Remote-Write 目标不支持 zstd 压缩算法，vmagent 会发送 Snappy 算法压缩后的数据。如果此时：</p>
<ol>
<li>Remote-Write 目标停机 10 分钟进行升级，vmagent 将数据缓冲至本地文件；</li>
<li>Remote-Write 目标升级完成，支持新的 zstd 压缩算法；</li>
</ol>
<p>那么现在：</p>
<ol>
<li>Remote-Write 目标会收到什么算法压缩的数据？</li>
<li>假设 Remote-Write 目标启动后 vmagent 也进行重启，Remote-Write 目标会收到什么算法压缩的数据？</li>
</ol>
</div>
    </aside>
<h2 id="further-reading">Further Reading</h2>
<p>你可以在以下位置找到关键的代码：</p>
<ul>
<li>Presistente queue folder path generation: <a href="https://bit.ly/3y2FxEx">https://bit.ly/3y2FxEx</a></li>
<li>Data compression before writing to FastQueue: <a href="https://bit.ly/4dlUeCN">https://bit.ly/4dlUeCN</a></li>
<li>FastQueue fast path &amp; slow path: <a href="https://bit.ly/4aYkD7X">https://bit.ly/4aYkD7X</a></li>
<li>Remote-Write worker: <a href="https://bit.ly/3JLrfL6">https://bit.ly/3JLrfL6</a></li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>GOPS 见闻：虎牙的监控指标管理经验与延伸思考</title>
			<link>https://jiekun.dev/posts/playing-with-high-cardinality/</link>
			<pubDate>Sat, 27 Apr 2024 19:43:32 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/playing-with-high-cardinality/</guid>
			<description>Medium This blog post is also available in English: Rethinking Huya’s Journey: Leveraging OpenTelemetry and VictoriaMetrics for Monitoring 上周在深圳参加了 GOPS 大会，来自虎牙的同学分享了他们在监控指标标准化和管理方面的实践，核心要点在于</description>
			<content type="html"><![CDATA[
    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="https://medium.com/@jiekun/exploring-huyas-journey-leveraging-opentelemetry-and-victoriametrics-for-monitoring-1a87ba2f6e64">Rethinking Huya’s Journey: Leveraging OpenTelemetry and VictoriaMetrics for Monitoring</a></li>
</ul>
</div>
    </aside>
<p>上周在深圳参加了 GOPS 大会，来自虎牙的同学分享了他们在监控指标标准化和管理方面的实践，核心要点在于：</p>
<ul>
<li>用 OpenTelemetry 完成指标的标准化；</li>
<li>依靠 VictoriaMetrics 预聚合和存储指标，提供高性能的查询。</li>
</ul>
<p>其中一些细节因为时间原因没有覆盖到，所以周末重新思考了一下，整理出本文。</p>
<h2 id="标准化">标准化</h2>
<p>可观测性领域在过往几年内变化很大，涌现了很多新的技术，所以变更技术栈以解决新的问题并不常见。在监控指标管理上，虎牙也存在多套方案，老方案通常都会有这样的毛病：</p>
<ol>
<li>不适应现有的需求：业务量与基础设施都与设计之初有巨大差异（e.g. 从虚拟机到容器化）；</li>
<li>指标缺乏管控：业务快速扩张时追求“易用”、“好用”，不设立使用门槛和要求；平稳期希望控制成本，但规则难以推动。</li>
</ol>
<p>解决这些问题的方法有很多，其中最简单粗暴的是：再重新做一套系统。</p>
<p>如果想在 2024 年打造一套可观测性体系，OpenTelemetry 或许是个不错的选择。OpenTelemetry 诞生的愿景是解决可观测性数据标准化的问题，减少用户需要了解的 API，摆脱对单一 Vendor 的依赖。</p>
<p><img src="../202404-huya/standardization.jpg" alt=""></p>
<p>虎牙在指标标准化上的实践，或许也是很多企业尝试过的：</p>
<ol>
<li>确定以 OpenTelemetry 作为指导标准；</li>
<li>指标 SDK 基于 OpenTelemetry SDK 进行封装；
<ul>
<li>最小化开发量，能覆盖大部分的编程语言；</li>
</ul>
</li>
<li>使用 OpenTelemetry Collector 兼容历史格式的数据上报，依照标准转换；
<ul>
<li>高度模块化，实现 Receiver 难度很低；</li>
</ul>
</li>
<li>使用 OpenTelemetry Collector 导出给指标存储系统（Prometheus，VictoriaMetrics 或者 Vendor）。</li>
</ol>
<h2 id="高基数问题">高基数问题</h2>
<p>数据标准化之后，就是如何优化指标查询的用户体验，虎牙给出的方案是预聚合 + 查询代理。</p>
<p>因为指标 Label 中经常存在一些不可枚举的字段（尽管我们总是跟开发强调不要这样做），例如 <code>ip</code>、<code>user_id</code>、<code>email</code>、<code>uuid</code>，它们会使得时序数据更加多而分散（每种 Label Value 的组合就是一条 Time Series，不同 Time Series 分散在不同位置存储）。当查询时，需要将这些数据重新会聚到一起，因此 Label Value 的基数越高，查询的成本就越大。</p>
<p>预聚合是针对高基数指标查询的优化，如果已知一个 Label 在查询时不会用作筛选条件，那么提前将其聚合好并存储起来，可以在查询时减少需要获取的明细数据量，提升查询效率。</p>
<p><img src="../202404-huya/pre_aggregation.jpg" alt=""></p>
<p>虎牙为预聚合指标提供了独立的存储，如图所示，OpenTelemetry Collector 将标准化的指标导出给 vmagent，vmagent 将原始数据 remote write 到 VMCluster（明细集群），并且按照规则对部分指标进行预聚合，remote write 到 VMCluster（预聚合集群）。又由于查询代理的存在，它可以分析用户的查询的粒度，以决定使用明细数据还是预聚合数据，在用户无感知的情况下提供更快的响应。</p>
<h2 id="拓展思考">拓展思考</h2>
<h3 id="识别高基数指标">识别高基数指标</h3>
<p>高基数指标是危险的，因为它消耗了很多查询资源，让系统存在 OOM 风险。那预聚合能规避这种风险吗？这取决于预聚合的规则如何生效：</p>
<ul>
<li>如果它是静态的、事后配置的，那么很遗憾，指标上报到配置规则的时间窗口内依然存在 OOM 的可能；</li>
<li>如果它可以基于上报数据实时分析，超过一定的基数阈值时自动增加预聚合规则，那么恭喜你，深夜 On-call 的概率大大降低。</li>
</ul>
<p>现在，问题变成如何识别高基数指标。在 VictoriaMetrics 中，有一项 <a href="https://docs.victoriametrics.com/#cardinality-explorer">Cardinality Explorer</a> 的功能，它从 IndexDB （即 VictoriaMetrics 的倒排索引）中查询指标数量以提供结果，这比起扫描完整的数据更轻量。但是这需要等数据写入了 IndexDB 之后才能进行查询，是否有办法在指标采集时实时计数呢？</p>
<p>我们可以先从用 HashSet 计数器开始，初始化一个全局的 <code>map[string]*HashSet</code>，每当收到一个 Sample 时，通过 <code>map[Sample.__name__]</code> 获取 HashSet，再将 Label Key + Value 的组合，例如 <code>name=zhu,ip=192.168.0.1</code>，放入 HashSet，这样 HashSet 中的元素个数就是这个 Metric 对应的 Time Series 个数。</p>
<p>当 Label Key + Value 组合很多时，HashSet 毫无疑问需要浪费海量的内存。为了进一步优化，我们想到在这个场景中，其实并不需要完全精确的指标基数值，因此很容易联想到用于计数的概率型的数据结构 <a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a>。借助 <a href="https://redis.io/docs/latest/develop/data-types/probabilistic/hyperloglogs/">Redis</a> 演示 HyperLogLog 的效果：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">&gt; PFADD istio_request_duration_milliseconds_bucket k1_v1_k2_v1 k1_v2_k2_v1 k1_v1_k2_v2 k1_v2_k2_v2
<span class="o">(</span>integer<span class="o">)</span> <span class="m">1</span>
&gt; PFCOUNT istio_request_duration_milliseconds_bucket
<span class="o">(</span>integer<span class="o">)</span> <span class="m">4</span>

<span class="c1"># Add 10000000 label combinations</span>
&gt; PFADD istio_request_duration_milliseconds_bucket ...
<span class="o">(</span>integer<span class="o">)</span> <span class="m">1</span>
<span class="c1"># Get inaccurate count result</span>
&gt; PFCOUNT istio_request_duration_milliseconds_bucket
<span class="o">(</span>integer<span class="o">)</span> <span class="m">9999913</span>
</code></pre></div><p>与 HashSet 不同，HyperLogLog 只会使用极少的内存。这个<a href="https://djhworld.github.io/hyperloglog/counting/">计算器</a>可以根据元素个数和错误概率为你估算所需的空间。</p>
<h3 id="预聚合与降采样">预聚合与降采样</h3>
<p>针对高基数的指标，例如：<code>istio_request_duration_milliseconds_bucket{prometheus=&quot;...&quot;, pod=&quot;...&quot;, node=&quot;...&quot;, source_workload=&quot;...&quot;, destination_workload=&quot;...&quot;}</code>，通过预聚合，可能可以将查询时需要获取的 Time Series 数量从 100000 降低到 1000，这很棒，但是还不够完美。</p>
<p>如果我们需要查询的是过去 6 个月的数据，由于每 30s 采集一次指标，形成一个数据点， 一个 Time Series 在 6 个月的时间跨度内具有 518400 个数据点，那么 1000 个 Time Series 聚合，则需要聚合 5 亿个数据点。</p>
<p>这时候降采样（Downsampling）能发挥更大的作用。降采样本质上也是预聚合的一种，它将原始的数据按照 5m，1h 等时间跨度进行聚合。如果上文的例子使用的是 1h 粒度的数据，那么只需要聚合 432 万个数据点，进一步提升查询效率。</p>
<p><img src="../202404-huya/aggregation.gif" alt=""></p>
<p>如果我们将指标的基数想象为分辨率，高基数的指标具有超高的分辨率，那么预聚合和降采样都是通过降低分辨率来让查询更加高效，区别在于预聚合降低了纵向分辨率，而降采样降低了横向分辨率。预聚合通常需要额外的存储空间，因为它们需要和明细的数据同时使用，而降采样虽然也产生了新的数据，但是通常只针对历史数据进行，因此可以认为降采样（在删除明细数据后）会节约磁盘空间。</p>
<p>降采样在开源项目 <a href="https://thanos.io/v0.8/components/compact/#downsampling-resolution-and-retention">Thanos</a> 中已经实现，VictoriaMetrics 在<a href="https://docs.victoriametrics.com/#downsampling">企业版</a>中也提供该功能，而 <a href="https://cortexmetrics.io/docs/roadmap/#downsampling">Cortex</a> 似乎还在规划中。</p>
<h2 id="总结">总结</h2>
<p>从许多分享中可以观察到，指标查询的优化通常采用降低维度 + 增加查询代理的思路，减少每次查询涉及的数据量，又无需用户感知背后的数据源差异。</p>
<p>另外，Prometheus 和 Thanos 的短板在处理海量数据量时持续被放大，所以许多技术方案在选型时都倾向于性能更好、资源使用效率更优秀的 VictoriaMetrics。最近我司也在尝试用 VictoriaMetrics 替换 Prometheus 和 Thanos，在测试环境中这为我们节约了 50% 的成本。考虑到块存储的价格，如果未来 VictoriaMetrics 能将降采样功能下放到社区版本，它可能会收获更多的使用者。</p>
]]></content>
		</item>
		
		<item>
			<title>KubeCon 欧洲 2024: 云原生在浪漫之都 | 舞台之上</title>
			<link>https://jiekun.dev/posts/kubecon-eu-2024-ii/</link>
			<pubDate>Sat, 23 Mar 2024 03:06:00 +0100</pubDate>
			
			<guid>https://jiekun.dev/posts/kubecon-eu-2024-ii/</guid>
			<description>Medium This blog post is also available in English: KubeCon Europe 2024: Cloud Native In La Ville-Lumière | In The Spotlight 现在是法国巴黎时间周六凌晨，KubeCon + CloudNativeCon Europe 2024 —— 至今 CNCF 主办的规模最大</description>
			<content type="html"><![CDATA[<p><img src="../202403-kubecon-eu/kceu24_banner.png" alt=""></p>

    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Medium</b>
        </div>
        <div class="admonition-content"><p>This blog post is also available in <strong>English</strong>:</p>
<ul>
<li><a href="https://medium.com/@jiekun/kubecon-europe-2024-cloud-native-in-la-ville-lumi%C3%A8re-in-the-spotlight-355a259311ac">KubeCon Europe 2024: Cloud Native In La Ville-Lumière | In The Spotlight</a></li>
</ul>
</div>
    </aside>
<p>现在是法国巴黎时间周六凌晨，KubeCon + CloudNativeCon Europe 2024 —— 至今 CNCF 主办的规模最大的活动 —— 刚刚结束，我在 Observability Day 上分享了关联可观测性三大支柱众多方案的其中之一：基于 Span 创造 Metric 和 Log。</p>
<p>我分享的内容其实思路很简单，但是我们故事背后，实际使用 Span Metrics Connector 却不像介绍的那么容易。</p>
<h2 id="session-review">Session Review</h2>
<p><a href="https://www.bilibili.com/video/BV1az421f7XT/">Video</a> | <a href="https://docs.google.com/presentation/d/1KHC2eZWOac6P8Vv8u6_u6MesBcAx7Ci_k1t9zLrCCIU/edit?usp=sharing">Slides</a> | <a href="https://jiekun.dev/posts/kubecon-eu-2024-ii/">Blog</a></p>

<figure class="jpg" ><img src="https://jiekun.dev/posts/202403-kubecon-eu/observability_day.jpg"alt="Observability Day 现场" loading="lazy" /><figcaption>
        <p>Observability Day 现场</p>
      </figcaption></figure>
<h3 id="exemplar-the-pain-point">Exemplar: The Pain Point</h3>
<p>关联可观测性 Signal 的本质是找到它们之间的共同点，很显然 Trace Context 是连接它们的纽带。但是回想一下，- 平时你看到的异常告警：</p>
<ul>
<li>是否有携带对应日志？</li>
<li>是否直接给出可疑 Trace？</li>
</ul>
<p>如果答案都是没有，那么恭喜你，和我们 —— 也可能是和许多开发者一样，忘记在 Metrics 上附带 Exemplar 了，这章正是写给你看的。</p>
<p>在我职业生涯至今的 80% 的时间里，我都不知道 Exemplar 的存在，或许因为它很新，也或许是缺少一个契机去了解。对于 Go 程序而言，很多时候保持 Context 的传递都是问题 —— 不是每个人都严格遵照规范写代码，更何况这些 “不规范” 的代码还能完美运行。</p>
<p>所以，即使有 Exemplar 的解决方案，它的使用者更多是框架、脚手架、SDK 的开发者，而不是业务逻辑本身的开发者。但是很多时候监控指标又和业务逻辑关联紧密，意味着其实业务逻辑更需要有 Exemplar 提供关联 Signals 的能力。</p>
<h3 id="span-metrics-connector">Span Metrics Connector</h3>
<p>如果关联散落在不同的 Signals 行不通，那么不如试试放弃关联，转而从一种 Signal 创造出其他两种 Signals。理论上，如果某种 Signal 携带了足够多的信息，能够涵盖其他两种 Signals，那这个想法就是可行的。</p>
<p><img src="../202403-kubecon-eu/span_metrics_connector.png" alt=""></p>
<p>在去年的 Humans of OTel 采访上，大多数的受访者都表示 Trace 是他们最喜欢的 Signal，因为它携带的信息最丰富。所以很自然地，有人开发了 Span Metrics Connector：</p>
<ul>
<li>将 Span 数量转换为 Counter，对应调用次数（Request）；</li>
<li>将 Span Status 转换为 Counter，与调用次数的比值对应错误率（Error Rate）；</li>
<li>将 Span 开始结束时间转换为 Histogram，对应调用耗时分布（Duration）；</li>
</ul>
<p>R.E.D 指标一下子就齐了。</p>
<p>继续沿用这个思路，只要往 Span 中继续补充信息，例如 HTTP 参数、SQL 语句，那么基本的调用日志也可以由 Span 获得，你可以将它转换成日志，作为现有日志的补充。</p>
<p>对了，这些途径得到的 Metrics 和 Logs 都会带有 Trace Context —— 因为它们本身就是 Traces 的一部分。</p>
<h3 id="ebpf">eBPF</h3>
<p>eBPF 其实和关联 Signals 没有那么大的联系，它只是提供了另一种 Span 的生成、采集方式 —— 如果你没有用 Trace SDK 埋点，那么它可以代替你做这个事情。准确来说，它应该归类到 Auto Instrumentation 的实现之一，而不是串联 Signals 的实现。</p>
<p><img src="../202403-kubecon-eu/ebpf_data_collection.png" alt=""></p>
<p>而 eBPF 程序在可观测性上一般提供两类支持，第一类是不修改你的代码和网络请求，只收集特定行为（例如网络调用），并且解析其内容；第二类则是结合代码、框架进行插装，让它产生与使用 Client SDK 埋点一样的效果。</p>
<p>这两种思路都能采集对应的 Span，但是：</p>
<ol>
<li>如果没有实际插装，eBPF 采集的 Span 缺少 Trace Context，关联它们需要依赖一些底层的信息，关联会变得很困难，不管是完整性还是性能上都是如此；</li>
<li>如果要进行实际插装，那就要与框架 SDK 紧密结合，需要逐一开发提供支持，并且也要关注性能损耗。</li>
</ol>
<p>我们接触过的 eBPF Agent 使用的是第一种思路，它能很好地提供 Metrics 和 Logs，但是在 Traces 的使用上表现不达期望。所以我对第二种思路会抱有更多的期待。</p>
<h2 id="the-missing-chapter">The Missing Chapter</h2>
<p>Signals 转换真的那么简单好用吗？也未必，在 Observability Day 上，许多细节因为时间、选材原因没有继续探讨。我想将它放在博客中作为一点补充。</p>
<h3 id="trace-sampling">Trace Sampling</h3>
<p>众所周知，Trace 中的一个难点在于海量数据的处理，假设全局每秒产生 1M 个 Span（这个数量并不多），每个 Span 体积为 100 Bytes，那么每日需要用于存储这些 Trace 的空间为：</p>
<pre tabindex="0"><code>1000000 * 100 Bytes / (1024 * 1024 * 1024 * 1024) Bytes/TiB * 86400 Seconds = 7.8 TiB
</code></pre><p>每年则需要 2800 TiB。</p>
<p>这些磁盘空间是有成本的，因此很多时候用户都设置了采样率来降低数据量，例如只上报 0.1% 的 Span。</p>
<p>采样率正常情况下不会附带到 Span 中，因此 Span Metrics Connector 的其中一个问题在于：Span 的数量是不准确、无法获知、可能动态变化的，对应地，Counter 指标的准确性需要额外信息才能进行修正。</p>
<p>以上是仅使用头部采样时存在的问题，当业务变得复杂，采样手段变多，存在回溯采样时 —— 即错误 Span 保证被上报，而正常 Span 按照固定/动态概率上报 —— 那么错误率的指标也会变得更加难以修正。</p>
<p><img src="../202403-kubecon-eu/sampling_and_metrics.png" alt=""></p>
<p>在实际使用中会存在更多复杂的情况。应对这些问题的其中一个手段是将采样率的控制收归平台，OpenTelemetry 的 SDK 提供了采样策略的 Interface，用户可以使用自定义的采样策略而非默认的头部采样。自定义采样策略只需要与可观测平台联动，通过 Notify 机制下发采样策略并缓存在 SDK 与 Span Metrics Connector 本地，就可以在 Signals 转换时对数据进行基础的修正。</p>
<h3 id="high-cardinality">High Cardinality</h3>
<p>使用 Span Metrics Connector 几乎不可避免会产生高基数指标。关于高基数指标的处理，我在分享中已经谈过一些手段，但是其实他们并不能根本解决问题，而只是延缓了问题发生的时间。</p>
<p>我们正在评估从 Prometheus &amp; Thanos 迁移至全新的 VictoriaMetrics 架构，VictoriaMetrics 作为 Prometheus 的替代品，提供了更好的性能与更低的资源开销。我在内部调研文档中提到过，这可以为我们节约 50% 以上的资源。</p>
<p>所以我是在押宝 VictoriaMetrics 的性能吗？也不全是。不管是什么存储方案，面对高基数指标的查询能提供的支撑都是有限的，选用 VictoriaMetrics 的根本原因是：</p>
<ol>
<li>它的横向扩容更加顺畅，意味着我们可能不需要进行逻辑上的 “拆分”，只需要继续提高 Sharding 数量；</li>
<li>如果 VMCluster 能够无限（或者至少在足够大的范围内）横向扩容，那么将它视为一个整体，就可以在它之前开发透明代理，用于分析指标使用情况、限制高基数指标的产生。</li>
</ol>
<p>原因 2 对新的架构来说非常重要，因为在 Prometheus + Thanos 体系中，许多 Prometheus、Thanos Sidecar 分散在各个集群，我们很难实现一个透明代理、快速部署覆盖所有实例。当然，中心化组件也有对应缺点：</p>
<ol>
<li>系统的高可用程度将会降低，可用性 = Min(VMCluster, 透明代理, &hellip;)；</li>
<li>指标数据如果集中存储，需要跨 AZ 数据传输，流量开销就会增高，同时还引入了网络专线（用于跨 AZ 数据传输）可用性的隐患。</li>
</ol>
<p><img src="../202403-kubecon-eu/metrics_management.png" alt=""></p>
<p>同样，为了（部分）解决这些问题，再引入 Replica 的方案，让数据留存多份副本、提供更高的可用性，就会让成本成倍提升，最终的架构方案可能变得更加复杂。</p>
<h2 id="conclusion">Conclusion</h2>
<p>这次分享的想法是我在接触指标管理的这几个月内诞生的，本质上是希望介绍和推广 Span Metrics Connector。作为 End User，很多时候对组件的使用、开发程度远不及 Vendor，所以我认为分享内容仍然面向的是 Entry Level 的用户，希望能给新人一些启发。</p>
<p>同时，Span Metrics Connector 代表的思想在实践上也不像我在 Session 演讲上说得简单，特别是在数据量达到一定程度之后，就必须要在准确性和性能上进行妥协 —— 一来 Trace 上报和处理能力是有限的，不能忽视五花八门的采样策略对数据处理流程的影响；二来即使真的存储下了海量的数据，对应的高基数指标的使用处处都是风险，需要投入足够的资源保驾护航。</p>
<h2 id="behind-the-scene">Behind The Scene</h2>
<p>这篇博客写于我在趣丸工作的第 243 天，也就是我真正踏入基础架构工作的第 7 个月。我在过往没有做过任何与基础架构相关的事情，然而在过去 7 个月中，我完成了 3 次外部分享（2 KubeCon，1 KCD）。我认为对于领域新人来说，踏上舞台面对观众并不容易。我对能够在感兴趣的领域工作感到非常幸运，并且认为这是兴趣驱动学习的绝佳体现。</p>

<figure class="jpg" ><img src="https://jiekun.dev/posts/202403-kubecon-eu/speaking.jpg"alt="Speaking" loading="lazy" /><figcaption>
        <p>Speaking</p>
      </figcaption></figure>

<figure class="jpg" ><img src="https://jiekun.dev/posts/202403-kubecon-eu/kubecon01.jpg"alt="Speaking (by CNCF photographer)" loading="lazy" /><figcaption>
        <p>Speaking (by CNCF photographer)</p>
      </figcaption></figure>
<p>不过长远来看，成长需要有更多的沉淀，所以这大概是未来很长一段时间内的最后一次外部分享。但是让我开心的是，我已经看到了一点点技术分享带来的影响，影响身边的人，让他们变得乐于分享、向往分享，并且开始尝试提交他们的 CFP。</p>
<p>感谢 KubeCon 提供的舞台。晚安，巴黎。</p>
<p><img src="../202403-kubecon-eu/badge.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon_3.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon_4.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon_1.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon_5.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon02.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon03.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon04.jpg" alt=""></p>
<p><img src="../202403-kubecon-eu/kubecon_2.jpg" alt=""></p>
]]></content>
		</item>
		
		<item>
			<title>KubeCon 欧洲 2024: 云原生在浪漫之都 | 序幕: 启航</title>
			<link>https://jiekun.dev/posts/kubecon-eu-2024-i/</link>
			<pubDate>Sun, 10 Mar 2024 12:01:03 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/kubecon-eu-2024-i/</guid>
			<description>现在离 KubeCon + CloudNativeCon Europe 2024 开幕还有 1 周零 2 天，我正在收拾前往巴黎的行李。 Dialogue With My Wife 夫人：电脑带吗？ 我：带！ 夫人：相机带吗？ 我：带！ 夫人：还带什么？ 我：三</description>
			<content type="html"><![CDATA[<p><img src="../202403-kubecon-eu/kceu24_banner.png" alt=""></p>
<p>现在离 KubeCon + CloudNativeCon Europe 2024 开幕还有 1 周零 2 天，我正在收拾前往巴黎的行李。</p>

    <aside class="admonition note">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-edit-2"><path d="M17 3a2.828 2.828 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5L17 3z"></path></svg></div><b>Dialogue With My Wife</b>
        </div>
        <div class="admonition-content"><ul>
<li>夫人：电脑带吗？</li>
<li>我：带！</li>
<li>夫人：相机带吗？</li>
<li>我：带！</li>
<li>夫人：还带什么？</li>
<li>我：三脚架、稳定器、灯、领夹麦、机顶麦、ND 滤镜！</li>
<li>夫人：你是去干啥的？</li>
<li>我：演讲！</li>
<li>夫人：我觉得你是去给小偷送钱的。</li>
<li>我：&hellip;</li>
</ul>
</div>
    </aside>
<h2 id="为什么参加">为什么参加</h2>
<p>2023 年我参加了 <a href="https://www.cncf.io/reports/kubecon-cloudnativecon-open-source-summit-china-2023-cn/">KubeCon + CloudNativeCon + Open Source Summit China</a>，会后我说，议题投稿和到场参与的人数（598 份投稿，1600 人参与）比起欧美（平均 1800 份投稿，9700 人参与）的同级活动还是少了一些。如果有好的故事，我还是想在更大的舞台分享一下的，开阔眼界，也好认识更多的人。</p>
<p>欧美的 KubeCon + CloudNativeCon 通常分为 4 天活动，其中，第 1 天为 Co-Located Events。这些 Co-Located Events 通常更专注于单个方向、特定项目，例如我所关注的 Observability Day 是可观测性领域的活动，在去年北美举办时，平均每场分享有 254 人参与。</p>
<p><img src="../202403-kubecon-eu/co-located_events.png" alt=""></p>
<p>我觉得在时间有限的技术分享中，很难兼顾不同层次的听众，所以 Co-Located Events 提供了很好的舞台，听众有相关的领域背景，演讲者就可以减少铺垫，把更多时间放在主题本身。</p>
<p>Co-Located Events 后的 3 天是主论坛分享，以及众多项目、厂商的展台开门接客。比起分享本身，我觉得能去展台游览，与社区的 Maintainer 对话更有吸引力。例如近期我们正在尝试从 Prometheus 迁移到 VictoriaMetrics，正好 VictoriaMetrics 是本次活动的赞助商之一，也有自己的展位，我准备了一些问题想和他们切磋：</p>
<ul>
<li>VictoriaMetrics 未来还会一直兼容 Prometheus 的协议和特性吗，有没有想过取而代之并且引领行业标准？</li>
<li>VictoriaMetrics 虽然在性能和资源开销上有优势，但是 Prometheus 有庞大的社区支持，更多的活跃开发者。VictoriaMetrics 在社区建设上有什么想法呢？</li>
</ul>
<p>同样，可观测性领域最大的社区 OpenTelemetry 也组织了自己的大型展台，现场的<a href="https://docs.google.com/spreadsheets/d/1a6o22N0rmdh9iRYt98TVJq8PzvN8FK6Kqhpk_d3KocE/edit?usp=sharing">活动</a>包括 User Feedback Session（面向用户 &amp; Maintainer）、Humans Of OTel 采访（面向 Maintainer、Governance Committee 等）、OTel Project Leadership 会议等等。我期望能在现场听一下大家的讨论，因为实际遇到的问题和反馈可能比分享更容易让人吸取经验教训。</p>
<p><img src="../202403-kubecon-eu/otel_schedule.png" alt=""></p>
<p>其他我会关注的展台包括 Grafana，他们的 eBPF 项目 Grafana Beyla 非常吸引人。噢，如果 Prometheus 也有自己的展台，我希望它能开在 VictoriaMetrics 展台旁边，方便两个社区的人友好交流。</p>
<h2 id="cfp">CFP</h2>
<p>KubeCon + CloudNativeCon 的 CFP 通常在活动前 6 个月开启，投递窗口 2 个月，评审大约在 1 个月后出结果。</p>
<p><img src="../202403-kubecon-eu/sessionize.png" alt=""></p>
<p>和我过往<a href="https://jiekun.dev/posts/kubecon-2023/#21-cfp-%E9%98%B6%E6%AE%B5">博客</a>介绍的流程一样，我的 CFP 在提交前修改过很多轮，也从社区的同学中得到了一些新的 Review 建议。在未来的 CFP 中，我会格外注重：</p>
<ol>
<li>明确我是 End User 还是 Vendor，例如以 <strong>{$CompanyName}&rsquo;s Story</strong> 开头，这是一个非常典型的 End User 视角标题；</li>
<li>我过去喜欢在结尾说“听众可以从中学到管理监控指标的经验”，或许明确具体他们可以做的事情会更好，例如“听众可以避免我们处理高基数指标犯的错，并且学会构建一套预先过滤高基数指标的中间件”。</li>
</ol>
<p>另外老生常谈的 CFP 重点就是明确你的分享对社区和生态有什么好处，以及如何证明你是一个有经验的分享者，这些也在上文的博客中介绍过。我觉得官方的 <a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/program/submission-reviewer-guidelines/#program-committee-responsibilities">Reviewer Guidelines</a> 中丰富的评分要点也可以作为参考。</p>
<p>官方通过 <a href="https://www.cncf.io/blog/2024/01/30/inside-the-numbers-the-kubecon-cloudnativecon-selection-process-for-europe-2024/">Inside the Numbers</a> 博客公布了本次活动主论坛的 CFP 情况，本次共计收到了 2541 份投稿，接收了其中的 233 个演讲，接收率仅为 9%，投稿人数及接收率均为历史新高/新低。而我参与的 Observability Day 共接收 28 个演讲，接收率为 11%。</p>
<h2 id="签证">签证</h2>
<p>因为 CFP 公布结果时离活动开始只剩 70 天，对于前往海外参与的同学，最首要的任务是：<strong>拿到签证</strong>。</p>
<p>70 天听起来似乎还有比较宽裕的时间，但是 1 月中旬时，广州的法国签证递时间交最早已经预约到 20 天之后了，在这个期间要准备签证所需的许多材料，签证递交后领事馆需要 5 - 10 个工作日才能返回结果，并且如果没能在春节前审批完毕，就要额外浪费 8 天；更重要的是如果首次签证没有下签，重新预约、递交、审核时间将会更加紧迫，很可能在活动开始前几天才能收到签证。</p>
<p>Linux Foundation 为参加活动的人提供 <a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/attend/visa-request/">Visa 邀请函</a>，这有助于提高签证通过的概率，特别是对一些下签较为严格的国家和地区。但是无论如何，都应该在确认参与之后尽快处理签证问题，最好可以提前将签证递交时间预约在 CFP Notification 后的 4 - 5 天，并提前准备除 Visa 邀请函外的所有材料，然后在收到邀请函之后就可以马上递交。</p>
<p><img src="../202403-kubecon-eu/visa_letter.png" alt=""></p>
<h2 id="演讲幕后">演讲幕后</h2>
<p>我从 1 月 17 日开始准备这次演讲的材料，到 2 月 22 日 Slides 才大致成型，然后到 3 月 5 日完成英语的演讲者备注，预留大约 10 天熟悉演讲内容和排练。</p>
<p>或许英语演讲对内容表达确实有很大的影响，我觉得很多写在最初中文稿的内容都没能顺利表达出来。</p>
<p><img src="../202403-kubecon-eu/chatgpt.png" alt=""></p>
<p>我的大部分演讲内容都是由 ChatGPT 翻译的，逐句 Prompt 的同时也还要把不熟悉、拗口的词汇剔除，尽量口语化。不得不说 ChatGPT 在保持较为稳定翻译质量的前提下，大大地减少了我的工作量。很难想象如果依赖 Google 翻译，我需要花多少时间去修正。</p>
<p>当然翻译只是演讲准备的其中一部分，另一部分则是对照自动朗读纠正发音，确保语言不会成为分享交流的障碍。</p>
<h2 id="启航">启航</h2>
<p>这篇博客是「KubeCon 欧洲 2024: 云原生在浪漫之都」系列的第一章，即活动前的准备工作。接下来还会更新另外两章，分别对应我的分享内容及会场见闻。</p>
<ul>
<li>（已更新）<a href="https://jiekun.dev/posts/kubecon-eu-2024-ii/">KubeCon 欧洲 2024: 云原生在浪漫之都 | 舞台之上</a></li>
<li>（待更新）<a href="/404.html">KubeCon 欧洲 2024: 云原生在浪漫之都 | 终章: 探索</a></li>
</ul>
<p><a href="https://sched.co/1YFfe"><img src="../202403-kubecon-eu/slides.png" alt=""></a></p>
<p>如开篇与家人的对话，考虑到欧洲行的机会难得，后续工作安排上也没有更多的时间外出，我将带上少量设备来记录这次旅程。期望能在 Paris Expo Porte de Versailles 见到你！</p>
]]></content>
		</item>
		
		<item>
			<title>2023 年度总结: 一年换 3 份工作 这是我身上的变化</title>
			<link>https://jiekun.dev/posts/2023-summary/</link>
			<pubDate>Fri, 05 Jan 2024 01:04:19 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2023-summary/</guid>
			<description>1. 反思 时间拨回 2023 年 1 月，我正在等待公司通知晋升结果和年终奖。如大家所知，2022 年互联网行情动荡，Big Tech 先后裁员，Shopee 也不例外，干</description>
			<content type="html"><![CDATA[<h2 id="1-反思">1. 反思</h2>
<p>时间拨回 2023 年 1 月，我正在等待公司通知晋升结果和年终奖。如大家所知，2022 年互联网行情动荡，Big Tech 先后裁员，Shopee 也不例外，干净利落裁了 2 轮。在这样的背景下，晋升和绩效能给我的安全感并不多 —— 准确地说是不如往年、不达期望。我开始重新思考开发者所谓的护城河在哪里，什么是我能做而其他人（或者说大部分人）不能的。</p>
<p>我从来没有考虑过那么早离开 Shopee，因为我所在的团队很优秀，而且也有很好的 Leader，如果一定要挑一点毛病，那就是工作内容<strong>不完全匹配</strong>长远深造的目标。我的目标是什么？过往几年我在 Trello 上有一个学习任务表，现在重新看一下，任务随时间的规律：</p>
<ul>
<li>从接触 Go 开始，到参与 Kubernetes 社区（未满意实现），再到参与 OpenTelemetry 社区；</li>
<li>从阅读开始，到写作，到组内分享，到外部分享。</li>
</ul>

<figure class="png" ><img src="https://jiekun.dev/posts/202401-2023-summary/trello.png"alt="我的 Trello" loading="lazy" /><figcaption>
        <p>我的 Trello</p>
      </figcaption></figure>
<p>所以我其实希望能做更加接近基础设施的工作 —— 很久了。它可以满足我对传统意义上 Computer Science 的学习意愿，也能让我有更多的机会与别人技术交流。什么，你说行行出状元，技术交流跟领域没关系？啪，醒醒！

    <aside class="admonition tip">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg></div><b>基础架构</b>
        </div>
        <div class="admonition-content"><p><strong>基础架构</strong>是个具体的概念但又包含了非常广阔的方向，它为上层业务提供方方面面的支撑。如果没办法定义，那不如列举一些关键词来向读者传递我对基础架构的印象：</p>
<ul>
<li>属于：容器、监控、网关、内核、Service Mesh、存储、&hellip;；</li>
<li>不属于：用户增长、广告投放、商品、物流、游戏、搜索、推荐、&hellip;。</li>
</ul>
</div>
    </aside></p>
<p>我曾尝试说服自己，既工作在前景不错的广告业务，又深入基础架构学习。但是这种理念随着年龄增长带来的压力越来越大，因为我看到更多的人在我向往的领域发光发热，而我还在吊儿郎当给文档改 Typo 做“贡献”。所以在那一刻，我决定花 1 年时间好好准备一下更多基础架构方向的积累，然后在 2024 年跳槽去这个全新的领域。不过在开始之前，我还需要打探一下当下的行情，到底是不是如外界所传的困难，所以我开始了年初的<a href="https://jiekun.dev/posts/2023-interviews/"><strong>面试之旅</strong></a>。</p>
<p>在这段时间，我一共面试了 4 家公司，分别是字节跳动（国际化电商）、米哈游（部门不详）、富途牛牛（网关）和猿辅导（监控日志），并且都是在毫无准备的情况下进行的，因为我觉得这可以让我的心态非常稳定 —— 面试通过，挺好；面试不通过，复习一下下次有机会。我对 9 场面试的结果非常满意，因为能体会得到面试官的问题并不难。我最关注的是猿辅导的面试，因为我需要知道未来往这个方向求职时会遇到什么问题、需要如何去学习。</p>
<p>本来，这段面试经历就到此结束了，想收集的信息也拿到了，是时候回到日常工作中了。突然，<strong>Shopee 内部传出了一个重磅消息</strong>。</p>
<h2 id="2-新机会">2. 新机会</h2>
<p>2023 年 2 月 16 日，产品线匆匆忙忙开了一次全员会议，告知员工可以<strong>主动申请离职</strong>，公司<strong>提供 N+2 的赔偿</strong>，考虑期限为 <strong>2 天</strong>。这个消息让我非常震惊，我至今无法理解公司用这样的（好聚好散）方式尝试解决部分员工工作态度问题的做法，因为我知道平时对公司最不满意的人很大概率在摆烂，他们并没有足够的底气离开舒适区。</p>
<p>说实话 N+2 对我来说吸引力只能算中等偏下，我当时薪酬不那么如意，但是也没有很强烈的诉求。不过又想到明年想换工作方向，而我的绩效一年比一年好（B、A-、A），薪酬调整却一年比一年糟糕（折算全年涨幅13.5%、10%、5%），让我对公司的前景不那么抱希望。最终我在漫长的考虑后搭上这趟离职车，来到了<strong>富途牛牛</strong>。</p>

<figure class="jpg" ><img src="https://jiekun.dev/posts/202401-2023-summary/shopee.jpg"alt="我在 Shopee 的最后一组照片" loading="lazy" /><figcaption>
        <p>我在 Shopee 的最后一组照片</p>
      </figcaption></figure>
<p>我在富途牛牛待的时间其实不长，只有不到 3 个月。选择富途牛牛的理由有很多，做网关、不用搬家、周末不加班&hellip; 但是选择离开的原因却很直接 —— 想要<strong>回到家人身边</strong>。这 3 个月里发生了很多事情让我的各种计划不断被打乱，包括生病、订婚、闹矛盾，所有的事情让我意识到，当下，我有更加需要陪伴的人。</p>
<p>我自认为匆匆离职是放弃和失去了很多东西的，然后设想接下来的几个月将会非常艰难。殊不知，我又错了。</p>
<h2 id="3-失业期间">3. 失业期间</h2>
<p>2023 年 5 月 31 日，我从富途牛牛离职，回到了广州。趁着没工作任务的压力，我投入了更多时间到<strong>开源社区</strong>，向 SkyWalking 提交了第一个 <a href="https://github.com/apache/skywalking-go/pull/55">PR</a>，阅读了更多 OpenTelemetry 代码，为未来的求职做准备。</p>
<p>我发现专注开源项目的乐趣远比想象中多。在参与 SkyWalking 项目时，我的每个 PR 和 Comment 几乎都能在极短时间内得到回复，例如 <a href="https://github.com/wu-sheng">@wu-sheng</a> 老师在首个 PR 发起后 14 分钟就回应要求补充测试。结合漩涡事件，我觉得开发者是非常期待自己的贡献<strong>得到重视</strong>的。</p>

    <aside class="admonition tip">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg></div><b>漩涡事件</b>
        </div>
        <div class="admonition-content">2021-02-01，<a href="https://github.com/Xuanwo">@Xuanwo</a> 向 <a href="https://github.com/pingcap/tipb">pingcap/tipb</a> 提交了 PR <a href="https://github.com/pingcap/tipb/pull/208">Add elems into FieldType</a>，PR 迟迟没有合并。后来 <a href="https://github.com/hanfei1991">@hanfei1991</a> 提交了一个一模一样的 PR： <a href="https://github.com/pingcap/tipb/pull/217">add elems for fieldtype</a>，当天就被合并了。随后项目维护者以 PR#217 已经被合并为由，提议关闭 PR#208。</div>
    </aside>
<p>不管是 SkyWalking 还是 OpenTelemetry 社区都能提供这种“重视每个贡献者”的感受，区别在于 SkyWalking 可能由 <a href="https://github.com/wu-sheng">@wu-sheng</a> 老师回复比较多，而 OpenTelemetry 社区则有非常多的 SIG 以及 maintainer 提供不同的意见。结合我后来的一些开源社区参与经历，我觉得搞明白“什么样的人合适维护开源软件”很重要。</p>

    <aside class="admonition warning">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-alert-circle"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="8" x2="12" y2="12"></line><line x1="12" y1="16" x2="12.01" y2="16"></line></svg></div><b>Maintainer 的标准</b>
        </div>
        <div class="admonition-content"><p>许多打工人只是工作需要写点代码，恰巧这些代码需要写在开源软件上。他们不会关注软件社群里其他用户的问题，因为“这跟我有什么关系呢”。而社群的维护者是对社群生产的软件有极高的认同感和责任心，并且自觉有义务推广它的使用的人，自然会关注使用软件的人碰到的问题，解决问题促进使用，总结问题看看软件哪些方面还有不足。<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Maintainer 的标准. (2022, September 12). 夜天之书. <a href="https://www.tisonkun.org/2022/09/12/maintainer-criterions/">https://www.tisonkun.org/2022/09/12/maintainer-criterions/</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
</div>
    </aside>
<p>对于我个人而言，因为在 Shopee 有看邮箱的习惯，所以我的 GitHub 消息基本都是邮件形式通知的，并且在 1 分钟内阅读到。我希望以后能继续保持这样，或许当我哪天成为一个项目的 maintainer 时，也能一样及时予以大家回应，至少表示“我已经在看这个问题了”。</p>
<p>断断续续学习了一个多月之后，我开始陆续进行一些面试，当然，这次面试的岗位就不再那么随心所欲了，而是严格地锁在了<strong>可观测性</strong>方向上。因为我觉得这个方向大家做的事情都还很基础，它可能体量很大，毕竟一家公司就有成千上万的应用需要，但是它的实践又很原始，缺少创新，需要想象力，意味着更广阔的空间。</p>
<p>这是我 Q3 面试的记录，我习惯于用手机记录每场面试，结束后再从面试官的角度复盘，思考如果我是面试官，我想要得到的是什么答案。录音绝对是优化面试表现的一大利器，我还记得第一次听自己录音时的尴尬：</p>
<ul>
<li>面试时觉得谈笑风生，听录音时发现磕磕碰碰，狠狠打了自己一巴掌；</li>
<li>面试时觉得高谈阔论，听录音时发现答非所问；</li>
<li>面试时觉得深挖内容炫技，听录音时发现每个扩展方向都半桶水。</li>
</ul>

<figure class="jpg" ><img src="https://jiekun.dev/posts/202401-2023-summary/interviews.jpg"alt="年中的面试之旅" loading="lazy" /><figcaption>
        <p>年中的面试之旅</p>
      </figcaption></figure>
<p>所以，录音首要的作用是把自己盲目的自信打垮，重新建立起新的、真正的自信，面试思路灵活固然是好的，但是更重要是答出面试官所想要的，在此基础上才能考虑锦上添花的内容。</p>
<h2 id="4-做回菜鸟">4. 做回菜鸟</h2>
<p>2023 年 8 月 14 日，我入职了趣丸，在业务团队摸爬滚打 5 年之后再一次来到了全新的领域。</p>
<p>2018 年刚毕业时，我在有米科技工作，这是一家创业公司，也是对我的职业生涯至今影响最大的公司。在有米，我可以为团队里的项目做各种各样的事情，包括各种底层的优化，这就涉及许多基础设施的管控范围问题。在 Shopee 或者一些稍大的企业，职责分工明确，数据库自然有 DBA 关注处理，RPC 框架也包办了很多内容，监控告警更是服务一上线就能自动生成。这可以让业务研发更加专注业务，但每个人能负责的事情范围就非常有限了，即使我发现了什么问题，提出了什么样的解决方案，最终采纳与否、修复与否又与我何干呢。</p>
<p>业务上，（虽然没有，但）即使我将它做得很好，得到 A+、S 之类的绩效激励，短期内产生很高的经济回报，但是对于无意在物流、广告这种业务上深耕的我来说，它并不有趣。编程既是职业也是兴趣，而兴趣既是驱动力，也是我的核心竞争力。所以不管多少次，我在转岗、换工作里都是最关注<strong>成长环境</strong>的。</p>
<p>那到底初创公司实实在在为员工提供了哪些在 Big Tech 做不到的呢？</p>
<ul>
<li>试错空间，业务规模小导致许多策略可以更加激进地实施；</li>
<li>责任范围，人力规模小导致每个人需要处理更广范围的事情，这对于想躺平的人可能是非常不好的，但是对兴趣驱动的人无疑是 <a href="https://en.wikipedia.org/wiki/M%C3%84R"><strong>MÄR Heaven</strong></a>。</li>
</ul>

    <aside class="admonition tip">
        <div class="admonition-title">
            <div class="icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg></div><b>操作系统也算优势？</b>
        </div>
        <div class="admonition-content"><p>允许使用 Linux 作为本地操作系统的企业能让我有极大的好感，因为：</p>
<ol>
<li>我在第一家公司用了 2 年 Ubuntu（公司强制要求），习惯的影响力是深远的；</li>
<li>专注开发，Linux 是没有什么花样可玩的操作系统，但是它又能在工作上玩出百般花样来；</li>
<li>我更乐意与用 Linux 的同事交流，至少他们不太可能有命令行操作上的烦恼；</li>
<li>鄙视链总是有的，不要尝试说服别人，只要自己接受就可以了。</li>
</ol>
</div>
    </aside>
<p>所以，趣丸让我有数年前在有米工作的感觉，我重新回到了用 Ubuntu 台式机、发布上线没灰度一刀切、服务不走 CI/CD 直接命令行重启的日子，也开始学习很多没接触过的知识。</p>
<h2 id="5-新的开始">5. 新的开始</h2>
<p>2023 年的下半年是梦幻的，我不仅来到了期盼已久的赛道工作，还在 9 月站上了 KubeCon + CloudNativeCon + Open Source Summit China 2023 的讲台。</p>
<p>曾经，在公司内分享是我的一个目标，我既遗憾在 Shopee 3 年依然没能完成它，也感慨来到新公司寥寥几天就跨过它实现了更大的目标，或许这就是不同环境对我的影响吧。这其中也有 CNCF 的 Diversity 理念、对新人的眷顾，感谢所有帮过我的人。</p>
<p>而当事情迈出第一步后，第二步也会紧随而来。12 月，我又回到了 Shopee，但是这一次是以分享者的角色回来参加 Kubernetes Community Days 的。</p>

<figure class="jpg" ><img src="https://jiekun.dev/posts/202401-2023-summary/talks.jpg"alt="我在外部分享"/><figcaption>
        <p>我在外部分享</p>
      </figcaption></figure>
<p>我有足够的理由相信，我当下做出的是过去 5 年来最棒的选择，2024 年尽最大的努力把握住来之不易的机会。</p>
<p><strong>Do what I love and love what I do</strong>.</p>
]]></content>
		</item>
		
		<item>
			<title>KubeCon 2023 北美：可观测日小记</title>
			<link>https://jiekun.dev/posts/kubecon-na-2023/</link>
			<pubDate>Sat, 25 Nov 2023 12:30:00 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/kubecon-na-2023/</guid>
			<description>前言 CNCF 主办的 Observability Day 在 11 月 6 日与北美 KubeCon + CloudNativeCon 同期举行。作为可观测性领域的新人，虽然因为时间关系没能到现场参加，但是主办方在活动当天就上传了录像，堪</description>
			<content type="html"><![CDATA[<p><img src="../202311-kubecon-na/kubecon_co_event.png" alt=""></p>
<h2 id="前言">前言</h2>
<p>CNCF 主办的 Observability Day 在 11 月 6 日与北美 KubeCon + CloudNativeCon 同期举行。作为可观测性领域的新人，虽然因为时间关系没能到现场参加，但是主办方在活动当天就上传了录像，堪称神速，所以有机会第一时间回看了这些分享，并且记录了少许工作相关的内容。</p>
<h2 id="session-小记">Session 小记</h2>
<h3 id="dynamic-sampling-in-practice---honeycomb">Dynamic Sampling in Practice - Honeycomb</h3>
<p><a href="https://www.bilibili.com/video/BV1hu4y187WE/?share_source=copy_web&amp;vd_source=6a34d69131ebaa81c8f8b005ccfbc86d">Video</a> | <a href="https://static.sched.com/hosted_files/colocatedeventsna2023/52/DynamicSampling_2023Nov06.pdf">Slides</a></p>
<p>关于分布式追踪的采样方案，我在过往的 <a href="https://jiekun.dev/otel">博客</a> 中已经简单介绍过了。Honeycomb 是一家可观测性方向的服务提供商，因此他们产品的视角也是可观测性平台的视角。Kent Quirk 在这场分享中提出的问题是：</p>
<blockquote>
<p>What if your data isn&rsquo;t predictable?</p>
</blockquote>
<p>试想一下，如果我是公司内可观测性平台的维护者，有数千个服务接入了我的平台。如果我为他们<strong>统一配置规则</strong>，例如“采样所有耗时 &gt; 5 秒的 Trace”，那么：</p>
<ol>
<li>对于高性能、低延迟的服务，如网关，一次 Trace 如果超过 5 秒，系统可能早就崩溃了；</li>
<li>对于离线服务，如大规模的计算作业，基本上所有 Trace 都超过 5 秒，采样上来的数据太多，把握不住重点。</li>
</ol>
<p>这个问题的关键点就是：维护者并不能知道所有服务的特点，也无法编写统一的规则。正如分享中提到：</p>
<blockquote>
<p>数据不可控带来的影响包括：</p>
<ol>
<li>系统过于复杂，难以编写统一规则；</li>
<li>为了更好地采集数据，系统需要经常变更以满足新的数据形态、规律；</li>
<li>采集上会遇到有突增流量、突增上报量；</li>
<li>管理采样的人并不是管理数据、流量产生的人。</li>
</ol>
</blockquote>
<p>因此，Kent Quirk 提出 <a href="https://docs.honeycomb.io/manage-data-volume/sampling/#tail-sampling">Dynamic Sampling</a>，下放决策权给应用服务。在 Honeycomb 上，维护者可以配置一些字段，应用服务按照实际情况填写，这些字段在采集上来之后组合成一个 Key，例如：</p>
<ul>
<li>http_code / sql_count / cache_count</li>
</ul>
<p>在正常处理流程中，这些 Key 对应的 Value 分布都是相对集中的，例如收集 10000 个 Trace 可能得到的结果：</p>
<ul>
<li>出现了 9700 次：http_code: 200 / sql_count: 0 / cache_count: 10</li>
<li>出现了 293 次：http_code: 200 / sql_count: 10 / cache_count: 10</li>
<li>出现了 7 次：http_code: 200 / sql_count: 5 / cache_count: 5</li>
</ul>
<p>依照不同 “组合” 的出现总次数，可以对其赋予不同的采集概率，例如出现次数最多的组合后续继续出现的话，仅采样 0.1%；第二多的组合则采样 10%，而出现次数最少的组合采样 100%，以此体现 Dynamic。</p>
<p>Dynamic Sampling 是发生在尾部采样阶段的，它的理念，或者说与传统尾部采样策略的差异在于：传统策略依照错误、耗时、数量等等因素决定，其<strong>决定权本质上是控制在 Collector 的</strong>；而 Dynamic Sampling 在 Collector 侧配置的是字段名，这些字段应用服务需要按实际情况，也就是<strong>下放了决策权给应用</strong>。当然，读者也可以认为它是<a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/tailsamplingprocessor">尾部采样</a>中的 <code>string_attribute</code> 的小变种，很多时候维护者也使用了 Attribute 中的内容来决定是否采样，只是这些逻辑并不为应用服务所知，现在只是让大家知道和填写而已。</p>
<p>有趣的是，2023 年初曾经有一个 issue 提出了几乎相同的想法：<a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/17874">#17874 New Component proposal: DeDuplicator processor / sampler</a>，只是当时原作者没有带来后续的实现。</p>
<h3 id="monitoring-and-metadata---google">Monitoring and Metadata - Google</h3>
<p><a href="https://www.bilibili.com/video/BV1xC4y177sE/?share_source=copy_web&amp;vd_source=6a34d69131ebaa81c8f8b005ccfbc86d">Video</a> | <a href="https://static.sched.com/hosted_files/colocatedeventsna2023/e0/kubecon%20talk%20ridwanmsharif%40.pptx">Slides</a></p>
<p>这场分享的小标题是：<strong>Exploring approaches to attaching metadata to logs, metrics and traces</strong>。刚好最近也在和 Metrics 打交道，所以想看看能不能从中学到一些。</p>
<blockquote>
<p>可观测性三大支柱中的 Metadata，即 Label，生成姿势都是较为接近的，所以小记中以 Metric 为例。</p>
</blockquote>
<p>在应用服务视角，它们上报一个的 Metric 举例如下：</p>
<pre tabindex="0"><code>http_requests_total{host=&quot;jiekun.dev&quot;, path=&quot;/posts/kubecon-na-2023&quot;, method=&quot;GET&quot;, status=&quot;200&quot;}
</code></pre><p>在过去，我们可能会认为这里面的 Label 不多，其中 <code>host</code>、<code>method</code>、<code>status</code> 是比较固定的，而 <code>path</code> 可能会存在高基数问题。这个指标产生的时间线，也就是不同 Label 的组合数量，可能是：</p>
<ul>
<li>1 个 <code>host</code> x 1000 个 <code>path</code> x 2 个 <code>method</code> x 5 个 <code>status</code> = 10000</li>
</ul>
<p>看起来尚可接受对吗？</p>
<p>在 Prometheus 服务端，这个 Metric 的真实样子可能是：</p>
<pre tabindex="0"><code>http_requests_total{az=&quot;us-central-1a&quot;, service=&quot;blog&quot;, pod=&quot;blog-a3xdw&quot;, env=&quot;prod&quot;, host=&quot;jiekun.dev&quot;, path=&quot;/posts/kubecon-na-2023&quot;, method=&quot;GET&quot;, status=&quot;200&quot;}
</code></pre><p>好吧，Metric 里还包含了许多基础设施相关的 Label，那似乎实际的时间线数量会是：</p>
<ul>
<li>10000 x 2 个 <code>az</code> x 1 个 <code>service</code> x 3 个 <code>pod</code> = 60000</li>
</ul>
<p>放大了 6 倍，似乎也还是可以接受，但是请不要忘记这只是个博文例子，在实际使用中，我们观察到的放大比例会非常高。</p>
<p>下面的流程图更详细地展示了一个指标的不同 Label 是在哪里得到的。简单来说，在配置 Prometheus 的抓取后，Prometheus 需要通过服务发现找到需要抓取的 Service 或者 Pod，这个过程中就会得到第一部分的 Label，例如 cluster、service、pod 等等；而在实际抓取时，访问应用服务提供的接口可以获取到它暴露的 Metrics 和 Labels，并合并两部分内容。</p>
<p><img src="../202311-kubecon-na/metric_labels.jpg" alt=""></p>
<p>谈到这里，可以引出本小节的第一个结论：由于基础设施 Label 会进一步放大时间线数量，应用服务在提供 Metrics 的时候对高基数问题的估量应该更保守一些，毕竟谁也不想在查询时动不动就聚合几百万条时间线，既可能压垮 Prometheus，也让查询等待时间变长，体验变差。</p>
<p>但是毕竟 Metrics 和 Label 还是由应用服务提供，可以认为是不可控的，平台方可以如何去管控呢？对于查询，一个简单有效的方法是：<strong>增加代理层，解析和校验 PromQL</strong>。</p>
<p>我们团队在上周实现了这个事情，上线了 PromQL Proxy 应用，置于 Grafana 和 Thanos Query Frontend 之间，按照规则来拦截查询：</p>
<ul>
<li>特定 Metric 如果缺少特定 Label 则不放行；</li>
<li>特定 Metric 查询时间区间超过阈值则不放行。</li>
</ul>
<p>一个示例的配置如下：</p>
<pre tabindex="0"><code>promql-proxy:
   - metric-name: istio_request_duration_milliseconds_*
     and_labels: [cluster]
     or_labels: [source_workload, destination_workload]
     time_range: 7d
     ...
</code></pre><p>它要求用户在涉及形如 <code>istio_request_duration_milliseconds_*</code> 的指标查询时：</p>
<ol>
<li>必须携带 <code>cluster</code> label 筛选；</li>
<li>至少携带 <code>source_workload</code> 或 <code>destination_workload</code> label 筛选；</li>
<li>查询时间区间长度不能超过 7 天；</li>
<li>&hellip;</li>
</ol>
<p><img src="../202311-kubecon-na/promql_proxy.jpg" alt=""></p>
<p>静态配置只能用于事故后补救、拦截，阻止同样问题再次发生。那要防范于未然，我们计划将其与指标维度监测打通，在指标采集过程中也会感知高基数问题，并且动态地加入 PromQL Proxy 的拦截范围。</p>
<h3 id="project-updates">Project Updates</h3>
<p><a href="https://www.bilibili.com/video/BV1t94y1V7HJ/?share_source=copy_web&amp;vd_source=6a34d69131ebaa81c8f8b005ccfbc86d">Video</a> | Slides</p>
<p>这个 Session 其实挺有趣而且介绍了很多新功能，但是考虑到信息集中对于当下缺少时间的人们非常重要，TL;DR：</p>
<ul>
<li>Prometheus：
<ul>
<li>Prometheus <a href="https://prometheus.io/docs/concepts/metric_types/#histogram">Native Histrogram</a> 是个值得关注的功能，今年的 3 次 KubeCon + CloudNativeCon 都出现了它的身影，它旨在提供相比传统固定分桶 Histrogram 更高精度、更动态的 Histrogram 实现，版本高于 v2.40 可以体验；</li>
<li>把 Prometheus 升级到 <a href="https://github.com/prometheus/prometheus/releases/tag/v2.44.0">v2.44</a> 以上，内存减半；</li>
<li><code>scrape_config_files</code> 告别把超长的配置写在同一个配置文件中；</li>
<li>Prometheus OTLP receiver 现在对接收 OTLP metrics 提供实验性支持；</li>
<li>Prometheus 3.0 正在路上；</li>
</ul>
</li>
<li>OpenTelemetry：
<ul>
<li>Logging 模块到达 GA；</li>
<li>OTLP 到达 1.0 版本，意味着它将变得更稳定、变更会更少，这对协议来说是非常重要的事情；</li>
</ul>
</li>
<li>Fluentd &amp; Fluent Bit：受限于对日志领域了解，没办法对具体内容逐一分享，感兴趣的读者可以翻阅录像。但是整体听下来的感受就是，它们也在像 OpenTelemetry 一样打造工具，例如 Processor、Pipeline 的设计结构如出一辙。或许这也是高度模块化、插件化的项目中比较值得推广的实践。</li>
</ul>
<h2 id="总结">总结</h2>
<p>除了上面提到的 Session，可观测性领域在 2023 年其实还有很多代表性的亮点，特别是 eBPF。本次 KubeCon + CloudNativeCon Observability Day 稍微缺少了相关的内容，或许是因为演讲者都投稿到隔壁 <a href="https://colocatedeventsna2023.sched.com/overview/type/CiliumCon">CiliumCon</a> 去了。</p>
<p>另外，也看到很多 Session 都在着重讲解成本问题，例如 FinOps、Prometheus 在过去一年怎样把内存减半等等。或许这也会是明年的一个工作方向，帮公司节约更多成本，或者在相近的成本下保持数据增长及组件健康 —— 就从 PromQL Proxy 开始吧。</p>
]]></content>
		</item>
		
		<item>
			<title>KubeCon 2023 上海：参会“小”记</title>
			<link>https://jiekun.dev/posts/kubecon-2023/</link>
			<pubDate>Thu, 05 Oct 2023 16:32:23 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/kubecon-2023/</guid>
			<description>0. 前言 国庆前到上海参加了 2 天的 KubeCon + CloudNativeCon + Open Source Summit China 2023（以下简称 KubeCon），并解锁了新的角色（Speaker，喇叭）。至此，2022 年</description>
			<content type="html"><![CDATA[<p><img src="../202309-kubecon/banner.png" alt=""></p>
<h2 id="0-前言">0. 前言</h2>
<p>国庆前到上海参加了 2 天的 KubeCon + CloudNativeCon + Open Source Summit China 2023（以下简称 KubeCon），并解锁了新的角色（Speaker，喇叭）。至此，<strong>2022 年</strong>（没错，是 21 个月前定的）OKR 完成度达到了 50%。国庆长假之后良心发现，决定记录一下这次 Journey，但不限于短短的 2 天内的见闻。</p>
<h2 id="1-session-小记">1. Session 小记</h2>
<p>KubeCon 两天（不包含 IstioCon）一共有约 150 场分享，在开始之前需要先安排好时间和路线，我是在飞机上匆忙完成的。受限于工作领域和专业知识，我参加的分享大部分是可观测性领域的，少部分是当前比较热门的 AIGC 相关内容，再补充一些 Kubernetes 的通用知识。</p>
<p>在记录别人的分享之前，先打个广告：我在本次大会上分享了 <strong>OpenTelemetry 的采样策略</strong>，感兴趣的同学可以查看：<a href="https://www.bilibili.com/video/BV1hH4y1o79V/">Video</a> | <a href="https://docs.google.com/presentation/d/16PHf3XxZBuLjD0b07SMJmk0yfFAHB2jJpMPGgONngRE/edit?usp=sharing">Slides</a> | <a href="https://jiekun.dev/posts/kubecon-2023-otel-sampling/">Blog</a>。</p>
<h3 id="11-用-ebpf-充当网络加速器">1.1 用 eBPF 充当网络加速器</h3>
<p><a href="https://youtu.be/gPmDp4KoxPk?si=1gM5opzklwaIhpry">Video</a> | <a href="https://static.sched.com/hosted_files/kccncosschn2023/09/KubeCon23SH-CNI-agnostic%20network-performance%20accelerator%20with%20eBPF.pdf">Slides</a></p>
<p>在 Kubernetes 部署的大背景下，由于每个 Pod 都有自己的网络协议栈，因此数据包从一个 Pod 发送到另一个 Pod 时会<strong>多次</strong>经过完整的网络协议栈。这会带来一些耗时上的影响，而当 <strong>Service Mesh 存在时</strong>，数据包又要额外地经过 Sidecar，所以这种开销将会成倍地上涨。</p>
<p><img src="../202309-kubecon/ebpf_accelerator_1.png" alt=""></p>
<p>为了减少这种开销，我们可能会思考如何将同机的数据传输更快速地送往目的地。在开发中，有很多问题我们都可以通过<strong>加缓存</strong>来优化，这种手段暴力但很有效。如果有一种手段可以把 Socket 缓存，<strong>使得数据包能绕过一些网络协议栈直接抵达目的地</strong>，数据传输性能可能会得到提升。</p>
<p>借助 eBPF，可以通过 <code>BPF_PROG_TYPE_SOCK_OPS</code> 将所有建立连接的 <strong>Socket</strong> 捕获并置入 map 中；当有 TCP 事件产生时，可以通过 <code>BPF_PROG_TYPE_SK_MSG</code> 感知并实现 <strong>Socket 数据的重定向</strong>。</p>
<p>接下来要解决的问题就是，如何通过 Socket 的信息将多个 Socket 两两配对。先举个简单的例子，
如果我捕获了两个 Socket，这两个 Socket 的信息中 <code>src_ip</code> / <code>src_port</code> / <code>dest_ip</code> / <code>dest_port</code> 四元组正好是交叉匹配的，那很容易将其关联起来，未来的数据包就可以从 <code>IP:PORT</code> -&gt; <code>IP:PORT</code> 的访问（会经过网络协议栈）转换为 Socket -&gt; Socket 的访问。</p>
<p>而在 Service Mesh 中情况会稍微复杂一些，因为：应用服务发出的数据包 dest_ip / dest_port 虽然是目标应用的，但是它会被 Envoy 代理拦截。这样的数据包应该先被重定向到 Envoy 的 Socket，再从 Envoy 的 Socket 重定向到目标应用的 Socket。</p>
<p><img src="../202309-kubecon/ebpf_accelerator_2.png" alt=""></p>
<p>这样的加速器在 Kubernetes 集群规模不大时会有良好的效果，因为 <strong>Node 数量少才会出现大量的 Node 内通信</strong>。而若 Node 中存在大量外部流量，网络间的延迟会大大压缩 eBPF 加速带来的优势，使得整体优化效果趋于平庸。</p>
<p>从性能测试报告中可以看到，这种优化方案极大地降低了 TCP 延迟，但是在包大小小于 512 Bytes 时会降低整体的吞吐量（优化前后 Ratio &lt; 1），潜在原因是：加速器在绕过网络协议栈的同时也绕过了相关的优化，如对小包的攒批发送。</p>
<p><img src="../202309-kubecon/ebpf_accelerator_3.png" alt=""></p>
<h3 id="12-基于-cluster-autoscaler-的-kubernetes-自动扩容">1.2 基于 Cluster Autoscaler 的 Kubernetes 自动扩容</h3>
<p><a href="https://youtu.be/FxD7ELbH_Gg?si=JfjYTusk90R00nRD">Video</a> | <a href="https://static.sched.com/hosted_files/kccncosschn2023/d0/How%20We%20Scale%20up%20to%202k%20Nodes%20for%20Batch%20Jobs%20Using%20Cluster%20Autoscaler%20v0922%20%E4%B8%AD%E6%96%87%E7%89%88.pdf">Slides</a></p>
<p>这场分享是关于 Kubernetes 中的 Worker Node 弹性扩缩容工具 <a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler">Cluster Autoscaler</a> （后文简称 CA）的。在利用 Kubernetes 托管批量作业时，因为这些作业常常是定时的，他们的特点是：只在运行时需要大量的机器资源。为了降低成本，通常有两个方向对批量作业进行优化：</p>
<ol>
<li>分散不同作业的运行时间，使得机器负载在一定周期内都保持均匀；</li>
<li>在作业运行时视资源需求量进行扩容，运行后进行缩容。</li>
</ol>
<p>CA 是针对后者的解决方案之一，当 Cluster 中存在大量的 Pending Pod 时，CA 就会自动触发扩容，引入新的节点让 Pod 调度上去；同样，CA 也会在资源使用率下降时将 Pod 调度到其他节点上去，并触发缩容。</p>
<p><img src="../202309-kubecon/ca_1.png" alt="">
<img src="../202309-kubecon/ca_2.png" alt=""></p>
<p>但是在扩缩容的过程中常常会有很多问题导致其失败。从流程上看，用户需要（由 CA 自动完成）：</p>
<ul>
<li>启用新的节点；</li>
<li>安装 Kubernetes 和相关组件；</li>
<li>加入现有集群</li>
<li>承接 Pending Pod 的调度并真正发挥其价值。</li>
</ul>
<p>在节点启用后、Pod 健康运行前，任何一个阶段出现问题都会导致节点运行的费用白白浪费掉，也是非常影响用户体验的事情。常见问题和解决方案在下文详细讨论。</p>
<p>在大规模的批量任务运行时，会在短期内出现大量的待调度 Pod，因此 CA 会根据算法和策略引入大量节点，这时集群中的中心化组件，不管是某些 Coordinator 服务还是像 etcd 这类的存储中间件，会承受往常数十倍的压力。在不增加资源投入（例如升级中心化组件配置）的前提下，这类问题通用的解决办法就是一招鲜：<strong>限速限量</strong>、<strong>分批</strong>。中心化组件的可承受压力通常都是可以预估的，这些数据可以反馈给 CA 控制节点启动数量、加入现有集群的队列长度等等。</p>
<p>第二个问题是当大量节点加入后，新 Pod 的启动不可避免地需要拉取超大体积的镜像，同样会引入<strong>网络</strong>、<strong>磁盘写入</strong>上的瓶颈。万金油的方案自然是：<strong>缓存</strong>、<strong>预热</strong>。基于批量作业运行的背景，可以推测大量 Pod 会使用相同的镜像，因此这些镜像可以先构建到操作系统镜像，在节点启动完成时镜像就已经准备好了，可以直接使用。从分享者展示的数据中可以了解到，这帮助他们将扩容时间从 22 分钟缩短至 4 分钟，写入流量峰值从 14 GiB/s 下降至 6 GiB/s，效果非常显著。</p>
<p>第三个问题是社区中已经解决的，但是也算是大规模扩容中的一点经验。在 Pending Pod 数量、节点池和预估节点数量都非常多时，想要计算他们之间的调度条件、关系就会变得更困难、耗时更长。这个问题可以推广多个相互关联的组件同时进行扩容或快速增长的场景，我们想要努力避免笛卡尔积型的计算，方法依然是前面的一招鲜：<strong>限速限量</strong>、<strong>分批</strong>。这个思路在数据库 JOIN 查询时也有体现：<a href="https://en.wikipedia.org/wiki/Nested_loop_join">Nested loop join</a>。</p>
<p>从上面的讨论可以看出，这些问题的解法相信许多开发者也在日常开发中有用到过，区别只是在它们被用在广告、物流、金融业务，还是这些基础设施的编排、调度上。计算机领域想通的东西很多，而且许多问题都不需要非常高深、复杂的解决方案就能得到不错的优化效果。</p>
<h3 id="13-chat-and-get-the-promql">1.3 Chat and Get the PromQL</h3>
<p><a href="https://www.youtube.com/watch?v=WW6vqLNwBm4">Video</a> | <a href="https://static.sched.com/hosted_files/kccncosschn2023/b8/Kubecon_35min_Text2PromQL_v3_submit.pdf">Slides</a></p>
<p>这是一场介绍 LLM 调试经验的分享，比较适合我这种完全没有了解过 AIGC 和 LLM 的小白。我不确定介绍的经验是较为入门、已经广泛使用的，还是仍在起步调研阶段，但是新人应该很容易通过这场分享的几个例子理解 LLM 与 Prompt 工程 （的冰山一角）。</p>
<p>2023 年有一件事很多公司都在做：<strong>提供基于 AIGC 的机器人</strong>。对于开发者来说 PromQL 可能并不陌生，但如果不是每天和 Prometheus 或者监控系统打交道，要毫无障碍、不查阅资料写出一条 PromQL 还是有点难度的，包括且不限于：语法关键词忘了、Metric 名字忘了、怎样组合出复杂运算忘了&hellip;借助 LLM，大家想达成的效果可能是：</p>
<p><img src="../202309-kubecon/chat_promql_1.png" alt=""></p>
<p>那么首先得教会机器人如何回答。如果直接把简单的 PromQL 的文档、Stack Overflow 回答、企业内 Q&amp;A 文档当作提示词（Prompt）丢给它，训练出来的机器人只能获得极低的回答准确率。因此，这里引出了 <a href="https://arxiv.org/pdf/2201.11903.pdf">Chain-of-Thought Prompt</a> 的调优思路，也就是不直接告诉机器人结果，而是给它一步一步解释结果是怎么来的。举个例子：</p>
<table>
<thead>
<tr>
<th>Standard Prompting</th>
<th></th>
<th>Chain-of-Thought Prompting</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q: 我有 5 个网球，我又买了 2 筒网球，每筒有 3 个网球。现在我有多少个网球？</td>
<td></td>
<td>（同左）</td>
</tr>
<tr>
<td>A: 11 个。（Prompt）</td>
<td></td>
<td>A: 我原本有 5 个网球，2 筒网球每筒有 3 个，一共是 6 个。5 + 6 = 11，答案是 11 个。（Prompt）</td>
</tr>
<tr>
<td>Q: 餐厅有 23 个苹果，如果他们用 20 个去做午餐，然后再买 6 个，餐厅一共有个苹果？</td>
<td></td>
<td>（同左）</td>
</tr>
<tr>
<td>A: 27 个。（错误）</td>
<td></td>
<td>A: 餐厅原本有 23 个苹果，他们用了 20 个去做午餐，所以还剩 23 - 20 = 3 个。他们又买了 6 个苹果，所以他们还剩 3 + 6 = 9，答案是 9 个。（正确）</td>
</tr>
</tbody>
</table>
<p>所以，针对 PromQL，可能会见到这样的 Prompt：</p>
<ul>
<li>Q: 写一个 PromQL 展示过去 5 分钟平均响应时间最长的 Top 10 应用。</li>
<li>A:
<ul>
<li>首先，我们需要计算每个应用过去 5 分钟的总响应时间：
<ul>
<li><code>sum by (service)(sum_over_time(arms_http_requests_seconds{}[5m]))</code>；</li>
</ul>
</li>
<li>然后，计算每个应用的调用次数：
<ul>
<li><code>sum by (service)(sum_over_time(arms_http_requests_count{}[5m]))</code>；</li>
</ul>
</li>
<li>接着，计算每个服务的平均响应时间：
<ul>
<li><code>sum by (service)(...) / sum by (service)(...)</code>；</li>
</ul>
</li>
<li>最后，用 <code>topk</code> 函数找到响应时间 Top 10 的应用：
<ul>
<li><code>topk(10, sum by (service)(...) / sum by (service)(...))</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>在特定测试数据集下，可以看到准确率的提升还是很明显的。</p>
<p><img src="../202309-kubecon/chat_promql_2.png" alt=""></p>
<h3 id="14-forget-kubectl-and-talk-to-your-clusters">1.4 Forget Kubectl and Talk to Your Clusters</h3>
<p><a href="https://youtu.be/_Wm6pD57JDQ?si=KIWHMwpIXCFdxU6a">Video</a> | <a href="https://static.sched.com/hosted_files/kccncosschn2023/bc/ForgetKubectlAndTalkToYourCluster_Kubecon_2023_EN_Qian_Ding_0928.pdf">Slides</a></p>
<p>这是一场很有意思的 LLM 应用分享，除了前面提到的 PromQL，你一定想知道 LLM 还可以帮你做什么，来自蚂蚁金服的答案是：管理 Kubernetes 集群。</p>
<p>我们直接从分享的中间部分开始回顾，或许很多企业都有设计过 IM 机器人帮助执行 <code>kubectl</code> 或者其他命令，因为从接收到告警消息，打开你的 Terminal 或者浏览器，经过无数步骤，到最终登入服务器执行命令行——太麻烦了，远不如在 IM 工具上发消息方便。</p>
<p>做这个机器人其实很简单，它甚至可以是一个只提供 Input 接口的 Server，在 LLM 火爆之前就已经是没有门槛的事情。但当你把这个机器人做出来，会发现：用的人不多——命令和参数太难记了！老鸟早就把一套命令行玩得行云流水不屑于用，小白用这机器人还要翻半天文档，效率还是很低。</p>
<p>所以，大家又会想做一个训练好的机器人，接收自然语言输入，转为机器语言去执行。</p>
<p><img src="../202309-kubecon/forget_kubectl_1.png" alt=""></p>
<p>有了这么个原型，开始尝试训练模型来输出一些 Shell Script 和 <code>kubectl xxx</code>，又会发现：有点危险——这俩写起来随心所欲的东西，靠谱吗？安全吗？怎样<strong>验证</strong>他们靠谱安全？</p>
<p>我们知道自然语言一直无法直接被机器使用，是因为它也很随心所欲——<strong>不结构化</strong>。Shell Script 和 <code>kubectl</code> 存在的问题很类似，那么能不能改为输出一些更加结构化的东西呢？</p>
<p>受 <a href="https://github.com/eosphoros-ai/DB-GPT">DB-GPT</a> 影响可以联想到，有一种更成熟和容易审计的语言：<strong>SQL</strong>。如果<strong>在 LLM 和 Cluster 之间实现一层 Cache</strong>，这层 Cache 可以使用 SQL 作为查询语言，LLM 就可以输出结构化的 SQL 直接使用，Cache 起到保护 Cluster 操作的作用。</p>
<p>这种设计其实还有很多细节没有在分享上讨论，包括：对需要 <code>kubectl</code> 操作资源的情况，例如重启，是怎么处理的？Cache Layer 如果没有命中结果，是否要再去找 Kubernetes 要信息，后面这个步骤怎么保证安全、没有注入风险？不过对于 LLM 的结构化输出的想法还是有借鉴的价值的，因为想把它用在实际运维工作中，确实需要对安全性、可靠性、可审计性有严格的把控能力。</p>
<p>另一个有趣的用途是关于 Kubernets 资源的 Label Extraction。我们知道有很多东西是由 Label 和对应规则代表的，例如，我们为了确认某个 Pod 会不会在接下来的热更新中存活，需要去查看它的 YAML，看一下里面是否有特定的 Label：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nn">...</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">   </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span><span class="w">   </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span><span class="w">      </span><span class="nt">custom-key-foo</span><span class="p">:</span><span class="w"> </span><span class="l">bar</span><span class="w">
</span><span class="w">      </span><span class="nt">another-custom-key/xyz</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># Here</span><span class="w">
</span></code></pre></div><p>所以如果你训练出一个能帮你找特定 Label 的 LLM 机器人，你可能会有以下问答：</p>
<ul>
<li>Q：App <code>nginx</code> 的 <code>another-custom-key/xyz</code> 是 <code>true</code> 吗？</li>
<li>A：是的。</li>
</ul>
<p>这应该很简单，因为这只是一个 Key-Value 查找的任务。不过更好的做法是用这些 Label 的含义作为 Prompt 去训练它，这里可能就涉及到前面的 Chain-of-Thought Prompt。个人觉得这个应用也比较有价值，更好的问答形式应该是：</p>
<ul>
<li>Q：App <code>nginx</code> 会不会在接下来的热更新中存活？</li>
<li>A：会的。</li>
</ul>
<p>最后，把所有东西放在一起，就有了如下的结构图：</p>
<p><img src="../202309-kubecon/forget_kubectl_2.png" alt=""></p>
<h2 id="2-我的-speaker-之旅">2. 我的 Speaker 之旅</h2>
<p>从 2019 年关注起，到 2023 年第一次参加，期间 KubeCon 一共举办了 11 届，分别在中国（上海 2 届，线上 1 届），北美（圣迭戈、洛杉矶、底特律各 1 届，线上 1 届），欧洲（
巴伦西亚、阿姆斯特丹各 1 届，线上 2 届）。在每次活动结束后，CNCF 都会发布 <a href="https://www.cncf.io/reports/kubecon-cloudnativecon-europe-2023/">Transparency Report</a> 来回顾活动以及公布一些数据。其中，演讲者相关的数据分享让我非常感兴趣:</p>
<ul>
<li><a href="https://www.cncf.io/reports/kubecon-cloudnativecon-europe-2023/">Europe 2023</a>：1761 投稿 / 186 接收 / 接收率 11%；</li>
<li><a href="https://www.cncf.io/reports/kubecon-cloudnativecon-north-america-2022-transparency-report/">NA 2022</a>：1551 投稿 / 176 接收 / 接收率 11%；</li>
<li><a href="https://www.cncf.io/reports/kubecon-cloudnativecon-europe-2022/">Europe 2022</a>：1187 投稿 / 146 接收 / 接收率 12%；</li>
<li><a href="https://www.cncf.io/wp-content/uploads/2022/02/KubeCon_China_21_Virtual_TransparencyReport_ENG.pdf">China 2021</a>：355 投稿 / 67 接收 / 接收率 19%；</li>
<li><a href="https://www.cncf.io/wp-content/uploads/2021/11/KubeCon_NA_21_Report.pdf">NA 2021</a>：976 投稿 / 136 接收 / 接收率 14%；</li>
<li><a href="https://www.cncf.io/wp-content/uploads/2021/06/KubeCon_EU_21_Virtual_TransparencyReport_FINAL.pdf">Europe 2021</a>：624 投稿 / 93 接收 / 接收率 15%；</li>
<li><a href="https://www.cncf.io/wp-content/uploads/2020/12/KubeCon_NA_20_Virtual_Report.pdf">NA 2020</a>：856 投稿 / 128 接收 / 接收率 15%；</li>
<li><a href="https://events.linuxfoundation.org/wp-content/uploads/2020/09/KubeCon_EU_20_Report_final.pdf">Europe 2020</a>：1525 投稿 / 244 接收 / 接收率 16%；</li>
<li><a href="https://www.cncf.io/wp-content/uploads/2020/08/KubeCon_NA_19_Report.pdf">NA 2019</a>：1801 投稿 / 225 接收 / 接收率 12%；</li>
<li><a href="https://dokumen.tips/documents/kubecon-cloudnativecon-open-source-summit-china-2019-2019-12-21-conference.html">China 2019</a>：937 投稿 / 未公布接收数或接收率。</li>
</ul>
<blockquote>
<p>投稿与接收数据出现在每次 Transparency Report 的形式和丰富程度不同，部分 Report 只公布了投稿数和接收率或只公布了 Session 数，因此相关数据经过转换计算。准确数据应以 Report 内容或官方统计为准。</p>
</blockquote>
<p><img src="../202309-kubecon/stats_of_kubecon.png" alt=""></p>
<p>通过数据可以看到，每届活动的投稿接收率维持在 10-20% 之间，其中，欧美的接收率又相较中国区略低一些。而投稿数量上看，虽然受过去几年疫情的影响，但欧美的投稿数量仍然远高于中国区。</p>
<p>个人认为，投稿数量一定程度受这些因素影响：疫情政策限制、活动宣传覆盖率、个人意愿。而具体到个人意愿，如果能事先了解一次活动的主题、内容、完整流程，<strong>有可参考对象</strong>，那参与意愿也会随之提升。</p>
<p>因此，写这篇“小”记的另一个动力是：<strong>分享一些投稿和准备的过程</strong>，希望帮助更多<strong>年轻的开发者</strong>参与类似的活动，特别是贡献更多的分享议题。这里强调年轻的开发者是因为：</p>
<ol>
<li>通常高级工程师们都已经有足够多的经验和经历支撑他们完成一次好的分享；</li>
<li>年轻的开发者需要的更多是<strong>自信</strong>和<strong>尝试</strong>，“小”记的目标正是<strong>鼓励</strong>分享，而不是<strong>指手画脚</strong>地<strong>教</strong>别人完成一次难点攻关去分享。</li>
</ol>
<h3 id="21-cfp-阶段">2.1 CFP 阶段</h3>
<p>想参与一次活动首先得知道活动的时间，以 KubeCon 为例，你可以在很多地方找到它接下来的举办时间和地点：<a href="https://events.linuxfoundation.org/?_sf_s=KubeCon">The Linux Foundation</a>。在有明确的投稿目标后，关注对应的 CFP（Call For Proposals）时间。例如，我参与的 2023 年中国区 KubeCon 在 9 月 26 - 28 日举行，它的 CFP 时间为 4 月 26 日 - 6 月 18 日。</p>
<blockquote>
<p>投稿提醒：目前正是 <a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/">2024 年欧洲 KubeCon</a> 的投稿时间，截止时间为 11 月 26 日。</p>
</blockquote>
<p>我的分享主题与分布式追踪的采样策略有关，在撰写投稿内容之前，我发邮件咨询了 OpenTelemetry 社区一位有丰富经验的开发者，因为我并不确定我想分享的内容是否有价值，是否已经印在了各种八股文手册中。</p>
<details>
  <summary>Mail: Looking for suggestion of KubeCon speech</summary>
  <blockquote>
<p>Hi.</p>
<p>我在很多地方看过你和其他人的采样策略分享，例如 link1 / link2 / &hellip;，所以有一些问题期望得到你的看法和建议：</p>
<ol>
<li>值得再花 30 分钟介绍采样策略吗？</li>
<li>是否应该花时间介绍现有的采样策略，还是说应该只关注新的采样方案，例如回溯采样？</li>
</ol>
<p>&hellip;</p>
</blockquote>

</details>
<p>这位开发者的回复认为介绍这个主题是可以接受的，因为距离上一次分享已经过了比较长时间，也有很多新的内容出现，并且邮件抄送了另一位社区的分享者，她有过类似主题的分享，因此我可以得到更多的 CFP 建议。过了几天，我在一家 KFC 里一边吃早餐一边完成了 CFP 的标题和内容，并再次回复邮件请教，并在大约 1 周后得到了新的答复。</p>
<details>
  <summary>Mail: CFP Review</summary>
  <blockquote>
<p>分布式跟踪在当今的微服务架构中扮演着重要的角色。然而，收集完整的 Trace 数据的成本很高。OpenTelemetry 提供了各种采样策略来减少资源使用，不同的策略需要不同的网络 I/O、内存和存储空间来实现不同的采样效果，这些都分析采样策略在特定场景表现的的关键维度。我们将分享定量分析不同采样策略的成本和质量的经验，并介绍一些我们在探索的新型采样策略，并将他们与现有策略进行比较。</p>
<ul>
<li>Reviewer 1：可以在介绍方案前先描述清楚为什么收集完整 Trace 数据的成本很高；</li>
<li>Reviewer 1：可以简单说一下不同采样策略是怎样组合的，因为它们各有不同的要求，同时这也可以为你场景和解决方案作铺垫；</li>
<li>Reviewer 2：这是 Collector 侧的采样策略还是也覆盖到 SDK 侧的，可以在描述里介绍清楚；</li>
<li>Reviewer 2：在结尾处介绍听众可以有怎样的收获；</li>
<li>&hellip;</li>
</ul>
</blockquote>

</details>
<p>CFP 修改是个漫长的过程，邮件沟通的效率也不高，最终我在 5 月 19 日确定了<a href="https://sched.co/1PTFF">投递内容</a>。在正式投递的过程中，还有许多材料需要准备，你需要介绍：</p>
<ul>
<li>你的分享会对项目生态和社区带来什么好处；</li>
<li>你在分享相关项目上的经验；</li>
<li>你的分享经历。</li>
</ul>
<p>作为首次参与的分享者，我提交了 2 段分享视频，分别是 2022 年参加 TiDB Hackathon 的 Lightning Talk 以及临时录制的与投递内容相关的分享。因为是单盲审稿，这些材料有助于让审稿人了解投递者对内容的掌握程度以及讲述能力。</p>
<p><img src="../202309-kubecon/additional_resources.png" alt=""></p>
<p>到这里，CFP 投递就告一段落了，接下来只需要等待 CFP 结果。2023 年中国区 KubeCon 的 CFP 结果在 8 月 3 日揭晓，中选的议题将有接近 2 个月时间进行准备（当然，提前进行准备总是更好的）。</p>
<p>这里还有一些其他的信息在我 CFP 投递过程中帮到我，希望也能对在阅读的你有帮助：</p>
<ul>
<li><a href="https://jpkroehling.notion.site/Crafting-Compelling-Conference-Proposals-3e96ad0660584a329354397912691153">Crafting Compelling Conference Proposals</a>；</li>
<li><a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/program/submission-reviewer-guidelines/">Submission Reviewer Guidelines</a>；</li>
<li><a href="https://www.lfasiallc.com/archive/2021/kubecon-cloudnativecon-open-source-summit-china/program/scoring-guidelines/">评分准则和最佳实践</a>；</li>
<li><a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/program/cfp/">Call For Proposals</a>。</li>
</ul>
<h3 id="22-分享准备">2.2 分享准备</h3>
<p>分享内容的准备工作因主题分享而异，但是通用的建议是及早收集材料，以免在收到 “议题被接收” 的邮件时因一页 PPT 都写不出来而良心不安。</p>
<p>在参加 KubeCon 之前，我过往的分享范围都是工作所在的小组、部门，所以我需要更多的工具、步骤来帮我完成这次对外的演讲。这些工具、步骤包括：</p>
<ol>
<li>为每页 PPT 准备完整的文字版本，详细程度基准是：任意路人都可以照念完成分享；</li>
<li>完成 1-2 次的分享演练，录音并聆听自己的分享；</li>
<li>完成 1 次组内分享，听取大家的建议作修改；</li>
<li>录制视频，邀请 3 位相关领域的专家观看和提出修改建议；</li>
<li>在演讲前完成最后的演练，录音并聆听，看看效果是否满意。</li>
</ol>
<p>在处理第 4 点的时候，有一些比较有趣的事情。因为向一位国外的开发者寻求建议，我需要准备英文的演讲视频。受限于英语水平，我让 ChatGPT 帮我完成了大部分的翻译工作，再一一进行核对。事实证明 ChatGPT 真的很喜欢添油加醋，包括但不限于在翻译的过程中理解我的文字并发表自己的思考。</p>
<p><img src="../202309-kubecon/playing_with_chatgpt.png" alt=""></p>
<p>在艰难完成翻译后，录制英文演讲视频时我又遇到了新的麻烦。因为对发音、语调总是不满意，在多次尝试后，我不得不寻找 AI 代讲，最终的 Dry Run 视频可以在这里找到：<a href="https://www.youtube.com/watch?v=TIMDgOVlWP4">dryun</a>。</p>
<div style="position: relative; padding-bottom: 56.25%; height: 100%; overflow: hidden;">
   <iframe src="//player.bilibili.com/player.html?bvid=BV1794y1t78S&amp;page=1&amp;autoplay=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="Bilibili Video"></iframe>
</div>

<p>回到准备过程本身，最重要的事情是让演练的听众、专家提出建议并调整演讲内容。通常，领域的专家不一定是非常专业的演讲者，或者说未必有很丰富的演讲经验，如果他们在表达专业意见上有阻碍，可以参考 CNCF 提供的<a href="https://drive.google.com/file/d/1dcXenOObdl2d7h1RBUqHnauTIuA2B2oq/view?pli=1">演讲者指南</a>，<strong>主动询问</strong>以下方面他们的想法：</p>
<ol>
<li>我的演讲表达足够清晰吗，你是否清晰了解我想分享的主题和内容？</li>
<li>我的 PPT 设计合理吗？
<ul>
<li>哪些页面文字太多或太少？</li>
<li>哪些页面可以做更多的图表表达，哪些图表不应该使用？</li>
<li>是否有合适的幽默内容片段？</li>
<li>演讲的速度是否容易 Follow？</li>
</ul>
</li>
<li>&hellip;</li>
</ol>
<p>同样，我在这里引用一些 Reviewer 的修改意见作为示例。</p>
<details>
  <summary>Conversation: Presentation Review</summary>
  <blockquote>
<ul>
<li>Section 2：头部采样和尾部采样的优缺点过于简略；</li>
<li>Section 3：性能评估的时候没有介绍 Collector 的部署架构和细节，包括多个影响性能测试的参数没有告诉听众；</li>
<li>Section 3：性能评估结果的图线太小，并且相关数据也没有对比参考，只展示数据不能说明这个数据是好是坏；</li>
<li>Section 4：有一种采样策略的使用场景讲解得不够清晰，应用场景不太明确；</li>
<li>&hellip;</li>
</ul>
</blockquote>

</details>
<p>多次修改后形成最终的分享，在参加活动前，可以将 PPT 导出上传到议题的页面，可以吸引一些还没决定参与哪场分享的听众。参会者阅读 PPT 可以更有针对性地选择分享会场，并且提前熟悉分享内容，便于跟上演讲者的节奏。</p>
<h3 id="23-演讲">2.3 演讲</h3>
<p>我的议题整理在之前的博客中，如果感兴趣的话可以前往 <a href="https://jiekun.dev/otel">KubeCon 2023 上海：OpenTelemetry 采样分享</a> 阅读。演讲整理确实是个非常辛苦的事情，因为书面用语和口头用语有非常大的差别，建议有钞能力的同学外包给 ChatGPT。</p>
<p>演讲之前，工作人员会特地叮嘱要重复听众的提问，以确保问题能清晰地记录在视频中，活动的视频会在 10 月 13 日之前上传至 Youtube。</p>
<p>在演讲的时候，主办方通常会有摄影师在场，这些视频会在活动后 1 周内上传，但是因为场地很多，所以并不保证每位演讲者都有能回去交差的照片。让随行同事帮忙拍一些保底会更稳妥，或者像我一样与家人一同前往上海，并且找主办方索要短暂入场的允许。</p>
<h2 id="3-小结">3 小结</h2>
<p>以上是对我作为演讲者参与 KubeCon 的一些记录，希望有你感兴趣的内容，也希望能鼓动感兴趣的年轻开发者参与到未来的活动中。</p>
<p>在投稿时，有一些建议我认为对一线开发者是非常有价值的：</p>
<ol>
<li>分享投稿不必介意以前是否有人分享过，不必追求 100% 新颖的想法、内容，更重要的是你希望听众从你这里收获什么。而这些事情会有审稿人替你操心，如果他们觉得不合适，自然会反馈回来；</li>
<li>分享投稿不会要求你的背景，比如职位 Title，是否是 Tech Leader 或者 CTO。同样，审稿人也会根据你的材料 Review 你是否适合完成这次分享。</li>
</ol>
<p>希望在下一次 KubeCon 上认识正在阅读本文的你！</p>
<h2 id="4-更多图片">4. 更多图片</h2>
<p>查看活动照片：<a href="https://www.flickr.com/photos/143247548@N03/albums/72177720311405294">KubeCon + CloudNativeCon + Open Source Summit China 2023</a></p>
<p><img src="https://live.staticflickr.com/65535/53217714240_f8ba6c8ba8_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53220136444_e4921573f8_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53235476845_06a90681c7_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53236882593_21d661b30c_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53236882838_e90578564c_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53236951309_c4e943b31f_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53236950864_f8fd89b392_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53236950874_4539883c7e_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53235001851_2de69ce3c4_o.jpg" alt=""></p>
<p><img src="https://live.staticflickr.com/65535/53234138657_60fa0a956d_o.jpg" alt=""></p>
]]></content>
		</item>
		
		<item>
			<title>KubeCon 2023 上海：OpenTelemetry 采样分享</title>
			<link>https://jiekun.dev/posts/kubecon-2023-otel-sampling/</link>
			<pubDate>Wed, 27 Sep 2023 16:54:21 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/kubecon-2023-otel-sampling/</guid>
			<description>0. 前言 因为一直有关注 Kubernetes 相关的内容，在 4 月 19 日 KubeCon + CloudNativeCon Europe 2023 举行期间，就已经知道时隔 3 年，CNCF 的旗舰会议要回到国内线下举行了。恰逢最近半年学习</description>
			<content type="html"><![CDATA[<h2 id="0-前言">0. 前言</h2>
<p>因为一直有关注 Kubernetes 相关的内容，在 4 月 19 日 KubeCon + CloudNativeCon Europe 2023 举行期间，就已经知道时隔 3 年，CNCF 的旗舰会议要回到国内线下举行了。恰逢最近半年学习重心转向 Observability，往往在起步阶段接触的新东西变多，就容易萌生一点 “自以为是” 和 “向别人分享” 的想法，于是提交了 CFP 碰碰运气。</p>
<p>7 月末得知 Proposal 被接受了，可以看得出来主办方是眷顾新人的。当时心情颇为复杂，一边是可以在更大的舞台跟众多开发者交流，一边是工作还没着落，很多准备材料都还处于原始的阶段。后续又熬过了2个月，熬出了只言片语，也不知道听众的接受度会有多高，所以到正式分享前都非常紧张。整个过程中有很多人给过我建议，特别需要感谢 Juraci Paixão Kröhling、Reese Lee、陆家靖老师和赵梓旗老师的 Review，带着这些的指导意见，我才得以进一步完善我的分享、输出观点。</p>
<p>Slides: <a href="https://docs.google.com/presentation/d/16PHf3XxZBuLjD0b07SMJmk0yfFAHB2jJpMPGgONngRE/edit?usp=sharing">Google Slides</a></p>
<p><img src="../202309-kubecon-otel/photo_1.jpg" alt=""></p>
<div style="position: relative; padding-bottom: 56.25%; height: 100%; overflow: hidden;">
   <iframe src="//player.bilibili.com/player.html?bvid=BV1hH4y1o79V&amp;page=1&amp;autoplay=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="Bilibili Video"></iframe>
</div>

<h2 id="1-可观测性之旅">1. 可观测性之旅</h2>
<p>云原生时代，微服务的使用越来越广泛，大家都将原有的单体服务拆分成小块。趣丸，一家主打兴趣社交和电子竞技的科技公司，亦是如此。在企业内，大部分的项目都运行在 Kubernetes 之上，搭配 Istio。对应用服务的观察，数据来源于服务内 SDK 上报、Istio 以及其他部署在节点上的 Agent。聚焦在分布式追踪这方面，我们每日产生超过百亿的 Span。通用的基础设施能提供非常多的监控指标，但仍有一些不起眼的角落缺乏足够的关注。为了覆盖这些场景，我们探索了 eBPF 的使用，尝试为各种没有 Istio 支持，或者出于各种原因缺乏埋点的应用提供请求级别的可观测性支持。</p>
<p><img src="../202309-kubecon-otel/kubernetes_and_istio.jpg" alt=""></p>
<p>在所有这些探索的过程中，越来越多的数据被送入处理流程。例如，在一个规模中等的集群使用 eBPF 采集数据时，每天有 40 TiB 的 Trace 数据产生。使用这些数据是有成本的，我们必须考虑它是否值得：</p>
<ul>
<li>有多少的 Trace 数据对问题排查有帮助？</li>
<li>怎样做才可以减少这些数据的产生呢？</li>
</ul>
<p>OpenTelemetry 生态中提供了一些简单的手段应对上面的问题。</p>
<h2 id="2-the-opentelemetry-ways">2. The OpenTelemetry Ways</h2>
<p>在详细了解解决方案之前，我们花几分钟再介绍一下分布式追踪。</p>
<p>分布式追踪可以为用户描述一次请求所经历的过程，形成一张调用时序图，我们称这次调用过程调用链路为 Trace。而 Trace 由每个服务或者说服务处理一个请求的过程组成，这些过程称为 Span。下图中，这次调用产生了 4 个 Span，4 个 Span 组成一条 Trace。</p>
<p><img src="../202309-kubecon-otel/trace_and_span.gif" alt=""></p>
<p>一条 Trace 中包含了很多信息，包括各个 Span 的耗时、标记位、自定义的 Key-Value 属性等等。Trace 是由不同服务上报的 Span 串联而来的，如果去做筛选、采样，让每天产生的 1000 万条 Trace 实际上只保留下来 1 万条，可以怎样实现呢？</p>
<p>第一种简单的方法，当请求抵达整个链路中第一个服务时，这个服务为这次请求生成一个独一无二的 Trace ID，以及其他的标记位，这些信息会贯穿整次请求。标记位中包含采样标记位，由服务依照一定的概率或者规则生成，代表要采样或者不采样。Trace ID 、标记位和其他上下文信息通过 RPC Header、Metadata 等方式传播给后续的服务，后续服务遵循第一个服务的采样决定，也随之采样上报或不上报。这种采样的方式称为<strong>头部采样</strong>。</p>
<p><img src="../202309-kubecon-otel/head_sampling.gif" alt=""></p>
<p>头部采样的特点在于，它是由头部服务，或者说第一个产生的 Span 决策的，传播至后续的 Span，整个采样决策发生客户端 SDK 层面，仅有少量被采样的数据允许被发送出去，因此，后续的处理流程中也只有少量数据流转、存储、展示。</p>
<p>头部采样最大的问题在于第一个 Span 的视野非常有限，无法预知未来会发生什么，也就无法依照整个请求是否有错误、是否执行时间过长来做决策。</p>
<p>为了解决这些问题，我们也可以把所有数据都上报，交由一个中间平台暂存、清洗，再决定保留还是丢弃整条 Trace。如下图所示，当请求抵达时，每个服务都将他自身产生的 Span 发送至 OpenTelemetry Collector，Collector 上的尾部采样组件在接收到第一个 Span 后，会等待一段时间（如 5 秒）以继续收集来自其他服务的、具有相同 Trace ID 的 Span。等待结束后，大量 Span 按照 Trace ID 归类，然后对同一个 Trace ID 下的 Span 进行遍历，以检查其中是否包含错误信息、累计耗时是否超过阈值等，有依据地筛选高价值的 Trace 进入后续的流程。</p>
<p><img src="../202309-kubecon-otel/tail_sampling.gif" alt=""></p>
<p>这种采样的模式称为尾部采样，它由 Collector 依据完整 Trace 的信息进行决策，决策的依据比头部采样丰富很多。但是由于需要承载大量临时数据，所以对基础设施要求很高。它的效果在于：</p>
<ul>
<li>持久化的数据有依据、有规律、有价值；</li>
<li>减少了展示有价值数据所需的成本，例如存储资源，并且对提高查询速度也有帮助。</li>
</ul>
<p>需要注意的是，在实际部署中，往往会存在多个 Collector 节点，而同一个 Trace 的不同 Span 是由不同服务产生的，这些服务位于不同地方，尾部采样要求他们都落入相同的 Collector 节点，那么必然需要一层负载均衡架设在 Collector 之前，依照 Trace ID 进行转发。这些负载均衡器可以是另一堆 OpenTelemetry 的 Collector，可以是以 Deployment 或 DaemonSet 形式部署的；也可以直接集成在 Client SDK 中。</p>
<p><img src="../202309-kubecon-otel/lb.jpg" alt=""></p>
<p>以上就是 OpenTelemetry 提供的采样、减少 Trace 数量的现成手段，你可能想知道实施他们需要多少成本，在下一小节中，我们将以一个 Demo 为例进行简要分析。</p>
<h2 id="3-资源使用">3. 资源使用</h2>
<p>为了直观对比头部采样和尾部采样的差异，我们准备了如下图所示的系统，包括：</p>
<ul>
<li>可配置的 Trace 生成器；</li>
<li>OpenTelemetry Collector；</li>
<li>OTLP 协议的 Trace Receiver。</li>
</ul>
<p><img src="../202309-kubecon-otel/benchmark.jpg" alt=""></p>
<p>Trace 生成器自然是根据我们的需要生成 Span；Collector 用于<strong>处理</strong>或<strong>不处理</strong>数据；这些数据最后会被送往 Receiver，进行统计和分析。每个组件的的资源使用量被限制在 4 CPU 和 8 GiB 内存。</p>
<p>在生成器端，有 1% 和 100% 的概率进行上报，模拟头部采样的情况。当生成器 100% 上报时，会由 Collector 暂存数据 5 秒，然后对包含错误和长耗时的 Trace 进行尾部采样。另外还有一组对照组，Collector 不进行尾部采样，直接将所有数据送往 Receiver。所有测试都会执行多次，平均每次处理超过 40 万个 Span，2 万条 Trace。</p>
<p><img src="../202309-kubecon-otel/benchmark_result.jpg" alt=""></p>
<p>在全流程耗时的比较中，可以看到不同采样设计的耗时差异比较大，头部采样 1% 时平均为 20ms，头部采样 100% 时则上涨到了 260ms，在进一步加入尾部采样后，耗时在 600ms 左右，在压力进一步增大时缺少尾部采样的延迟数据是因为其他方面的指标已经超过临界值，所以无法再记录数据。结果很好理解，不同头部采样比例的耗时与每秒发送的 Span 数量是成正比的，正好是 10 倍的关系，而尾部采样中，我们配置了针对错误和耗时的 2 个采样策略，每个策略均会被执行、遍历所有 Span，因此需要一些额外的时间处理，数据才能抵达 Receiver。</p>
<p>在 CPU 使用率方面，1% 头部采样与另外两种采样方案的差别在 15-20 倍左右。当数据 100% 上报时，有无进行尾部采样对 CPU 使用率的影响相对小很多，只有 10% 的上涨。可以猜测，CPU 有更多的时间花在对上报数据的序列化、反序列化等等过程，而非采样决策本身。</p>
<p>我们之前也说过尾部采样需要更多的基础设施资源，这在内存上体现得比较明显。随着每秒上报数量的不断增加，在每秒上报超过 20000 Span 之后，实施尾部采样时所需的内存就超过了 7 GiB，已经到达组件的内存上限了，所以也出现了延迟大幅上涨的情况。相比来说，头部采样 1% 时内存压力就非常小了，仅使用了 200 MiB。所以，为了搭建尾部采样的体系，不少成本需要投资在内存上，例如，测试里处于临界的压力时，同样是 100% 上报，有尾部采样需要使用无尾部采样时接近 2 倍内存资源。</p>
<p>那么投资了这些资源之后，能获得什么呢？我们检查 Receiver 收到的数据，全量上报时平均收集到 22 万个 Span，而 头部采样 1% 和尾部采样只收集到了几千个 Span，数量是大幅减少的。他们之间的量级差距影响的是存储的成本，以及数据检索的性能。尾部采样与头部采样 1% 相比，在较为接近的数据量的前提下，能获取更多对排查有价值的数据，因为尾部采样的结果都是包含 Error 或者总耗时超过 5 秒的 Trace。</p>
<p>以上就是对几个测试场景的对比概述，基于这些结果，我们通常会推荐大家为<strong>每 8000 Span/s 的压力</strong>准备 <strong>1 CPU 和 2 GiB 的内存资源</strong>，这个恰好也是 OpenTelemetry 目前官方的推荐比例。但是这些数字受实际数据集的影响很大，Demo 更多是为了给大家基本的成本印象。</p>
<p>另外一个可能有助于控制成本的建议就是<strong>配置动态化</strong>、中心化，接受信息反馈。OpenTelemetry 和其他分布式追踪平台提供的 SDK 配置都是静态的。可观测性平台作为基础设施的提供方，需要有能力去实时控制用户的配置，这样有助于在发生问题的时候及时调整，防止单点拖垮整个平台。其次，可观测性平台通常也具有数据分析的能力，分析之后的结果可以用于动态修正链路的采样率，让每一分成本都花在更有意义的地方。</p>
<h2 id="4-更有趣的想法">4. 更有趣的想法？</h2>
<p>前面简要分析过一些现成的采样策略，他们能覆盖到生产中的很多场景，但是生产环境的数据的混沌程度远比想象中高，依然会有非常多的边缘 case 无法通过这些策略识别。这一小节针对这些边缘情况介绍和讨论一些未进入 OpenTelemetry 中的采样策略。</p>
<p>以下图为例，左侧的服务 A-E，如果依照顺序进行调用，会得到右侧的 Trace。</p>
<p><img src="../202309-kubecon-otel/an_example.jpg" alt=""></p>
<p>当系统每天有数百万请求，若他们都非常正常一致，通过头部采样即可筛选出其中少数几个，作为问题排查的样例。某一天，系统中出现了一些包含 Error 的调用，或者出现了很慢的调用，那需要进一步通过尾部采样捕获这些样本。</p>
<p><img src="../202309-kubecon-otel/slow_and_error_traces.jpg" alt=""></p>
<p>随着时间的推移，生产环境的数据越来越奇怪，如下图中框住的例子，他们比起正常调用或是多了一个 Span，或者少了一个 Span，但是执行速度很快，也不包含任何错误。这其实非常常见，例如某些逻辑分支会多执行一条 SQL，或者多一次 RPC 调用。</p>
<p><img src="../202309-kubecon-otel/edge_cases.jpg" alt=""></p>
<p>作为开发者，在观察业务健康情况的时候，自然是希望各种不同执行路径的数据都有一定量的样本，那怎么去识别这些所谓的 “执行路径不同” 的调用呢？如果我们这里的数据不是 Trace，而是二叉树，在一堆二叉树中找出与众不同的树，一种暴力的方法是：把所有数据序列化，求 MD5，再找出 MD5 不同的目标，Trace 也可以做类似的处理。</p>
<p>在尾部采样时，对原始的 Trace 数据，按照时间和调用父子关系把 Trace 序列化，并通过摘要计算（如 MD5）得到一个新的结果，这个结果可以称为 Type ID，它代表的是一类请求路径相同的 Trace。如果在 Collector 用简单的频率计数统计每种类型的频率，就可以让所有类型的数据都留下样本。这种方案目前在社区中已有相关提案。</p>
<p><img src="../202309-kubecon-otel/metadata_serialization.jpg" alt=""></p>
<p>但是如果我们考虑成本，这种方案依然是基于尾部采样的，意味着整体处理流程中仍需要足够多的数据上报，这是影响 CPU 和内存用量的主要因素，其次才是遍历和分析过程。那么，有没有办法进一步减少上报的数据量呢？这或许需要从上报的 Client SDK 端入手。</p>
<p>以往，Trace 上下文信息都是自顶向下单向传播的，这让上层 Span 的上报决策无法受下层 Span 的状态影响，也就导致了头部采样决策信息有限的问题。因此我们很容易联想到，如果 Trace 信息能够自底向上反向传递会如何？</p>
<p><img src="../202309-kubecon-otel/context_direction.jpg" alt=""></p>
<p>如下图所示，服务在收到调用时，执行自己的逻辑，在执行过程中如果有任何感兴趣的情况出现（例如有 Error、走入异常分支），可以不遵循头部采样决策，上报自身的 Span，并将这个情况通过 RPC Response 返回给调用方。调用方此时未结束流程，仍有机会根据响应上报 Span。若每个服务都能接受 Response 的采样提示，并返回给自己的调用方，即可形成反向采样，或者回溯采样（Retroactive Sampling）。</p>
<p><img src="../202309-kubecon-otel/retroactive_sampling.gif" alt=""></p>
<p>很显然，这样的采样方式带来几个好处：</p>
<ul>
<li>相比头部采样，它授予了所有应用采样决策的权利；</li>
<li>相比需要收集大量数据的尾部采样，它减少了发往应用之外的数据，降低流通在整个数据采集链路中的数据量，对整体资源成本控制非常有帮助。</li>
</ul>
<p>但是有利即有弊，这种采样无法收集到已经结束的 Span，例如上图中最左侧的服务，在全链路发生错误之前已经完成了请求的处理和响应，因此不会受到任何采样的通知，最终采样的只是完整链路的一部分。其次，这种采样高度依赖统一的通信框架或协议，可以想象，在基建不统一的情况下，想要整个企业都插装、换用协议、修改响应字段（/ Header / Metadata）是非常难推行的。</p>
<p>不过抛开少数障碍来看，比起头部采样和尾部采样，回溯采样的效果仍然是非常让人期待的，是否有办法绕过这些障碍将它落地呢？在探索实现的过程中，我们关注到了今年 NSDI 的一篇论文，解决的痛点和我们的目标很接近，下面来看看它的几个实现要点。</p>
<p>如下图所示，不同的服务位于不同的 Kubernetes 节点，每个节点上均有一个回溯采样的 Agent，在节点之外会存在协调全局的 Collector。当请求发生时，每个服务都将自己的 Span 送往 Agent，Span 中会包含采样决策。正常情况下，Agent 仅与 Collector 交换少量 Metadata，如 Trace ID - Agent ID 关系，让 Collector 知道某个 Trace 的相关数据会存在于哪些 Agent。</p>
<p><img src="../202309-kubecon-otel/hindsight_1.png" alt=""></p>
<p>若后续流程正常，这些 Metadata 和原始数据很快会被丢弃。但若某个服务发现感兴趣的事情，期望采样时，Agnet 会将完整的数据及采样要求发往 Collector，完整数据中会包含面包屑形式的调用路径，如 <code>A-&gt;B-&gt;C-&gt;D</code>。Collector 收到这些信息之后，可以：</p>
<ol>
<li>根据面包屑调用路径寻找对应服务的 Agnet 索要完整 Span 数据；</li>
<li>根据 Trace ID 以及之前收集到的 Metadata 寻找对应 Agent 索要完整数据。</li>
</ol>
<p><img src="../202309-kubecon-otel/hindsight_2.jpg" alt=""></p>
<p>不管以何种方式，Collector 反向请求得到数据后，就可以完成回溯采样，形成一条有价值的 Trace。</p>
<p>这种方式的回溯采样可以节约节点之间的数据传输量，大部分时间里都只有 Metadata 被发往节点之外。当且仅当有问题发生时，Collector 才会索要完整数据。对比尾部采样，它的缺点在于将原来需要 Collector 暂存的数据转移到了应用所在节点上，“严格控制 Agnet 资源的用量” 和 “让 Agnet 尽可能留存数据” 是存在矛盾的，只能在其中作取舍。</p>
<p>但这种回溯采样还是非常有竞争力的，因为它同时满足两个关键点：</p>
<ul>
<li>让每个应用自行决策；</li>
<li>上报数据量少。</li>
</ul>
<p>在资源评估中，我们也可以看到它的潜力，在延迟、带宽、边缘场景覆盖率上，和各种采样方案相比都不落下风，更多的数据可以在论文中查阅。</p>
<h2 id="5-展望">5. 展望</h2>
<p>采样策略自 Dapper 论文发表以来，已经发展了很多年，但是其实我们依然能看到现在主流的头部采样、尾部采样方案各有优缺点，甚至可以说短板仍然很明显。而其他的新兴的采样方案，要么依赖特定基础设施，要么还未经过大规模的实践验证，所以还有很大的发展空间。</p>
<p>OpenTelemetry 作为 CNCF 托管项目中，活跃度仅次于 Kubernetes 的项目，有着非常良好的社区氛围，在可观测性方向可以做的事情也很多，取决于开发者们的想象力。期望有兴趣的同学可以在社区中进一步交流采样和其他各方面的想法。</p>
<h2 id="6-现场组图">6. 现场组图</h2>
<p><img src="../202309-kubecon-otel/photo_2.jpg" alt=""></p>
<p><img src="../202309-kubecon-otel/photo_3.jpg" alt=""></p>
<p><img src="../202309-kubecon-otel/photo_4.jpg" alt=""></p>
<p><img src="../202309-kubecon-otel/photo_5.jpg" alt=""></p>
<p><img src="../202309-kubecon-otel/photo_6.jpg" alt=""></p>
]]></content>
		</item>
		
		<item>
			<title>技术内幕: 构建 Go 语言的动态插装 Agent</title>
			<link>https://jiekun.dev/posts/dynamic_instrumentation_agent/</link>
			<pubDate>Sun, 04 Jun 2023 13:58:25 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/dynamic_instrumentation_agent/</guid>
			<description>TL;DR 我们在 Sqreen （译注：一家安全公司）一直致力于让的安全保护透明无感、接入平滑。最近，我们发布了 Sqreen for Go，它可以在不需要任何代码改动的情况下检测和</description>
			<content type="html"><![CDATA[<h2 id="tldr">TL;DR</h2>
<p>我们在 Sqreen （译注：一家安全公司）一直致力于让的安全保护透明无感、接入平滑。最近，我们发布了 <a href="http://blog.sqreen.com/rasp-for-go">Sqreen for Go</a>，它可以在不需要任何代码改动的情况下检测和阻止 Go 应用中的安全问题。为了实现这一点，我们利用了动态插装（dynamic instrumentation）在运行时向程序中插入额外的安全逻辑。作为我们<a href="https://blog.sqreen.com/tag/dynamic-instrumentation/">动态插装系列</a>的最新发文，这篇文章将要讨论动态插装，Sqreen 的 Go Agent，以及我们是如何把他们结合在一起的。</p>
<p>这种检测和保护是基于 microagent 的，microagent 是一个从运行的程序中获取数据，并与外部组件通信以报告统计信息或特定数据的组件。这里描述的 的，microagent 是一个 Go 包，它与 Sqreen 的后端服务通信。它专门设计用于安全地插装到生产系统中，因此我们用了精妙的（sophisticated）方法来最大化其稳定性，同时让它对性能的影响尽可能小。</p>
<p><img src="../202306-dynamic-instrumentation-agent/microagent.gif" alt=""></p>
<blockquote>
<p>运行中的 Go 程序与 Sqreen 概览：Agent 协程自动启动，并根据我们面板中的配置对程序进行插装。</p>
</blockquote>
<p>Sqreen 的动态插装有很多优点：</p>
<ul>
<li>不需要对应用代码进行修改，因此安装简易便捷；</li>
<li>完整覆盖程序堆栈，包括所有第三方库、标准库和语言的运行时；</li>
<li>安全逻辑可以由中心化的配置面板控制和更新，不需要重新部署运行中的应用。</li>
</ul>
<p>Agent 可以主要分为三个部分：</p>
<ol>
<li>插装引擎，处理让函数（function）增加额外业务逻辑的底层机制；</li>
<li>安全规则引擎，通过调用插装引擎来为函数增加安全防护逻辑。它遵循由 Sqreen 后端下发的高级（high-level）逻辑描述，例如保护 SQL 语句受到 SQL 注入攻击等；</li>
<li>数据记录机制，异步收集安全防护的数据，并定期发送到 Sqreen 后端。</li>
</ol>
<p>接下来的章节详细介绍了我们如何在 Go 语言中解决这个非常有挑战的问题。Go 语言中的标准库 <code>database/sql</code> 将被用作 SQL 注入工具防护组件的示例。</p>
<h2 id="插装-go-代码">插装 Go 代码</h2>
<p>运行时插装在动态语言中有广泛的使用，通常称为 Monkey Patching。但是 Go 是一门强类型的静态语言，用它构建的代码由 Go 编译器变异成包含二进制机器码的程序文件：</p>
<p><img src="../202306-dynamic-instrumentation-agent/compile.jpg" alt=""></p>
<p>在运行时，操作系统和硬件加载并执行这个二进制程序文件：</p>
<p><img src="../202306-dynamic-instrumentation-agent/execute.jpg" alt=""></p>
<p>因此，运行中的 Go 程序其实就是一个运行中的二进制程序。我们通常认为，运行时插装去修改它的二进制代码是不安全、有风险的，在生产环境某些场景中甚至是不可能的。</p>
<h2 id="选择正确的插装方案">选择正确的插装方案</h2>
<p>前面的讨论已经告诉我们所有能做插装的地方了：由开发者手动使用的工具进行源码级别的插装，到针对运行中的程序的硬件级别的插装。这意味着我们有很多方案可以选择。而对于 Sqreen 来说，就是要选择最适合 Sqreen Agent 场景的方案：</p>
<ul>
<li>对开发者友好：易于开发和部署；</li>
<li>适用于生产环境：能将安全防护应用于运行中的程序，高效，可靠且安全。</li>
</ul>
<p>由此可得出以下的表格：</p>
<table>
<thead>
<tr>
<th style="text-align:center">插装类型</th>
<th style="text-align:center">静态插装</th>
<th style="text-align:center">静态插装</th>
<th style="text-align:center">静态插装</th>
<th style="text-align:center">动态插装</th>
<th style="text-align:center">动态插装</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">插装位置</td>
<td style="text-align:center">源代码</td>
<td style="text-align:center">编译器</td>
<td style="text-align:center">二进制程序文件</td>
<td style="text-align:center">运行中的程序</td>
<td style="text-align:center">运行中的程序</td>
</tr>
<tr>
<td style="text-align:center">插装技术</td>
<td style="text-align:center">源代码插装</td>
<td style="text-align:center">钩子函数（探针）插装</td>
<td style="text-align:center">二进制程序文件插装</td>
<td style="text-align:center">二进制程序代码插装</td>
<td style="text-align:center">基于 Trap 的插装</td>
</tr>
<tr>
<td style="text-align:center">开发者友好</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">适用生产环境</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<p>长话短说，我们选择编译时插装技术：</p>
<ul>
<li>它对生产环境没有影响，因为它只在开发环境完成；</li>
<li>它由编译器自动、透明地完成；</li>
<li>它完全在用户空间完成，不需要往返操作系统（内核）；</li>
<li>它具有可移植性，因为它不依赖操作系统或者硬件支持。</li>
</ul>
<p>而其他的插装技术：</p>
<ul>
<li>二进制层面的插装很难在生产环境做到安全可靠；</li>
<li>基于 Trap 的技术（例如用户空间探针）较为低效，因为需要硬件中断。同时它也不具备可移植性，且需要不安全的执行权限；</li>
<li>源代码插装对于开发者来说很难管理，并且只能处理应用程序代码范围的插装。</li>
</ul>
<p>基于以上的分析，我们决定使用编译时插装的技术来为 Go 语言程序添加运行时插装能力。</p>
<h2 id="钩子策略hooking-strategy">钩子策略（Hooking strategy）</h2>
<p>我们需要编译器为 Go 程序中的函数添加插装钩子点位（hook points），以便让 Sqreen 的 microagent 监控和保护函数执行。例如，我们想在 SQL 执行函数添加钩子，检测函数参数中的 SQL 语句是否存在注入情况，并在检测到（注入）攻击时中止函数调用。</p>
<p>为此，我们的钩子策略允许我们通过以下方式监控和保护函数的执行：</p>
<ul>
<li>读取函数参数，监控甚至检测攻击；</li>
<li>可以立即返回，以安全地中止函数调用，防止发生攻击。</li>
</ul>
<p><img src="../202306-dynamic-instrumentation-agent/hook.webp" alt=""></p>
<blockquote>
<p>SQL 执行函数钩子启用时，SQL 注入保护的示例：当语句中检测到注入时，函数需要马上中止，返回一个不为 <code>nil</code> 的错误。</p>
</blockquote>
<p>以下代码段展示了一个被插装的 Go 函数，它使用了之前描述的钩子策略：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="c1">// 这是一个函数的示例，返回给定参数的json序列化结果。
</span><span class="c1">//
</span><span class="c1">// 该函数插装了一个演示的钩子，监控函数调用，以实现保护
</span><span class="c1">// 控制流程，并在必要时中止调用。
</span><span class="c1">//
</span><span class="c1">// 为此，以下插装代码块由两部分组成:
</span><span class="c1">//
</span><span class="c1">// 1. The prolog: 它是插装的起点，挂钩在正常代码执行之前，
</span><span class="c1">//    对应其输入参数。它会返回一个布尔值和 epilog 钩子，
</span><span class="c1">//    当函数调用必须中止时布尔值为 true。
</span><span class="c1">//
</span><span class="c1">// 2. The epilog: 它是由 prelog 返回的函数，用于挂钩在函
</span><span class="c1">//    数返回时以及对应函数返回值。它由 defer 执行，以保证在
</span><span class="c1">//    任何返回情况下均会执行到。
</span><span class="c1">//
</span><span class="c1"></span><span class="kd">func</span> <span class="nf">myInstrumentedFunction</span><span class="p">(</span><span class="nx">a</span> <span class="kt">int</span><span class="p">)</span> <span class="p">(</span><span class="nx">result</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">,</span> <span class="nx">err</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
	<span class="c1">// 插装代码段
</span><span class="c1"></span>	<span class="p">{</span>
		<span class="c1">// prelog 钩子启用。
</span><span class="c1"></span>		<span class="c1">// 注意这个示例不是线程安全的，但我们的实际实现中加载函数值
</span><span class="c1"></span>		<span class="c1">// 是原子（atomically）的。
</span><span class="c1"></span>		<span class="k">if</span> <span class="nx">myInstrumentedFunctionHook</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
			<span class="c1">// 用函数参数调用 prelog 钩子，并检查返回值
</span><span class="c1"></span>			<span class="nx">epilog</span><span class="p">,</span> <span class="nx">abort</span> <span class="o">:=</span> <span class="nf">myInstrumentedFunctionHook</span><span class="p">(</span><span class="nx">a</span><span class="p">)</span>
			
			<span class="c1">// 不管 abort 值如何，epilog 方法总会由 defer 执行以
</span><span class="c1"></span>			<span class="c1">// 观测所有返回情况。
</span><span class="c1"></span>			<span class="k">if</span> <span class="nx">epilog</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
				<span class="k">defer</span> <span class="nf">epilog</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">result</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">err</span><span class="p">)</span>
				
			<span class="p">}</span>
			
			<span class="c1">// 如果 abort 值为 true，则立即从函数中返回。返回前可能
</span><span class="c1"></span>			<span class="c1">// 执行 epilog 函数。
</span><span class="c1"></span>			<span class="k">if</span> <span class="nx">abort</span> <span class="p">{</span>
				<span class="k">return</span>
			<span class="p">}</span>
		<span class="p">}</span>
	<span class="p">}</span>

	<span class="c1">// 正常代码
</span><span class="c1"></span>	<span class="k">return</span> <span class="nx">json</span><span class="p">.</span><span class="nf">Marshal</span><span class="p">(</span><span class="nx">a</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1">// 插装函数的 prolog 钩子
</span><span class="c1"></span><span class="kd">var</span> <span class="nx">myInstrumentedFunctionHook</span> <span class="nx">myInstrumentedFunctionPrologHookType</span>

<span class="c1">// 函数的 prelog 和 epilog 钩子定义，强类型并与函数签名保持一致。
</span><span class="c1"></span><span class="kd">type</span> <span class="p">(</span>
	<span class="nx">myInstrumentedFunctionPrologHookType</span> <span class="kd">func</span><span class="p">(</span><span class="nx">a</span> <span class="kt">int</span><span class="p">)</span> <span class="p">(</span><span class="nx">myInstrumentedFunctionEpilogHookType</span><span class="p">,</span> <span class="kt">bool</span><span class="p">)</span>
	<span class="nx">myInstrumentedFunctionEpilogHookType</span> <span class="kd">func</span><span class="p">(</span><span class="nx">result</span> <span class="o">*</span><span class="p">[]</span><span class="kt">byte</span><span class="p">,</span> <span class="nx">err</span> <span class="o">*</span><span class="kt">error</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><p>你可以在 Go Playground 运行完整的示例代码：<a href="https://play.golang.org/p/zAQaf_rGaRs">https://play.golang.org/p/zAQaf_rGaRs</a></p>
<h2 id="编译时compile-time插装向-go-程序添加钩子点位">编译时（Compile-Time）插装：向 Go 程序添加钩子点位</h2>
<p>Go 编译器默认不提供这种钩子点位插装。但是，代码生成已经很常见，并且在 Go 语言中也有广泛使用。例如，Go 编译器在代码覆盖率或竞态检测中都有使用到这种技术。Go 语言标准库有解析、修改、重新生成Go 代码所需的所有工具。因此，我们选择在一个独立的插装工具中实现安全的源码层面插装，使其能与 Go 编译器集成，生成插装后的 Go 程序文件。</p>
<p><img src="../202306-dynamic-instrumentation-agent/instrument.webp" alt=""></p>
<blockquote>
<p>集成 Sqreen 插装工具到 Go 编译器中并生成插装后的 Go 程序文件。</p>
</blockquote>
<p>这个工具会在每次编译时被 Go 编译器调用，并插装所有定义了的函数。</p>
<p><img src="../202306-dynamic-instrumentation-agent/instrument_2.webp" alt=""></p>
<blockquote>
<p>SQL 执行函数源码层级的插装示例：接收 Go 源码文件作为输入，输出增加了钩子点位插装的新源码。</p>
</blockquote>
<p>原有的源码文件不会被修改，插装后的源码会生成到编译器的构建目录（build directory）中。因此，可以使用 Go 构建选项 <code>-work</code> 来查看插装后的代码，它会打印结果并保留构建目录。</p>
<p>在编译器层级处理插装的另一个好处是，可以完整地对所有 Go 语言涉及到的组件进行插装。我们只对少量的 Go 库包进行了插装，这些库包记录在文档中：<a href="https://docs.sqreen.com/go/instrumentation/#list-of-instrumented-packages">https://docs.sqreen.com/go/instrumentation/#list-of-instrumented-packages</a></p>
<h2 id="运行时插装挂载安全防护逻辑到钩子点位">运行时插装：挂载安全防护逻辑到钩子点位</h2>
<p>基于上述的编译时插装方案，Sqreen 的 Go Agent 现在可以通过钩子表（一个由工具生成的 Go 数组）找到钩子点位，并在需要时进行插装。在 SQL 注入防护的例子中，当我们在面板上启用该功能后，Agent 会收到 SQL 注入安全的规则。它会包括插装 SQL 执行函数（当前一共有 3 个：<code>prepare</code>，<code>exec</code> 和 <code>query</code>）所需的信息，以及 SQL 注入防护逻辑。</p>
<p>借助标准库中的 <code>reflection</code>，钩子点位的 Go 类型（译注：此处应指函数位置、函数签名等信息）也用于检查和挂载防护逻辑。挂载原子操作，在并发使用场景下也是安全的。</p>
<p><img src="../202306-dynamic-instrumentation-agent/runtime_instrument.gif" alt=""></p>
<blockquote>
<p>在这个示例中，Agent 收到 Sqreen 后端的 SQL 注入防护指令。当应用设置中的防护开启，Agent 检索钩子表中的钩子，检验是否和将要挂载的函数类型信息匹配，最后原子地挂载到钩子点位上。</p>
</blockquote>
<p>挂载之后，函数的执行就能被观察到，更重要的是，能在检测到攻击时中止执行。安全防护可以在函数调用上下文进行它的检测，并借助 Go 函数的签名，安全地中止函数调用，返回一个不为 <code>nil</code> 的错误。</p>
<p>我们的安全防护还可以自动通过取消（cancel） Go request context 和根据面板配置响应 HTTP 请求，来中止 HTTP 调用处理。</p>
<p><img src="../202306-dynamic-instrumentation-agent/http.webp" alt=""></p>
<blockquote>
<p>HTTP 请求由 Sqreen 自动管理：根据面板配置进行响应，以及通过取消 Go request context 来中止请求，并正确地传播中止信息。</p>
</blockquote>
<h2 id="数据传输">数据传输</h2>
<p>所有加在请求处理流程中的操作都是设计成异步的，以规避对响应时间的影响。当一个新的 HTTP 请求开始时，我们的中间件函数添加了一些数据结构到请求中，它们可以在挂载的防护中被获取到，用以收集安全相关的信息，例如攻击详情、指标和事件。当请求中止时，请求的数据结构通过非阻塞的 Go channel 异步送往 Agent，这样不会时阻塞到 HTTP 请求的 handler 把它发出去。</p>
<p>Agent 协程大部分时间都在休眠，仅在 Go channel 有数据时被 Go 调度器唤醒。Agent 收集数据，暂存攒批，最后定时发送至我们的后端服务（默认 20 秒一次）。我们的安全防护不收集敏感数据，Agent 会强制清除所有已发送至后端的数据。总而言之，这个实现就是个简单的异步 Go 程序。</p>
<h2 id="性能和鲁棒性">性能和鲁棒性</h2>
<p>Sqreen Go Agent 只使用了标准的 Go 语言技术，但是它所充当的角色需要我们仔细考虑以下几方面：</p>
<ul>
<li>我们关注它对 Go 调度器的影响以及并发场景下的压力。我们通过设定很少的、固定数量的 goroutine 数（目前为 3）来减轻潜在影响。其中一个不错的例子是我们的指标管理，它是基于原子操作的、无锁的。这些都是为了避免 Go channel 替代方案中引入在阻塞操作进而对调度产生影响。这种选择使其执行开销可以忽略不计，并且不涉及任何数据队列管理。这对于存在大量并发、可以管理上千个 goroutines 的 Go 服务来说是非常重要的；</li>
<li>我们通过执行的 deadline 来保证 Agent 有时间和内存用量的边界限制（特别是对于我们挂载的防护），以及各种数据结构的最大长度；</li>
<li>我们关注垃圾回收的压力，通过使用内存池来规避频繁的小内存分配过程。</li>
</ul>
<p>Agent还有针对通信失败、大量请求流量、内部发生非预期的行为的鲁棒性设计，其工作不依赖于后端服务，并且可以重启或者停止工作来保证最大程度的安全可靠。</p>
<h2 id="展望未来">展望未来</h2>
<p>我们在这篇博客中描述了生产级插装 Agent 的上层概念。动态插装 Agent可以用于处理很多不同的任务，例如性能监控、错误监控或安全防护。</p>
<p>在 <a href="https://www.sqreen.com/">Sqreen</a>，我们的 Go Agent 利用动态插装技术来保护应用，并且提高 Go 应用的可观测性。如果对 Sqreen 感兴趣或者想动手试试 Go Agent，可以<a href="https://my.sqreen.com/signup">来 Sqreen 官网转一转</a>。</p>
<p><img src="../202306-dynamic-instrumentation-agent/sqreen.webp" alt=""></p>
<p>请继续期待下一期关于 Go Agent 内部实现的细节介绍！</p>
]]></content>
		</item>
		
		<item>
			<title>可观测性专题: 分布式追踪中的采样</title>
			<link>https://jiekun.dev/posts/sampling-in-distributed-traces/</link>
			<pubDate>Mon, 17 Apr 2023 19:51:13 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/sampling-in-distributed-traces/</guid>
			<description>1. Warm-up 我们常说 Metrics，Logging，Tracing 是可观测性的三大支柱，而其中 Distributed Tracing 就是当前微服务架构下用来排查服务问题的手段之一。 下</description>
			<content type="html"><![CDATA[<h2 id="1-warm-up">1. Warm-up</h2>
<p>我们常说 Metrics，Logging，Tracing 是可观测性的三大支柱，而其中 Distributed Tracing 就是当前微服务架构下用来排查服务问题的手段之一。</p>
<p>下图是由 Zipkin 呈现的可视化调用链路，对于一条完整的调用链路，我们通常用 <strong><code>Trace</code></strong> 来表示，一个 <code>Trace</code> 描述一次请求在（多个）服务中经过的路径。继续细分，每个路径均可称为 <strong><code>Span</code></strong>，<code>Span</code> 代表一个过程，它可以是一次 RPC 调用、中间件调用，也可以是一个 <code>for</code> 循环逻辑。</p>
<p><img src="../202304-sampling-in-distributed-traces/trace_and_span.png" alt=""></p>
<p><code>Span</code> 之间有简单的规则，他们可以相互平行，也可以相互包含。例如右侧这个调用图，Service A 调用 Service B，Service B 调用 MySQL 和 Redis，所以 <code>Span 1</code> 包含其他的 <code>Span</code>，<code>Span 2</code> 包含两次中间件操作，<code>Span 3</code> 和 <code>Span 4</code> 相互平行。</p>
<p><img src="../202304-sampling-in-distributed-traces/relationship_between_spans.png" alt=""></p>
<p>多个 <code>Span</code> 构成一个 <code>Trace</code>，所以需要有东西描述 <code>Span</code>，描述 <code>Trace</code>，描述 <code>Span</code> 和 <code>Trace</code> 之间的关系，它叫 <strong><code>Span Context</code></strong>。定义这样一个 interface，它可以获取当前 <code>Span</code>，可以知道这个 <code>Span</code> 的上级 Span，也可以知道这些 <code>Span</code> 属于哪一个 <code>Trace</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">SpanContext</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="o">...</span>
    <span class="nf">TraceID</span><span class="p">()</span>    <span class="kt">string</span>
    <span class="nf">SpanID</span><span class="p">()</span>     <span class="kt">string</span>
    <span class="nx">ParentSpanID</span> <span class="kt">string</span>
    <span class="o">...</span>
<span class="p">}</span>

</code></pre></div><p><code>Span Context</code> 的具体实现形式不限，例如通过定义结构体来实现：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="c1">// Defination 定义
</span><span class="c1"></span><span class="kd">type</span> <span class="nx">SpanContext</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">TraceID</span>  <span class="nx">TraceID</span> <span class="s">`json:&#34;trace_id&#34;`</span>
    <span class="nx">SpanID</span>   <span class="nx">ID</span>      <span class="s">`json:&#34;span_id&#34;`</span>
    <span class="nx">ParentID</span> <span class="o">*</span><span class="nx">ID</span>     <span class="s">`json:&#34;parent_id,omitempty&#34;`</span>
    <span class="o">...</span>
<span class="p">}</span>


<span class="c1">// Real-world example 示例
</span><span class="c1"></span><span class="p">{</span>
    <span class="s">&#34;trace_id&#34;</span><span class="p">:</span> <span class="s">&#34;d8128872e435850e1c080232c316db96&#34;</span><span class="p">,</span>
    <span class="s">&#34;span_id&#34;</span><span class="p">:</span> <span class="s">&#34;6cd9b539e437e354&#34;</span><span class="p">,</span>
    <span class="s">&#34;parent_id&#34;</span><span class="p">:</span> <span class="s">&#34;2d01366826248d1a&#34;</span><span class="p">,</span>
    <span class="o">...</span>
<span class="p">}</span>

</code></pre></div><p>也可以用一个 Request ID 来实现 <code>Span Context</code>，这个 <code>Request ID</code> 可以分为 3 段，第一段是 <code>Trace ID</code>，第二段是 <code>Span ID</code>，第三段是 <code>Parent Span ID</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="c1">// Defination 定义
</span><span class="c1"></span><span class="kd">type</span> <span class="nx">spanContext</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">RequestID</span> <span class="kt">string</span> <span class="s">`json:&#34;reqiest_id&#34;`</span> <span class="c1">// {TraceID}:{SpanID}:{ParentID}
</span><span class="c1"></span><span class="p">}</span>


<span class="c1">// Real-world example 示例
</span><span class="c1"></span><span class="s">&#34;e9e976fde12bc6745f1c51fa80652d01:000000788c34c719:0000000000000000&#34;</span>
<span class="s">&#34;e9e976fde12bc6745f1c51fa80652d01:010000a1d0a89300:000000788c34c719&#34;</span>
</code></pre></div><p>例如上面这个 <code>Request ID</code> 分属于两个不同的 <code>Span</code>，因此他们有不同的 <code>Span ID</code>，但是他们的 <code>Trace ID</code> 是相同的，说明他们属于同一个 <code>Trace</code>；其中，第二个 <code>Request ID</code> 里面的 <code>Parent Span ID</code> 等于第一个 <code>Request ID</code> 里的 <code>Span ID</code>，说明他们存在调用关系。</p>
<p>随着服务数量的日益增加，承接全量的 Tracing 数据所需的资源越来越多。我们先简单算一下，如果某个链路的调用量 4000 QPS，每个调用产生大概 30 个 <code>Span</code>，每个 <code>Span</code> 大约 500 Byte，那一天产生的数据就是：</p>
<blockquote>
<p>4000 * 30 * 500 Bytes * 24 Hours = 4.7 TiB</p>
</blockquote>
<p>如果有 100 个调用链路入口，那每天就能产生 <strong>400 TiB</strong> 的数据。要完整接下这些数据比较困难，因此需要借助<strong>采样</strong>来减少数据量。</p>
<p>本文 2、3 节介绍是当前 Distributed Tracing 中常用的采样策略，第 4 节和第 5 节介绍两篇论文，代表 Distributed Tracing 采样的研究方向，亦作为现有策略的发散和补充。</p>
<h2 id="2-head-sampling-and-unitary-sampling">2. Head Sampling And Unitary Sampling</h2>
<p>通常来说，<code>Trace ID</code> 里面可以携带一些信息，例如下图的实现方式：<code>Trace ID</code> 转成二进制后，用了最后 8 位作为标记位，其中最后两位分别是 <code>Sample Flag</code> 和 <code>Debug Flag</code>。</p>
<p><img src="../202304-sampling-in-distributed-traces/head_based_sampling.png" alt=""></p>
<p>因为同一个 <code>Trace</code> 中，各个 <code>Span Context</code> 都持有相同的 <code>Trace ID</code>，因此他们都会遵循 <code>Trace ID</code> 中的采样标记。<code>Trace ID</code> 是在调用链路入口的地方就生成好的，也就是调用链路开头，所以这种采样决策称为 <strong>头部采样</strong>。</p>
<p>这种采样方式的特点是非常轻量，也保持了 Trace 的连贯性（我们后面会提及一些不连贯的采样方式），它是在应用上报的时候采样的，没命中采样标记位的数据不会上报，不产生网络、磁盘 I/O，最终只有少量数据送往应用之外。</p>
<p>我们现在换一个视角考虑采样问题，如果我们是一个中间服务，例如下图中的蓝色服务，它的上游有 1000 QPS 的调用量和固定 0.1% 的头部采样率，但是它自身仅收到其中的 3% 调用，最终每秒仅能上报 0.03 次。</p>
<p><img src="../202304-sampling-in-distributed-traces/downstream_aspect.png" alt=""></p>
<p>我们知道通过 Trace 除了观察外部的调用链路以外，也可用于观察自己服务内打点上报的内容，例如自身对 MySQL、Redis 的调用。在这个场景里面，中间服务由于极低的上报率，难以借助 Trace 观测到自身的问题。难道它就没有任何办法去影响采样决策？当然是有解法的，对于愿意忽略上下文，把 Trace 当做服务内可观测性强化工具使用的场景，可以使用单元采样的策略。</p>
<p>假设入口处采样率为 0.1%，正常情况下，下游所有服务都要遵循它的决策。而单元采样允许链路中某个小单元忽略采样标记位，无视上下文强行上报，它可以保证单元内的调用链路是完整采集的，但是缺失外部上下游的信息。例如图里的服务无视上下游100%上报，最后能看到的结果就是 0.1% 的 <code>Trace</code> 是完整的、连贯的，另外99.9% 的 <code>Trace</code> 只有它自己应用内的一些调用链路。</p>
<p>具体举例子，下图深色的 <code>Span</code> 是开启了单元采样的服务产生的，浅色的 <code>Span</code> 是其他服务产生的。0.1% 的 <code>Trace</code>（就全链路而言）是完整的，而 99.9% 的 <code>Trace</code> 仅部分完整。</p>
<p><img src="../202304-sampling-in-distributed-traces/unitary_sampling_2.png" alt=""></p>
<h2 id="3-tail-based-sampling">3. Tail-based Sampling</h2>
<p>在讨论尾部采样之前，我们要知道头部采样有什么样的缺点。由于 <code>Trace</code> 诞生瞬间，它的命运就已经决定了，所以它不能知道未来是否会发生错误、是否会阻塞很久，这些信息无法作为采样决策的依据，那就会导致我们使用了大量空间存放正常 <code>Trace</code>，丢失很多异常 <code>Trace</code>。</p>
<p>例如下图，一段时间内，共有 10w 个正常 <code>Trace</code> 以及少量错误或者长耗时 <code>Trace</code>，0.1% 采样的结果极有可能是留存 100 个 正常 <code>Trace</code>。</p>
<p><img src="../202304-sampling-in-distributed-traces/troubles_of_head_based_sampling.png" alt=""></p>
<p>我们理想的效果更应该是：有问题的 <code>Trace</code> 全部保留，并且搭配一些正常 <code>Trace</code> 作为样本，怎样才能达到这个效果呢？</p>
<p>通常 Tracing 基础设施的架构都可以用下图来概括，不同服务把数据上报到 Collector，Collector 兼容不同服务上报的数据格式，对 Trace 平台后端输出统一格式的数据，后端把数据落库，并且提供接口让前端查询和展示。那这里存在一个中间的 Collector，看起来非常适合做数据的收集和分析。我们很容易考虑让 Collector 临时承载所有数据，等到 Trace 结束再依据其中信息做采样决策。</p>
<p><img src="../202304-sampling-in-distributed-traces/typical_tracing_architecture.png" alt=""></p>
<p>这种采样方式叫尾部采样，因为它是在调用结束的时候才决策的。通常 Collector 在一个 <code>Trace</code> 第一个 <code>Span</code> 抵达的时候会将它暂存一段时间，等待这个 <code>Trace</code> 的其他 <code>Span</code> 也上报上来。等待窗口期结束后，按照 <code>Trace ID</code> 组织好各个 <code>Span</code> 的数据，然后使用不同的 Filter 对这些 <code>Span</code> 进行遍历，例如检查里面有没有携带错误信息的 <code>Span</code>，或者 <code>Span</code> 里面有没有一些自定义的 Tag 等等。依据这些信息决定丢弃还是保留这个 <code>Trace</code>，最后按照 Trace 后端约定的格式输出。</p>
<p><img src="../202304-sampling-in-distributed-traces/tail_based_sampling.png" alt=""></p>
<p>尾部采样的好处是可以尽可能观察到整个 <code>Trace</code>，取决于暂存的时间窗口有多宽，因为特殊情况有的 <code>Trace</code> 可以长达数分钟，还是存在在不完整的情况下做决策的可能的。因为需要大量内存来暂存数据，所以尾部采样对基础设施的要求很高，它减少了最终送达 Trace 后端落库的数据量，并且不像头部采样一样都是些没用的数据。理想情况下它可以自由控制后端数据的比例，例如正常 <code>Trace</code> 占 30%，异常 <code>Trace</code> 占70%。</p>
<h2 id="4-capturing-more-needles-and-less-hay">4. Capturing More Needles And Less Hay</h2>
<h2 id="5-one-step-forward-tracing-edge-cases">5. One Step Forward: Tracing Edge-Cases</h2>
<h2 id="6-conclusion">6. Conclusion</h2>
]]></content>
		</item>
		
		<item>
			<title>写在 2023 年初的后端社招面试经历（四年经验）：字节 米哈游 富途 猿辅导</title>
			<link>https://jiekun.dev/posts/2023-interviews/</link>
			<pubDate>Sun, 26 Feb 2023 13:28:22 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2023-interviews/</guid>
			<description>目录 背景 面试准备 面试 字节跳动 米哈游 富途牛牛 猿辅导 总结 一些推荐 1. 背景 距离上一次面试已经过去快 3 年了，又碰上 2022 年互联网行业大动荡，很多企业都做出</description>
			<content type="html"><![CDATA[<h2 id="目录">目录</h2>
<ol>
<li><a href="#1-%E8%83%8C%E6%99%AF">背景</a></li>
<li><a href="#2-%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87">面试准备</a></li>
<li><a href="#3-%E9%9D%A2%E8%AF%95">面试</a>
<ul>
<li><a href="#31-%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%9B%BD%E9%99%85%E5%8C%96%E7%94%B5%E5%95%86">字节跳动</a></li>
<li><a href="#32-%E7%B1%B3%E5%93%88%E6%B8%B8">米哈游</a></li>
<li><a href="#33-%E5%AF%8C%E9%80%94%E7%89%9B%E7%89%9B%E4%BA%92%E8%81%94%E7%BD%91-%E5%9F%BA%E7%A1%80%E6%8E%A5%E5%85%A5">富途牛牛</a></li>
<li><a href="#34-%E7%8C%BF%E8%BE%85%E5%AF%BC%E5%A4%A7%E7%9B%91%E6%8E%A7-%E6%97%A5%E5%BF%97">猿辅导</a></li>
</ul>
</li>
<li><a href="#4-%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#5-%E4%B8%80%E4%BA%9B%E6%8E%A8%E8%8D%90">一些推荐</a></li>
</ol>
<h2 id="1-背景">1. 背景</h2>
<p>距离上一次<a href="https://jiekun.dev/posts/2020-03-28-shopee%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/">面试</a>已经过去快 3 年了，又碰上 2022 年互联网行业大动荡，很多企业都做出了裁员决定。身为互联网人要时刻关注自身成长，所以会对 “跟面试官切磋” 这种事情比较感兴趣，其实也是一种打探行情的手段：</p>
<ul>
<li>3 年间自己的技术是线性成长、指数成长还是对数成长，跟同龄人相比如何？</li>
<li>当前求职是买方市场还是卖方市场？</li>
</ul>
<p>因此收集这两个信息是我面试<strong>最初的目的</strong>，当然整个过程很长，<strong>最终的选择</strong>也会受很多事情影响。</p>
<h2 id="2-面试准备">2. 面试准备</h2>
<p>毕业之后我在两家公司工作过，触及的业务包括营销数据分析、供应链物流、社媒广告投放等。每个领域包含的内容都比较多，除非是手上正在负责，其它内容想回忆起来是相当难的。因此在简历撰写上，<strong>尽量将业务转化为技术模型</strong>，好处在于：</p>
<ol>
<li>让面试官能更多地从技术角度切入谈某项业务；</li>
<li>求职方向更灵活，没做过这项业务的面试官也有问题可问；</li>
<li>减少自己复习过往业务的时间（<strong>摆烂</strong>）。</li>
</ol>
<p>正常来说简历准备好之后，要有具体的专业知识做支撑。考虑到工作年限不长，所以仍是以基础为准，对接触一线业务的后端来说计算机网络、数据库、操作系统三大块是一定绕不开的，在此之上搭建分布式、微服务架构、服务治理等知识框架。最后补充对工作项目的思考，例如做的项目在业界中是否有竞争对手、大家的方案横向对比有什么优劣点，自己的创新点在哪里等等。</p>
<p><strong>但是</strong>面试准备是服务于我的面试目的的，基于<strong>评估自身技术水平</strong>的想法，我最终也没有拿起课本，而是决定看看在 “<strong>不刻意准备</strong>”（<strong>摆烂</strong>）的情况下能表达到什么程度。个人不认为裸面（again，<strong>摆烂</strong>）是个好的、值得推广的实践，这导致在面试的时候很多问题（例如：是否了解 Kafka、是否了解一致性哈希）我选择直接回答 “不会”、“没了解过” 来避免 follow up questions，但是在一些特殊背景下确实可以更真实反映出自身的水平。</p>
<p>当然，面试中有一些比较 “硬” 的条件要求（算法题咱说的就是你）是须要有所积累的。因为本身不擅长算法，解新题其实会需要一定的时间，所以我选择反复写 Top 100 Like 的老题目来保持手感。
<img src="../202302-2023-interviews/leetcode.png" alt=""></p>
<p>最后关于求职方向的选择，更多是出于个人偏好，不具备什么可参考性。对我来说，由于未来倾向于换到云原生相关的赛道，那自然是以基础架构相关的岗位为主。但是找到 100% 符合目标的职位其实是很难的，而且所谓的 “云原生”、“基础架构” 本身就是个非常大的范围，其中细分方向、职能无数。征询了一些朋友的意见，最后也是尽可能地往目标方向靠拢即可。</p>
<h2 id="3-面试">3. 面试</h2>
<p>求职过程中，有一些公司是直接拒掉了简历的，一方面是简历比较普通，其次也可能确实没有招人的需求。这也是符合预期的，平时大家开发的时候 <a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">Liveness Probes</a> 也会有失败，说明（简历）该回炉重造了。Anyways，最终进入面试流程的有 4 家，如果只对其中某一家感兴趣的话可以从导航目录直接跳过去。</p>
<p>在面试过程中我都会进行录音，这是个很有收益的事情，过往面试中我观察到有些同学会自认为回答得 “尚可”，殊不知很多细节只是在脑中形成思路，在表述上则是断断续续。任何细节的缺失在面试官听来都可能导致理解上的差异，最终予以不够好的评价。面试后听录音重新 Review 面试，可以从面试官的角度听自己的回答，也方便整理面试经历。</p>
<h3 id="31-字节跳动国际化电商">3.1 字节跳动（国际化电商）</h3>
<p>字节的面试流程是组内面试官-&gt;组外面试官(交叉面)-&gt;组内面试官，当然因为菜的原因没继续走到第三面。两位面试官都很感兴趣所做的业务，聊业务的比重也是 4 家中最多的。另外字节的面试的时候有个小插曲，二面刚好是疫情爆发最严重的时候，顶着发烧面试也算是一次独特的经历吧。</p>
<p>详细记录：<a href="https://jiekun.dev/posts/2022-bytedance-interview/">写在 2022 年末的字节跳动面试复盘</a></p>
<h4 id="一面摘录">一面摘录</h4>
<ul>
<li>了解索引下推吗？什么情况下会下推到引擎去处理？
<ul>
<li>通过某个索引没办法按顺序地覆盖所有的查询条件，但是仍然可以利用索引内存在的字段（尽管不是有序的，需要扫描）去进一步过滤；</li>
<li>举例：idx(a,b,c,d)，查询条件为 a=? and b=? and d=?，发生下推减少回表数量；</li>
</ul>
</li>
<li>什么场景下索引会失效？
<ul>
<li>场景有很多，但是如果我是一个引擎，我关注的不是什么情况会失效，而是走什么路径所花费的随机 I/O 和顺序 I/O 最少，如果走某个索引花费的随机 I/O 比从聚簇索引（顺序）查（成本）都还要高，那还不如直接去全表扫描；</li>
<li>典型例子：捞超过全表 30% 的数据；</li>
</ul>
</li>
<li>有没有具体一点的例子？
<ul>
<li>还是刚刚提到的例子，比如说我要按照 update_time 去做范围查询，捞很多的数据，即使 update_time 有索引，也会选择全表扫描；</li>
</ul>
</li>
<li>WHERE id NOT IN (?, ?, ?) 会走索引吗？
<ul>
<li>还是要看成本；</li>
<li>举例：id 字段只包含 3 个值，1、2、3，3 只有几行，而 1、2 各有 100w 行，如果查询条件是 NOT IN (1, 2) 会走索引，如果查询条件是 NOT IN (3) 不会走索引。</li>
</ul>
</li>
</ul>
<p>反问环节</p>
<ul>
<li>团队里面大约有多少个仓库、部署了多少服务（大致规模）？</li>
<li>这些项目会做单元测试吗，或者说平时的自测、代码质量保障是通过什么方式做的？
<ul>
<li>工具类的库会写单测；</li>
<li>自动化测试会由流量回放平台，QA 执行常用的用例；</li>
</ul>
</li>
<li>整个流量回放都是 QA 负责的吗？
<ul>
<li>后端需要在代码里面做配合；</li>
</ul>
</li>
<li>一个业务迭代版本是怎么安排时间发布的呢，比如说是每周固定发布还是说测试完成后的几天发布？
<ul>
<li>按双月来排期，产品拟定优先级， 研发扣除 oncall 等时间分配任务；</li>
</ul>
</li>
<li>oncall 那周安排多少时间精力做 oncall 和其它问题？
<ul>
<li>80% 时间在 oncall，剩下的时间会看情况修复一下线上和其他的小问题；</li>
</ul>
</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
<h4 id="二面摘录">二面摘录</h4>
<ul>
<li>这种（短链接服务）场景里面写入（创建短链）耗时长可否容忍？
<ul>
<li>一定程度上是 OK 的因为创建短链的请求比访问短链的请求少很多，容忍度更高；</li>
</ul>
</li>
<li>在这个大量 KV 数据读写的场景，为什么不考虑直接使用 KV 存储或者 Redis 来支撑？
<ul>
<li>考虑过，但是短链服务本质上更需要背后收集到的访问数据来体现业务价值，而访问数据的聚合分析需要数仓，公司内没有很好的 KV 存储到数仓的支持，不想当小白鼠；</li>
</ul>
</li>
<li>为何不考虑数据仓库提供 HBase 来支持读写，节约掉 MySQL / KV 存储同步到数仓的过程？
<ul>
<li>嗯，好像是个可考虑的想法，但是不太了解 HBase；</li>
</ul>
</li>
<li>能说一下 LevelDB 的存储结构吗？
<ul>
<li>内心：完了写上简历了但又没复习，啥都不记得了；</li>
</ul>
</li>
<li>算法：定义 Redis 跳跃表的结构，再实现一版它的插入方法。
<ul>
<li>内心：orz。</li>
</ul>
</li>
</ul>
<p>反问</p>
<ul>
<li>在字节的技术人对于公司的基础架构的满意程度如何？
<ul>
<li>该有的都有；</li>
</ul>
</li>
<li>外出参加技术会议、交流在字节里机会是否丰富？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
<h3 id="32-米哈游">3.2 米哈游</h3>
<p>整体来说面试问题都很基础和简单，能不能通过的话（如果没特意复习）就靠平时的积累了。Golang 岗位里对数据结构的提问非常频繁，个人认为对 <code>map</code>、<code>sync.Map</code>、<code>context</code>
等的熟悉程度应该达到能完整记忆每个结构体字段的水准。</p>
<p>详细记录：<a href="https://jiekun.dev/posts/2023-mihoyo-interview/">2023 年初的米哈游面试复盘</a></p>
<h4 id="一面摘录-1">一面摘录</h4>
<ul>
<li>
<p>Go 里面使用 Map 时应注意问题和数据结构？</p>
<ul>
<li>可以通过定义 value 为 struct 来节约内存；</li>
<li>哈希分桶的结构，用哈希值的高八位和低八位分别来做桶内定位的依据和分桶的依据等；</li>
</ul>
</li>
<li>
<p>Map 扩容是怎么做的？</p>
<ul>
<li>依照 Redis 渐进式 rehash 的思路说了一版；</li>
</ul>
</li>
<li>
<p>Map 的 panic 能被 recover 掉吗？了解 panic 和 recover 的机制吗？</p>
<ul>
<li>不懂，但是实际上是不可以的，具体原因可以看看 Map 并发读写的时候抛出的是什么，是不是普通的 panic；</li>
</ul>
</li>
<li>
<p>Map 怎么知道自己处于竞争状态？是 Go 编码实现的还是底层硬件实现的？</p>
<ul>
<li>通过结构体中的标记位实现的，可能是通过 CAS 操作的；</li>
</ul>
</li>
<li>
<p>CAS 具体是怎么实现的呢？</p>
</li>
<li>
<p>并发使用 Map 除了加锁还有什么其他方案吗？</p>
</li>
<li>
<p>有对比过 sync.Map 和加锁的区别吗？</p>
</li>
<li>
<p>说一下（Redis）分布式锁的实现？</p>
<ul>
<li>setnx / 唯一 value / ttl</li>
</ul>
</li>
<li>
<p>基于 Redis 的分布式锁会有什么问题？</p>
<ul>
<li>主从模型下同步不保证一致会导致锁失效</li>
</ul>
</li>
<li>
<p>Redis 分布式锁超时可以超时时间设长一点可以吗？不可以的话需要怎么解决？</p>
<ul>
<li>不根本解决问题，可以考虑旁路的 goroutine 不断自旋续期</li>
</ul>
</li>
<li>
<p>对 Redis 锁续期这个怎么实现呢？</p>
</li>
<li>
<p>日常在用的 Redis 集群都是什么架构？在主从模式和 Redis Cluster 中分布式锁会有什么问题？</p>
</li>
</ul>
<p>反问</p>
<ul>
<li>Golang 在米哈游的使用场景？</li>
<li>项目组的一些细节，代码组织、管理形式等是怎样的？</li>
<li>项目质量的保障手段有哪些，单元测试覆盖率要求如何？</li>
<li>测试的同学主要以白盒测试还是黑盒测试为主？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
<h3 id="33-富途牛牛互联网-基础接入">3.3 富途牛牛（互联网-基础/接入）</h3>
<p>4 家中富途牛牛问的基础知识是最多的，给我印象很深刻的是跟每位面试官的沟通都（提）很（示）顺（很）畅（多），那因为一些不熟悉的知识点我基本是依靠同类的工具去类比和猜想，面试官很愿意听我的这些猜想，有些思路上和所问的实现确实是不同的，面试官会提出来那（正确实现中）某某问题是如何（在我提出的实现中）解决的，引导我慢慢靠近或者推导出正确实现。</p>
<p>我认为作为面试官，这些应该是标配培训的能力，但是实际上在面试中能见到的甚少，一是面试时间有限，二是作为面试官一天面试很多人，耐心难免也会有消磨，这都是可以理解的。所以实际上能做到如此的话，对面试者确实会是非常好的体验。</p>
<p>详细记录：<a href="https://jiekun.dev/posts/2023-futu-interview/">2023 年初的富途牛牛面试复盘</a></p>
<h4 id="一面摘录-2">一面摘录</h4>
<ul>
<li>问一段代码输出结果？</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test1</span><span class="p">())</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test2</span><span class="p">())</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test3</span><span class="p">())</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test4</span><span class="p">())</span>

	<span class="k">return</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test1</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">v</span><span class="p">)</span>
	<span class="k">return</span> <span class="nx">v</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test2</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="kd">func</span><span class="p">()</span> <span class="p">{</span>
		<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">v</span><span class="p">)</span>
	<span class="p">}()</span>
	<span class="k">return</span> <span class="mi">3</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test3</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">v</span><span class="p">)</span>
	<span class="nx">v</span> <span class="p">=</span> <span class="mi">3</span>
	<span class="k">return</span> <span class="mi">4</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test4</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="kd">func</span><span class="p">(</span><span class="nx">n</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
		<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">n</span><span class="p">)</span>
	<span class="p">}(</span><span class="nx">v</span><span class="p">)</span>
	<span class="k">return</span> <span class="mi">5</span>
<span class="p">}</span>
</code></pre></div><ul>
<li>Golang 标准库中 map 的底层数据结构是什么样子的？</li>
<li>Map 的查询时间复杂度如何分析？</li>
<li>极端情况下有很多哈希冲突，Golang 标准库如何去避免最坏的查询时间复杂度？</li>
<li>Golang map Rehash 的策略是怎样的？什么时机会发生 Rehash？</li>
<li>Rehash 具体会影响什么？哈希结果会受到什么影响？</li>
<li>Rehash 过程中存放在旧桶的元素如何迁移？</li>
<li>并发环境共享同一个 map 是安全的吗？
<ul>
<li>panic</li>
</ul>
</li>
<li>如果并发环境想要用这种哈希容器有什么方案？
<ul>
<li>sync.Mutex / sync.RWMutex</li>
<li>sync.Map</li>
</ul>
</li>
<li>加锁存在什么问题呢？</li>
<li>sync.Map 比加锁的方案好在哪里，它的底层数据结构是怎样的？
<ul>
<li>缓存 + map 组成的结构</li>
<li>底层 map 的操作依然是加锁的，但是读的时候使用上缓存可以增加并发性能</li>
</ul>
</li>
<li>sync.Map 的 Load() 方法流程？</li>
<li>sync.Map Store() 如何保持缓存层和底层 Map 数据是相同的? 是不是每次执行修改都需要去加锁？
<ul>
<li>或许是通过加锁和 CAS 保证的？（面试官：它下面还有一些 tricky 的思路，面试结束可以再去看看）</li>
</ul>
</li>
<li>channel 被 close 操作之后进行读和写会有什么问题？</li>
<li>未被初始化的 channel 进行读写会有什么问题？</li>
<li>channel 底层数据结构是怎样的，尝试用结构体来表述一下？</li>
</ul>
<p>反问</p>
<ul>
<li>了解面试部门的基本情况？</li>
<li>部门内微服务的数量？每个研发大概会负责多少服务的开发工作？</li>
<li>C++ 和 Golang 在团队内的使用场景和比例？</li>
<li>研发对开发质量的保障是如何完成的，测试和覆盖率是否有要求？</li>
<li>研发和测试的人员配置比例？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
<h4 id="二面摘录-1">二面摘录</h4>
<ul>
<li>
<p>如果做一个翻译服务，翻译能力来自于供应商，如何从技术上对几家（A、B、C）供应商作出评估？</p>
</li>
<li>
<p>如果几家都要接入，且各家之间的翻译能力都各有优劣，那应该如何去搭建这个服务的框架？</p>
<ul>
<li>调度器</li>
<li>数据采集 / 反馈机制，帮助调度器更好地工作</li>
<li>可扩展性，固化供应商的接入标准，方便未来扩展更多供应商选择</li>
</ul>
</li>
<li>
<p>除了回答的这些方面，一个服务的设计还需要注意什么？</p>
<ul>
<li>正常服务应该提供的网关，包括鉴权、限流、多租户</li>
<li>提供给外部的服务需要注意 SLA，SLA 则围绕日志、监控、Tracing 做文章</li>
</ul>
</li>
<li>
<p>一副扑克牌中随机取 5 张，取到顺子的概率是多少？</p>
<ul>
<li>Hint 1：一种花色有多少种顺子？9 种</li>
<li>Hint 2：一个顺子有 5 张牌，有多少种组合可能？4 ^ 5 种</li>
<li>Hint 3：分子已经知道了，分母怎么表示，n 张取 m 张怎么表示？</li>
</ul>
</li>
</ul>
<p>反问</p>
<ul>
<li>项目基本都是微服务 &amp; Kubernetes 这套方案吗？</li>
<li>研发跟基础设施打交道能到什么样的深度，例如能使用 Kubernetes 的那些内容，中间件的使用权限上有什么样的管控？</li>
<li>正常业务的 CI/CD 里面都做了/集成了多少测试或检查？</li>
<li>业务的研发能在 Kubernetes 上具体写哪些东西呢，例如 sidecar、operator 等等？
<ul>
<li>有专门的团队去做，但是还在起步阶段，大家都可以贡献；</li>
</ul>
</li>
</ul>
<h4 id="三面摘录">三面摘录</h4>
<ul>
<li>
<p>数据库迁移的原因是什么？</p>
</li>
<li>
<p>完成迁移之后 DB 成本降低多少？</p>
</li>
<li>
<p>迁移过程中双读双写具体是什么样的方案？</p>
</li>
<li>
<p>双写过程中只写成功了其中一个 DB，返回给用户报错，那是否会存在脏数据呢？</p>
</li>
<li>
<p>双读具体是什么方案，其中一个读成功了就返回还是要两个都读成功才可以？</p>
</li>
<li>
<p>HTTP 流量的录制工具主要是做什么用呢？</p>
</li>
<li>
<p>HTTP 流量录制会涉及到一些登陆态的处理吗？</p>
</li>
<li>
<p>掷骰子，游戏规则：希望结果尽可能大，如果对第一次的结果不满意可以掷第二次，但是第一次结果就作废了，以第二次的结果为准。这个掷骰子结果的数学期望是多少呢？</p>
<ul>
<li>Hint 1：如果第一次扔到 6，还考虑扔第二次吗？如果第一次扔到 1 考虑吗？</li>
<li>Hint 2：那什么情况考虑扔第二次，什么情况不考虑？</li>
</ul>
</li>
<li>
<p>输入两个整数 a 和 b，输出他们相除的结果，如果有循环小数用括号表示。如：</p>
<ul>
<li>a=-1，b=2，输出 &ldquo;-0.5&rdquo;</li>
<li>a=1，b=3，输出 &ldquo;0.(3)&rdquo;</li>
<li>a=10，b=80，输出 &ldquo;0.125&rdquo;</li>
<li>a=-100，b=10，输出 &ldquo;-10&rdquo;</li>
</ul>
</li>
</ul>
<p>三面反问</p>
<ul>
<li>一、二、三轮的面试官都是团队中的什么角色呢？</li>
<li>组织架构中小组、中心的概念和规模？</li>
<li>作为管理者如果看到团队中的技术氛围比较欠缺，会考虑什么样的手段（去提升）呢？</li>
<li>在已有组件能支撑业务的情况下，如何看待 Member 提出的一些组件的升级或引入呢？</li>
<li>对于 CI/CD 这块，可能不会直接产生业务影响（例如更高的订单量），在公司的现状如何，以及如何看待将时间投入在这上面呢？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
<h3 id="34-猿辅导大监控-日志">3.4 猿辅导（大监控-日志）</h3>
<p>其实最初有一点点惊讶原来猿辅导在国家一些政策影响下仍在继续活跃。由于投递的是更贴近基础设施的岗位，很多问题能听得出来都是从基础架构工程师的角度发问的。另外它们家的面试有一个比较印象深刻的点就是，每位面试官都喜欢问：“你觉得 XXXXX”，例如 “你觉得哪些项目挑战最大”、“你觉得这里面最难的点在哪里”。不过作为投递里面唯一完全没接触过的领域，他们问的很多问题我都非常有兴趣继续探讨下去，也是少有的关注简历上<a href="https://gist.github.com/jiekun/ac4387b613e91c2d4142df35614cab34"><strong>CDC同步方案</strong></a>的团队。</p>
<p>详细记录：<a href="https://jiekun.dev/posts/2023-yuanfudao-interview/">2023 年初的猿辅导面试复盘</a></p>
<h4 id="一面摘录-3">一面摘录</h4>
<ul>
<li>为什么存储要从 TiDB 迁移到 MySQL？</li>
<li>迁移过程中有遇到过什么问题或者有难度的挑战吗？</li>
<li>说下这些问题（双写一致性、迁移前后数据核对）怎么解决的吧？</li>
<li>设计不锁表、数据版本不回绕的数据迁移方案具体是要解决怎样的问题呢？</li>
<li>怎么理解可观测性（Observability）？</li>
<li>Redis 有看过源码吗，贡献过什么 Feature？</li>
<li>Redis 6 里面的 Threaded I/O 是想解决什么问题？</li>
<li>讲一下 WiscKey 论文，想解决的是什么场景问题？ KV 分离能解决写放大的问题吗？</li>
</ul>
<p>写代码</p>
<ul>
<li>一个有序数组，按某个位置进行旋转，如 [1,2,3,4,5] 变成 [3,4,5,1,2]，在这个旋转后的数组中查找给定值；</li>
</ul>
<p>反问</p>
<ul>
<li>部门里面目前在负责那些日志相关的事情，例如是要搭建日志平台，或者现有日志平台的运维方，还是负责使用方的接入？</li>
<li>现在日志的体量大约是多少 PB，每天有多少日志需要采集收录？</li>
<li>日志的采集现在是怎么做的呢？</li>
<li>职位 OnCall 的情况如何？</li>
<li>这个日志平台还未正式上线的话，以往业务团队是怎么查询的呢？</li>
</ul>
<h4 id="二面摘录-2">二面摘录</h4>
<ul>
<li>短链接唯一 ID 设计这块挑战是什么？</li>
<li>针对相同长链接，会生成相同的还是不同的短链接，（两种方案分别是）怎么实现的？</li>
<li>数据迁移的过程中遇到什么问题？</li>
<li>为什么要为这些业务设计 ClickHouse 的存储？OLAP 和离线数仓的差别在哪里？</li>
<li>讲一下 Trace 的数据模型，什么是 Span，Trace ID 和 Span ID 是怎么设计的？</li>
<li>Metrics 的数据模型有了解吗？</li>
<li>LSM-Tree 和 B+ Tree 的本质区别是什么呢？</li>
<li>LSM-Tree 有很多实现，能不能用 B+ Tree 作为其中的一种方案呢？用 B+ Tree 代替原来的 SSTable 有什么好处呢？</li>
</ul>
<p>写代码</p>
<ul>
<li>用一个环形链表实现一个队列，新元素进入时可能需要扩容，但是不需要考虑缩容；</li>
</ul>
<p>反问</p>
<ul>
<li>面试的职位未来是专注日志方向的吗？</li>
<li>对可观测性 SaaS 平台的时间规划是怎样的，何时会希望推出产品，交付使用？</li>
<li>这套 SaaS 平台面向的用户是内部用户还是外部用户呢？</li>
<li>职位 Go 和 Java 都需要，Go 语言在团队里面是怎样发挥作用的呢，具体支撑哪些功能，平台还是底层实现？</li>
</ul>
<h4 id="三面摘录-1">三面摘录</h4>
<ul>
<li>数据库迁移，双写阶段有写入失败时怎样处理？</li>
<li>双写的几个阶段的目标分别是什么，某些阶段能不能省略不做？</li>
<li>还有其他项目觉得比较有挑战的吗？</li>
<li>讲解一下做过的可观测性方向的事情？</li>
<li>监控和 Trace 是怎么做联动的？</li>
</ul>
<p>写代码</p>
<ul>
<li>用两个栈对数据进行排序，例如第一个栈中当前有 [1,3,4,2,6,9,7]，第二个栈为 []，利用这两个数据结构把数据排序，尽可能少申请空间或者使用额外的数据结构；</li>
</ul>
<p>反问</p>
<ul>
<li>目前公司内可观测性，例如 Trace 和日志建设的完善程度如何？</li>
<li>部署架构中都用了哪些 Agent 来辅助可观测性信息的采集，各是做什么的？</li>
<li>除了 Kubernetes 还在用哪些容器调度管理的方案，没有能迁移的原因（想借此评估一下对统一可观测性架构设计的影响和难度）？</li>
</ul>
<h2 id="4-总结">4. 总结</h2>
<p>整体来说面试没有出现想象中的地狱难度，几乎所有的面试官都很有耐心交流。但是被问到这么多的基础问题确实有一点点出乎意料，正常以为会是项目 &amp; 基础各占 50% 的比例。不过或许这也是好事情，个人非常赞同基础扎实但业务薄弱的工程师 &gt; 对业务有不错理解但基础不扎实（或比较远离一线开发、代码生疏）的工程师。另外其实计算机基础确确实实有在我的日常开发中帮到过我（quick question：你有在实际工作、排查问题中找过 <code>TIME_WAIT</code> 的网络连接吗？）。</p>
<p>然后回到最初面试的目的，是为了回答下面两个问题：</p>
<ul>
<li>3 年间自己的技术是线性成长、指数成长还是对数成长，跟同龄人相比如何？</li>
</ul>
<blockquote>
<p>是有成长的，但是没有那么理想，可能更介于线性成长和对数成长之间；</p>
</blockquote>
<ul>
<li>当前求职是买方市场还是卖方市场？</li>
</ul>
<blockquote>
<p>哈哈</p>
</blockquote>
<h2 id="5-一些推荐">5. 一些推荐</h2>
<p>关于面试我认为下面的材料很大程度帮到过我，所以也会推荐给在看本文的你，或者要求职的同学。</p>
<p><strong>USENIX</strong>：<a href="https://www.usenix.org/conferences">https://www.usenix.org/conferences</a></p>
<blockquote>
<p>如果想树立一些属于自己的亮点，一个捷径是了解面试官不懂的知识~~（不是）~~。关心前沿的学术和工业论文非常简单有效，USENIX 上覆盖了很多基础方向，例如计算机网络、操作系统、存储、分布式、安全，以及按职能划分的 SRE 等等。除了 USENIX 上的以外，如果有你关注方向的其他顶会那当然也是可以的，例如我以前会去看看 VLDB 和 SIGMOD 上的论文了解 KV 存储的一些新知识和研究方向。</p>
</blockquote>
<p><strong>操作系统导论</strong>：<a href="https://book.douban.com/subject/33463930/">https://book.douban.com/subject/33463930/</a></p>
<blockquote>
<p>一本很有意思的操作系统的入门书，可以写写里面代码了解一下 Linux 的 API，对于进程和内存相关的讲解让我印象非常深刻。</p>
</blockquote>
<p><strong>Go程序员面试笔试宝典</strong>：<a href="https://book.douban.com/subject/35871233/">https://book.douban.com/subject/35871233/</a></p>
<blockquote>
<p>首先声明一点这个书没帮到我面试，因为在面试前我没什么时间看它&hellip;正常来说我也不会推荐这种速食读物（手动狗头），但是结合面试遇到的提问来看，我认为它会对急着在一两个月内找到工作的同学很帮助。不过无论如何，程序员的学习是不建议走捷径的，如果对 Golang 感兴趣的话，有很多更好的替代品，包括 <a href="https://draveness.me">Draveness</a> 老师、<a href="https://research.swtch.com/">Russ Cox</a> 的博客等等。</p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>2023 年初的猿辅导面试复盘</title>
			<link>https://jiekun.dev/posts/2023-yuanfudao-interview/</link>
			<pubDate>Mon, 06 Feb 2023 12:45:58 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2023-yuanfudao-interview/</guid>
			<description>面试 一面（55 分钟） 面试官先介绍了一下面试流程，自我介绍、聊项目、写代码。 你挑一个有亮点有挑战的项目说一下？ 为什么存储要从 TiDB 迁移到 MySQL</description>
			<content type="html"><![CDATA[<h2 id="面试">面试</h2>
<h3 id="一面55-分钟">一面（55 分钟）</h3>
<p>面试官先介绍了一下面试流程，自我介绍、聊项目、写代码。</p>
<ul>
<li>你挑一个有亮点有挑战的项目说一下？</li>
<li>为什么存储要从 TiDB 迁移到 MySQL？</li>
<li>迁移过程中有遇到过什么问题或者有难度的挑战吗？</li>
<li>说下这些问题（双写一致性、迁移前后数据核对）怎么解决的吧？</li>
<li>你们整个系统还有什么其他的挑战吗？</li>
<li>以你们的数据量，这个系统不一定要使用 TiDB 吧？</li>
<li>传统的分库分表也可以做到对业务透明吧？</li>
<li>那你们业务里长链接生成短链接的具体规则是怎样的？</li>
<li>设计不锁表、数据版本不回绕的数据迁移方案具体是要解决怎样的问题呢？
<ul>
<li>面试官这里就数据迁移的方案继续追问，大概拉扯了 5 分钟，多组问题；</li>
<li>不难发现，要在简短的数十秒聊天中去介绍一套业界不广泛流行的技术方案，包括它解决的难点、如何解决，是非常困难的。简历上的信息以及口述的辅助需要找到合适的方法，引导面试官想象出来关键点，这是需要花时间打磨和改进的；</li>
</ul>
</li>
<li>这个数据同步不能用像 Redis 主从复制的那种机制吗？
<ul>
<li>解决的问题不一样，Redis 主从复制有 RDB 生成的过程，是阻塞的；</li>
</ul>
</li>
<li>对什么技术或者方向感兴趣？</li>
<li>怎么理解可观测性（Observability）？</li>
<li>Redis 有看过源码吗，贡献过什么 Feature？</li>
<li>Redis 6 里面的 Threaded I/O 是想解决什么问题？</li>
<li>讲一下 WiscKey 论文，想解决的是什么场景问题？ KV 分离能解决写放大的问题吗？</li>
<li>对 LSM-Tree 的 Compaction 了解吗？有哪几种 Compaction 方式？</li>
<li>对数据库的隔离级别了解吗？MVCC 和快照隔离级别有什么关联？</li>
</ul>
<p>写代码</p>
<ul>
<li>一个有序数组，按某个位置进行旋转，如 [1,2,3,4,5] 变成 [3,4,5,1,2]，在这个旋转后的数组中查找给定值；</li>
</ul>
<p>反问</p>
<ul>
<li>部门里面目前在负责那些日志相关的事情，例如是要搭建日志平台，或者现有日志平台的运维方，还是负责使用方的接入？</li>
<li>现在日志的体量大约是多少 PB，每天有多少日志需要采集收录？</li>
<li>日志的采集现在是怎么做的呢？</li>
<li>职位 OnCall 的情况如何？</li>
<li>这个日志平台还未正式上线的话，以往业务团队是怎么查询的呢？</li>
</ul>
<h3 id="二面1-小时-5-分钟">二面（1 小时 5 分钟）</h3>
<ul>
<li>在做过的事情里面挑一块来讲一下吧；</li>
<li>在这个项目里面你觉得哪些是比较有意思的？</li>
<li>短链接唯一 ID 设计这块挑战是什么？</li>
<li>针对相同长链接，会生成相同的还是不同的短链接，（两种方案分别是）怎么实现的？</li>
<li>数据迁移的过程中遇到什么问题？</li>
<li>为什么要为这些业务设计 ClickHouse 的存储？OLAP 和离线数仓的差别在哪里？</li>
<li>除了 ClickHouse 还了解过哪些 OLAP 数据库？</li>
<li>给团队做的基础组件有哪些比较有意思的聊一下？</li>
<li>讲一下 Trace 的数据模型，什么是 Span，Trace ID 和 Span ID 是怎么设计的？</li>
<li>Metrics 的数据模型有了解吗？</li>
<li>LSM-Tree 和 B+ Tree 的本质区别是什么呢？</li>
<li>LSM-Tree 有很多实现，能不能用 B+ Tree 作为其中的一种方案呢？用 B+ Tree 代替原来的 SSTable 有什么好处呢？</li>
<li>InnoDB Buffer Pool 里 LRU 的实现有什么优化？</li>
<li>介绍 HotRing，论文的实现以及针对什么样的场景和问题？</li>
</ul>
<p>写代码</p>
<ul>
<li>用一个环形链表实现一个队列，新元素进入时可能需要扩容，但是不需要考虑缩容；</li>
</ul>
<p>反问</p>
<ul>
<li>面试的职位未来是专注日志方向的吗？</li>
<li>对可观测性 SaaS 平台的时间规划是怎样的，何时会希望推出产品，交付使用？</li>
<li>这套 SaaS 平台面向的用户是内部用户还是外部用户呢？</li>
<li>职位 Go 和 Java 都需要，Go 语言在团队里面是怎样发挥作用的呢，具体支撑哪些功能，平台还是底层实现？</li>
</ul>
<h3 id="三面1-小时-15-分钟">三面（1 小时 15 分钟）</h3>
<ul>
<li>自我介绍，挑一些具体问题讲一下；</li>
<li>数据库迁移，双写阶段有写入失败时怎样处理？</li>
<li>双写的几个阶段的目标分别是什么，某些阶段能不能省略不做？</li>
<li>还有其他项目觉得比较有挑战的吗？</li>
<li>讲解一下做过的可观测性方向的事情？</li>
<li>监控和 Trace 是怎么做联动的？</li>
</ul>
<p>写代码</p>
<ul>
<li>用两个栈对数据进行排序，例如第一个栈中当前有 [1,3,4,2,6,9,7]，第二个栈为 []，利用这两个数据结构把数据排序，尽可能少申请空间或者使用额外的数据结构；</li>
</ul>
<p>反问</p>
<ul>
<li>目前公司内可观测性，例如 Trace 和日志建设的完善程度如何？</li>
<li>部署架构中都用了哪些 Agent 来辅助可观测性信息的采集，各是做什么的？</li>
<li>除了 Kubernetes 还在用哪些容器调度管理的方案，没有能迁移的原因（想借此评估一下对统一可观测性架构设计的影响和难度）？</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>2023 年初的米哈游面试复盘</title>
			<link>https://jiekun.dev/posts/2023-mihoyo-interview/</link>
			<pubDate>Sun, 05 Feb 2023 16:44:50 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2023-mihoyo-interview/</guid>
			<description>面试 一面（1 小时 13 分钟） 自我介绍 Go 基础 Go 里面使用 Map 时应注意问题和数据结构？ Map 扩容是怎么做的？ Map 的 panic 能被 recover 掉吗？了解 panic 和 recover 的机制吗？ Map 怎么知道</description>
			<content type="html"><![CDATA[<h2 id="面试">面试</h2>
<h3 id="一面1-小时-13-分钟">一面（1 小时 13 分钟）</h3>
<ul>
<li>自我介绍</li>
</ul>
<p>Go 基础</p>
<ul>
<li>Go 里面使用 Map 时应注意问题和数据结构？</li>
<li>Map 扩容是怎么做的？</li>
<li>Map 的 panic 能被 recover 掉吗？了解 panic 和 recover 的机制吗？</li>
<li>Map 怎么知道自己处于竞争状态？是 Go 编码实现的还是底层硬件实现的？</li>
<li>CAS 具体是怎么实现的呢？</li>
<li>并发使用 Map 除了加锁还有什么其他方案吗？</li>
<li>有对比过 sync.Map 和加锁的区别吗？</li>
<li>实际使用 sync.Map 的时候碰到过什么问题？</li>
<li>sync.Mutex 的数据结构可以说一下吗？</li>
<li>Context 平时什么场景使用到？</li>
<li>context.WithTimeout 使用现象和实现？</li>
<li>context.WithTimeout 还有 cancel 返回值，如果不去调用是否有问题？</li>
</ul>
<p>存储</p>
<ul>
<li>Redis 哪些场景在使用？</li>
<li>说一下分布式锁的实现？</li>
<li>基于 Redis 的分布式锁会有什么问题？</li>
<li>Redis 分布式锁超时可以超时时间设长一点可以吗？不可以的话需要怎么解决？</li>
<li>对 Redis 锁续期这个怎么实现呢？</li>
<li>日常在用的 Redis 集群都是什么架构？在主从模式和 Redis Cluster 中分布式锁会有什么问题？</li>
<li>日常什么项目会用到缓存，用 Redis 做缓存有遇到什么问题吗？</li>
</ul>
<p>消息队列</p>
<ul>
<li>平时在使用 Kafka 吗，具体做哪些业务使用到？</li>
</ul>
<p>业务</p>
<ul>
<li>主要 owner 哪些业务或者经历过哪些成长较多/难度较大的项目？</li>
<li>介绍一个业务项目从 0 到 1 的上线过程？</li>
<li>介绍 TiDB -&gt; MySQL 的数据迁移，原因和方案？</li>
</ul>
<p>继续存储</p>
<ul>
<li>为 <code>SELECT e FROM a WHERE b = 1 AND c &gt; 1 ORDER BY d;</code> 建立索引。</li>
<li>有用过 EXPLAIN 吗，结果中有哪些字段值得关注？</li>
</ul>
<p>写代码</p>
<ul>
<li>30 个并发打印 0-99</li>
</ul>
<p>反问</p>
<ul>
<li>Golang 在米哈游的使用场景？</li>
<li>项目组的一些细节，代码组织、管理形式等是怎样的？</li>
<li>项目质量的保障手段有哪些，单元测试覆盖率要求如何？</li>
<li>测试的同学主要以白盒测试还是黑盒测试为主？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>2023 年初的富途牛牛面试复盘</title>
			<link>https://jiekun.dev/posts/2023-futu-interview/</link>
			<pubDate>Sun, 05 Feb 2023 11:45:58 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2023-futu-interview/</guid>
			<description>面试 一面（1 小时 40 分钟） 面试官先介绍了富途的面试流程，技术面试一共分为 3 轮，其中第一轮是考察基础、数据结构算法、编程基础、计算机理论，二三轮</description>
			<content type="html"><![CDATA[<h2 id="面试">面试</h2>
<h3 id="一面1-小时-40-分钟">一面（1 小时 40 分钟）</h3>
<p>面试官先介绍了富途的面试流程，技术面试一共分为 3 轮，其中第一轮是考察基础、数据结构算法、编程基础、计算机理论，二三轮会继续拓展广度和深度，通过后续还会有 HR 面。</p>
<ul>
<li>介绍一下近两年工作使用的语言、框架、使用的存储组件？</li>
<li>Golang 用了多少年？</li>
<li>找工作的原因和背景？</li>
</ul>
<p>Go 基础</p>
<ul>
<li>切片和数组有什么区别？</li>
<li>切片底层数据结构、扩容时机和策略？</li>
<li>问一段代码输出结果（具体代码记不清楚了，但拟了一段类似代码）？</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
	<span class="nx">arr</span> <span class="o">:=</span> <span class="p">[]</span><span class="kt">int</span><span class="p">{</span><span class="mi">1</span><span class="p">}</span>

	<span class="nf">myfunc1</span><span class="p">(</span><span class="nx">arr</span><span class="p">)</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">arr</span><span class="p">)</span>

	<span class="nx">arr</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span><span class="nx">arr</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
	<span class="nx">arr</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span><span class="nx">arr</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
	<span class="nf">myfunc2</span><span class="p">(</span><span class="nx">arr</span><span class="p">)</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">arr</span><span class="p">)</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">myfunc1</span><span class="p">(</span><span class="nx">arr</span> <span class="p">[]</span><span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="nx">arr</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span><span class="nx">arr</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
	<span class="nx">arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">=</span> <span class="mi">0</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">arr</span><span class="p">)</span>
	<span class="k">return</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">myfunc2</span><span class="p">(</span><span class="nx">arr</span> <span class="p">[]</span><span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="nx">arr</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span><span class="nx">arr</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
	<span class="nx">arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">=</span> <span class="mi">9</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">arr</span><span class="p">)</span>
	<span class="k">return</span>
<span class="p">}</span>
</code></pre></div><ul>
<li>已知元素长度申请切片的时候应该怎么做？</li>
<li>defer 方法执行顺序是、（参数确定的）时机怎么样的？</li>
<li>问另一段代码输出结果（也同样是拟了一段类似代码）？</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test1</span><span class="p">())</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test2</span><span class="p">())</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test3</span><span class="p">())</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nf">test4</span><span class="p">())</span>

	<span class="k">return</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test1</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">v</span><span class="p">)</span>
	<span class="k">return</span> <span class="nx">v</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test2</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="kd">func</span><span class="p">()</span> <span class="p">{</span>
		<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">v</span><span class="p">)</span>
	<span class="p">}()</span>
	<span class="k">return</span> <span class="mi">3</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test3</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">v</span><span class="p">)</span>
	<span class="nx">v</span> <span class="p">=</span> <span class="mi">3</span>
	<span class="k">return</span> <span class="mi">4</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">test4</span><span class="p">()</span> <span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">defer</span> <span class="kd">func</span><span class="p">(</span><span class="nx">n</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
		<span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">n</span><span class="p">)</span>
	<span class="p">}(</span><span class="nx">v</span><span class="p">)</span>
	<span class="k">return</span> <span class="mi">5</span>
<span class="p">}</span>
</code></pre></div><ul>
<li>什么是哈希函数？哈希函数有什么特性？</li>
<li>Golang 标准库中 map 的底层数据结构是什么样子的？</li>
<li>Map 的查询时间复杂度如何分析？</li>
<li>极端情况下有很多哈希冲突，Golang 标准库如何去避免最坏的查询时间复杂度？</li>
<li>Golang map Rehash 的策略是怎样的？什么时机会发生 Rehash？</li>
<li>Rehash 具体会影响什么？哈希结果会受到什么影响？</li>
<li>Rehash 过程中存放在旧桶的元素如何迁移？</li>
<li>并发环境共享同一个 map 是安全的吗？
<ul>
<li>panic</li>
</ul>
</li>
<li>如果并发环境想要用这种哈希容器有什么方案？
<ul>
<li>sync.Mutex / sync.RWMutex</li>
<li>sync.Map</li>
</ul>
</li>
<li>加锁存在什么问题呢？</li>
<li>sync.Map 比加锁的方案好在哪里，它的底层数据结构是怎样的？
<ul>
<li>缓存 + map 组成的结构</li>
<li>底层 map 的操作依然是加锁的，但是读的时候使用上缓存可以增加并发性能</li>
</ul>
</li>
<li>sync.Map 的 Load() 方法流程？</li>
<li>sync.Map Store() 如何保持缓存层和底层 Map 数据是相同的? 是不是每次执行修改都需要去加锁？</li>
<li>一致性哈希了解吗？</li>
<li>channel 被 close 操作之后进行读和写会有什么问题？</li>
<li>未被初始化的 channel 进行读写会有什么问题？</li>
<li>channel 底层数据结构是怎样的，尝试用结构体来表述一下？</li>
</ul>
<p>写代码</p>
<ul>
<li>给定一个正整数数组 arr，求 arr[i] / arr[j] 的最大值，其中 i &lt; j。</li>
</ul>
<p>网络</p>
<ul>
<li>TIME_WAIT 状态出现 TCP 的哪个阶段（或者场景）？</li>
<li>查看 TCP 连接状态需要用什么命令？</li>
<li>发现存在大量 TIME_WAIT 状态会存在什么问题？</li>
<li>出现大量 TIME_WAIT 的话应用层有什么优化方案？</li>
<li>连接池的中心思想是什么？主要解决的是什么问题？</li>
<li>了解 TCP 中的粘包现象吗？</li>
<li>如果有一个请求需要发送数据，但是我想把包拆分开（不等待），在应用层应该怎么做？</li>
</ul>
<p>存储</p>
<ul>
<li>如果一个表中有主键和普通索引，查询命中主键和普通索引有什么区别？</li>
<li>聚簇索引具体是个什么样的数据结构？</li>
<li>这种数据结构对于范围查找有什么好处？</li>
<li>InnoDB 中的隔离级别有哪几种？</li>
<li>Read UnCommitted 存在什么问题？</li>
<li>Read Committed 解决了什么问题又存在什么问题？</li>
<li>Repeatable Read 会面临什么问题？</li>
<li>什么是幻读现象？如果另一个事务插入了一个条的数据可以被读取到吗？</li>
<li>Redis 的哈希数据类型，想插入元素，底层数据结构是怎样变化？</li>
<li>哈希数据类型一定会用上哈希表吗？</li>
<li>ziplist 的存储结构是怎样的？</li>
<li>Redis 的持久化机制有哪几种？</li>
<li>RDB 的原理是什么，用在哪些场景？</li>
<li>AOF 的原理和使用场景呢？</li>
<li>AOF 对于写入特别频繁的场景会存在什么问题？</li>
<li>AOF 在做压缩的时候 Redis 对外是否正常提供服务？</li>
</ul>
<p>写代码</p>
<ul>
<li>给定 n 个不同元素的数组，设计算法等概率取 m 个不同的元素</li>
</ul>
<p>反问</p>
<ul>
<li>了解面试部门的基本情况？</li>
<li>部门内微服务的数量？每个研发大概会负责多少服务的开发工作？</li>
<li>C++ 和 Golang 在团队内的使用场景和比例？</li>
<li>研发对开发质量的保障是如何完成的，测试和覆盖率是否有要求？</li>
<li>研发和测试的人员配置比例？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
<h3 id="二面1-小时-10-分钟">二面（1 小时 10 分钟）</h3>
<ul>
<li>自我介绍</li>
<li>了解团队规模，在团队中的角色</li>
<li>平时在技术成长上是怎么做的？</li>
<li>相关技术积累的文章是团队一起写的还是独立完成的？</li>
<li>了解一下过往绩效？</li>
<li>看工作机会的原因？</li>
</ul>
<p>场景题</p>
<ul>
<li>如果做一个翻译服务，翻译能力来自于供应商，如何从技术上对几家（A、B、C）供应商作出评估？</li>
<li>如果几家都要接入，且各家之间的翻译能力都各有优劣，那应该如何去搭建这个服务的框架？
<ul>
<li>调度器</li>
<li>数据采集 / 反馈机制，帮助调度器更好地工作</li>
<li>可扩展性，固化供应商的接入标准，方便未来扩展更多供应商选择</li>
</ul>
</li>
<li>除了回答的这些方面，一个服务的设计还需要注意什么？
<ul>
<li>正常服务应该提供的网关，包括鉴权、限流、多租户</li>
<li>提供给外部的服务需要注意 SLA，SLA 则围绕日志、监控、Tracing 做文章</li>
</ul>
</li>
</ul>
<p>算法题</p>
<ul>
<li>操作系统有任务管理器，管理任务的执行，任务之间存在依赖关系，写一个算法判断是否存在任务的循环依赖？</li>
<li>是否了解二叉排序树？左子树比根小，右子树比根大，如何移除一个二叉排序树的节点？
<ul>
<li>这个题目卡了挺久的，因为数据结构和算法比较薄弱，面试官给了很多提示，包括指引我从最简单的情况（所有节点只有左节点）开始考虑；</li>
</ul>
</li>
<li>一副扑克牌中随机取 5 张，取到顺子的概率是多少？
<ul>
<li>Hint 1：一种花色有多少种顺子？9 种</li>
<li>Hint 2：一个顺子有 5 张牌，有多少种组合可能？4 ^ 5 种</li>
<li>Hint 3：分子已经知道了，分母怎么表示，n 张取 m 张怎么表示？</li>
</ul>
</li>
</ul>
<p>中间件基础</p>
<ul>
<li>消息中间件是否了解？Kafka 是否了解？了解它的基本组件吗？
<ul>
<li>不了解</li>
</ul>
</li>
<li>Redis 实现的分布式锁有了解吗，讲一下？</li>
<li>Redis 分布式锁中设置超时时间有什么考虑？</li>
</ul>
<p>操作系统</p>
<ul>
<li>线程和协程有什么区别呢？</li>
<li>协程在开销和轻量的优势具体体现在哪些地方呢？</li>
<li>怎么理解线程安全？</li>
<li>产生线程安全问题的原因是什么？</li>
<li>两个线程做自增的操作（i++），各做 10 次，最终这个变量可能的值最大和最小各是多少？</li>
</ul>
<p>网络</p>
<ul>
<li>平时有抓过包吗？</li>
<li>HTTPS 包抓包原理是否了解？</li>
<li>DNS 是否了解？</li>
</ul>
<p>反问</p>
<ul>
<li>项目基本都是微服务 &amp; Kubernetes 这套方案吗？</li>
<li>研发跟基础设施打交道能到什么样的深度，例如能使用 Kubernetes 的那些内容，中间件的使用权限上有什么样的管控？</li>
<li>正常业务的 CI/CD 里面都做了/集成了多少测试或检查？</li>
<li>业务的研发能在 Kubernetes 上具体写哪些东西呢，例如 sidecar、operator 等等？
<ul>
<li>有专门的团队去做，但是还在起步阶段，大家都可以贡献；</li>
</ul>
</li>
</ul>
<h3 id="三面1-小时-10-分钟">三面（1 小时 10 分钟）</h3>
<p>项目</p>
<ul>
<li>自我介绍</li>
<li>数据库迁移的原因是什么？</li>
<li>完成迁移之后 DB 成本降低多少？</li>
<li>迁移过程中双读双写具体是什么样的方案？</li>
<li>双写过程中只写成功了其中一个 DB，返回给用户报错，那是否会存在脏数据呢？</li>
<li>双读具体是什么方案，其中一个读成功了就返回还是要两个都读成功才可以？</li>
<li>HTTP 流量的录制工具主要是做什么用呢？</li>
<li>HTTP 流量录制会涉及到一些登陆态的处理吗？</li>
</ul>
<p>计算机基础</p>
<ul>
<li>HTTP 主流版本是什么版本？</li>
<li>HTTP2 相对于 HTTP1.1 有什么新的特性呢？</li>
<li>HTTPS 是怎么保证安全性的呢？</li>
<li>SSL 里的公钥是谁给到客户端的呢？怎么验证没有被篡改呢？</li>
<li>为什么要选择对称加密和非对称加密一起使用呢？它们各有什么优缺点？</li>
<li>提供短链服务的时候是否有支持 HTTP 缓存呢？</li>
<li>缓存机制是什么样子的呢？</li>
<li>HTTP 缓存除了通过超时时间来做，还有其他的机制吗？</li>
<li>多线程编程中线程安全怎么来保证呢？</li>
<li>刚刚谈到加锁，加锁的话一般有哪些类型呢？</li>
<li>读写锁有什么优点呢？</li>
<li>CAS 是什么样的机制？</li>
<li>开发过程中怎么避免死锁呢？</li>
<li>内存泄露和内存溢出有什么区别呢？</li>
<li>熟悉的排序算法有哪些？归并排序和快速排序还记得原理吗？</li>
<li>归并排序时间复杂度是什么？有什么样的优缺点呢？</li>
</ul>
<p>智力题</p>
<ul>
<li>掷骰子，游戏规则：希望结果尽可能大，如果对第一次的结果不满意可以掷第二次，但是第一次结果就作废了，以第二次的结果为准。这个掷骰子结果的数学期望是多少呢？</li>
</ul>
<p>写代码</p>
<ul>
<li>输入两个整数 a 和 b，输出他们相除的结果，如果有循环小数用括号表示。如：
<ul>
<li>a=-1，b=2，输出 &ldquo;-0.5&rdquo;</li>
<li>a=1，b=3，输出 &ldquo;0.(3)&rdquo;</li>
<li>a=10，b=80，输出 &ldquo;0.125&rdquo;</li>
<li>a=-100，b=10，输出 &ldquo;-10&rdquo;</li>
</ul>
</li>
</ul>
<p>工作规划</p>
<ul>
<li>换工作主要是什么原因呢？</li>
<li>对富途了解吗？</li>
<li>现在团队规模？</li>
<li>工作中的同事怎么评价你呢？</li>
<li>平时有什么兴趣爱好？</li>
</ul>
<p>反问</p>
<ul>
<li>一、二、三轮的面试官都是团队中的什么角色呢？</li>
<li>组织架构中小组、中心的概念和规模？</li>
<li>作为管理者如果看到团队中的技术氛围比较欠缺，会考虑什么样的手段（去提升）呢？</li>
<li>在已有组件能支撑业务的情况下，如何看待 Member 提出的一些组件的升级或引入呢？</li>
<li>对于 CI/CD 这块，可能不会直接产生业务影响（例如更高的订单量），在公司的现状如何，以及如何看待将时间投入在这上面呢？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>写在 2022 年末的字节跳动面试复盘</title>
			<link>https://jiekun.dev/posts/2022-bytedance-interview/</link>
			<pubDate>Wed, 28 Dec 2022 16:14:26 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2022-bytedance-interview/</guid>
			<description>背景 朋友经常跟我说要注意大环境，多看看身边优秀的人活得怎么样，不是说总要比来比去，但是也不能沉溺在舒适圈里，所以偶尔，偶尔会有一些跳出合同跟</description>
			<content type="html"><![CDATA[<h2 id="背景">背景</h2>
<p>朋友经常跟我说要注意大环境，多看看身边优秀的人活得怎么样，不是说总要比来比去，但是也不能沉溺在舒适圈里，所以偶尔，偶尔会有一些跳出合同跟新球队聊聊加盟的想法。当然，想法在过去很长一段时间都只是想法，直到秋天的几轮裁员，心里才跟自己说：要不面面看？</p>
<p>然而现实很残酷，下半年（特别是 Q4）通常都是电商的发力时间段，让本就不充裕的准备时间更是捉襟见肘，直到面试前两周，征询了一些朋友的建议，决定开摆，看看日常的积累能抵多少的八股文。</p>
<h2 id="面试">面试</h2>
<p>由于快到年末了，大家都很忙，所以 HR 微信约了下班后的一面时间。</p>
<h3 id="一面1-小时-20-分钟">一面（1 小时 20 分钟）</h3>
<ul>
<li>自我介绍</li>
<li>追踪完整的推广链路（进行分佣）是怎么做的呢？</li>
<li>推广的链接里面会带用户的信息吗？</li>
<li>短链接是自己做的吗，具体是怎么映射长链和跳转的？</li>
<li>这个推广的提成是按照订单维度来算的吗？</li>
<li>这种模式会存在商家作弊吗？</li>
<li>这个短链的长度是固定的吗，是怎么设计的？</li>
<li>跳转的时候用的是 301 还是 302 跳转？为什么？</li>
<li>短链数据为什么从 TiDB 迁移到 MySQL？</li>
<li>短链迁移到 MySQL 做的分库分表依据是什么？</li>
<li>双写的时候怎么保证 TiDB 和 MySQL 数据一致？</li>
<li>短链有典型的冷热数据特点，怎么处理的？</li>
<li>实时核对系统是怎么做的呢？</li>
<li>如果两个系统间的链路太长，数据变更时间很长或者数据丢了，那核对系统要以哪边的数据为准（去修改另一个系统）呢？</li>
<li>OpenTracing 这个是基架做的吗，为什么业务团队也要去搭呢？</li>
<li>加入了这么多上报会不会对性能有影响？</li>
<li>Tracing 有一定的采样率，如果调用链路中某个服务有报错，它并不一定能被采样到。怎样能使报错的调用都被采样到呢？</li>
<li>binlog 有哪几种模式？</li>
<li>为什么需要不同模式？</li>
<li>主机房执行了一个事务，同步到从机房，它的事务性能保证吗？</li>
<li>什么是覆盖索引？
<ul>
<li>如果一个查询能从某个索引的 B+ 树上拿到所有的数据不需要回表等操作，这个索引就称为这个查询的覆盖索引；</li>
</ul>
</li>
<li>了解索引下推吗？什么情况下会下推到引擎去处理？
<ul>
<li>通过某个索引没办法按顺序地覆盖所有的查询条件，但是仍然可以利用索引内存在的字段（尽管不是有序的，需要扫描）去进一步过滤；</li>
<li>举例：idx(a,b,c,d)，查询条件为 a=? and b=? and d=?，发生下推减少回表数量；</li>
</ul>
</li>
<li>什么场景下索引会失效？
<ul>
<li>场景有很多，但是如果我是一个引擎，我关注的不是什么情况会失效，而是走什么路径所花费的随机 I/O 和顺序 I/O 最少，如果走某个索引花费的随机 I/O 比从聚簇索引（顺序）查（成本）都还要高，那还不如直接去全表扫描；</li>
<li>典型例子：捞超过全表 30% 的数据；</li>
</ul>
</li>
<li>有没有具体一点的例子？
<ul>
<li>还是刚刚提到的例子，比如说我要按照 update_time 去做范围查询，捞很多的数据，即使 update_time 有索引，也会选择全表扫描；</li>
</ul>
</li>
<li>WHERE id NOT IN (?, ?, ?) 会走索引吗？
<ul>
<li>还是要看成本；</li>
<li>举例：id 字段只包含 3 个值，1、2、3，3 只有几行，而 1、2 各有 100w 行，如果查询条件是 NOT IN (1, 2) 会走索引，如果查询条件是 NOT IN (3) 不会走索引；</li>
</ul>
</li>
<li>Redis 使用的过程中有碰到过一些热 Key、大 Key 的问题吗？
<ul>
<li>有，能自行定位到的都业务自行处理了；</li>
<li>如果不知道是哪个 Key 导致的，则 rdbdump 导出之后做（离线）分析，看看哪个 Key（哪些 Key 前缀）占的空间特别大，再将他们做哈希、打散等处理；</li>
</ul>
</li>
<li>rdb 导出会不会太慢了，比如说里面有一两亿的数据，里面会包含了一些大 Key，怎么样更快找出来？
<ul>
<li>数据导出会从从节点上导出，不会很慢；</li>
<li>如果觉得导出还是太慢，可以看看 Redis 是否有提供什么命令直接找，印象中有命令能找出 Value 大于特定值的 Key；</li>
</ul>
</li>
<li>如果有一些热点 Key，比如某个链接被明星分享了，访问就会很频繁，怎么办？
<ul>
<li>Redis 存放的就该是热点数据，所以觉得这个应该是服务它的使用场景的；</li>
<li>如果热点数据里面的 Value 太大了，因为它是单线程操作的，可能会导致一些压力，可以尝试使用 Redis 6 的多线程来缓解网络 I/O 上的压力；</li>
</ul>
</li>
<li>如果定位到了热 Key 之后怎么防止它把单个节点打爆呢？
<ul>
<li>减少 Value 的体积然后用 Redis 做索引，把实际的内容放到其他存储去；</li>
<li>（答非所问）</li>
</ul>
</li>
<li>用 RAND(5) 实现 RAND(7)？
<ul>
<li>眼熟，但是不会；</li>
</ul>
</li>
<li>A 和 B 从一堆棋子中轮流取，每次需要取走 1-5 个棋子，A 先取，如何必胜？
<ul>
<li>眼熟，讨论了一会；</li>
</ul>
</li>
<li>翻转链表中的第 m 至 n 的节点
<ul>
<li>不难；</li>
</ul>
</li>
</ul>
<p>反问环节</p>
<ul>
<li>团队里面大约有多少个仓库、部署了多少服务（大致规模）？</li>
<li>这些项目会做单元测试吗，或者说平时的自测、代码质量保障是通过什么方式做的？
<ul>
<li>工具类的库会写单测；</li>
<li>自动化测试会由流量回放平台，QA 执行常用的用例；</li>
</ul>
</li>
<li>整个流量回放都是 QA 负责的吗？
<ul>
<li>后端需要在代码里面做配合；</li>
</ul>
</li>
<li>一个业务迭代版本是怎么安排时间发布的呢，比如说是每周固定发布还是说测试完成后的几天发布？
<ul>
<li>按双月来排期，产品拟定优先级， 研发扣除 oncall 等时间分配任务；</li>
</ul>
</li>
<li>oncall 那周安排多少时间精力做 oncall 和其它问题？
<ul>
<li>80% 时间在 oncall，剩下的时间会看情况修复一下线上和其他的小问题；</li>
</ul>
</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
<p>第二天收到 HR 的电话约了二面时间。</p>
<h3 id="二面1-小时-5-分钟">二面（1 小时 5 分钟）</h3>
<ul>
<li>说一下短链接业务的背景、上下文？</li>
<li>为什么要用短链接，短链接到底解决什么问题？</li>
<li>有没有看过这些短链带来的点击或者成交量有多少？</li>
<li>造成到达率只有 50% 不到（商品页浏览数/短链点击数）原因是什么呢？</li>
<li>项目的机房部署是怎么样的？</li>
<li>东南亚到美洲的机房时延大概是多少？</li>
<li>项目如果跨机房部署，会遇到什么技术问题呢？</li>
<li>在项目中是主导设计还是主力开发？</li>
<li>这个系统是你从 0 到 1 做起来的吗？</li>
<li>能说一下项目的系统架构吗？</li>
<li>短链从用户分享、短链生成到用户点击在系统里面的工作过程？</li>
<li>301 跟 302 跳转有什么区别，具体会发生什么事情？</li>
<li>301 或 302，以及还有一种链接不会发生变化的跳转，具体在 HTTP 协议中是什么命令？</li>
<li>在做短链系统里面哪些地方是技术难点？
<ul>
<li>短链 ID 如何设计；</li>
<li>短链系统是流量入口，因此重点关注高可用；</li>
<li>访问数据实时和离线的分析；</li>
</ul>
</li>
<li>分库分表是怎么做的，为什么需要分库分表？
<ul>
<li>数据增长较快；</li>
<li>单点的访问模式，保持较小的 B+ 树有利于访问性能；</li>
</ul>
</li>
<li>数据增长快，为什么不考虑冷热数据分离，定期归档？</li>
<li>业务场景里面不太可能有统计，实际上都是 KV 查询，压力应该不大，需要分表吗？</li>
<li>TiDB 迁移到 MySQL 后耗时大幅降低是做了什么优化？</li>
<li>这种场景里面写入耗时长可否容忍？</li>
<li>在这个大量 KV 数据读写的场景，为什么不考虑直接使用 KV 存储或者 Redis 来支撑？</li>
<li>为何不考虑数据仓库提供 HBase 来支持读写，节约掉 MySQL / KV 存储同步到数仓的过程？</li>
<li>能说一下 LevelDB 的存储结构吗？</li>
<li>实现 Redis 跳跃表</li>
<li>为什么考虑换工作？</li>
<li>未来 4 年的规划？</li>
</ul>
<p>反问环节</p>
<ul>
<li>在字节的技术人对于公司的基础架构的满意程度如何？
<ul>
<li>该有的都有；</li>
</ul>
</li>
<li>外出参加技术会议、交流在字节里机会是否丰富？</li>
<li>前面很多问题都没有答对，面试官的建议？</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>GIAC 2022 深圳站小记</title>
			<link>https://jiekun.dev/posts/giac-2022/</link>
			<pubDate>Sat, 23 Jul 2022 17:43:07 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/giac-2022/</guid>
			<description>目录 启程 课程规划 快手 KBus：CDC 解决方案 Databus Pattern CDC Tool Production-Grade CDC Solution 开源与技术管理 项目推广 开源收益 写在最后 碎碎念 启程 周末蹭公司的门票参到 GIAC 现场学习了两</description>
			<content type="html"><![CDATA[<h2 id="目录">目录</h2>
<ol>
<li><a href="#%E5%90%AF%E7%A8%8B">启程</a></li>
<li><a href="#%E8%AF%BE%E7%A8%8B%E8%A7%84%E5%88%92">课程规划</a></li>
<li><a href="#%E5%BF%AB%E6%89%8B-kbuscdc-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">快手 KBus：CDC 解决方案</a>
<ul>
<li><a href="#databus-pattern">Databus Pattern</a></li>
<li><a href="#cdc-tool">CDC Tool</a></li>
<li><a href="#production-grade-cdc-solution">Production-Grade CDC Solution</a></li>
</ul>
</li>
<li><a href="#%E5%BC%80%E6%BA%90%E4%B8%8E%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86">开源与技术管理</a>
<ul>
<li><a href="#%E9%A1%B9%E7%9B%AE%E6%8E%A8%E5%B9%BF">项目推广</a></li>
<li><a href="#%E5%BC%80%E6%BA%90%E6%94%B6%E7%9B%8A">开源收益</a></li>
</ul>
</li>
<li><a href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E">写在最后</a></li>
<li><a href="#%E7%A2%8E%E7%A2%8E%E5%BF%B5">碎碎念</a></li>
</ol>
<hr>
<h2 id="启程">启程</h2>
<p>周末蹭公司的门票参到 <a href="https://giac.msup.com.cn/2022sz/schedule">GIAC</a> 现场学习了两天，受疫情影响，大会临时从华侨城改到了 40 公里外的龙岗，原定早上出发晚上回来的行程直接改成在酒店住两晚。对离得近的同学来说，改期自然是要比改地点好一些，特别感谢 <strong>Shopee Academy</strong> 的同事一直帮忙协调解决了很多问题。</p>
<p><img src="../202207-giac/giac_entrance_ticket.jpg" alt=""></p>
<h2 id="课程规划">课程规划</h2>
<p>GIAC 每天分为上下午场，每场又有 6 个分会场，分别对应不同主题，一个主题下大约有 3-4 场分享，因此想全都到现场听是不可能的。晚上在酒店预先做了点攻略，先把感兴趣的主题圈画出来，再看主题下具体有什么分享。</p>
<p><img src="../202207-giac/giac_topics.png" alt=""></p>
<p>选择听哪场分享影响因素有很多，例如作为后端工程师，我可能对前端、AI、大数据的内容暂时不感兴趣，如果想去听，那么：</p>
<ul>
<li>要花大量时间预热背景知识，在半天时间内几乎不可能；</li>
<li>对团队内这个方向的实践不熟悉，不好对比，没有对比就没办法提出学习改进的思路。</li>
</ul>
<p>另外因为前几周刚刚返厂维修了膝盖，走路全靠拐杖，要在不同会场之间蠕动还很困难，所以尽可能保持每个半天都待在同一个会场，剩余分享可以在会后看回放学习，只少了提问交流的机会。</p>
<p>综合各种因素和限制，最后选择了学习以下的分享，按照自己的理解重新分类，并从中挑选几个话题进行分享：</p>
<ul>
<li><strong>Database</strong>
<ul>
<li>快手数据总线 KBus 的设计和实践</li>
<li>云巢：基于 K8s 的数据库云原生服务平台实践</li>
</ul>
</li>
<li><strong>服务治理</strong>
<ul>
<li>基于 dubbo-go 构建跨语言的服务治理平台</li>
<li>无侵入式多重灰度和全链路压力测试</li>
</ul>
</li>
<li><strong>Open-source software</strong>
<ul>
<li>让开源成为公司技术管理的杠杆</li>
</ul>
</li>
<li><strong>运维</strong>
<ul>
<li>腾讯游戏的海量 SRE 运维实践</li>
</ul>
</li>
<li><strong>Kubernetes</strong>
<ul>
<li>云原生跨集群统一算力调度在网易的实践</li>
</ul>
</li>
</ul>
<h2 id="快手-kbuscdc-解决方案">快手 KBus：CDC 解决方案</h2>
<p>数据写入 Database、缓存、搜索引擎是很常见的存储方案，在过往的一些项目中，产生数据的一方会独立完成这些操作，先写入某个中间件，再写入某个中间件。引入 Databus（数据总线）之后，产生数据的应用可以专注于完成 Database 的写入，在它的视角里面，数据库写事务成功提交，处理就已经完成了，写入架构可以变成下面这样：</p>
<p><img src="../202207-giac/kbus.png" alt=""></p>
<h3 id="databus-pattern">Databus Pattern</h3>
<p>在 Shopee Affiliate 团队，同样也有 Databus 的概念。当用户注册后，一条 “注册” 消息会被发送至 Kafka，不同微服务消费到这条消息后对用户进行审核、打标（Tagging）等操作。跟快手 KBus 的不同之处在于，KBus 本质上是一个 CDC 应用，它的消息代表的是数据变更内容；而 Affiliate 团队的 Databus 是用 Kafka 承载的是一个业务事件消息。</p>
<p><img src="../202207-giac/different_databus.png" alt=""></p>
<p>两种类型的 Databus 是否可以合并呢？其实业务事件大多数场景下都是一次 Database 操作的结果，例如用户注册可能就是一条 <code>INSERT</code> 语句，用户审批可能是一条 <code>UPDATE</code> 语句等，Consumer 确实可以通过识别这些 SQL 语句的执行来实现类似功能，但是：</p>
<ul>
<li>如果业务非常复杂，从 100 次 <code>INSERT</code> 消息中识别一个事件可能需要筛除掉另外的 99 条 <code>INSERT</code> 消息。换句话说，SQL 执行的语义必然不如自定义的业务事件<strong>语义清晰</strong>，简化 Producer 的逻辑即是加重 Consumer 的逻辑；</li>
<li>业务应用有能力向 Databus 投递复合的数据。例如一个 User 的数据散落在不同表中，我希望借助 Databus 来更新这个 User 的缓存，单靠某句 <code>INSERT</code> 或者 <code>UPDATE</code> 的消息不容易完成，需要联合上下文相关的语句才能构建完整的 User 模型。这种场景在 KBus 的模式下就会比较困难，需要 Consumer 来处理；而如果 Producer 投递的就已经是组装好的数据，那 Consumer 侧就只需要 <code>SET</code> 操作直接更新缓存即可。</li>
</ul>
<h3 id="cdc-tool">CDC Tool</h3>
<p>在业务的角度来看，如果在使用不同的存储中间件，用<strong>可靠</strong>的 CDC 方案来完成次级存储（Redis、Elasticsearch、Clickhouse）的写入可以提升开发效率，在一些方案设计时，只要体现出业务应用与 Database 的交互，不再关心缓存的写入时机，听起来似乎很诱人。Affiliate 团队当前大部分 Redis 的写入是在业务应用内完成，Elasticsearch 的写入则是利用与 KBus 类似的 CDC 组件来完成。</p>
<p>在确认 KBus 是一个 CDC 平台后，很自然地会将它与我们当前正在使用的 <a href="https://github.com/alibaba/canal">canal</a> 进行比较。下图来自分享老师的 PPT，可以看到 KBus 内部是多个 Server + Kafka 的模型。</p>
<p><img src="../202207-giac/kbus_design.png" alt=""></p>
<p>其中，<strong>Meta Server</strong> 存储元信息，不同 Database 的配置应该是依赖它来存储的，而<strong>协调中心</strong>自然是分布式系统中的中心化节点，协调不同 Server 的工作。而 Server 就是伪装成 Database 的 Slave，是真正的 CDC worker。</p>
<p>这套设计跟 canal 很像，canal 中没有 Meta Server，取而代之的是一个 MySQL 或配置文件；协调中心则是直接使用了 ZooKeeper，“协调” 工作通过类似于<strong>抢占</strong>的操作来完成，某个 Server 抢占到了 Database 的使用权，那它就是这个 Database 的 CDC worker。</p>
<p>canal 中 ZooKeeper 同时用于 “协调” 和 “记录位点信息”，KBus 将它们拆到了不同的地方，但不管怎么做，由于 “消息投递至 Kafka” 与 “更新位点（至 ZooKeeper 或 Meta Server）” 不是事务操作，总会出现消息已投递，但未来得及记录进度，Server 就意外不可用的情况，紧接着替代的 Server 就会从历史进度开始获取变更数据信息继续投递。这个问题在 Consumer 视角来看，就是会出现消息重复投递的情况，需要自行实现幂等处理。</p>
<p><img src="../202207-giac/kbus_server.png" alt=""></p>
<p>在现场我还提了另一个问题，日常 canal 使用中，我们发现如果单纯依赖 “抢占” 逻辑，当出现新的 Database 需要被 CDC worker 处理时，极有可能出现资源分配不均匀的情况，某个 CDC worker 抢占到了大量 Database 目标，而其他 CDC worker 则没有太多负载。KBus 的解决方案是通过考察落在 Server 上的 Database 数量来尽可能保持均衡，这样做一定程度能缓解倾斜的问题，但是由于不同的 Database 使用情况不同，例如有的 Database 可能写操作非常多，而有的 Database 则很闲，几乎不产生数据变更，那实际上 Server 上的 CPU 使用情况仍然会出现倾斜。当然，这个问题优先级可能比较低，况且 KBus 也已经有根据数量来保持平衡的策略，比完全依赖抢占会改善很多。对 CDC 组件来说，保证消息不丢失是最重要的。</p>
<h3 id="production-grade-cdc-solution">Production-Grade CDC Solution</h3>
<p>工具需要不断完善才能变成一个平台，对外提供能力。之前一直好奇正儿八经的 CDC 平台是什么样子的（当然，也是因为过往公司内没有合适的 CDC 平台，不同团队各造轮子），通过这次分享窥探了一下 “别人是怎么做的”，然后发现，痛点在哪里都是痛点，问题在哪里都是问题。</p>
<p>我们在用 canal 的时候觉得它不好用，很多地方都做得像个玩具（例如管理后台的登录态存储在内存中，意味着难以部署在多个机器上做高可用），再看 KBus，核心技术思路几乎是完全一致的，例如元信息存储、DDL 执行期间 Server 切换等的处理方式。然后面对 Server 分配不均匀、重复投递这些问题，canal 没处理好的，KBus 或多或少也有（面对过）类似问题，那为什么要用 KBus 不用六七年前就已经发布了的 canal 呢？</p>
<p>答案跟下一节要讲的开源有一点联系。</p>
<p>我不太相信阿里内部使用工具跟开源出来的项目一样。canal 本身有很多小问题，都不是一个面向企业级业务量的工具应该出现的。自研的工具优势很简单：</p>
<ul>
<li>业务场景明确，设计有针对；</li>
<li>从 0 到 1 溯源，各种技术决策的原因可追踪；</li>
<li>专职维护，没有二次开发困难。</li>
</ul>
<p>那开源项目难道就做不到这些了吗？也不见得，Kubernetes、TiDB、Redis 都是开源的，当开源的项目满足不了业务需求，要么提 Issue 和 Pull Request 贡献，要么二次开发或者重新造轮子，这些就是用开源工具的难点，特别是用一个社区不活跃的开源工具。</p>
<p>回到正题，当企业内能孵化出这样的项目，它本身：</p>
<ul>
<li>开发和解决问题是团队的职责；</li>
<li>不好用就没人用，没人用就没有对应的成果和绩效。所以只要这个能力一直被需要，它就能一直在改进。</li>
</ul>
<p>所以在听完分享之后我觉得 KBus 确实是一个使用上能满足企业级业务接入的要求、能运维得当的 CDC 解决方案。在之前，我会想象别人家 Production-Grade 的解决方案能解决我们遇到的（绝大多数）问题，现在改变了主意：<strong>原来别家也一样，那 canal 改改也可以。只是比起自己造的轮子，从开源社区白嫖的工具 “改改” 难度大了许多而已</strong>。</p>
<h2 id="开源与技术管理">开源与技术管理</h2>
<p>这一场的分享者是 Apache Member 郭炜老师，很可惜老师没有来到现场，改用线上的形式。Slides：<a href="https://drive.google.com/file/d/1glfSIR09ksjyJdAFc-twWU4eQKnOOV4-/view?usp=sharing">HERE</a>。</p>
<p>头一天晚上在酒店的时候，看到这场分享的题目，心里想的是：</p>
<ul>
<li>我有做出来过什么开源（/能在不同团队里使用）的东西吗？
<ul>
<li>如果有的话，那它好推广吗？不好推广的原因是什么？</li>
</ul>
</li>
<li>为什么要做开源和推广？</li>
<li>我从开源和推广里面收获过什么？</li>
</ul>
<p>第二天带着杂七杂八的问题来到了分享的会场，因为上一场在其他会场结束得比较晚，导致来到的时候只能蹲在后面的角落。</p>
<p><img src="../202207-giac/oss.jpg" alt=""></p>
<h3 id="项目推广">项目推广</h3>
<p>对于内部开源，老师提到了一些作为（开源）管理者应该倡导和要避免的要点，仔细一看，有我们一直鼓励的、正在实践的、做失败的、踩过坑不好维护的，各种问题都有。其中，团队内一直都提倡结合实际痛点，落地能解决问题的、团队适用的工具，对产品线内外宣讲也很支持。</p>
<p><img src="../202207-giac/advocating_opensourcing.png" alt=""></p>
<p>如果能观察一下自己、企业内做失败的工具，问题都很容易总结出来：</p>
<ul>
<li>边界不清晰。什么都想做的项目，基本上都失败了；</li>
<li>代码开源。应该推广的是产品而不是代码；</li>
<li>开发者寥寥无几。通常只有写下这个工具的一两个人在维护和迭代。</li>
</ul>
<p>对于推广的工具，大部分的使用者都不是它的开发者，所以他们还不是社区的一部分，这就是所谓的 “代码开源”。那使用者没这么多时间去开发，在企业内似乎也很正常？其实没关系，开源社区的参与并不只是代码上的参与，传统的需求流程和老师提出来的下一代的开发形式差别就在这里。</p>
<p>想一下，你推广出去的开源工具，有听到用户的声音了吗？你的用户在使用你的代码，还是有 feedback 给你，或者甚至提方案、提 Pull Request？那接到这些信息的时候，你或者社区内的其他人有关注吗？所有的这些问题对应的就是：</p>
<ul>
<li>谁在参与这个社区；</li>
<li>这个社区的活跃程度。</li>
</ul>
<p>提升这方面的要点其实就一句话：<strong>让更多的人参与进来</strong>。不光是对开源项目，任何想推广的内部项目也都可以这样处理。</p>
<p><img src="../202207-giac/software_developing.png" alt=""></p>
<h3 id="开源收益">开源收益</h3>
<p>参与开源有两条不同的路径，一是将新的轮子推广出去，二是参与到已有开源项目的开发中。在企业内想推广一些<strong>新</strong>工具和平台往往都是不容易的（强制推行的除外），因为业务团队大都有正儿八经的业务项目需要维护，那为什么要做额外的工具和推广呢？当你决定要把某个项目共享出去，可能是基于：</p>
<ul>
<li>共享轮子；</li>
<li>内部开源走向外部开源；</li>
<li>产生技术影响力；</li>
<li>打造商业模式。</li>
</ul>
<p>但是能实现这些其实都是很难的，更多的项目还没走出部门内就已经死了。</p>
<p>而参与到开源项目，对公司和个人都有一些来得更直接的收益。其次就像某人所说的，“The best programs are the ones written when the programmer is supposed to be working on something else.”。</p>
<p><img src="../202207-giac/oss_incentive.png" alt=""></p>
<p>最后，开源项目不代表免费，也不代表不盈利，受限于篇幅，这里推荐阅读一下 slides 中 “<strong>外部开源要做商业么？</strong>” 的部分，企业、项目的可持续发展离不开社区的目标。</p>
<h2 id="写在最后">写在最后</h2>
<p>文章大部分只是听分享过程中闪过的一些想法和随手的笔录，<strong>有的思考和观点并不严谨，也不一定正确</strong>。</p>
<p>在听分享的过程中，发现最没有意义的就是介绍一个很庞大的系统，模块非常多，功能非常全，几乎我能想到的功能它都有。不出 10 页 slides 一定有超多框框箭头的架构图，有降级熔断模块、告警监控模块、管理模块、调度模块等等，如果有哪个系统能把这么多的模块都做得很完善，那自然是很优秀的，但可惜没有能借鉴的地方，因为大家都知道要去做，只是受限于 ROI，未必需要都做出来。这样的分享更像是在展示一款产品，说，你来用吧。抱歉，我其实不是来听这些的。</p>
<p>以及，2 天听的分享时间上满满当当，匆忙间也没办法记录下太多的内容。后续等录播上线之后，还有其他老师的分享需要看录播完善一下思考才能写进来。</p>
<h2 id="碎碎念">碎碎念</h2>
<p>原本以为临时改了这么远的地点，参会的人会少很多，毕竟也提供了线上直播，但是其实周五当天人还是挺多的，以致于换会场的时候发现没有位置坐了，拄着拐杖听了大半个小时。周六反而人少了一些，可能大家都觉得周五外出摸一天鱼更有利于吸收知识。</p>
<p><img src="../202207-giac/giac_entrance.jpeg" alt=""></p>
<p><img src="../202207-giac/audience.jpeg" alt=""></p>
<p>早上急急忙忙起来只吃了个鸡蛋，喝了豆浆，偷了根香蕉就往会场赶，倒是中午的时候听完慢悠悠去用餐比较舒服，但是去晚了就剩养生食品，想着晚上要出去吃，中午就随便糊弄一下也行。</p>
<p><img src="../202207-giac/lunch.jpeg" alt=""></p>
<p>晚上跟朋友去吃了一顿自助餐，改善一下开会的体验，毕竟坐一整天确实挺累的，不过如果有下一次的话，那大概也还是会去，咱毕竟是去上课不是来接雨水的。</p>
<p><img src="../202207-giac/dinner.jpeg" alt=""></p>
]]></content>
		</item>
		
		<item>
			<title>揭露数据不一致的利器 —— 实时核对系统</title>
			<link>https://jiekun.dev/posts/data-check/</link>
			<pubDate>Thu, 17 Mar 2022 18:00:00 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/data-check/</guid>
			<description>随着企业业务发展，以及微服务化大趋势下单体服务的拆分，服务间的通信交互越来越多。与单体服务不同，微服务间的数据往往需要通过额外的手段来保障一</description>
			<content type="html"><![CDATA[<blockquote>
<p>随着企业业务发展，以及微服务化大趋势下单体服务的拆分，服务间的通信交互越来越多。与单体服务不同，微服务间的数据往往需要通过额外的手段来保障一致性，例如事务消息、异步任务补偿等。除了从机制上最大程度保障以外，如何观测并及时发现数据不一致也非常重要。</p>
<p>本文介绍 Shopee Financial Products 团队设计和开发的<strong>实时核对系统（Real-time Checking System）</strong>，它接入简单，只需根据核对需求配置对应的核对规则，实现了规则热加载，并能在不侵入业务的前提下对系统数据进行实时监测对比，及时发现数据的不一致。系统落地至今，已在 Shopee 多个产品线推广使用，帮助不同团队快速发现线上数据不一致问题，为数据保驾护航。</p>
</blockquote>
<pre tabindex="0"><code>目录

1. 背景
   1.1 系统数据的不一致性
   1.2 离线核对的缺陷
2. 实时数据核对
   2.1 系统架构与核对流程
   2.2 核对功能演进
3. 性能表现
4. 总结
</code></pre><h2 id="1-背景">1. 背景</h2>
<h3 id="11-系统数据的不一致性">1.1 系统数据的不一致性</h3>
<p>在日常的开发迭代中我们能发现，系统的数据有时并不按照我们设想的那样进行变更。常见的场景如：用户进行了还款（Repay），系统 A 收到了还款请求后调用系统 B，将已冻结的账户进行解冻，但因为某些原因（如系统故障、网络分区等），解冻的请求没有抵达 B，或者解冻成功的响应没有返回给 A，此时会出现已经确定收款但未解冻，或未确认收款却已解冻的情况，从而引起用户投诉或资金损失。</p>
<p><img src="../202203-data-check/1.png" alt="Fig1. Data Inconsistency"></p>
<p>造成这类问题的原因通常有：代码逻辑 Bug、并发场景处理不当、基础组件（网络、数据库、中间件）故障、跨系统间缺乏原生的一致性保障等等。随着业务扩展，企业内的应用越来越多，且有许多<strong>单体应用</strong>（Monolithic Application）向<strong>微服务</strong>（Microservices）拆分转型，分布式的场景下丢失了数据库事务的支持，需要解决数据一致性的问题。</p>
<p>保障数据一致的方案有很多种，在单体服务且缺少不同组件间（例如跨 Database、不同存储中间件）事务支持的场景下，可以使用本地事务表 + 补偿任务的组合，将主表数据与检查任务通过事务写入，再通过异步任务不断检查目标数据是否一致并进行补偿，可实现最终一致性；在跨服务场景下，Saga 模式通过可靠消息及服务提供回滚事务的能力，来实现分布式事务。</p>
<p>但是，对于重要的业务，不管使用何种一致性方案，<strong>提供额外的检查、核对、兜底手段都是必要的</strong>，由此衍生出了很多的业务核对、对账的需求。服务间通过特定手段保障数据一致性，并设计无侵入的旁路系统进行数据核对和校验，是微服务架构下的典型搭配。</p>
<p><img src="../202203-data-check/2.png" alt="Fig2. Data Consistency Insurance"></p>
<h3 id="12-离线核对的缺陷">1.2 离线核对的缺陷</h3>
<p>常见的离线数据核对可以通过定时任务，<strong>按照一定的筛选条件，从不同数据源中获取特定数据，再进行比较</strong>。这种方案的伪代码如：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">Check</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// 获取上游 update_time 落在 [a, b) 的数据行
</span><span class="c1"></span>    <span class="nx">upstreamRows</span> <span class="o">:=</span> <span class="nf">QueryUpstreamDB</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span>

    <span class="k">for</span> <span class="nx">uniqueKey</span><span class="p">,</span> <span class="nx">sourceData</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">upstreamRows</span> <span class="p">{</span>
        <span class="c1">// 为每个上游数据查找对应的下游数据
</span><span class="c1"></span>        <span class="nx">targetData</span> <span class="o">:=</span> <span class="nf">QueryDownstreamDB</span><span class="p">(</span><span class="nx">uniqueKey</span><span class="p">)</span>

        <span class="c1">// 对比上下游数据
</span><span class="c1"></span>        <span class="nf">Compare</span><span class="p">(</span><span class="nx">sourceData</span><span class="p">,</span> <span class="nx">targetData</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p><strong>时效性低</strong>是这类查表方案的通病。核对操作通常放在异步任务中定时执行，执行时间和离数据变更时间有一定延迟，且定时任务的查询条件也会对核对目标造成影响。当出现异常数据时，不能及时发现问题，只能等待下次定时任务执行后才能发现。</p>
<p>引入了<strong>额外的扫表开销</strong>同样是个不容忽视的问题。在数据量较大，尤其是存在大量 <code>INSERT</code> 操作的场景下，想要核对就需要 <code>SELECT</code> 出上下游的目标数据。为了在不影响正常业务的情况下及时处理完核对任务，开发者可通过将查询转移到从库，甚至引入核对任务独占的从库，但此类查表核对方案在资源使用和实现复杂度方面都不够理想。</p>
<p>同时，由于查表得到的结果只是当前的数据版本，在两次检查之间，数据可能发生了多次变更，<strong>定时任务无法感知和观测到每个状态变更</strong>，在数据被频繁 <code>UPDATE</code> 的场景下也存在一定的核对和检测难度。</p>
<p>因此，要实现更好的数据核对，我们需要考虑以下几点目标：</p>
<ul>
<li><strong>实现秒级核对</strong>。</li>
<li><strong>尽量减少数据库查询</strong>。</li>
<li><strong>核对数据变更，而非核对数据快照</strong>。</li>
<li><strong>简单灵活的接入方式</strong>。</li>
</ul>
<h2 id="2-实时数据核对">2. 实时数据核对</h2>
<p>为了更好地发现数据不一致的情况，Shopee Financial Products 团队在 2021 年中设计并实现了 <strong>Real-time Checking System</strong>（实时核对系统，RCS）。RCS 具有以下核心优势：</p>
<ul>
<li>秒级数据核对。</li>
<li>对业务逻辑无侵入。</li>
<li>可配置化接入。</li>
</ul>
<p>从上线至今，RCS 帮助团队及时检测到了多次数据问题，可以将原因归纳为以下几个方面：</p>
<ul>
<li>代码逻辑 Bug：包括幂等处理、并发问题、业务逻辑错误等。</li>
<li>系统运行环境：DB 异常、网络抖动、MQ 异常等。</li>
</ul>
<p><img src="../202203-data-check/3.png" alt="Fig3. Types of spotted bugs"></p>
<p>本节主要介绍 RCS 的实现，包括系统架构和核对流程、核对性能优化、消息通知机制等。</p>
<h3 id="21-系统架构与核对流程">2.1 系统架构与核对流程</h3>
<p>在系统设计上，我们将 RCS 分为了三层：</p>
<ul>
<li><strong>变更数据获取</strong>（Data Fetching Layer）</li>
<li><strong>数据核对</strong>（Data Checking Layer）</li>
<li><strong>核对结果处理</strong>（Result Handling Layer）</li>
</ul>
<p><img src="../202203-data-check/4.png" alt="Fig4. System Layers"></p>
<h4 id="211-变更数据获取">2.1.1 变更数据获取</h4>
<p>实时核对，顾名思义需要着重关注“实时”和“核对”两个要点。Data Fetching Layer 负责达成实时的目标，通过对不同 CDC（Change Data Capture，变更数据抓取）方案的调研，我们使用了 Log-Based 的方案来提供时效性保障。</p>
<blockquote>
<p><strong>扩展阅读</strong></p>
<p>CDC 模式用于感知数据变更，主要可以分为以下 4 类：</p>
<ul>
<li>Timestamps，基于 update_time 或类似字段进行查询来获取变更数据。</li>
<li>Table Differencing，获取完整数据快照进行比对。</li>
<li>Triggers，为 DDL、DML 设置 Trigger，将变更内容用额外的操作记录至数据库。</li>
<li>Log-Based，典型例子为利用 MySQL binlog 和 MongoDB oplog。</li>
</ul>
<p>其中，Timestamps 方案和 Table Differencing 均由定时任务驱动，时效性较弱。Timestamps 方案无法感知被删除的数据，使用时需要由软删除代替；Table Differencing 方案弥补了这个缺点，但是多次获取完整数据会让整套方案显得非常笨重。</p>
<p>Triggers 方案和 Log-Based 方案获取到的均为数据变更而非数据快照，但 Triggers 感知后以特定的语句将其记录下来，本质上是一次写操作，仍给数据库带来了额外的负担。</p>
</blockquote>
<p>当 MySQL 产生数据变更时，高可用的 binlog 同步组件会获取到对应 binlog，并将其投递至 Kafka 中，以此获取变更数据的数据值用于核对。</p>
<p><img src="../202203-data-check/5.png" alt="Fig5. Data Fetching Layer"></p>
<p>在实际使用中，需要核对的数据可能并非都存在于 MySQL 中，例如我们也需要核对 MySQL 与 MongoDB 的数据、MySQL 与 Redis 的数据。为此，业务系统也可以通过自行投递特定格式的 Kafka 消息来接入，从而保证接入的灵活性。</p>
<h4 id="212-数据核对">2.1.2 数据核对</h4>
<p>Data Checking Layer 负责处理接收到的数据流，包括获取特定的核对规则，接收到数据时进行暂存或比对。RCS 对 binlog 数据进行抽象，提炼了一套通用的可配置化的核对规则。用户只需要填写对应的规则，即可实现自助接入。规则定义示例如下：</p>
<p><img src="../202203-data-check/6.png" alt="Fig6. Config Example"></p>
<p>不难想象，不同系统间数据的变更是有先后的，且变更的消息被 RCS 接收到也会有先后顺序。因此，先抵达的数据需要被存储下来作为后续比对的目标，后抵达的数据则按照规则与已有数据进行比对。</p>
<p><img src="../202203-data-check/7.png" alt="Fig7. Check Flow"></p>
<p>为了便于描述，这里先定义几个名称：</p>
<ul>
<li>数据上游：先到达 RCS 的数据为上游。</li>
<li>数据下游：后到达 RCS 的数据为下游。</li>
<li>核对项：某个数据核对需求，包括上游数据和下游数据。例如：System A 与 System B 核对用户资金状态的需求。</li>
</ul>
<p><img src="../202203-data-check/8.png" alt="Fig8. Kafka Data Check Flow"></p>
<p>以下面这一次核对为例，它需要判断数据是否在 10 秒达成一致，整体的核对流程可以简要描述为：</p>
<ul>
<li>（图 8）核对项的上游数据到达，暂存 Redis 和延迟队列。</li>
<li>（图 8）RCS 等待核对项的下游数据：
<ul>
<li>比对数据到达，进行核对，并删除 Redis key；</li>
<li>比对数据未到达，判断延迟队列中的数据。</li>
</ul>
</li>
<li>（图 9）延迟队列到达时间后，再次查询在 Redis 中是否有对应数据：
<ul>
<li>存在，则超过核对时间阈值，发送异常告警，删除 Redis key；</li>
<li>不存在，则已核对。</li>
</ul>
</li>
</ul>
<p><img src="../202203-data-check/9.png" alt="Fig9. DelayQueue Check Flow"></p>
<h4 id="213-消息通知机制">2.1.3 消息通知机制</h4>
<p>RCS 的目标是及时发现数据不一致的问题，因此，在 Result Handling Layer 中接入了 Shopee 企业 IM（SeaTalk）的机器人进行告警。未来告警接口也会进行开放，便于扩展和让其它消息应用进行接入。</p>
<p>我们设计了四种消息通知机制：</p>
<ul>
<li>Mismatch Notice</li>
<li>Aggregated Notice</li>
<li>Recovery Notice</li>
<li>Statistical Notice</li>
</ul>
<p>Mismatch Notice 应对一般场景下的核对失败，及时通知到对应的业务负责人，便于快速定位问题原因并修复数据。但当大量数据出现不一致时，Aggregated Notice 会取而代之，将告警进行聚合发送，避免影响到值班人员的正常阅读。</p>
<p>RCS 也会将核对失败的数据持久化，因而具备恢复感知的能力。当异常数据恢复时，Recovery Notice 会发送消息告知使用者何种不一致已经恢复，间隔了多少时间。</p>
<p>最后，Statistical Notice 会向使用者报告常规的统计数据，包括 DB 主从延迟、当日核对成功率等。</p>
<h3 id="22-核对功能演进">2.2 核对功能演进</h3>
<p>系统上线至今，接入或自行部署使用 RCS 的团队越来越多，对应的业务场景也各不相同，早期的核对规则难以满足不同团队的核对需求。在 2021 年末，Shopee Financial Products 研发团队又对 Data Checking Layer 进行了一系列的扩展，目的是减少维护成本，以较为通用的方式支持不同团队的使用。</p>
<h4 id="221-等值--映射核对">2.2.1 等值 / 映射核对</h4>
<p>在最早上线的版本中，RCS 系统包含了等值和状态映射核对的功能，是针对组内实际面临的场景设计的，满足日常的使用需求。</p>
<p>核对系统主要处理的是上下游系统之间金额数值、状态的变化，通常我们能获取到的 binlog 核心字段示例和核对逻辑如下：</p>
<p><img src="../202203-data-check/10.png" alt="Fig10. Equivalence Check"></p>
<p>假设先接收到 System A 的 binlog 消息，暂存 Redis，规定时间内也接收到了 System B 的 binlog 消息：</p>
<ul>
<li>根据 System B 这条 binlog 的特征，发现配置有两条核对规则：
<ul>
<li><code>loan_amount</code> 为 200，需要找到一条对应的 System A 的 binlog，且 <code>order_amount</code> 需与之匹配；</li>
<li><code>loan_status</code> 为 4，需要找到一条对应的 System A 的 binlog，且 <code>order_status</code> 需为 2。</li>
</ul>
</li>
</ul>
<p>对于不同系统间产生的单条记录变更的核对，等值和映射检查能覆盖到大部分场景。但是因为这两种核对的逻辑都是固定下来的，所以业务方如果有不同的核对需要，则需要新的代码逻辑实现。为此，研发团队考虑<strong>将核对逻辑交给使用方来描述</strong>，因而催生出了表达式核对的功能。</p>
<h4 id="222-表达式核对">2.2.2 表达式核对</h4>
<p>如果我们考虑以下的 binlog 示例，不同系统间的数据模型设计并不一致，字段非一一对应。</p>
<p><img src="../202203-data-check/11.png" alt="Fig11. Expression Check"></p>
<p>System A 记录了<strong>订单的金额为 100</strong>，而 System B 记录了订单的<strong>已支付金额为 30，借贷金额为 70</strong>，需要核对的是 System A <code>order_amount</code> 是否等于 System B <code>paid_amount + loan_amount</code>，原有的设计无法支持。</p>
<p>为此，我们引入了表达式求值的方案，当 binlog 抵达时，<strong>使用方通过一个返回值为布尔类型的表达式来描述自己的核对逻辑</strong>，如：</p>
<ul>
<li>判断 2.2.2 中求和场景：<code>a.order_amount == b.paid_amount + b.loan_amount</code></li>
<li>兼容判断 2.2.1 中场景：
<ul>
<li><code>a.order_amount == b.loan_amount</code></li>
<li><code>a.order_status == 2 &amp;&amp; b.loan_status == 4</code></li>
</ul>
</li>
</ul>
<p>在表达式核对方案下，两个系统间的几乎所有的单条数据核对场景都能进行覆盖，且这种方案的好处在于研发团队不用再费心思提供新的计算、映射、与或非逻辑实现的支持，大大减少了维护成本。</p>
<h4 id="223-动态配置数据核对">2.2.3 动态配置数据核对</h4>
<p>在电商和金融的场景中，存在一些动态数据，例如费率、活动优惠折扣等，会随着业务和运营计划发生实时变化。这类数据通常存储在配置表中，因此通过简单的表达式无法进行定义，而不同业务系统中的配置表结构设计也不一样，很难在核对系统代码中进行声明。</p>
<p>为了满足这种场景，RCS 引入了对业务系统 SQL 查询的支持，当获取到新的 binlog 时，检查这条 binlog 满足的核对规则，使用方在核对规则中会配置需要执行的 SQL 语句，以及分库分表规则，由核对系统执行并得到比对的内容，再进行表达式核对：</p>
<ul>
<li>binlog 中获取到当前订单的费率 <code>order_rate</code> 为 0.5。</li>
<li>根据配置信息执行 <code>SELECT</code> 语句查询实时的费率 <code>rate</code>。</li>
<li>执行表达式核对 <code>a.order_rate == rate</code>。</li>
</ul>
<p>除此之外，RCS 也能支持 JSON 串核对，譬如 System A 需要核对 <code>order_rate</code>，但是存储 <code>order_rate</code> 信息是一个 JSON 串，<code>rate_info = {&quot;decimal_base&quot;:&quot;10000&quot;, &quot;order_rate&quot;:&quot;0.5&quot;}</code>。可以在 RCS 的核对规则中，自定义 JSON 解析表达式，提取真实需要核对的字段。</p>
<h2 id="3-性能表现">3. 性能表现</h2>
<p>RCS 系统的性能主要取决于 Data Fetching Layer 和 Data Checking Layer。</p>
<p>Data Fetching Layer 的性能代表实时获取变更数据的能力，受 binlog 解析（CPU 密集型任务）及 Kafka 的消息持久化（I/O 密集型任务）影响。<strong>业务团队可根据需要选择对应的硬件搭建 CDC 模块</strong>，以我们使用场景为例，每秒可投递的消息数量超过 <strong>20K</strong>。</p>
<p>Data Checking Layer 则负责进行数据核对，为了测试 RCS 的性能极限，Data Fetching 采用 Kafka 发送源数据，核对系统采用单机部署。测试结果表明，<strong>RCS 每秒可完成核对 10K+ 次</strong>，详细数据如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Component</th>
<th style="text-align:center">Machine</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Kafka</td>
<td style="text-align:center">3 * 48 Core 128 GB</td>
</tr>
<tr>
<td style="text-align:center">Redis</td>
<td style="text-align:center">3 * 48 Core 128 GB</td>
</tr>
<tr>
<td style="text-align:center"><strong>Real-time Checking System</strong></td>
<td style="text-align:center"><strong>1 * 48 Core 128 GB</strong></td>
</tr>
</tbody>
</table>
<p><br/><br/></p>
<table>
<thead>
<tr>
<th style="text-align:center">Number of check entry</th>
<th style="text-align:center">TPS</th>
<th style="text-align:center">CPU Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1 entry</td>
<td style="text-align:center"><strong>14.3K</strong></td>
<td style="text-align:center">454%</td>
</tr>
<tr>
<td style="text-align:center">2 entries</td>
<td style="text-align:center"><strong>12.0K</strong></td>
<td style="text-align:center">687%</td>
</tr>
<tr>
<td style="text-align:center">3 entries</td>
<td style="text-align:center"><strong>10.4K</strong></td>
<td style="text-align:center">913%</td>
</tr>
</tbody>
</table>
<p>从压测结果分析，RCS 的性能瓶颈主要取决于 Redis 集群的性能，单次核对耗时约为 0.5ms。
当然，RCS 支持集群部署，做为 Kafka 的消费者，可以利用 Kafka consumer group 的 Rebanancing 机制，从而实现动态扩/缩容的机制。</p>
<h2 id="4-总结">4. 总结</h2>
<p>Shopee Financial Products 团队在 2021 年落地的 RCS 目前在多个产品线推广和使用，主要解决传统 T+1 式离线数据核对延迟高、业务耦合紧密，且随新业务上线还带来额外的开发负担的问题。</p>
<p>RCS 通过灵活的核对规则配置化、表达式场景覆盖以及 Log-Based 的 CDC 方案，提供近实时的数据核对解决方案，最大程度地降低数据不一致导致的资金、信息安全等风险。我们也欢迎不同的用户和团队接入或部署使用，在后续的更新迭代中，RCS 会进一步提升核对的性能，以支撑业务量增长带来的核对需求。</p>
]]></content>
		</item>
		
		<item>
			<title>2021 年度总结：期望与选择</title>
			<link>https://jiekun.dev/posts/2021-summary/</link>
			<pubDate>Sun, 16 Jan 2022 14:28:15 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2021-summary/</guid>
			<description>Goodbye 2021 好的，其实对自己的 2021 年并不太满意，原因有很多，包括遇到了各种各样的人和事，以及在经历工作前几年的付出和成长，随之而来的更高的期望值。然而</description>
			<content type="html"><![CDATA[<h2 id="goodbye-2021">Goodbye 2021</h2>
<p>好的，其实对自己的 2021 年并不太满意，原因有很多，包括遇到了各种各样的人和事，以及在经历工作前几年的付出和成长，随之而来的更高的期望值。然而事与愿违，过去这一年很多事情都不如想象中的顺利。</p>
<p>又赶上一年一度的总结，当你想跟别人讲 2021 年的故事的时候，除了人人都能看到的以外，总要有一些不同的思考吧。所以，今年的想法是从头到尾整理好这些不满意的点，看看下一年能怎样做得更漂亮。</p>
<h3 id="期望">期望</h3>
<p>时间回到 2020 年 10 月，当时还在原来的团队，临近年末的时候争取到了一个很大的项目改动，机遇和挑战总是并存的，对 Developer 来说，谁不想在大的挑战里面交一份满意的答卷呢（躺平党：nsdd）？幸运的是，改动没有出很大的问题，后来还是顺利上线了，自己也收获到了入职来的第一个好绩效。</p>
<p>因为公司的绩效计算是每年的 Q4 至次年 Q3 作为一个结算周期，“当你在 Q4 拿到了一个 A，你会憧憬着剩下的 3 个季度，3 次机会，再争取一次 A”，这句话我至少已经跟不同的人重复过 10 多次。为什么需要第二个 A 呢？因为原来的绩效制度不像现在，有这么多细分的等级，仅凭一个 A 在年终时并不足以让你拿到更高一档的全年绩效，依然会是一个冷冰冰的 B，所以其实拿一次和拿两次好绩效，在当时的我看来，差异是很大的。</p>
<p>然而问题就正好出在这里，2020 年 Q4 结束之后，因为业务技术架构的变更，为了将老的业务迁移到新的系统，部门内有大量的梳理和配置工作要做。梳理是由于对接第三方的业务场景，当系统里面存在着 100+ 不同的第三方且无法以开放平台的方式让外部自助接入，那其实为不同的客户做不同的特殊逻辑也是很正常的。在新平台里，大多数的特殊逻辑都以配置化的方式实现，迁移后只需要进行配置就能支持，听起来很方便不是么？从产品和运营的角度来看，或许是对的。</p>
<p>我记得在发起调动申请的时候，部门内 HR 同事有跟我说过这样一句话：“以我这么多年作为 Recruiter 的经验看，其实业务的 QPS、并发这些，对 Developer 的成长还是很重要的”。这句话本身确实没有错，但是从我的角度来看，接到的任务将我推离了业务系统，梳理者和配置者的角色本身与“研发”冲突，这是一个已经开发好的系统，交付给使用者使用，而我就是那个使用者。另外，其实配置并不是一个容易、简短的过程，团队内不止一个人参与，配置了半年也只完成了 50% 左右的量。</p>
<p>说到这里，我又想起来当初上级跟我说的另一句话：“之所以将你放到迁移专项中，是因为你之前一直也说对 Go 很感兴趣，原来（老系统）是 Python 写的，这次去研究新系统正好可以锻炼一下”。我很难说清这半年里我对 Go 有了哪些新的理解，但是至少是把自己给锻炼走了，因为我想做一个 Developer，而不是业务运营。</p>
<p>那么，到这里关于“期望”的故事就差不多讲完了，因为有一个好的开局，所以作为 Developer，我对自己的 2021 年其实有很高的期望。当个人成长与团队业务发展有所冲突的时候，其实最受伤的还是个人，因为团队的业务目标是既定的，不可能因为你的技术方向和规划有所让步。如果真的要寻求改变，那需要自己做出选择。</p>
<h3 id="选择">选择</h3>
<p>调动或者离职一定不是个很简单就能决定的事情，因为它未必能解决你的问题，而且会有很大的风险。在新的团队氛围相对不可预知，并且重新建立信任也需要花很长的时间。</p>
<p>那到底要不要走呢？或许 Leader 从我入职到离开都没能发现我在争取的是什么，工作内容能以什么方式帮到 Member 成长，这是最核心的竞争力。或许我会因为薪资、工作时间、Title 的事情去做一些争取，但是这一定不是转岗的理由。</p>
<p>除了解决问题以外，做出选择还要考虑到会失去什么：</p>
<ul>
<li>如果提出转岗，基本意味着剩下的时间内不要再考虑什么好的绩效。</li>
<li>或许会错过一年一次的晋升机会。</li>
</ul>
<p>虽然已经工作了很多年，可能也已经没了刚毕业时那么强烈的技术热情，但是抓住每个成长的机会还是太重要了，回头想想，难道当初拿到第一个 A 的时候不正因为这种想法么？</p>
<h3 id="新团队">新团队</h3>
<p>2021 年 8 月份来到了现在的新团队，如果说要用什么样的词语来描述新的工作，我想应该是“踏实”，久违的作为一个开发者的感觉，在小小博客中无法表述。还是之前的话，我说，我希望 Member 在帮到团队的同时，团队也能在成长上帮到 Member。在这里，我更愿意把顺序调整一下：团队能在成长上帮到员工，那我会更乐意在常规业务以外的方方面面帮到团队。</p>
<h3 id="学习">学习</h3>
<p>过去这年书单多了 21 本书（当然没全部读完），整理的时候很惊讶发现没有任何数据库或存储相关的书。在往年，KVS 和 Cache 是自己很关注的方向，个人应该要有自己的招牌，也就是擅长的领域。</p>
<p><img src="../202201-2021-summary/2021_books.png" alt=""></p>
<p>在下半年中，多花了很多的时间关注微服务架构和 Kubernetes，前者是因为业务需要，而后者则是当前技术栈下的选择，如果想参与开源项目，我会说一定要选择一个与个人工作生态能结合的开源社区作为目标。</p>
<p>书单中有 3 本书是打算特别推荐的，按照阅读的顺序罗列。</p>
<p><img src="../202201-2021-summary/operating_systems.png" alt=""></p>
<p>第一本是《操作系统导论》，王海鹏老师翻译得很流畅，当然如果有能力的话读原版是最好的，可惜国内没有引入，只能到国外买。虚拟化和并发两节写得挺不错，有一种“如果我是操作系统，我怎样处理虚拟化和并发”的体验。比起其他 OS 的书，如果只能推荐一本的话，那毫无疑问会是这本。</p>
<p><img src="../202201-2021-summary/microservices.png" alt=""></p>
<p>《微服务架构设计模式》讲的是微服务的方方面面，个人认为比起现在火爆的领域驱动设计，理解微服务的几个关键点更加重要：</p>
<ul>
<li>单体服务缺点，微服务优点</li>
<li>拆分策略</li>
<li>服务间通信</li>
<li>Sega 事务</li>
</ul>
<p>亲眼见过有的单体项目被拆分成几个臃肿无比的新单体服务，里面很多事情都是违背了微服务的理念的。所以个人觉得那并非微服务，只是为了一己的 KPI 找事情做而已，后果就是新来的人都要给这堆屎山代码填坑，再后来搞 DDD 也不能解决任何问题。</p>
<p>回到这本书上，其实书里面的概念就是微服务最基础的东西，但是如果你没接触过微服务，或者只是跟着别人做过一点所谓的“微服务”，那可以带着问题来读，比如：“我做的小型单体服务是微服务吗？”，这些基础知识或许会改变你对微服务的印象。</p>
<p><img src="../202201-2021-summary/kubernetes_in_action.png" alt=""></p>
<p>最后一本是《Kubernetes in Action》。读 Kubernetes 的书是由于一个很偶然的机会，要去了解一些相关的知识。推荐这本书是因为它对新人很友好，程序员最好的学习方式就是敲代码，也是 in Action 系列书籍受欢迎的原因之一。只要本地或者 GKE 上搭建有 Kubernetes 集群，就可以很轻松实践书里的所有内容，阅读时长大概 3 周到 1 个月，就算只是抄一遍书里的代码，也可以对 Kubernetes 的在企业基建中的角色有深入的体会。</p>
<h3 id="okr">OKR</h3>
<p>2021 年的最后来盘点一下去年工作之外的 OKR 完成情况。</p>
<ul>
<li><input disabled="" type="checkbox"> O1：团队技术影响力
<ul>
<li><input checked="" disabled="" type="checkbox"> KR1：5 次技术分享（6/5）</li>
<li><input disabled="" type="checkbox"> KR2：5 篇技术博客（3/5）</li>
</ul>
</li>
<li><input disabled="" type="checkbox"> O2：开源社区贡献
<ul>
<li><input disabled="" type="checkbox"> KR1：翻译<a href="https://jiekun.github.io/tech-writing/">《技术写作课程》</a>（4/17）</li>
<li><input checked="" disabled="" type="checkbox"> KR2：为 Kubernetes 提交 1 次 PR（1/1）</li>
<li><input checked="" disabled="" type="checkbox"> KR3：为 redis-py 提交 1 次 PR（2/1）</li>
</ul>
</li>
<li><input checked="" disabled="" type="checkbox"> O3：新的好习惯
<ul>
<li><input checked="" disabled="" type="checkbox"> KR1：早睡早起（诶嘿嘿嘿嘿嘿嘿）</li>
<li><input checked="" disabled="" type="checkbox"> KR2：做饭</li>
</ul>
</li>
</ul>
<h2 id="hello-2022">Hello 2022</h2>
<p>2022 年时间上好像会比往年充裕一些，所以新的 OKR 本来可以更加激进，不过生活里面也有很多想做的事情，最后平衡下来大概只能挑一些合适的来发展。</p>
<ul>
<li>O1：团队技术影响力
<ul>
<li>KR1：2 篇 Shopee 技术博客</li>
<li>KR2：1 次 Shopee Academy 分享</li>
</ul>
</li>
<li>O2：开源社区贡献
<ul>
<li>KR1：成为 Kubernetes Member</li>
<li>KR2：成为 Kubernetes Scheduling SIG Reviewer</li>
<li>KR3：翻译<a href="https://jiekun.github.io/tech-writing/">《技术写作课程》</a>（orz 填坑）</li>
</ul>
</li>
<li>O3：生活
<ul>
<li>KR1：去两个新的城市旅游</li>
<li>KR2：一台单反 &amp; 多拍照</li>
<li>KR3：一辆新车（?）</li>
</ul>
</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>Learn from issues: PodTopologySpread Skew 与 nodeAffinity 过滤</title>
			<link>https://jiekun.dev/posts/exclude-filtered-nodes/</link>
			<pubDate>Mon, 20 Dec 2021 20:06:27 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/exclude-filtered-nodes/</guid>
			<description>『Learn from issues』 系列通过讲解 Kubernetes 的 Issue 及 PR 中涉及的概念、代码，来帮助 Kubernetes 新人快速了解功能和代码思路。在以往的学习中，阅读大型项目的代码</description>
			<content type="html"><![CDATA[<blockquote>
<p>『Learn from issues』 系列通过讲解 Kubernetes 的 Issue 及 PR 中涉及的概念、代码，来帮助 Kubernetes 新人快速了解功能和代码思路。在以往的学习中，阅读大型项目的代码往往比较困难，而且如果没有使用场景，一些功能对新手而言或许会比较模糊且无法复现。本系列挑选的 Issue/PR 通常是只针对特定功能、bug 的改动，并且提供足够精简清晰的上下文来降低理解的负担。文末会附上对应的 Issue/PR 链接方便查看原内容。</p>
</blockquote>
<h2 id="功能简介">功能简介</h2>
<p>Kubernetes Scheduler 的任务是将未被调度的 Pod 调度至特定 Node 上。自 v1.19 版本开始，我们可以使用 Pod Topology Spread Constraints 来控制 Pod 在一定拓扑结构集群的调度。</p>
<p>我们假定有 4 个带有 Labels 的 Node：</p>
<pre tabindex="0"><code>NAME    STATUS   ROLES    AGE     VERSION   LABELS
node1   Ready    &lt;none&gt;   4m26s   v1.16.0   node=node1,zone=zoneA
node2   Ready    &lt;none&gt;   3m58s   v1.16.0   node=node2,zone=zoneA
node3   Ready    &lt;none&gt;   3m17s   v1.16.0   node=node3,zone=zoneB
node4   Ready    &lt;none&gt;   2m43s   v1.16.0   node=node4,zone=zoneB
</code></pre><p>编写以下 yaml 文件使用 Pod Topology Spread Constraints：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mypod</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">foo</span><span class="p">:</span><span class="w"> </span><span class="l">bar</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">topologySpreadConstraints</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">maxSkew</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">                                 </span><span class="c"># 最大不均匀度</span><span class="w">
</span><span class="w">    </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">zone                         </span><span class="w"> </span><span class="c"># Node 拓扑结构的 Label</span><span class="w">
</span><span class="w">    </span><span class="nt">whenUnsatisfiable</span><span class="p">:</span><span class="w"> </span><span class="l">DoNotSchedule          </span><span class="w"> </span><span class="c"># 不满足条件时的策略</span><span class="w">
</span><span class="w">    </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">                             </span><span class="c"># 针对带有哪些 Label 的 Pods 生效</span><span class="w">
</span><span class="w">      </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">foo</span><span class="p">:</span><span class="w"> </span><span class="l">bar</span><span class="w">
</span><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">pause</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">k8s.gcr.io/pause:3.1</span><span class="w">
</span></code></pre></div><p>简单来说，<code>pod.spec.topologySpreadConstraints</code> 要求满足条件的 Pod 在集群中分布的不均匀度不超过 1，统计的以 Node 中 的 <code>zone</code> 字段聚合。以前文的 4 Nodes 集群为例，<code>zone</code> 只有两个值：<code>zoneA</code> 和 <code>zoneB</code>，如果当前已有 3 个 Pod 如下图分布，那么当前的不均匀度为 <code>2 - 1 = 1</code>。新 Pod 想要加入进来，如果加入至 <code>zoneA</code>，则不均匀度变为 <code>3 - 1 = 2</code>，超出了设定值，因此只能被调度至 <code>zoneB</code> 的 Node 上。至于最终调度至 Node 3 或是 Node 4 均符合预期结果。</p>
<p><img src="../202112-exclude-filtered-nodes/topology_spread_constraint.png" alt=""></p>
<p>不同的 <code>pod.spec.topologySpreadConstraints</code> 条件为 <code>&amp;&amp;</code> 关系，需要同时满足。因此，如果期望 Pod 被调度到 Node 4，可以通过增加以下配置，以 <code>node</code> 作为统计字段：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nn">...</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">topologySpreadConstraints</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">maxSkew</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">    </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">zone</span><span class="w">
</span><span class="w">    </span><span class="l">...</span><span class="w">
</span><span class="w">  </span>- <span class="nt">maxSkew</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">    </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">node</span><span class="w">
</span><span class="w">    </span><span class="nt">whenUnsatisfiable</span><span class="p">:</span><span class="w"> </span><span class="l">DoNotSchedule</span><span class="w">
</span><span class="w">    </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">foo</span><span class="p">:</span><span class="w"> </span><span class="l">bar</span><span class="w">
</span><span class="w"></span><span class="nn">...</span><span class="w">
</span></code></pre></div><p>更多示例可以参考<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">官方文档</a>。</p>
<p>除了 Pod Topology Spread Constraints，<a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity">Node affinity</a> 也可以用来控制调度，本文只介绍涉及的配置以减少需要理解的内容。以下面 yaml 为例，要求 Pod 必须调度至带有 <code>kubernetes.io/e2e-az-name</code> 标签且标签值为 <code>e2e-az1</code> 或 <code>e2e-az2</code> 的 Nodes 上：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">with-node-affinity</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">affinity</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">nodeAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">  </span><span class="c"># 硬性要求, 必须满足</span><span class="w">
</span><span class="w">        </span><span class="nt">nodeSelectorTerms</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes.io/e2e-az-name            </span><span class="w"> </span><span class="c"># 必须调度至带有此标签的 Nodes</span><span class="w">
</span><span class="w">            </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In                              </span><span class="w"> </span><span class="c"># 标签的值落在以下范围内</span><span class="w">
</span><span class="w">            </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">e2e-az1</span><span class="w">
</span><span class="w">            </span>- <span class="l">e2e-az2</span><span class="w">
</span><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">with-node-affinity</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">k8s.gcr.io/pause:2.0</span><span class="w">
</span></code></pre></div><h2 id="问题描述">问题描述</h2>
<p>当同时使用 Pod Topology Spread Constraints 和 Node affinity 来控制调度时，我们考虑以下例子，当前集群一共有 3 个 Nodes，其中 Node 1 和 Node 2 属于 zoneA，Node 3 属于 zoneB。已有 2 个 Pod 落在 Node 2 上，1 个 Pod 落在 Node 3。</p>
<p><img src="../202112-exclude-filtered-nodes/filter_bug_example.png" alt=""></p>
<p>现在如下文 yaml 新建一个 deployment，要求不同 zone 之间不均匀度不超过 1，且 Pod 不落入带有 <code>name=2</code> 标签的 Nodes。如果调度至 Node 3，那么不同 <code>zone</code> 之间的不均匀度为 <code>2 - 2 = 0</code>，并且也没调度至带有 <code>name=2</code> 标签的 Node，看起来很合理不是吗？</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nn">...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">topologySpreadConstraints</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">maxSkew</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">zone</span><span class="w">
</span><span class="w">        </span><span class="nt">whenUnsatisfiable</span><span class="p">:</span><span class="w"> </span><span class="l">DoNotSchedule</span><span class="w">
</span><span class="w">        </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">pause</span><span class="w">
</span><span class="w">      </span><span class="nt">affinity</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">nodeAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">nodeSelectorTerms</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">name</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">NotIn</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;2&#34;</span><span class="p">]</span><span class="w">
</span><span class="w"></span><span class="nn">...</span><span class="w">
</span></code></pre></div><p>但是如果先考虑 nodeAffinity，Pod 永远不能调度至 <code>name=2</code> 标签的 Node，实际上，在 zoneA 中用于计算不均匀度的 Pod 数量应该为 0（仅有 Node 1 拥有的 Pod 才应被计算），而 zoneB 中的 Pod 为 1，如果继续调度至 zoneB，则不均匀度应为 <code>2 - 0 = 2</code>，不符合要求。</p>
<p>因此，这里的问题是在计算不均匀度时，应该先排除被 <code>nodeAffinity</code> 所过滤的 Node。</p>
<h2 id="代码修复">代码修复</h2>
<p>知道问题之后修复就比较容易，对应代码为以下方法：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="p">(</span><span class="nx">pl</span> <span class="o">*</span><span class="nx">PodTopologySpread</span><span class="p">)</span> <span class="nf">calPreFilterState</span><span class="p">(</span><span class="nx">pod</span> <span class="o">*</span><span class="nx">v1</span><span class="p">.</span><span class="nx">Pod</span><span class="p">)</span> <span class="p">(</span><span class="o">*</span><span class="nx">preFilterState</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
	<span class="nx">allNodes</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">pl</span><span class="p">.</span><span class="nx">sharedLister</span><span class="p">.</span><span class="nf">NodeInfos</span><span class="p">().</span><span class="nf">List</span><span class="p">()</span>  <span class="c1">// 获取到所有节点
</span><span class="c1"></span>	<span class="o">...</span>
	<span class="nx">requiredSchedulingTerm</span> <span class="o">:=</span> <span class="nx">nodeaffinity</span><span class="p">.</span><span class="nf">GetRequiredNodeAffinity</span><span class="p">(</span><span class="nx">pod</span><span class="p">)</span>
	<span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">n</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">allNodes</span> <span class="p">{</span>
		<span class="nx">node</span> <span class="o">:=</span> <span class="nx">n</span><span class="p">.</span><span class="nf">Node</span><span class="p">()</span>

		<span class="nx">match</span><span class="p">,</span> <span class="nx">_</span> <span class="o">:=</span> <span class="nx">requiredSchedulingTerm</span><span class="p">.</span><span class="nf">Match</span><span class="p">(</span><span class="nx">node</span><span class="p">)</span>  <span class="c1">// 是否匹配 nodeAffinity 要求
</span><span class="c1"></span>		<span class="k">if</span> <span class="p">!</span><span class="nx">match</span> <span class="p">{</span>
			<span class="k">continue</span>
		<span class="p">}</span>
		<span class="k">if</span> <span class="p">!</span><span class="nf">nodeLabelsMatchSpreadConstraints</span><span class="p">(</span><span class="nx">node</span><span class="p">.</span><span class="nx">Labels</span><span class="p">,</span> <span class="nx">constraints</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// 是否匹配 Spread Constraints 要求
</span><span class="c1"></span>			<span class="k">continue</span>
		<span class="p">}</span>
		<span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">c</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">constraints</span> <span class="p">{</span>
			<span class="nx">pair</span> <span class="o">:=</span> <span class="nx">topologyPair</span><span class="p">{</span><span class="nx">key</span><span class="p">:</span> <span class="nx">c</span><span class="p">.</span><span class="nx">TopologyKey</span><span class="p">,</span> <span class="nx">value</span><span class="p">:</span> <span class="nx">node</span><span class="p">.</span><span class="nx">Labels</span><span class="p">[</span><span class="nx">c</span><span class="p">.</span><span class="nx">TopologyKey</span><span class="p">]}</span>
			<span class="nx">s</span><span class="p">.</span><span class="nx">TpPairToMatchNum</span><span class="p">[</span><span class="nx">pair</span><span class="p">]</span> <span class="p">=</span> <span class="nb">new</span><span class="p">(</span><span class="kt">int32</span><span class="p">)</span>  <span class="c1">// 全都满足后记录在 map 中
</span><span class="c1"></span>		<span class="p">}</span>
	<span class="p">}</span>

	<span class="nx">processNode</span> <span class="o">:=</span> <span class="kd">func</span><span class="p">(</span><span class="nx">i</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
		<span class="nx">nodeInfo</span> <span class="o">:=</span> <span class="nx">allNodes</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span>  <span class="c1">// 此处用了 allNodes, 即包括不满足 nodeAffinity 要求的 Nodes
</span><span class="c1"></span>		<span class="nx">node</span> <span class="o">:=</span> <span class="nx">nodeInfo</span><span class="p">.</span><span class="nf">Node</span><span class="p">()</span>

		<span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">constraint</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">constraints</span> <span class="p">{</span>
			<span class="c1">// 计算 Spread Constraints 分组的 Pod 数量
</span><span class="c1"></span>		<span class="p">}</span>
	<span class="p">}</span>
	<span class="nx">pl</span><span class="p">.</span><span class="nx">parallelizer</span><span class="p">.</span><span class="nf">Until</span><span class="p">(</span><span class="nx">context</span><span class="p">.</span><span class="nf">Background</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="nx">allNodes</span><span class="p">),</span> <span class="nx">processNode</span><span class="p">)</span>

	<span class="c1">// 最后得出满足不同 Topology 要求的方案
</span><span class="c1"></span>	<span class="o">...</span>
<span class="p">}</span>
</code></pre></div><p>显然由于在计算 Spread Constraints 分组时使用了 <code>allNodes[i]</code>，因此被 nodeAffinity 过滤的 Nodes 也被计算入内。所以只需要构造一个新的切片，记录被过滤后得到的节点 <code>filteredNodes[i]</code>，并在后续的处理中以此为统计目标：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="p">(</span><span class="nx">pl</span> <span class="o">*</span><span class="nx">PodTopologySpread</span><span class="p">)</span> <span class="nf">calPreFilterState</span><span class="p">(</span><span class="nx">pod</span> <span class="o">*</span><span class="nx">v1</span><span class="p">.</span><span class="nx">Pod</span><span class="p">)</span> <span class="p">(</span><span class="o">*</span><span class="nx">preFilterState</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
	<span class="nx">allNodes</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">pl</span><span class="p">.</span><span class="nx">sharedLister</span><span class="p">.</span><span class="nf">NodeInfos</span><span class="p">().</span><span class="nf">List</span><span class="p">()</span>
	<span class="o">...</span>
	<span class="kd">var</span> <span class="nx">filteredNodes</span> <span class="p">[]</span><span class="o">*</span><span class="nx">framework</span><span class="p">.</span><span class="nx">NodeInfo</span>  <span class="c1">// 构造新切片
</span><span class="c1"></span>	<span class="nx">requiredSchedulingTerm</span> <span class="o">:=</span> <span class="nx">nodeaffinity</span><span class="p">.</span><span class="nf">GetRequiredNodeAffinity</span><span class="p">(</span><span class="nx">pod</span><span class="p">)</span>
	<span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">n</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">allNodes</span> <span class="p">{</span>
		<span class="nx">node</span> <span class="o">:=</span> <span class="nx">n</span><span class="p">.</span><span class="nf">Node</span><span class="p">()</span>

		<span class="nx">match</span><span class="p">,</span> <span class="nx">_</span> <span class="o">:=</span> <span class="nx">requiredSchedulingTerm</span><span class="p">.</span><span class="nf">Match</span><span class="p">(</span><span class="nx">node</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">!</span><span class="nx">match</span> <span class="p">{</span>
			<span class="k">continue</span>        
		<span class="p">}</span>
		<span class="k">if</span> <span class="p">!</span><span class="nf">nodeLabelsMatchSpreadConstraints</span><span class="p">(</span><span class="nx">node</span><span class="p">.</span><span class="nx">Labels</span><span class="p">,</span> <span class="nx">constraints</span><span class="p">)</span> <span class="p">{</span>
			<span class="k">continue</span>
		<span class="p">}</span>
		<span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">c</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">constraints</span> <span class="p">{</span>
			<span class="o">...</span>
		<span class="p">}</span>
		
		<span class="c1">// 此处均为满足 nodeAffinity 和 Spread Constraints 的结果, 加入 filteredNodes
</span><span class="c1"></span>		<span class="nx">filteredNodes</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span><span class="nx">filteredNodes</span><span class="p">,</span> <span class="nx">n</span><span class="p">)</span>
	<span class="p">}</span>

	<span class="nx">processNode</span> <span class="o">:=</span> <span class="kd">func</span><span class="p">(</span><span class="nx">i</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
		<span class="nx">nodeInfo</span> <span class="o">:=</span> <span class="nx">filteredNodes</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span>  <span class="c1">// 改用 filteredNodes 而非 allNodes
</span><span class="c1"></span>		<span class="nx">node</span> <span class="o">:=</span> <span class="nx">nodeInfo</span><span class="p">.</span><span class="nf">Node</span><span class="p">()</span>

		<span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">constraint</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">constraints</span> <span class="p">{</span>
			<span class="o">...</span>
		<span class="p">}</span>
	<span class="p">}</span>
	<span class="nx">pl</span><span class="p">.</span><span class="nx">parallelizer</span><span class="p">.</span><span class="nf">Until</span><span class="p">(</span><span class="nx">context</span><span class="p">.</span><span class="nf">Background</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="nx">filteredNodes</span><span class="p">),</span> <span class="nx">processNode</span><span class="p">)</span>
	<span class="o">...</span>
<span class="p">}</span>
</code></pre></div><h2 id="issue--pr">Issue &amp; PR</h2>
<p><a href="https://github.com/kubernetes/kubernetes/issues/106971">#106971: Potential bug of PodTopologySpread when nodeAffinity is specified</a></p>
<p><a href="https://github.com/kubernetes/kubernetes/pull/107009">#107009: nodeAffinity filtered nodes should be excluded when calculating skew in PodTopologySpread</a></p>
]]></content>
		</item>
		
		<item>
			<title>技术博客写作指北——素材、排版和配图</title>
			<link>https://jiekun.dev/posts/blog-writting/</link>
			<pubDate>Thu, 01 Apr 2021 21:00:00 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/blog-writting/</guid>
			<description>简介 技术博客是分享和总结的平台，也记录了毕业三年内作者一点一滴成长的过程。在写作过程中不难发现，除了选材以外，还存在一些简单的套路，能够快速</description>
			<content type="html"><![CDATA[<h2 id="简介">简介</h2>
<p>技术博客是分享和总结的平台，也记录了毕业三年内作者一点一滴成长的过程。在写作过程中不难发现，除了选材以外，还存在一些简单的套路，能够快速改善读者的阅读体验。本文通过正反举例的方式为各位作者介绍在博客排版和配图上的技巧，希望通过这些套路能帮助大家更容易下笔写作和贡献更精彩的分享。</p>
<h2 id="内容和编排">内容和编排</h2>
<p>博客的选题和材料收集都是特别耗费时间的，最常见的困境就是觉得手上没有能达到对外分享的技术干货。但首先应该认识到的是，写作不是为了记录知识，而是一种将系统知识分享给更多的人的方式，因此如果你打算现学点什么内容，并在短时间内以博客的形式分享出去——请务必打消这个念头，重新开始长线规划这次写作任务。</p>
<h3 id="知识储备">知识储备</h3>
<p>通常技术博客更适合分享这样的内容：</p>
<ul>
<li>用于解决特定问题的<strong>系统设计</strong>、大型功能或改动的<strong>落地实践</strong></li>
<li><strong>前沿知识</strong>，新概念与新设计</li>
</ul>
<p>很容易看出两类知识前者更偏向结合业务，而后者更多能在外部的项目源码、论文、博客中检索到。</p>
<p>对于<strong>设计和实践类的写作任务</strong>，通常整个知识储备周期会比较长，从撰写设计文档开始至落地上线，在整个过程中需要<strong>记录关键节点信息</strong>，例如遇到问题则记录背景，设计中记录设计难点、实现过程中记录落地阻力，投入使用后记录新问题。尽管这类写作可能需要长达几周或数月的时间，但是分享者能把控的内容细节会相对较多。</p>
<p>而对于<strong>前沿知识</strong>，准备材料实际上就是阅读的过程，无论是针对代码或是论文。在这种场景下，分享者的任务应是降低门槛、传播知识，因此<strong>铺垫</strong>、<strong>抽象</strong>、<strong>总结</strong>是必须体现的。以论文分享写作为例，为了铺垫，分享者不能局限于论文内，而要<strong>对同一方向的知识有更多的了解</strong>，例如同类方案及其缺点；而在抽象和总结上，配合自己的理解、<strong>绕过复杂的公式和代码</strong>，以更简洁的方式让读者明白思路和优势。</p>
<h3 id="编排">编排</h3>
<p>每个作者都应该形成自己的写作风格，但是如果你还没有思路，也可以从参照基础套路开始，再逐渐调整出自己的方式。</p>
<p><strong>从问题出发</strong>，让读者感兴趣的简单方法就是先让他们看到问题所在。在这个过程中描述问题背景，配合已有的方案、同类项目进行对比，说明存在什么缺陷，以及为何需要一套新的方案。</p>
<p><strong>从整体到细节</strong>，先描绘大体的方案轮廓，再分小节丰富完善。在这部分可以配合前面描述的问题，讲解解决问题的核心细节，而无需将所有设计和功能都摊开来分析。在这个过程中要换位思考，如果读者是自己，会不会对这个内容的实现细节感兴趣，再决定要花多少篇幅介绍。</p>
<p><strong>末尾总结</strong>，分享者在这部分应该达成的目标是：让只读总结的读者也能了解到大体的思路。</p>
<p>因此，对大多数的分享内容，我们都可以拟定如下的章节和标签：</p>
<blockquote>
<p>1 简介</p>
<ul>
<li>
<p>1.1 问题背景</p>
</li>
<li>
<p>1.2 现有方案</p>
</li>
</ul>
<p>2 方案设计 / 新技术简介</p>
<p>3 细节实现分析</p>
<ul>
<li>
<p>3.1 重难点1实现原理</p>
</li>
<li>
<p>3.2 重难点2实现原理</p>
</li>
</ul>
<p>4 总结</p>
</blockquote>
<h2 id="优雅的排版">优雅的排版</h2>
<p>在文章排版上，风格统一是最重要的。本节中介绍一些常见的写作、排版错误示范，作者们应该尽可能总结避免这些容易引起读者不适的设计。</p>
<h3 id="代码块">代码块</h3>
<p>技术博文中出现代码块的概率是比较高的，为了能让更多读者受益，在使用代码块时，应该考虑读者是否有相关基础，是否容易读懂。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Go" data-lang="Go"><span class="kd">func</span> <span class="p">(</span><span class="nx">svc</span> <span class="o">*</span><span class="nx">Service</span><span class="p">)</span> <span class="nf">ReplayTraffic</span><span class="p">(</span><span class="nx">param</span> <span class="o">*</span><span class="nx">ReplayTrafficRequest</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
    <span class="c1">// Get origin traffic
</span><span class="c1"></span>    <span class="nx">rConfig</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">svc</span><span class="p">.</span><span class="nx">dao</span><span class="p">.</span><span class="nf">GetReplayConfig</span><span class="p">(</span><span class="nx">param</span><span class="p">.</span><span class="nx">ReplayID</span><span class="p">)</span>
    <span class="o">...</span>

    <span class="c1">// Replay each traffic with goroutine
</span><span class="c1"></span>    <span class="k">for</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">traffic</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">originTraffics</span> <span class="p">{</span>
        <span class="nx">wg</span><span class="p">.</span><span class="nf">Add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">go</span> <span class="kd">func</span><span class="p">(</span><span class="nx">traffic</span> <span class="o">*</span><span class="nx">model</span><span class="p">.</span><span class="nx">OriginTrafficTab</span><span class="p">)</span> <span class="p">{</span>
            <span class="o">...</span>
            <span class="k">return</span>
        <span class="p">}(</span><span class="nx">traffic</span><span class="p">)</span>
        <span class="nx">wg</span><span class="p">.</span><span class="nf">Wait</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="c1">// Return
</span><span class="c1"></span>    <span class="k">return</span> <span class="kc">nil</span>
<span class="p">}</span>
</code></pre></div><p>上文示例的代码块省略了很多内容，做到让读者能在半屏内看完全文，并且正确地使用了代码高亮的功能。最糟糕的编排是<strong>粘贴大段代码</strong>嵌入文中，很多时候读者翻到代码就容易关掉页面，或者直接拉至代码结束的位置继续阅读，这样代码块就没有存在的意义了。</p>
<p>因此在如果有使用的必要，可以尝试对大段代码作如下调整：</p>
<ul>
<li><strong>抽象</strong>：使用伪代码代替特定语言代码，使用配图来讲解</li>
<li><strong>精简</strong>：只保留核心逻辑展示进行解释，删减其余代码、替换成简练的功能描述</li>
<li><strong>拆分</strong>：分开多段代码块分别讲解</li>
</ul>
<h3 id="风格统一">风格统一</h3>
<p>组合使用不同的段落、标题风格以及使用特殊符号<strong>不是</strong>一个良好的实践。例如：</p>
<ul>
<li>Objective 1：提高技术影响力
<ul>
<li>KR1：完成 Go 语言设计与实现全书</li>
<li>KR2：社区做三次任意主题的技术分享</li>
</ul>
</li>
<li>Objective 2：提高工程能力
<ol>
<li>KR1：将 Kubernetes 作为主要的工作重点</li>
<li>KR2：成为 Kubernetes 前 50 的提交者</li>
</ol>
</li>
</ul>
<p>本文中的段落列表（除错误示例外）均为 <strong>Unordered Lists</strong> ，大家也可以使用 <strong>Ordered Lists</strong> ，只要保持统一即可。</p>
<h3 id="段落长度">段落长度</h3>
<p>尽可能让段落长度不要太短也不要太长，过长的段落会给读者带来很大的阅读负担，通常读者需要在一个合适的地方休整，将读到的内容进行分析和理解；完全不为消化内容留空间的超长句、长段落会让阅读效率大打折扣。而简短的句子则应想办法合并至其他段落。</p>
<h3 id="typo">Typo</h3>
<p>最后一个让阅读更加舒适的要点是避免 Typo。在技术文章中通常会有大量的专业名词，例如 Mysql、redis、ElasticSearch、shopee、java、python 等，不要让读者看到不正确的拼写。</p>
<p>同样重要的还有避免错误的标点用法，不要混用全角半角符号，并且区分开<code>、</code>和<code>，</code>等。</p>
<h3 id="其他">其他</h3>
<p>通过查阅<a href="https://github.com/sparanoid/chinese-copywriting-guidelines/blob/master/README.zh-CN.md">《中文文案排版指北》</a>可以了解更多的中文排版小技巧。在使用 Markdown 进行写作时，可以多参考语法说明，熟悉各种语法技巧，并且抛弃在Office上才适用的习惯，例如段落开头添加空格。另外上一小节中长串名词应注意大小写，正确的写法为 MySQL、Redis、Elasticsearch、Shopee、Java、Python。</p>
<h2 id="作图思路">作图思路</h2>
<p>通常来说，通过改善作图来吸引更多的读者，成本比选材要低得多。许多作图工具都能产出相同的图案，因此工具在这里扮演的角色未必是最重要的。笔者归纳了一些作图的小技巧以及踩过的坑，遵循这些规律一般都可以得到简洁、工整的博客配图。和之前一样，每个小节尽量配合一些反例来讲解。</p>
<h3 id="主题和风格">主题和风格</h3>
<p>博客配图需要统一的风格，最简单的风格特征构建可以通过以下两点完成：</p>
<ul>
<li><strong>背景色</strong></li>
<li><strong>元素配色</strong></li>
</ul>
<p>在同一篇博文中，<strong>保持配图背景色一致</strong>是最基本的要求。为了让配图更有辨识度，通常：</p>
<ul>
<li><strong>背景色不使用纯白色</strong></li>
<li><strong>背景不带有网格、花纹图案</strong></li>
<li><strong>不使用 PNG 格式搭配透明背景色</strong></li>
</ul>
<p>当博客被转发或者博客站点主题发生变更时，柔和的背景色不容易显得格格不入。</p>
<p>对于元素，尽可能博文内的<strong>元素配色都进行统一</strong>，一般而言选择<strong>4-6种配色</strong>可以应对大部分的情况。作图不应该五彩斑斓，而是带有一定的辨识度和风格，让读者看了配图的结构和配色后能够想起类似的配图和作者。</p>
<p>下面这幅配图中使用了4中颜色来填充元素：
<img src="../202104-blog-writting/illustration-tools.png" alt=""></p>
<p>因此在后续的作图中应该尽量保持用相同的配色方案，并且同类元素使用同种颜色：
<img src="../202104-blog-writting/decentralized-vcs.png" alt=""></p>
<p>使用多种颜色去填充相对而言会是更糟的选择：
<img src="../202104-blog-writting/decentralized-vcs-modified.png" alt=""></p>
<h3 id="圆角和阴影">圆角和阴影</h3>
<p>第二个小技巧是<strong>在元素上使用圆角和阴影</strong>，这个改动非常简单，可以让元素看起来：</p>
<ul>
<li>更加柔和、不突兀</li>
<li>具有立体感</li>
</ul>
<p>请忽略示例图中的错误配色组合，如前一节所述，五彩斑斓的配色通常不如简洁、固定的配色适合放在博客配图中。
<img src="../202104-blog-writting/hotring_hash_collision.png" alt=""></p>
<p>通过去除所有的圆角、移除阴影后，配图变成如下样式，整体的观感也有所下降：
<img src="../202104-blog-writting/hotring_hash_collision_modified.png" alt=""></p>
<h3 id="构图和比例">构图和比例</h3>
<p>我们经常会见到在创作时使用相同大小的元素，嵌入到博文后缺变得忽大忽小，通过在最开始便<strong>固定好画布的宽度</strong>可以轻松解决这个问题。通常使用宽度 1200px 的画布可以兼容大部分博客系统的版面变化，并且和以前一样，请保持相同元素在不同配图中形状、大小、配色要尽可能一致。</p>
<p>另一个要注意的问题是，请尽量保持配图的宽度大于高度，例如使用 <strong>1200 * 500</strong>、<strong>1200 * 700</strong>，而<strong>不要使用</strong> 1200 * 3000 的画布。</p>
<p>下图作为<strong>错误示范</strong>，长图在不同的浏览器/客户端下显示效果欠佳。这种情况在绘制系统架构图、复杂的流程图、时序图等时会经常遇见。实际上只有少数情况下是需要展示出全局的流程、架构，而其他时候则可以将其进行拆分，通过多个章节和配图来慢慢讲解。</p>
<p><img src="../202104-blog-writting/lcs_db_distributed_data_consistency_modified.png" alt=""></p>
<h2 id="总结">总结</h2>
<p>尽量避免一些临时起意的写作，因为好的内容都需要有素材和知识储备来支撑，所以写作前可以尝试：</p>
<ul>
<li>分享业务系统设计要<strong>尽早计划</strong>以及<strong>记录关键节点</strong></li>
<li>分享前沿知识应该<strong>了解相同专业方向</strong>和<strong>为读者铺垫、抽象、总结</strong></li>
</ul>
<p>在文章结构的安排上有很多固定模板，大部分写作遵循以下套路都足以将事情讲解清晰：</p>
<ul>
<li><strong>先抛问题</strong></li>
<li><strong>从整体到细节</strong></li>
<li><strong>概括总结</strong></li>
</ul>
<p>在写作完成后可以按照以下 Checklist 来对全文进行对齐和润色，对文字亦或是图片都要做到统一：</p>
<ul>
<li>排版问题：代码块<strong>抽象、精简、拆分</strong>；段落<strong>格式统一</strong>、长度易读；避免 Typo</li>
<li>作图问题：元素尽可能少并<strong>简洁</strong>，拆分<strong>多图</strong>表达；统一背景、<strong>复用配色</strong>方案；尝试<strong>圆角和阴影</strong>；固定宽度<strong>横向构图</strong></li>
</ul>
<h2 id="参考资料">参考资料</h2>
<p>[1] <a href="https://draveness.me/sketch-and-sketch/">Draveness, 技术文章配图指南</a></p>
<p>[2] <a href="https://github.com/sparanoid/chinese-copywriting-guidelines">sparanoid, 中文文案排版指北</a></p>
<h2 id="附录写作工具箱">附录：写作工具箱</h2>
<table>
<thead>
<tr>
<th>分类 　</th>
<th>名称</th>
<th>链接</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>配色</td>
<td>Coolors</td>
<td><a href="https://coolors.co/">https://coolors.co/</a></td>
<td></td>
</tr>
<tr>
<td>配色</td>
<td>Colormind</td>
<td><a href="http://colormind.io/">http://colormind.io/</a></td>
<td></td>
</tr>
<tr>
<td>配色</td>
<td>ColorSpace</td>
<td><a href="https://mycolor.space/">https://mycolor.space/</a></td>
<td></td>
</tr>
<tr>
<td>作图</td>
<td>Sketch</td>
<td><a href="https://www.sketch.com/">https://www.sketch.com/</a></td>
<td></td>
</tr>
<tr>
<td>作图</td>
<td>Paper</td>
<td><a href="https://paper.bywetransfer.com/">https://paper.bywetransfer.com/</a></td>
<td>需要Apple Pen</td>
</tr>
<tr>
<td>作图</td>
<td>LucidChart</td>
<td><a href="https://www.lucidchart.com/pages/">https://www.lucidchart.com/pages/</a></td>
<td></td>
</tr>
<tr>
<td>素材</td>
<td>IconPark</td>
<td><a href="https://iconpark.bytedance.com/">https://iconpark.bytedance.com/</a></td>
<td></td>
</tr>
<tr>
<td>素材</td>
<td>iconfont+</td>
<td><a href="https://www.iconfont.cn/">https://www.iconfont.cn/</a></td>
<td></td>
</tr>
<tr>
<td>博客</td>
<td>PingCAP</td>
<td><a href="https://pingcap.com/blog-cn/">https://pingcap.com/blog-cn/</a></td>
<td></td>
</tr>
<tr>
<td>博客</td>
<td>Meituan</td>
<td><a href="https://tech.meituan.com/">https://tech.meituan.com/</a></td>
<td></td>
</tr>
<tr>
<td>博客</td>
<td>Netflix</td>
<td><a href="https://netflixtechblog.com/">https://netflixtechblog.com/</a></td>
<td></td>
</tr>
<tr>
<td>论文</td>
<td>NSDI</td>
<td><a href="https://www.usenix.org/conference/nsdi20/technical-sessions">https://www.usenix.org/</a></td>
<td>网络/分布式</td>
</tr>
<tr>
<td>论文</td>
<td>SOSP</td>
<td><a href="https://dl.acm.org/doi/proceedings/10.1145/3341301">https://dl.acm.org/</a></td>
<td>操作系统</td>
</tr>
<tr>
<td>论文</td>
<td>OSDI</td>
<td><a href="https://www.usenix.org/conference/osdi20/technical-sessions">https://www.usenix.org/</a></td>
<td>操作系统</td>
</tr>
<tr>
<td>论文</td>
<td>VLDB</td>
<td><a href="https://vldb.org/pvldb/vol13-volume-info/">https://vldb.org/</a></td>
<td>数据库</td>
</tr>
<tr>
<td>论文</td>
<td>SIGMOD</td>
<td><a href="https://sigmod2020.org/sigmod_research_list.shtml">https://sigmod2020.org/</a></td>
<td>数据库</td>
</tr>
<tr>
<td>论文</td>
<td>FAST</td>
<td><a href="https://www.usenix.org/conference/fast21/technical-sessions">https://www.usenix.org/</a></td>
<td>存储</td>
</tr>
</tbody>
</table>
]]></content>
		</item>
		
		<item>
			<title>Paper Reading：HotRing——哈希冲突中热点数据高效读取方案</title>
			<link>https://jiekun.dev/posts/hotring/</link>
			<pubDate>Sat, 13 Mar 2021 16:39:07 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/hotring/</guid>
			<description>Paper Reading系列旨在分享著名Conference上发表的论文。FAST（USENIX Conference on File and Storage Technologies）是存储领域的顶会</description>
			<content type="html"><![CDATA[<blockquote>
<p>Paper Reading系列旨在分享著名Conference上发表的论文。FAST（USENIX Conference on File and Storage Technologies）是存储领域的顶会之一，<a href="https://www.usenix.org/conference/fast20">第18届FAST</a>于美国Santa Clara举行。</p>
</blockquote>
<h2 id="关于paper">关于Paper</h2>
<p>《<strong>HotRing: A Hotsport-Aware In-Memory Key-Value Store</strong>》发表于2020年，主要研究的是使用链表结构解决哈希冲突时，访问热点数据存在一定额外开销的问题。论文提出的HotRing结构支持热点数据发现，并且可通过使环状链表的头部指针指向hot item，减少读取所需遍历的路径，达到提升访问效率的目的。</p>
<h2 id="hash-collision简介">Hash Collision简介</h2>
<p>当我们使用哈希表时，不可避免地会存在<strong>哈希冲突</strong>。我们将大量数据通过计算哈希值的方式放入相对较小的哈希表中，不同item得到的哈希值可能会是一致的。通常通过rehash扩大哈希表，可以降低哈希冲突的概率。但是哈希冲突仍然存在，也需要有对应的方法在出现冲突时让数据仍能正确读取到。</p>
<p><img src="../202103-hotring/hotring_hash_collision.png" alt=""></p>
<h3 id="collision解决方案">Collision解决方案</h3>
<p>当出现不同的item具有相同哈希值时，需要有合适的位置来存放多个item。这些item可以被安插在同一张哈希表的不同位置，也可以被放到哈希表之外的空间，而让哈希表保存外部空间的地址值。</p>
<h4 id="open-addressing">Open Addressing</h4>
<p><strong>开放地址法</strong>是将冲突的item放在哈希表内的方案。使用开放地址法时，查找对应item的操作称为<strong>探测</strong>（Probing）。当期望写入的哈希位置已经存在其他item B时，可以将item A放至：</p>
<ul>
<li>相邻的空位——<strong>线性探测</strong></li>
<li>间隔1、4、9、16的空位——<strong>平方探测</strong></li>
<li>另一个的Hash方法计算的空位——<strong>二次哈希</strong></li>
</ul>
<p>开放地址法的查询终止条件为：探测到对应item或探测到空位。当探测到非目标item时，目标item可能在下一个位置，也可能不存在，因此需要继续探测。开放地址法要求哈希表比数据集更大，当负载因子处于高位时，对于冲突item的查询，遍历路径则会变得相对长，性能也会因此下降。因此开放地址法需要相当大的空间来存放哈希表。</p>
<h4 id="collision-chain">Collision Chain</h4>
<p><strong>链表法</strong>将item存储在哈希表之外，每个哈希桶存放有指向链表头部的指针，通过顺序遍历链表确认查找的item是否存在。</p>
<p>与开放地址法相比，链表法可以允许item数量大于哈希表。在负载因子增长的情况下，开放地址法的探测速度会显著变慢，而链表法仍能保持查询效率与长度挂钩地线性增长。</p>
<p><img src="../202103-hotring/hotring_collision_solution.png" alt=""></p>
<h2 id="hotring">HotRing</h2>
<p>在实际使用场景中，经常会有大量item被放入哈希表，而其中只有极少数是热点数据。</p>
<p>对于<strong>链表法</strong>的热点数据的访问，简化模型下需要查找的次数为：</p>
<pre tabindex="0"><code>T = 1 + L / 2 
  = 1 + (N / B) / 2
</code></pre><p>其中<strong>L代表哈希桶对应的链表长度</strong>，<strong>N为总item数</strong>，<strong>B为哈希桶数量</strong>。</p>
<p>如果可以让热点数据长期位于链表头部，访问的复杂度就可以贴近<code>O(1)</code>。但是对单链表的item位置调整，也就是类似于LRU/LFU的实现，操作上开销不低，并且实际上除了极少数hot item的位置，其余item的顺序其实并没有那么重要。设计一种代替链表的、贴合缓存使用场景的数据结构，通常会期望：</p>
<ul>
<li>能加速热点item的访问
<ul>
<li>能及时发现热点</li>
<li>能以较低的额外开销将热点移至便于访问的位置</li>
</ul>
</li>
<li>能支持并发场景下操作</li>
<li>高效率Rehash</li>
<li>&hellip;</li>
</ul>
<p>针对这类场景和需求，HotRing结构应运而生。</p>
<h3 id="设计概览">设计概览</h3>
<p>HotRing是一个环状的链表结构。在加速热点数据的访问上，HotRing让哈希表中的头指针始终指向hot item或能高效访问多个hot item的位置。比起调整链表中item位置，修改头指针更加高效简洁。为了能够发现热点数据，每个item也需要能够存储相关的统计信息，例如访问次数。通过额外的后台线程来分析统计值，可以在热点发生变化时及时对头指针进行调整。</p>
<p><img src="../202103-hotring/hotring_overview.png" alt=""></p>
<h3 id="具体实现">具体实现</h3>
<h4 id="数据查找">数据查找</h4>
<p>若环状链表数据没有任何顺序，确认item不存在的复杂度为O(n)，从时间效率上看可以再优化。HotRing选择在写入时略微增加开销，让环状链表保持顺序性，从而查找时就能更快定位或结束遍历。</p>
<p>对于目标元素<code>item(k)</code>结束查找的标志可以是：</p>
<ul>
<li>item存在，则满足：</li>
</ul>
<pre tabindex="0"><code>item(k) = item(i)
</code></pre><ul>
<li>若不满足上式，且满足下列任一条件时，说明item不存在：</li>
</ul>
<pre tabindex="0"><code>item(i-1) &lt; item(k)   &lt; item(i)    或
item(k)   &lt; item(i)   &lt; item(i-1)  或
item(i)   &lt; item(i-1) &lt; item(k) 
</code></pre><p><img src="../202103-hotring/hotring_search.png" alt=""></p>
<p>而为了减少对字符串的字典序比较，HotRing为每个item都增加了一个tag，即<code>item(k) = (tag(k), key(k))</code>。</p>
<p>通过这种设计，无需遍历链表中所有元素即可提前终止遍历，平均情况下查找item数可以达到<code>(n/2) + 1</code>。实际上，因为头部指针位置的优化，大多数查找能够更早定位到hot item而结束。</p>
<h4 id="热点发现">热点发现</h4>
<p>实际场景中，由于hot item一直在变，因此需要能准确、及时发现hot item的机制，我们也可以从这两个方面来定性评定发现算法的优劣：</p>
<ul>
<li><strong>准确性</strong>：头指针指向hot item的比例</li>
<li><strong>及时性</strong>：多少延迟之后头指针可以指向hot item</li>
</ul>
<p>HotRing设计了两种方案来实现热点发现，分别是<strong>随机策略</strong>和<strong>统计样本策略</strong>。</p>
<p><strong>随机策略</strong>非常简单，HotRing周期性地将头指针指向本次查询到的item。默认周期为5，即每5次查询到item时，若头指针已经指向该item，则不发生调整；否则将头指针指向item。这个方案巧妙之处在于，hot item的访问概率远大于cold item，利用这点,无需任何统计信息即可实现热点发现。</p>
<p>当然，这个方案在环中存在多个hot item时表现并不好，同时准确率也比另一种策略要低。另外，当整体系统压力较小、热点分散的情景下，随机策略的准确性也会进一步降低，头指针需要频繁发生变更。因此我们还需要另一种能够对多热点优化、准确率更高的方案。</p>
<p><img src="../202103-hotring/hotring_head_selection.png" alt=""></p>
<p><strong>统计样本策略</strong>，顾名思义需要一定的数据样本。HotRing的头指针带有15bit的Total Counter，而环中每个item带有14bit的Counter，Total Counter表示对该环的总命中次数，item的Counter则代表该item的命中次数。</p>
<p>HotRing周期性地进行样本分析，每次分析起始时，Total Counter和Counter均为0，在一定时间后，根据Total Counter和每个item的Counter值决定使用哪个item作为头节点。</p>
<p><img src="../202103-hotring/hotring_head_optimizing.png" alt=""></p>
<p>如上图公式所示，<code>ni</code>表示<code>item(i)</code>采样期间的的访问次数，<code>N</code>代表总访问次数，<code>(i-t) mod k</code>代表从头节点<code>item(t)</code>出发访问到<code>item(i)</code>所需遍历的长度，因此<code>Wt</code>即为<strong>该环状链表遍历长度的加权平均值</strong>，该值越小说明头节点的选择越优异。</p>
<p>统计样本策略更加准确，同时也能使用于多个hot item的场景，但是经常进行分析也会有一定的开销。因此，优化的周期策略是每隔R次查询时先判断本次fetch到的item是否为头指针指向的item，若是，则hot item很可能没有发生变化；反之则有必要发起新的一轮样本统计。</p>
<p><strong>热点继承</strong>是指hot item发生变更时应该如何处理。HotRing使用的思路也非常简单，如果头节点发生了更新，最近更新的item理应有更大可能性被读取到，因此头指针直接指向这个新的item；而当头节点被删除时，头指针直接指向下一个item，后续依赖热点发现的策略作进一步调整。</p>
<h4 id="无锁rehash">无锁Rehash</h4>
<p>当哈希表需要扩容时，由于哈希槽的增加，环状链表也需要将item分配到新的环中。和传统的rehash不同，HotRing决定rehash的条件是查找所需的平均内存访问次数，而非哈希表负载因子，这种方案能够和hot item分布情况相结合，减少rehash次数。HotRing的rehash分为3个阶段：<strong>初始化</strong>、<strong>分裂</strong>、<strong>清理</strong>。</p>
<p>在<strong>初始化</strong>阶段，HotRing创建一个后台线程，这个线程会新建一个原有哈希表<strong>2倍大小的新哈希表</strong>。这里重新描述一下哈希表和tag的关系，在计算一个item的哈希值时，值的前k位用作哈希表定位，后t位作为tag。因此，当哈希表扩容2倍，需要占用k+1位哈希值，tag值则缩小为t-1位。通过这个关系，环状链表在扩容时可根据tag值一分为二：原有tag值t位，因此范围为<code>range = 2^t</code>，扩容后范围为<code>2^(t-1)</code>，因此正好可以按<code>[0, range/2)</code>和<code>[range/2, range)</code>划分为两个新的环，对应新哈希表上两个slot。</p>
<p>初始化线程还会创建一个rehash节点，其中包含两个子rehash item。每个rehash item有不同的tag，例如<code>0</code>和<code>range/2</code>，后续可以作为两个新环的临时头节点（最后将被清理）。在rehash时，新哈希表的对应槽上的头指针指向这两个rehash item。同时rehash item上也有对应的标志位，表示其不包含键值对，只作为rehash过程中的头节点使用。</p>
<p><img src="../202103-hotring/hotring_rehash.png" alt=""></p>
<p>在<strong>分裂</strong>阶段，rehash线程将两个rehash item放入环中，它们将会作为tag范围和遍历的边界，当Insert操作完成，新的哈希表就会生效。由于没有item的复制和迁移，整个过程大部分操作都是通过无锁的CAS完成的，开销会相对较低。在清理阶段之前，查找操作以新的rehash item为起点，最多需要遍历半个环。</p>
<p>最后<strong>清理</strong>阶段，在这个阶段，rehash线程需要确认所有的旧哈希表访问都已经结束，进而先删除旧哈希表，然后清理所有的rehash节点。要注意这个阶段，旧哈希表的访问会阻塞rehash线程进入下一步操作，但是不影响主线程进行读写。</p>
<h2 id="总结">总结</h2>
<p>HotRing适应的场景是热点高度集中的哈希表访问。在此情形下，HotRing的设计有如下特点：</p>
<ul>
<li>将热点数据排列在链表最靠前位置，缩短访问路径</li>
<li>环状链表设计，实现上一特点只需要头指针变更，无需item移动</li>
<li>结合场景特点，实现简单有效的随机策略和适应性强、路径优化更好的统计样本策略来处理热点数据、热点漂移</li>
<li>使用原子的CAS操作避免引入锁机制</li>
<li>巧妙的环状链表rehash思路，无数据迁移成本，rehash过程中不阻塞读写</li>
</ul>
<p>HotRing和其他的哈希冲突解决方案相比，有多个特点是结合特定场景和数据分布而落地的，在一定条件下的测试结果表明其提升非常明显，并且热点数据大都能够在两次内存访问内检索到。其中对环状数据结构的设计及其配套的随机、采样思路对高性能的业务场景设计都有不少参考价值。</p>
<h2 id="references">References</h2>
<p><a href="https://www.usenix.org/system/files/fast20-chen_jiqiang.pdf">[1] J Chen, HotRing: A Hotspot-Aware In-Memory Key-Value Store. In FAST &lsquo;20.</a></p>
]]></content>
		</item>
		
		<item>
			<title>2020年度总结：拥抱开源、拥抱社区</title>
			<link>https://jiekun.dev/posts/2020-summary/</link>
			<pubDate>Thu, 04 Feb 2021 03:04:29 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-summary/</guid>
			<description>安利phyxinon演奏的Altale 关于我的2020 2020从年初开始就注定是特别不平凡的一年。本来这里还应该有大段的文字，但是被疫情耽误</description>
			<content type="html"><![CDATA[<blockquote>
<p>安利phyxinon演奏的<a href="https://www.youtube.com/watch?v=6fz5z8K-j6k">Altale</a></p>
</blockquote>
<h2 id="关于我的2020">关于我的2020</h2>
<p>2020从年初开始就注定是特别不平凡的一年。本来这里还应该有大段的文字，但是被疫情耽误的计划实在是太多了，几乎所有的出游任务都挂起了超过半年，所以。</p>
<h3 id="新工作">新工作</h3>
<p>在2020年初我换了新的工作，这个在之前的日志里面已经说过了，特别感谢老东家和各位前同事，<a href="https://baike.baidu.com/item/%E6%84%9F%E6%81%A9/138">感恩</a>也是在刚毕业一年多里面学到最重要的东西。很多大块的知识都是在最初的这一年多中慢慢积累起来的，刚毕业的时候不懂技能广度重要还是深度更重要（当然现在也还没搞清楚），所以不管是经典的还是新鲜的内容我都尝试去了解，并且希望其中能有一些感兴趣的方向可以长线发展。而恰好在这段时间内，手头的工作非常适合钻研、落地一些想法，我觉得好奇心和发展平台能同时存在的机会真的特别少，很多人会在年轻的时候没有合适机遇，在年长的时候没有充足的精力，所以庆幸我的这段经历非常充实，也非常有意义。</p>
<p>换工作是一个非常难的决定，我花了很长时间思考，通过换工作我想要得到什么、将会失去什么。除此之外还有个很重要的理由，是我想在长满白头发之前先到处走走看。</p>
<p><img src="../202102-2020-summary/sz.jpeg" alt=""></p>
<p>于是我来到了现在的工作岗位上，刚到深圳那天天气特别好（我没料到后面每天天气都一样好）。在后续半年里面陆陆续续了解了一些项目的内容。是的我觉得到现在也只能算是了解，因为变更和迭代内容太快，而且实际上可能也就仅比想象中的“屎山”代码稍微靠谱那么一丢丢——虽然它还能正常运行。大约有10-15位同事和我一起在项目内施工，这可能还比隔壁项目组的少些——因为拆分得不够彻底，一些逻辑维护在原来的项目，各个组的同事或多或少都要用上。所以，我也很好奇漂亮工整的项目在这样大、快速扩张的业务里面真的能存在吗，如果有的话，它是如何管理得这么好的。</p>
<p>言归正传，我负责的工作是物流履约链路上的最末端，第三方的服务本来就是相当不可控的，还是非常感谢这些大哥没在双11、双12搞出什么大问题来，不然可能这篇博客里面写的就是一年跳槽2次的体验了。</p>
<p><img src="../202102-2020-summary/desk.jpeg" alt=""></p>
<p>在2020年结束前，我给手上项目落地了一个简单的<a href="https://jiekun.dev/posts/db-partitioning/">数据库拆分</a>。在很多内容都已经搭建完善的情况下，再出现从0到1做完一件事的机会太难得了。在8月份凌晨切换DB集群的时候，DBA一边处理切换一边和我们讲解各种存在的问题，业务数据涨太快了——尽管这和流量灰度的预期是一致的。再后来到9月份，相关的改造也提上了日程，我就直接向leader认领了把大刀。不得不说在项目里搞搞事情确实很有趣的，虽然加班改过很多个版本的设计说明书，也有被老板严肃批评过设计方案不理想。前前后后一共花2个多月，终于在双12结束之后把这版改造扔上了生产环境。</p>
<h2 id="关于我的博客">关于我的博客</h2>
<p>在过去的这年，因为工作上忙了很多，所以也不能像2019年那样一直不停地写文章。当然，今年特别是下半年之后，我觉得博客产出应该是一件更加<strong>严谨</strong>和<strong>细致</strong>的事情，所以本身也不应该有很多的水文出现。</p>
<p>如何让文章更加贴近实践和有价值、有意义，这是众多思考中的一点，也是最核心的点。通常诞生一篇新博客，需要：</p>
<ul>
<li>有明确的目标：解决遇到的什么问题 / 介绍什么样的前沿内容</li>
<li>素材积累：落地方案调研、对比、分析 / 翻译论文、阅读源码</li>
<li>编排组织内容：从什么出发，用哪种结构才能让别人更容易看懂、有收获</li>
<li>文章润色和微调</li>
</ul>
<p>这里面素材的积累是最难的，每当我想要写一篇新的内容时都会问自己，这些东西真的会了吗，如果有人要来Challenge，能答得上来吗。所以，作者相对于笔下的内容都应该有翻倍以上的知识储备来应对读者的提问。这大约会占掉60%以上的时间，但这也是一个正常的学习过程，写作本身是为了学习，然后才是分享。</p>
<p>另外，每次的初稿都和发布时有很大的差异，我觉得大概是因为写作的时候思路太零散，所以这些内容在最后润色的时候都会被一一梳理和纠正过来，如果未来可以顺畅自然一些就更加好了，不该总是反复改动。</p>
<p>今年自己最满意的写作应该是<a href="https://jiekun.dev/posts/mvcc/">《Paper Reading：聊一聊MVCC》</a>——虽然它只是一篇介绍性的文章，然而选题、读论文、反复改稿的过程里面参考了很多内容，也非常有收获。如果其他人也能从中了解到想学的内容的话那就更棒了。</p>
<h2 id="关于github">关于Github</h2>
<p>2020年从0开始尝试动笔给开源项目提交一些小改动。我觉得即使是从改Typo起步也是合理的，当然如果能有更深入的见解和提案的话能再上一个层次。</p>
<p>从Pull Requests来统计，我提交了这些内容（按repo排序）：</p>
<ul>
<li>[redis-doc] <a href="https://github.com/redis/redis-doc/pull/1408">Added Threaded I/O topic</a></li>
<li>[redis-py] <a href="https://github.com/andymccurdy/redis-py/pull/1307">Added &ldquo;ACL LOG&rdquo; command new in Redis 6 RC2</a></li>
<li>[redis-py] <a href="https://github.com/andymccurdy/redis-py/pull/1393">Fixing #1390 modules key in info command</a></li>
<li>[redis-py] <a href="https://github.com/andymccurdy/redis-py/pull/1412">Added GET argument to SET command</a></li>
<li>[redis-py] <a href="https://github.com/andymccurdy/redis-py/pull/1437">#1434 Added support for ZMSCORE new in Redis 6.2 RC</a></li>
<li>[go-redis] <a href="https://github.com/go-redis/redis/pull/1585">Added test setup document in README.md</a></li>
<li>[tidb-in-action] <a href="https://github.com/tidb-incubator/tidb-in-action/pull/910">README typo</a></li>
<li>[tidb doc] <a href="https://github.com/pingcap/docs-cn/pull/4304">Fixed typo in mysql-compatibility.md</a></li>
</ul>
<p>总体来说虽然有点少，但还是决定对自己宽容作为新手的这一年，希望2021年有更多更有意义的提交。</p>
<p>另外既然讲到开源项目，如何平衡工作和业余的时间也是个大问题。每天其实办公的时间也不能算少（当然，比起互联网大厂来说我觉得算能接受），如果还继续坚持这样那样的事情的话，大概还要继续单着一段时间吧。</p>
<h2 id="关于新的一年">关于新的一年</h2>
<p>新的一年目前还没有什么特别明确的规划，这非常不好，因为摸不着方向很容易走弯路。以往每次遇到这种情况的时候，我都是随手翻一本新书来看，看完了这段迷茫的时间也过去得差不多了。不过这次还是再来稍微立点Flag看看能不能完成吧。</p>
<h3 id="我和redis">我和Redis</h3>
<p>这真的是个非常理想的、新人友好的项目，而且使用广泛，社区大。在2020年原作者Antirez退居二线，交由RedisLab/社区维护之后，迭代新功能的速度快了很多。我觉得自己已经有半桶水的准备来给这个项目添砖加瓦，希望一切都顺顺利利，也要多向活跃在社区内的开发者交流和学习。</p>
<h3 id="我和go">我和Go</h3>
<p>在过去的一年里面其实和这个新生态打交道的机遇并不太好，还是靠自己手上乱七八糟的小repo为主。语言类的事情一旦和工作内容没办法相结合就很容易做了忘，再做再忘。我觉得新的一年里面这个问题应该要有不同的解决方法，其实从一开始就可以假定这不会在工作上用到，社区还能有数不清的repo和issue在等着自己，所以<code>go run 2021.go</code>。</p>
]]></content>
		</item>
		
		<item>
			<title>业务核心数据库架构演变——权衡取舍的艺术</title>
			<link>https://jiekun.dev/posts/db-partitioning/</link>
			<pubDate>Mon, 21 Dec 2020 22:49:07 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/db-partitioning/</guid>
			<description>Shopee供应链 Logistics Channel Service 项目（下称LCS）是物流履约链路上的最后一环，连接Shopee物流订单与第三方物流服务（3rd Party Logistics，</description>
			<content type="html"><![CDATA[<blockquote>
<p>Shopee供应链 Logistics Channel Service 项目（下称LCS）是物流履约链路上的最后一环，连接Shopee物流订单与第三方物流服务（3rd Party Logistics，下称 3PL ），几乎所有与 3PL 的交互都会收拢到LCS服务中。</p>
<p>从 2019 年 9 月至今，随着上游系统拆分迁移，越来越多 3PL 进入 LCS 负责范围；并且由于电商业务在 2020 年的飞速发展，系统每月的订单量也在陡增，对数据库的要求和压力随之而来，在短短 1 年内，数据库架构跟随业务增长进行了多次调整。</p>
<p>本文简要回顾了 LCS 诞生至今的数据库架构变化，并介绍项目组在 2020 年末落地的分库实践，梳理落地过程中踩过的坑和总结的经验、教训和思考。</p>
<p>新方案实践的过程中，有遇到常规库表拆分中共有的问题，也有针对项目场景的“特色”问题，解决问题更多是权衡取舍的过程，在没有完美解决方案的情况下，需要结合业务特性来分析和选择最有利的方式处理。</p>
</blockquote>
<h1 id="introduction">Introduction</h1>
<h2 id="项目起源">项目起源</h2>
<p>LCS 是一个基于 Python Django 框架的项目，业务核心是物流订单的履约过程，包括连接上游和第三方物流服务的创建订单、轨迹与运费更新。在部署上，LCS 依据业务所在的市场（印尼、马来西亚、新加坡等）不同，应用层分市场部署，并使用各自市场对应的数据库。在项目起步初期，这些不同市场的数据库共用同一套物理集群，共享内存和磁盘空间，在资源上看，是足以应付初期流量的。</p>
<p><img src="../202012-db-partition/lcs_db_single_cluster.png" alt=""></p>
<p>随着业务的铺开，共用集群的问题慢慢体现了出来。地区与地区之间存在业务差异，订单数量、订单轨迹比例不同，依赖物理集群自身的资源调度不能满足我们的需要，很多时候：</p>
<ul>
<li>订单量大的地区的数据库读写影响了订单量少的地区的 I/O 资源</li>
<li>轨迹推送 RPS 远比下单高，大量的轨迹信息读写影响了核心的下单流程</li>
</ul>
<p>在尽量不影响业务的情况下，我们先选择了将热点地区的数据库拆分到单独的物理集群上，独占资源，保证自身服务稳定的同时，也减少了对其他地区服务的影响。在这个过程中，由于不同市场使用的是不同的逻辑库，所以切换没有任何的业务改动，在 DBA 的协助下，可以非常迅速地完成这个操作。</p>
<p><img src="../202012-db-partition/lcs_db_multi_cluster.png" alt=""></p>
<p>面对轨迹推送更高 RPS 的问题，我们使用了临时表和消息队列进行削峰，让解析轨迹并绑定到对应订单上的过程延迟发生，整个处理操作更加平滑。问题在于临时表是设计在业务 MySQL 库中的，业务上，轨迹更新可以缓冲，但是 MySQL 受到的压力并没有减少。</p>
<p>因此，在前面的物理集群拆分后，我们又启用了 TiDB 存放临时轨迹数据，尽量降低对 MySQL 的 <code>INSERT</code> 和 <code>DELETE</code> 操作数量，这样做的好处在于能减少由于写操作带来的频繁页分裂与合并，有利于查询性能，以及写操作引起的主从延迟。</p>
<p><img src="../202012-db-partition/lcs_db_with_tidb.png" alt=""></p>
<h2 id="面临挑战">面临挑战</h2>
<p>尽管已经做了两次拆分和调整，但是随着订单量的持续上涨，又由于物流订单中的信息繁杂，尤其上游早期未加以限制的各种收发货地址、名称、联系方式，以及跨国运输业务所需要的详细的商品细节，再加上物流轨迹的描述信息，让每个订单的<strong>文本类型数据非常多</strong>，数据库表的<strong>体积</strong>容易暴涨。</p>
<p>根据 2020 年下半年的数据统计，印尼地区的 MySQL 集群磁盘使用量在短短数个月内已经突破 30%，并且随着上游流量灰度至本服务的比例上涨，每个月的增量都比以往更大。在灰度结束后，又迎来了下半年几个重要的促销活动时间节点——双9、双11、双12，数据体积进一步增长，仅通过日常的数据清理与数据库压缩已经没有办法维持集群磁盘空间的未来使用了。</p>
<h1 id="evolution">Evolution</h1>
<p>DBA 团队在历次集群调整的过程中，都一再强调了数据增速过快，磁盘空间规划和使用的问题。而业务产品团队也提出运营数据相关的需求，历史物流订单的数据在未来没有办法直接删除，而需要归档用于统计分析。这也推动了业务研发团队要尽快输出方案，应对更大的单量和不同的产品需求。</p>
<h2 id="设计目标">设计目标</h2>
<p>在当前设计下，每个地区使用单个数据库，由于单库的数据体积暴涨，因此将各地区的数据库进行分库势在必行。我们期望新的架构可以：</p>
<ul>
<li><strong>承载未来较长一段时间的数据存储需求</strong>。因为硬件资源有限，很多时候变动并不容易实施，而且重新调整架构也是让 DBA 和业务研发人员非常痛苦的一件事情；</li>
<li><strong>同样稳定可靠</strong>。对核心业务链路上的项目而言，稳定性是最重要的；</li>
<li><strong>保留合理的可扩展性</strong>。重新调整架构很难，但不代表当前架构下不能做业务无感知的横向扩展；</li>
<li><strong>便于进行数据归档</strong>。来自产品团队的需求，数据也是支撑未来业务设计的核心因素。</li>
</ul>
<h2 id="方案设计">方案设计</h2>
<h3 id="分库模型">分库模型</h3>
<p>在最初的设计中，我们期望新的分库模型能够很容易完成数据归档的操作，例如可以从一个较粗的粒度将历史数据转移到归档机器上。因此第一个诞生的想法是设计<strong>按月份拆分的数据库</strong>。当前的单库设计——所有的数据都落在不同的哈希分表中，要将历史数据捞出来进行转移是非常麻烦的：</p>
<ul>
<li>DBA 团队不会访问和维护数据库中的数据，因此业务侧要自己完成归档操作；</li>
<li>访问和迁移指定时间范围的数据，意味着所有哈希分表的 B+ 树需要发生大量的页合并操作，不利于线上业务的性能。</li>
</ul>
<p>因此，按月分库的想法初衷是想把可以进行归档的数据集中在一起，不管是业务侧想办法迁移，还是 DBA 能够提供数据库维度的操作，都能简化一定的操作成本。</p>
<p><img src="../202012-db-partition/lcs_db_time_partitioning.png" alt=""></p>
<p>然而，没有十全十美的方案，如果想要按月份拆分，当月内的数据就会落到同一个数据库中，在未来不可避免会存在各个库的数据量不均匀，热点数据集中等问题。并且随着单月数据量的增大，未来再来处理单库体积，例如将单月的数据再做哈希分库，数据库的结构就变得更为复杂了。</p>
<p>所以，第二个较为容易实施的划分方案自然是一开始就<strong>直接按照哈希分库</strong>，让数据均匀地落到不同的分库中去。但这样又有和单库做数据归档一样的问题——库表均按哈希划分，数据均匀分布，没有较粗的粒度可以定位出历史数据，需要依赖应用层一点一点做迁移。</p>
<p><img src="../202012-db-partition/lcs_db_hash_partitioning.png" alt=""></p>
<p>这时，我们需要考虑在两种方案之间做一定的权衡，选取更适合当前和未来业务的方案：</p>
<ul>
<li><strong>支撑未来业务</strong>：两种方案都降低了单库的数据量，但是按时间分库会在业务进一步增长后，单库体积继续难以管控；哈希分库会更加均匀；</li>
<li><strong>稳定性</strong>：从部署和使用上，两种方案的稳定性影响因素都比较类似。但是以时间分库可能需要 DBA 团队的手动维护，包括如何持续未来各个月份的数据库等。我们会更倾向于使用人工操作次数少的方案，哈希分库在搭建完成、交付后更可靠；</li>
<li><strong>可扩展性</strong>：按时间分库比较难继续做拆分，例如在未来改成时间+哈希的方案，但是会显著增加复杂度；哈希分库可以考虑直接增加“<code>% base</code>”的数值，业务调整更小、更容易落地；</li>
<li><strong>数据归档</strong>：哈希分库不好处理归档数据，归档操作粒度太细，有应用层的操作开销，引入大量的数据行<code>DELETE</code>操作，并且不加以控制资源使用量会影响线上业务；按时间分库如果有DBA支持，可以更方便地完成数据归档，操作难度大幅降低。</li>
</ul>
<p>结合各方面的考量，我们<strong>最终选择了哈希分库的方案</strong>，通过牺牲数据归档操作的便捷性，期望能让业务应用在未来相对更稳定可靠。</p>
<h3 id="应用部署架构拆分">应用部署架构拆分</h3>
<p>在确认分库的模型后，我们又遇到了另一个问题：受限于资源，想要给每个地区市场搭建多套物理集群，让每个哈希的分库都能独享机器，目前机房的剩余数量已经没办法支持。按照单个 MySQL 集群 1 主多从的搭配，n 个地区市场、每个市场 m 个哈希分库，一共需要 <code>(1 master + s slave) × n × m</code> 台物理机，成本是非常高昂的。所以 DBA 团队能够交付到给业务团队的集群数只有 n 套，也就是 n 个地区市场均为独立集群，该市场上的 m 个哈希分库共用一套集群。</p>
<p>由于 Python 应用的特点，各个 Pyhton 进程都持有各自的连接池，因此，业务侧持有的数据库连接数为：</p>
<ul>
<li><strong>单进程连接数 * 进程数 * 机器数</strong>。</li>
</ul>
<p>而由于机器资源的问题，不同的 m 个哈希分库又落在了同一套物理集群上，对主库的机器而言，连接数上限变成了：</p>
<ul>
<li><strong>单进程连接数 * 进程数 * 机器数 * 数据库数</strong>。</li>
</ul>
<p><img src="../202012-db-partition/lcs_db_connections.png" alt=""></p>
<p>依照当前的业务量进行计算，维持现有架构直连新分库集群将会超过机器设置的连接数上限，而且本身大量的连接数对服务而言也是非常不利的。因此业务侧需要想办法降低连接数峰值，否则新的数据库集群将无法使用。</p>
<p>改造可以从计算的公式入手，降低 4 个参数中的任意一个都能提供我们想要的效果。其中：</p>
<ul>
<li>数据库数是依据业务数据，从保证未来单库数据体积不超过一定值计算得出的，因此不能再继续调低；</li>
<li>进程数和连接池连接数的配置是依照业务请求量调整的，降低的话会让单机的请求处理能力下降。</li>
</ul>
<p>所以我们尝试在<strong>机器数量</strong>上做改变。由于<strong>处理下单和处理轨迹推送更新的服务没有分离</strong>，且<strong>轨迹流量是订单流量的数倍</strong>，因此该服务使用了较多的机器数量同时支撑下单与轨迹更新。但是轨迹流量是暂存 TiDB 而不访问 MySQL 的，如果可以服务分开部署，<strong>老服务只负责下单访问 MySQL，新服务轨迹更新只访问 TiDB</strong>，那么需要访问 MySQL 的机器数量就可以大幅降低。以印尼地区为例，轨迹请求数量为下单请求的 9 倍，参考这个比例，并考虑一定冗余机器数保护核心的下单业务流程，我们在 Nginx 代理层<strong>将不同类型的接口划分至了不同服务</strong>。</p>
<p>拆分后，处理下单等服务的<strong>机器数量降低到原来的 25%</strong>，相应地，在连接数计算结果上，数值也缩小至 <strong>1/4</strong>。</p>
<p><img src="../202012-db-partition/lcs_db_connections_with_different_app.png" alt=""></p>
<p>当然，造成连接数过高的原因有很多，解决方案也有很多，例如用 Golang 将项目重构（减少服务进程数）、在应用层和数据库集群之间再搭建一套服务用来统一管理连接、使用分库的中间件等。目前对 LCS 项目而言，重构的开销会比较大，其他的方案也需要单独设计和推动，<strong>应用架构拆分</strong>可能是较为可靠且<strong>最容易落地的方案之一</strong>。</p>
<h2 id="业务改造">业务改造</h2>
<p>确认数据库架构方案之后，应用层需要进行调整的内容主要包括：</p>
<ul>
<li>分库依据规则；</li>
<li>应用数据路由；</li>
<li>跨库操作补偿。</li>
</ul>
<h3 id="分库依据与路由规则">分库依据与路由规则</h3>
<p>为了避免数据迁移，让新数据库架构能够平滑、可灰度地上线，我们圈定了部分表作为划分进分库的范围，这部分表的<strong>新增数据将会在新分库集群上进行读写，而老数据会在原数据库读写</strong>。</p>
<p>业务团队梳理了对应范围表的读写模型，因为<strong>都依照其中的订单 ID 进行读写</strong>，毫无疑问<strong>订单 ID 可以作为分库的依据</strong>。因为数据库路由由应用层管理，只需要对订单 ID 稍加改造，加入一些标志信息，让应用层能区分开：</p>
<ul>
<li>订单 ID 应该在原数据库还是新的哈希分库；</li>
<li>订单 ID 应该落在第几个哈希分库。</li>
</ul>
<p>调整框架内的数据库路由规则比较繁杂，包括将每类表的管理类重写，因为涉及的表比较多，所以也改动了大量的代码，这部分不一一赘述。</p>
<h3 id="跨库一致性补偿">跨库一致性补偿</h3>
<p>由于只圈定了部分表到分库中，那么这部分表<strong>与原数据库表的交互就丢失了事务可行性</strong>，也就是没办法依赖数据库的事务保证它们一致了。 MySQL 提供了 XA 跨库事务操作，但是在实际使用中，使用 XA 跨库事务有很大的性能开销，并且也需要开发者有对应的知识储备来正确操作。</p>
<p>因此，最终应用层的方案是增加一套检查机制，使得不同库表的操作如果发生异常，也能在异步的检查任务执行完成后，恢复（回退/清理）到一致的状态。</p>
<p>以下单流程为例，我们有以下表落在了不同数据库，但需要严格保持一致：</p>
<ul>
<li>订单表：在分库中，存有订单 ID 和订单对应 3PL 物流单号信息（通过订单单号获取订单信息，包括 3PL 物流单号）；</li>
<li>反查表：在旧库中，存有 3PL 物流单号信息和对应订单单号信息（通过 3PL 物流单号查订单单号）。</li>
</ul>
<blockquote>
<p>由于分库依据是订单 ID ，所以反查表的查询模式（按 3PL 物流单号查询）让它没有办法放在分库中，只有带订单 ID 的查询才能在分库集群上正确被路由，否则需要遍历所有分库获取数据。</p>
</blockquote>
<p>为了保持反查表和订单表数据的一致，我们在旧库中新增了一个检查表（Checker），这样 Checker 与反查表能使用事务特性，保证如果反查表需要发生变更，会有对应的 Checker 被记录下来。</p>
<p>反查表操作结束后，应用层继续操作订单表，如果操作失败，此时<strong>反查表和订单表就会出现数据不一致的情况</strong>。应用层有定期执行的<strong>异步任务</strong>，通过检查 Checker 信息，<strong>对比当前订单表和反查表是否一致</strong>，如果不一致，则通过<strong>修改反查表记录让它们回到一致的状态</strong>。</p>
<p><img src="../202012-db-partition/lcs_db_distributed_data_consistency.png" alt=""></p>
<p>以上图为例，<code>mapping</code> 与 <code>order_info</code> 数据在不同数据库中，通过单库事务保证 <code>mapping</code> 数据与 <code>check_log</code> 数据同时存在，若后续 <code>order_info</code> 数据执行异常，后台任务延迟获取到 <code>check_log</code> 后，对比 <code>mapping</code> 与 <code>order_info</code> 数据，选择是否要对 <code>mapping</code> 进行清理。</p>
<p><strong>Checker 扮演的角色相当于 InnoDB 中的 undo log</strong>，如果事务执行失败，参照其中的内容进行回退或类似的操作，保证最终一致性。</p>
<p>应用层实现数据一致性补偿，是最初提出几个不同方案的其中之一，缺点是一致性需要在后台任务执行后才能保证，异常情况下涉及的表会出现短暂不一致的情况。若在各个分库中都设置对应的反查表，同样可以继续保留数据库事务的可行性，但是因为查询条件不同，需要额外遍历所有分库进行查询的开销。以上思路，包括不使用 XA 事务，都是出于不同业务场景、实践成本下的权衡取舍结果。</p>
<h2 id="发布维护">发布维护</h2>
<h3 id="灰度发布">灰度发布</h3>
<p>应用架构、数据库架构的调整，在项目上都引入了非常多的新内容，因此灰度发布需要检查的内容也非常多。</p>
<p>应用架构将部分流量划分到了新部署的服务中去，在上线需要谨慎验证<strong>新服务的各种中间件连通性，流量处理结果是否与原服务一致</strong>，并且轨迹信息数据的发起端在第三方，任何的请求丢失都可能影响到重量和运费计算等核心指标。因为路由划分依赖 Nginx，在发布时我们提前部署好应用层的服务，并让 Devops 团队协助，在 Nginx 节点上按比例让新路由配置逐步生效进行灰度。</p>
<p>数据库架构的调整后，SQL 查询落入新分库集群或是老集群应用层的订单 ID 控制，因此灰度也由应用层实施。在代码全部发布完后，应用层通过配置开关管理订单 ID 规则，在满足特定条件（如特定机器 IP、比例和时间等）时才产生新分库规则的订单 ID，其余订单仍保持使用旧订单 ID。观察灰度订单的完整履约结果，确认无误后再慢慢扩大灰度比例。</p>
<h3 id="数据归档">数据归档</h3>
<p>前面提到过，这套设计方案下，数据按照时间进行归档会比较困难，需要操作表中的具体数据。归档过程中大量 <code>UPDATE</code> 和 <code>DELETE</code> 产生的磁盘 I/O 会对业务性能表现产生影响。</p>
<p>当前业务中只需保留最近6个月的数据，因此我们需要将创建时间在 6 个月前的订单筛选出来、写入至归档库、删除业务库数据。研发团队在设计后台归档任务的时候尽可能<strong>避免集中迁移</strong>，理论上只要迁移速度等同于下单写入的QPS即可维持平衡，因此将任务设计成每分钟执行，对数据库的压力能控制在可接受范围内。</p>
<h3 id="无迁移扩容">无迁移扩容</h3>
<p>通常在数据库扩容时，我们需要将原有数据进行迁移，让其平均分布在各个新数据库中。但有了归档基础后，我们可以发现在预留充足时间的情况下，数据库的逻辑扩容无需进行数据迁移。</p>
<p>以数据库数量从 16 个扩至 64 个为例，通过修改订单 ID 规则，让新订单根据 <code>% 64</code>求路由，老订单继续使用 <code>% 16</code>，那么每个数据库的数据增长速度为总订单量增速的 1/64，是原来 1/16 的 25%。在<strong>增速减缓，归档迁出速度不变</strong>的情况下，原有的 16 个数据库中数据量会逐步从总订单量的 1/16 降低至 1/64，而新增的 48 个数据库数据量也会从 0 增长至 1/64。</p>
<p><img src="../202012-db-partition/lcs_db_scale_without_rebalancing.png" alt=""></p>
<p>通过这种无数据迁移（Rebalance）的扩容，可以避免实施双写方案的复杂性和不确定性，且手动操作和人工检查双写正确性的环节更少；代价则是<strong>无法在扩容后马上降低原有数据库的压力</strong>，因为仍有大量老订单读写落在老数据库中，<strong>压力需要随时间缓慢降低</strong>。在监控机制完善且业务增长有一定规律的情况下，我们可以综合这些因素，预留足够多的时间进行扩容、接受缓慢的数据重平衡。</p>
<h1 id="conclusion">Conclusion</h1>
<p>除非有完美的解决方案，每一次的架构调整背后都是综合考量和权衡取舍的结果。本文中介绍了 LCS 项目在上线一年以来数据库架构演变过程的重要节点，以及在 2020 年末进行的分库改造实践、踩坑和总结思考。在新项目架构设计过程中，通常人们都会想设计一套未来数年都能稳定可用的系统，但是由于各种因素的限制，一些方案或是初期成本过高（尽管能减少未来的变更），或是较为激进、不可控，都会影响到最终实施和落地难度，而被排除在外。</p>
<p>架构设计是基于当前、考虑未来、平衡成本的任务，多个方面相互制约，未必都有最优解。在存在短板时能取长补短的系统架构才更有利于快速的业务发展。</p>
]]></content>
		</item>
		
		<item>
			<title>Paper Reading：聊一聊MVCC</title>
			<link>https://jiekun.dev/posts/mvcc/</link>
			<pubDate>Sat, 21 Nov 2020 00:05:07 +0800</pubDate>
			
			<guid>https://jiekun.dev/posts/mvcc/</guid>
			<description>Paper Reading系列旨在分享著名Conference上发表的论文。VLDB（Very Large Data Bases）是数据库业界三大会议之一，其余两者为IC</description>
			<content type="html"><![CDATA[<blockquote>
<p>Paper Reading系列旨在分享著名Conference上发表的论文。VLDB（Very Large Data Bases）是数据库业界三大会议之一，其余两者为ICDE（The International Council for Open and Distance Education）和SIGMOD。</p>
</blockquote>
<h1 id="关于paper">关于Paper</h1>
<p><strong>《An Empirical Evaluation of In-Memory Multi-Version Concurrency Control》</strong> 出自2017年VLDB，主要贡献是对主流的MVCC技术要点进行了完整的梳理，并且在自研的<strong>Peloton</strong>数据库实现了所有Approaches，用于固定变量进行横向测试对比。</p>
<p>有趣的是，论文最初投稿时使用的并不是这个标题。据Andrew Pavlo（论文作者之一，CMU Associate Professor）称他们给VLDB投稿时得到的Review反馈非常正面，除了要求改掉当时的标题：<strong>《This is the Best Paper Ever on In-Memory Multi-Version Concurrency Control》</strong>。</p>
<p>但是作者们还是想在这篇论文标题上得意洋洋一番，所以后续又以下图这些标题重新投递过两次。</p>
<p><img src="../202012-mvcc/mvcc_paper.png" alt="">
Fig 1: About The Paper</p>
<p>当然，这些主观性强的标题都是没办法发表的，最后他们也不得不改成了现在所见到的标题。</p>
<h1 id="mvcc简介">MVCC简介</h1>
<p>MVCC（Multi-Version Concurrency Control）字面包含了两个方面的内容：</p>
<ul>
<li>Multi-Versioning：产生多版本的数据内容，使得读写可以不互相阻塞。</li>
<li>Concurrency Control：并发控制，使得并行执行的内容能保持串行化结果。</li>
</ul>
<p>例如，对于SQL：<code>SELECT a FROM tab_1 where id = 1;</code>，事务T1和T3可以访问到不同版本的数据结果：</p>
<pre tabindex="0"><code>+------------------------------------------------------------------------------------------------------------------+
|   | T1                                | T2                                   | T3                                |
|---|-----------------------------------|--------------------------------------|-----------------------------------|
| 1 | BEGIN;                            |                                      |                                   |
| 2 |                                   | BEGIN;                               |                                   |
| 3 |                                   | UPDATE tab_1 SET a = 2 WHERE id = 1; |                                   |
| 4 |                                   | COMMIT;                              |                                   |
| 5 |                                   |                                      | BEGIN;                            |
| 6 | SELECT a FROM tab_1 WHERE id = 1; |                                      | SELECT a FROM tab_1 WHERE id = 1; |
+------------------------------------------------------------------------------------------------------------------+
</code></pre><p>T1在T2前开启，T3在T2修改记录后开启，因此T1读到的是修改前的版本，T3读到的是commit后的版本。</p>
<p>MVCC的目的是<strong>让不同的事务都能运行在各自的快照版本数据下而不互相阻塞</strong>：写操作写操作可以生成新版本数据，而读操作仍能够读到旧的版本。目前很多主流的DBMS都支持MVCC，如：MySQL、Microsoft SQL Server、Oracle、Hekaton等。</p>
<p>虽然诞生已久，也有很多数据库支持，但是MVCC并没有一个“标准”的实现。不同的数据库在MVCC的设计上都有自己的权衡和取舍，不同的设计在不同场景下也有性能上的差异。</p>
<p>MVCC的实现主要可以分为四个关键模块设计：</p>
<ul>
<li>并发控制协议</li>
<li>版本数据存储</li>
<li>垃圾清理机制</li>
<li>索引管理</li>
</ul>
<p>我们后面将会逐一介绍不同模块的多种设计与实现。不过首先，让我们来认识一下为了支持MVCC，DMBS中需要补充什么样的元数据。</p>
<h1 id="版本数据形式">版本数据形式</h1>
<p>从<strong>事务</strong>（transaction）维度和<strong>数据行</strong>（tuple）维度而言，为了支持MVCC，都需要引入特定的Metadata。</p>
<p>对于<strong>事务</strong>，DBMS需要提供一个唯一的标识符区分不同事务。这个标识符通常是单调递增的时间戳（可以是0、1、2的序号，也可以是真实时间），我们把它称作事务的ID。有了<code>TID</code>，DMBS可以用他们来标记数据行的版本。</p>
<p>对于<strong>数据行</strong>，DBMS需要以下4个字段来在并发事务中进行定位：</p>
<ul>
<li><code>txn-id</code>：事务ID，并可用作写锁</li>
<li><code>begin-ts</code>与<code>end-ts</code>：代表版本数据的生命周期</li>
<li><code>pointer</code>：指向同一行数据相邻（新/旧）版的指针，依靠指针，版本数据可以形成一个<strong>单向</strong>链表</li>
</ul>
<p><img src="../202012-mvcc/mvcc_tuple_metadata.png" alt="">
Fig 2: MVCC Metadata Sample</p>
<p>MVCC中的MV是通过版本数据行的这些Metadata实现的，如果我们把模型稍微简化一下，只要记录有<code>begin-ts</code>和<code>end-ts</code>，我们就可以通过对比他们与当前事务的<code>TID</code>判断出哪个版本行才是事务可见的。而CC的实现，实际上也可以独立于MV存在，例如通过Timestamp Ordering或Two-phase Locking保持事务的串行性。</p>
<p><img src="../202012-mvcc/mvcc_version_link.png" alt="">
Fig 3: MVCC Tuple Linked List</p>
<h1 id="并发控制协议">并发控制协议</h1>
<p>每个DBMS系统都需要有一套并发控制协议，这套协议需要做的事情有两个：</p>
<ul>
<li>判定特定事务是否可以访问或修改特定版本的数据</li>
<li>判定特定事务是否可以提交它的改动</li>
</ul>
<p>注意通过这套协议，MVCC解决的是不同事务间执行顺序和结果的问题（而不是多版本数据），也就是通过<strong>锁</strong>或者<strong>时间顺序</strong>保持串行性。本节中将介绍两种协议：MVTO和MV2PL，MVOCC与Serialization Certifier可以在论文中进一步了解。</p>
<h2 id="timestamp-ordering-mvto">Timestamp Ordering (MVTO)</h2>
<p>MVTO的设计思路是依赖时间顺序保证事务的串行性执行结果：</p>
<ul>
<li>写锁依然通过<code>txn-id</code>来实现，只要<code>txn-id</code>不为0或者不为事务自己的<code>TID</code>，说明有其他事务进行了改动，第二个想进行改动的事务将会终止</li>
<li>读锁通过时间先后顺序保证，并发读的场景中互不阻塞，但是会将读取这个版本数据行的最大<code>TID</code>进行记录，如果有未来事务进行了读取（尽管它已经发生，也就是发生在过去），那么当前事务将不能修改这行数据（不能新增版本数据行）</li>
</ul>
<p>MVTO的实现关键在于借助事务的唯一标识符（<code>TID</code>，即时间戳）来计算不同事务的先后顺序。</p>
<p>在这个实现中，版本数据行除了上面提到的Metadata字段外，还引入了一个<code>read-ts</code>字段，它记录的是上一个读取它的事务<code>TID</code>。</p>
<p>当事务T对逻辑数据行A进行读操作时，DBMS需要根据当前的<code>TID</code>搜寻A合适的版本数据，使得<code>TID</code>落在begin-ts和end-ts之间。同时，事务T能读到的数据必须是<code>txn-id</code>为0或<code>TID</code>的，意味着数据行没有被其他事务加上写锁，因为MVTO不允许事务读取到未提交的改动。在读取A的版本数据Ax时，如果Ax的<code>read-ts</code>小于<code>TID</code>，则将该字段修改为<code>TID</code>。</p>
<p><img src="../202012-mvcc/mvcc_mvto.png" alt="">
Fig 4: MVCC Timestamp Ordering Concurrency Control</p>
<p>在MVTO中，事务更新数据行的结果总是生成一个该数据行的最新版本。事务T在满足如下条件的时候，可以对版本<code>Bx</code>进行更新：</p>
<ul>
<li><code>Bx</code>版本数据没有被其他事务加上写锁</li>
<li><code>TID</code>必须大于等于<code>Bx</code>的<code>read-ts</code>，代表没有在<code>TID</code>之后的事务读了这行数据</li>
</ul>
<p>更新时事务T会新增一个版本数据<code>Bx+1</code>，它的<code>txn-id</code>等于<code>TID</code>。在事务T提交的时候，<code>Bx+1</code>的<code>begin-ts</code>设为<code>TID</code>，<code>end-ts</code>设为<code>INF</code>，并且将上一个版本数据<code>Bx</code>的<code>end-ts</code>设为<code>TID</code>。</p>
<h2 id="two-phase-locking-mv2pl">Two-phase Locking (MV2PL)</h2>
<p>MV2PL仍然使用<code>begin-ts</code>和<code>end-ts</code>来决定版本记录是否可见。是否可读、可写，由读写锁来控制。</p>
<p>MV2PL使用<code>read-cnt</code>作为读锁，当寻找到对应版本行数据时，通过<code>read-cnt</code>加1可以给版本数据加读锁。同时，在版本数据持有写锁时，<code>read-cnt</code>不能进行递增。</p>
<p><img src="../202012-mvcc/mvcc_mv2pl.png" alt="">
Fig 5: MVCC Two-phase Locking Concurrency Control</p>
<p>同样，使用<code>txn-id</code>作为写锁，写锁决定版本数据是否能被修改：</p>
<ul>
<li>当版本数据的<code>txn-id</code>为0或当前<code>TID</code></li>
<li><code>read-cnt</code>为0</li>
</ul>
<h2 id="小结">小结</h2>
<p>MVTO和MV2PL数据行结构都非常相似，在上面的简述中可以看出只有<code>read-ts</code>和<code>read-cnt</code>区别。</p>
<p>由于<code>read-ts</code>规则的存在，未来开始的事务的读将会阻止前面开始的事务的写，因此MVTO的并发读写规则是以时间先后顺序来控制的，它虽然有锁的表现，但是本质是时间顺序的体现。</p>
<p>而在MV2PL中，<code>read-cnt</code>描述的是当前版本数据行的读锁个数，并不关心这些读锁是来自未来的事务还是以前的事务。因此<code>read-cnt</code>可以看作一个共享锁，与MVTO有本质区别。</p>
<h1 id="版本数据存储">版本数据存储</h1>
<p>在MVCC中，每次的更新都会创建一个新的版本数据。版本数据行中的指针负责指向前一个版本的数据或后一个版本的数据，以此形成一个单向的版本链。版本链不能是双向链表，因为双向链表的修改操作需要加锁，不能借助原子指令完成。</p>
<p>主流的版本数据的存储Schema有多种，不过可以提前透露的是，Delta存储是最优的方案，InnoDB使用的就是Delta存储，Postgres使用了Append-only存储，而极少数的DBMS在使用Time-travel存储。我们将逐一介绍。</p>
<h2 id="append-only">Append-only</h2>
<p>Append-only将所有数据行的不同版本（包括master版本）都存放在同一块空间中（例如同一张表）。每当有逻辑数据更新时，DMBS在表中先请求一个数据行的空间，然后将最新版本的数据复制一份到新数据行空间中，最后将变更内容应用到这一行上。</p>
<p><img src="../202012-mvcc/mvcc_append_only.png" alt="">
Fig 6: MVCC Append-only Storage</p>
<p>前面说过，因为锁的关系，没有办法维护一个双向链表的版本数据，那么版本数据的方向就变得非常重要：</p>
<ul>
<li>如果版本数据是从老到新（O2N）排列的，那么每次获取较新的版本数据（大部分场景都是如此）都需要遍历整个链表</li>
<li>如果版本数据是从新到老（N2O）排列的，那么每次插入新的版本数据时，链表的起点都要发生变更</li>
</ul>
<p>在O2N的方案中，由于无用版本遍历的存在，这种方案的性能高度依赖于版本数据的垃圾回收机制，如果垃圾回收能够将单链表维持在较短的长度，那么查询的性能是可以有提升的，否则就会很耗费时间。</p>
<p>而在N2O的方案中，也有方法可以减少变更起点的次数，就是采用一个映射entry代表链表的起点，这样当新版本数据产生时，只有entry指向的地址需要改变，而指向entry的索引则可以不发生变更。这种优化在辅助索引非常多的表上有很好的提升，但是会需要额外的存储空间。</p>
<p><img src="../202012-mvcc/mvcc_o2n_n2o.png" alt="">
Fig 7: MVCC O2N vs. N2O</p>
<p>由于Append-only存储的是完整的数据行，即使数据行中只有少量字段发生了变更。这种行为在表中带有非内联数据（即数据不记录在tuple内，如BLOB、TEXT）时会导致引入大量的重复且大体积数据。其中一个优化方式是允许不同的版本数据行指向同一个BLOB、TEXT对象，并且增加<code>cnt</code>元数据来记录引用次数，便于GC处理。</p>
<h2 id="time-travel">Time-Travel</h2>
<p>Time-Travel和Append-only的存储很相似，版本数据都是链表记录数据行，但是历史的版本数据与最新版本数据的存储空间分离开。在主表上，只有最新的master版本数据，而历史数据的链表存放在一张“Time-Travel”表中。</p>
<p>在更新逻辑行时，DBMS将master版本的数据复制进“Time-Travel”表中，然后原地更新主表中的数据行，形成新的版本数据。</p>
<p><img src="../202012-mvcc/mvcc_time_travel.png" alt="">
Fig 8: MVCC Time-Travel Storage</p>
<p>Time-Travel的设计可以避免索引上的指针频繁更新，因为他们始终指向主表上的master版本数据，并且数据原地更新，地址也没有发生变更。</p>
<p>但是因为版本数据存储的是完整tuple，因此也会有非内联数据的问题，同样，可以使用共享对象的方式进行优化。</p>
<h2 id="delta">Delta</h2>
<p>最后介绍的Delta存储同样在主表上只维护master版本的数据，然后将版本数据存放在额外的“Delta”空间中。“Delta”空间在MySQL InnoDB和Oracle中指的就是用于rollback的数据段，例如InnoDB中的undo log。</p>
<p>在更新逻辑数据行时，DMBS同样先申请“delta”空间的位置，然后将被改动的属性的老版本数据写入其中，而不是完整的tuple行。最后DMBS在主表上原地更新master版本的数据。</p>
<p><img src="../202012-mvcc/mvcc_delta.png" alt="">
Fig 9: MVCC Delta Storage</p>
<p>Delta存储在记录版本数据时表现非常优秀，当UPDATE只操作了数据行的子集时，减少了内存的分配占用，也没有外联数据版本体积过大的问题。然而，在重度读的场景中，为了获得对应的版本数据，DMBS必须从各个字段的版本数据链中获取到对应版本的字段值，再进行拼凑，这就带来了一定的额外开销。</p>
<h2 id="小结-1">小结</h2>
<p>由此可见，不同的版本数据存储方案都有各自适应的场景。例如Append-only存储在一些数据分析场景下更佳，因为版本数据存储在连续的空间中，当进行大范围的扫描时可以提高缓存的命中率，而且还可以配合硬件预读进行优化。另外，存储完整数据行的方案（Append-only、Time-Travel）可以暴露物理的版本数据给索引管理系统，为索引管理提供了更多可选的方案，而Delta存储中就没有物理的版本数据行，在以上方面的对比处于劣势。</p>
<h1 id="垃圾清理机制">垃圾清理机制</h1>
<p>不断创建版本数据的好处在于，如果一直不进行清理的话，DBMS可以借助它们实现“Time Travel”，意味着可以访问任意时刻的数据快照。Postgre在之前的版本曾经这样做过，但是当他们意识到没有什么场景需要这种功能之后，在新版本就放弃支持了。</p>
<p>版本数据积累的坏处有很多，包括巨大的存储开销，极高的版本链遍历开销（也取决于版本链的方向和使用场景）。所以自然而然就需要有GC操作去释放这部分的空间。</p>
<p>GC可以分作3个步骤：</p>
<ul>
<li>检测过时版本</li>
<li>在链表中将它们断开连接（移除链表元素）</li>
<li>释放空间</li>
</ul>
<p>检测过时版本数据有很多方法，例如检测版本行是否由异常的事务创建，或者检查版本行是否对所有活跃事务都不可见。对于后者，可以通过比较版本行的<code>end-ts</code>和活跃事务的<code>TID</code>来实现。DBMS通常可以把事务信息集中存储，但在多核系统上这会是扩展性的一个瓶颈。</p>
<p>有了检测方法之后，DMBS可以从不同的维度去寻找这些过时版本，比如从版本数据行出发，以及从事务出发。</p>
<h2 id="tuple-level">Tuple-level</h2>
<p>论文中介绍了两种数据行维度的GC方法，VAC和COOP。</p>
<p>Background Vacuuming（VAC）使用一个后台线程，周期性地扫描数据库以寻找过时的版本。这种方案最简单的实现就是遍历版本数据链表，但是这样做的GC性能很难在数据量增长时同步提升，我们需要减少无目的的遍历，或者让遍历范围能缩小下来。一种优化的方案是让DBMS维护一个bitmap，映射包含改动过数据的block，这样后台的vacuum线程就可以跳过上一次GC以来没有发生数据变更的block。</p>
<p><img src="../202012-mvcc/mvcc_tuple_gc.png" alt="">
Fig 10: MVCC Tuple-level GC</p>
<p>Cooperative Cleaning（COOP）的思路是改用worker线程进行GC。寻找版本数据时，worker线程也需要跟着版本链表进行遍历，在遍历过程中，如果发现过时版本数据，就直接进行清理。这种方案会存在两个问题：</p>
<ul>
<li>只支持O2N的版本数据记录方式，否则worker线程每次遍历的都是靠前的活跃版本数据，找到目标后就停止，不能发现过时数据</li>
<li>存在“dusty corners”问题，GC与查询任务关联在一起，因此如果逻辑数据创建有多个版本数据后，就没有发生过任何查询，那么这些版本数据就一直没办法得到清理。一般DBMS会通过结合VAC来处理这部分的数据</li>
</ul>
<h2 id="transaction-level">Transaction-level</h2>
<p>事务维度的GC一般通过事务记录它读写数据行的集合，DBMS需要监控集合中的版本数据是否都过时了。当某个事务的版本数据集合对所有的活跃事务都不可见时，就可以将这个集合中的版本数据都进行GC清理。</p>
<p><img src="../202012-mvcc/mvcc_tx_gc.png" alt="">
Fig 11: MVCC Transaction-level GC</p>
<h2 id="小结-2">小结</h2>
<p>Tuple-level的VAC是最常用的版本数据清理方案，通过增加GC线程的数量可以提升它的性能。但是对比Transaction-level GC，这种方案在出现长事务的时候会对性能有较大的影响，因为长事务意味着它开始之后的所有版本数据都得不到清理，这时候版本数据链就会变得很长，直到长事务提交或者中止。</p>
<h1 id="索引管理">索引管理</h1>
<p>所有支持MVCC的DBMSs都将版本数据和索引数据分开存储。我们可以将索引看作KV键值对，键是被索引的数据行中的字段值（例如ID），值是索引对应的数据行的指针。</p>
<p>主键索引的情况比较简单，因为主键（同时也是索引的Key）是保持不变的，索引的Value总是指向版本数据链的起点，比如在InnoDB中，主键索引的数据行就是指向主表的。在主键索引中，索引的键值对指针会发生什么样的变更，取决于DBMS使用了哪种的数据存储方式。</p>
<p>对于Delta存储，我们上面讨论过，主表永远都是存的master版本数据，它是原地更新的，因此在更新数据时，主表中的数据行位置不发生改变，因此索引Value的指针也没有发生改变。</p>
<p>对于Append-only的存储，版本数据链有两种不同的方向：</p>
<ul>
<li>O2N，新的版本数据Append在版本链的末端，因此索引的Value指针始终指向链表的起点不变；只有在发生GC的时候才会调整指针地址</li>
<li>N2O，每当产生新版本时，都需要调整索引值的指针，此时DBMS一般会在索引上进行DELETE &amp; INSERT的操作完成调整</li>
</ul>
<p>对于辅助索引，被索引的字段值（同时也是索引中的Key）可能改变，索引的Value指向的版本数据也有可能改变。因此有不同的方案对索引中的指针进行管理。</p>
<h2 id="logical-pointers">Logical Pointers</h2>
<p>最常用的方案是建立一层中间表，让索引的Value能够一直不变，例如指向主键。这种方案也是InnoDB在使用的，所以我们通常说辅助索引会包含被索引值以及主键值。通过主键值将索引中的指针固定下来，这样每当版本数据链表起点发生改变时，只需要同时更新主键值对应的指针。虽然只有一个辅助索引时，听起来改动的复杂度是相同的，都是改变了1处指针，但是当有许多辅助索引时，就会是O(1) vs. O(n)的差异了。</p>
<p>借助主键的坏处是辅助索引的体积会随着主键体积发生变化，另一个方案是为逻辑tuple提供64-bit的唯一ID。实际上思路并没有区别，都是在物理版本链和索引之间增加了一层映射，只是看映射的内容如何选取一个唯一固定、节约空间的值。</p>
<h2 id="physical-pointers">Physical Pointers</h2>
<p>Uber曾经发过一篇文章：<a href="https://eng.uber.com/postgres-to-mysql-migration/">《Why Uber Engineering Switched from Postgres to MySQL》</a>，实际上他们并不是一开始就在用Postgres。Uber最早使用的也是MySQL，中途招了一些热衷于Postgres的工程师，所以他们就从MySQL切到了Postgres。他们在表中加了非常多的辅助索引，在使用过程中发现，Postgres的辅助索引是指向磁盘中的版本链起点的，在版本链起点发生变动时，多个辅助索引的指针就要发生修改。在Append-only的存储方式下，这种设计的好处是没有通过中间层映射（例如主键ID）回表查询，坏处也非常明显，当辅助索引非常多的时候，版本数据链起点的变更将会导致所有辅助索引的指针都需要更新。</p>
<p>目前还有一些DBMS使用了这种方案，例如MemSQL、Hekaton。如果Uber的工程师有读过这篇论文，他们可能可以节约不少的迁移成本。</p>
<h2 id="小结-3">小结</h2>
<p>同样，不同的管理方式也有各自适合的场景。对于Logical Pointer，在写入频繁的场景下表现更好，因为辅助索引只需要在索引字段值发生改变时才会改变，在读取场景下，它还需要对不同的版本链进行对比，因为同一个逻辑值有可能对应不同的物理值，例如DELETE后再INSERT同一个值；对于Physical Pointers，缺点之前已经提到过，频繁的更新场景会导致写入性能变差，但是在检索时就会有它的优势。</p>
<p>另外，在支持MVCC的DBMS中，所谓的“覆盖索引”其实并不能通过扫描单个索引得到Query结果，因为索引里面并没有版本数据。对于Append-only的设计，回到主表进行检索是必须的；而对于Delta存储，至少也需要在Delta空间（例如undo log）中查找对应版本。</p>
<h1 id="总结">总结</h1>
<p>论文对MVCC的4个要点进行了分类总结：</p>
<ul>
<li>并发控制协议：MVTO、MVOCC、MV2PL和Serialization Certifier</li>
<li>版本数据存储：Append-only、Time-Travel和Delta</li>
<li>垃圾清理机制：Tuple-level和Transaction-level</li>
<li>索引管理：Logical Pointers和Physical Pointers</li>
</ul>
<p>意在说明MVCC并没有一套标准的实现，不同的实现之间针对具体场景Workload的不同也有着不同的表现。在Paper Reading中我们并没有展示论文中不同Approaches的测试结果，关心的同学可以在文末的链接找到原文查看。</p>
<p>另外，尽管可以从不同的DBMS中总结出一些共用的实现方案，但是它们各自都有进一步地做不同的优化，例如InnoDB中的undo log管理与GC就比原文的概述复杂得多。</p>
<h1 id="references">References</h1>
<p><a href="https://15721.courses.cs.cmu.edu/spring2020/papers/03-mvcc1/wu-vldb2017.pdf">[1] Y. Wu, An Empirical Evaluation of In-Memory Multi-Version Concurrency Control. In VLDB 2017.</a></p>
<p><a href="https://15721.courses.cs.cmu.edu/spring2020/papers/05-mvcc3/p128-bottcher.pdf">[2] J. Böttcher, Scalable Garbage Collection for In-Memory MVCC Systems. In VLDB 2019.</a></p>
<p><a href="https://www.youtube.com/playlist?list=PLSE8ODhjZXjasmrEd2_Yi1deeE360zv5O">[3] CMU 15-721 Advanced Database Systems.</a></p>
]]></content>
		</item>
		
		<item>
			<title>Redis 6.0新Feature实现原理——Threaded I/O</title>
			<link>https://jiekun.dev/posts/redis-tio-implementation/</link>
			<pubDate>Sun, 20 Sep 2020 05:16:52 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/redis-tio-implementation/</guid>
			<description>Introduction Redis从6.0版本开始引入了Threaded I/O，目的是为了提升执行命令前后的网络I/O性能。本文会先从Redis的主流程开始分析，</description>
			<content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Redis从6.0版本开始引入了Threaded I/O，目的是为了提升执行命令前后的网络I/O性能。本文会先从Redis的主流程开始分析，讲解网络I/O发生在哪里，以及现有的网络I/O模型，然后介绍Threaded I/O的新模型、实现以及生效场景，最后会进行场景测试，对比Threaded I/O关闭与开启，以及启用Threaded I/O与在单实例上搭建集群的性能差异。如果你已经了解过Redis的循环流程，可以直接跳至<strong>Threaded I/O相关</strong>的部分；如果你只关心新功能的实际提升，可以跳至<strong>性能测试</strong>部分查看。</p>
<h1 id="redis是如何运行的">Redis是如何运行的</h1>
<h2 id="事件循环">事件循环</h2>
<h3 id="main">main</h3>
<p>Redis的入口位于server.c下，<code>main()</code>方法流程如图所示。</p>
<p><img src="../2020/09/redis_main-878x1024.png" alt="">
在<code>main()</code>方法中Redis首先需要做的是<strong>初始化各种库以及服务配置</strong>。具体举例：</p>
<ul>
<li><code>crc64_init()</code>会初始化一个crc校验用的Lookup Table</li>
<li><code>getRandomBytes()</code>为<code>hashseed</code>填充随机元素作为初始化值，用作哈希表的seed</li>
<li>…</li>
<li><code>initServerConfig()</code>中执行了大量对<code>server</code>对象属性的初始化操作：
<ul>
<li>初始化<code>server.runid</code>，如<code>16e05f486b8d41e79593a35c8b96edaff101c194</code></li>
<li>获取当前的时区信息，存放至<code>server.timezone</code>中</li>
<li>初始化<code>server.next_client_id</code>值，使得连接进来的客户端id从1开始自增</li>
<li>…</li>
</ul>
</li>
<li><code>ACLInit()</code>是对Redis 6.0新增的ACL系统的初始化操作，包括初始化用户列表、ACL日志、默认用户等信息</li>
<li>通过<code>moduleInitModulesSystem()</code>和<code>tlsInit()</code>初始化模块系统和SSL等</li>
<li>…</li>
</ul>
<p>初始化结束后，开始<strong>读取用户的启动参数</strong>，和大多数配置加载过程类似，Redis也通过字符串匹配等分析用户输入的<code>argc</code>和<code>argv[]</code>，这个过程中可能会发生：</p>
<ul>
<li>获取到配置文件路径，修改<code>server.configfile</code>的值，后续用于加载配置文件</li>
<li>获取到启动选项参数，如<code>loadmodule</code>和对应的Module文件路径，保存至<code>options</code>变量中</li>
</ul>
<p>解析完参数之后，执行<code>loadServerConfig()</code>，<strong>读取配置文件并与命令行参数options的内容进行合并</strong>，组成一个<code>config</code>变量，并且逐个将name和value设置进configs列表中。对于每个config，有对应的switch-case的代码，例如对于<code>loadmodule</code>，会执行<code>queueLoadModule()</code>方法，以完成真正的配置加载：</p>
<pre tabindex="0"><code>...
        } else if (!strcasecmp(argv[0],&quot;logfile&quot;) &amp;&amp; argc == 2) {   
            ... 
        } else if (!strcasecmp(argv[0],&quot;loadmodule&quot;) &amp;&amp; argc &gt;= 2) {
            queueLoadModule(argv[1],&amp;argv[2],argc-2);
        } else if (!strcasecmp(argv[0],&quot;sentinel&quot;)) {
...

</code></pre><p>回到<code>main</code>方法的流程，Redis会开始打印启动的日志，执行<code>initServer()</code>方法，服务根据配置项，继续<strong>为<code>server</code>对象初始化内容</strong>，例如：</p>
<ul>
<li>创建事件循环结构体<code>aeEventLoop</code>（定义在ae.h），赋值给<code>server.el</code></li>
<li>根据配置的db数目，分配大小为<code>sizeof(redisDb) * dbnum</code>的内存空间，<code>server.db</code>保存这块空间的地址指针</li>
<li>每个db都是一个redisDb结构，将这个结构中的保存key、保存过期时间等的字典初始化为空dict</li>
<li>…</li>
</ul>
<p>此后就是一些根据不同运行模式的初始化，例如常规模式运行时会记录常规日志、加载磁盘持久化的数据；而在sentinel模式运行时记录哨兵日志，不加载数据等。</p>
<p>在所有准备操作都完成后，<strong>Redis开始陷入<code>aeMain()</code>的事件循环，在这个循环中会不断执行<code>aeProcessEvents()</code>处理发生的各种事件，直到Redis结束退出</strong>。</p>
<h3 id="两种事件">两种事件</h3>
<p>Redis中存在有两种类型的事件：<strong>时间事件</strong>、<strong>文件事件</strong>。</p>
<p><strong>时间事件也就是到了一定事件会发生的事件</strong>，在Redis中它们被记录成一个链表，每次创建新的事件事件的时候，都会在链表头部插入一个<code>aeTimeEvent</code>节点，其中保存了该事件会在何时发生，需要调用什么样的方法处理。遍历整个链表我们可以知道离最近要发生的时间事件还有多久，因为链表里面的节点按照自增id顺序排列，而在发生时间的维度上时乱序的。</p>
<p><img src="../2020/09/redis_time_event-1024x836.png" alt="">
<strong>文件事件可以看作I/O引起的事件</strong>，客户端发送命令会让服务端产生一个读I/O，对应一个读事件；同样当客户端等待服务端消息的时候需要变得可写，让服务端写入内容，因此会对应一个写事件。<code>AE_READABLE</code>事件会在客户端建立连接、发送命令或其他连接变得可读的时候发生，而<code>AE_WRITABLE</code>事件则会在客户端连接变得可写的时候发生。</p>
<p><img src="../2020/09/redis_file_event_happen-1024x512.png" alt="">
文件事件的结构简单很多，<code>aeFileEvent</code>记录了这是一个可读事件还是可写事件，对应的处理方法，以及用户数据。</p>
<p><img src="../2020/09/redis_file_event-1024x529.png" alt="">
如果同时发生了两种事件，Redis会优先处理<code>AE_READABLE</code>事件。</p>
<h3 id="aeprocessevents">aeProcessEvents</h3>
<p><strong><code>aeProcessEvents()</code>方法处理已经发生和即将发生的各种事件</strong>。</p>
<p><img src="../2020/09/redis_aeProcessEvents-945x1024.png" alt="">
在<code>aeMain()</code>循环进入<code>aeProcessEvents()</code>后，Redis首先检查下一次的时间事件会在什么时候发生，在还没有时间事件发生的这段时间内，可以调用多路复用的API <code>aeApiPoll()</code>阻塞并等待文件事件的发生。如果没有文件事件发生，那么超时后返回0，否则返回已发生的文件事件数量<code>numevents</code>。</p>
<p>在有文件事件可处理的情况下，Redis会调用<code>AE_READABLE</code>事件的<code>rfileProc</code>方法以及<code>AE_WRITABLE</code>事件的<code>wfileProc</code>方法进行处理：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
            <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">invert</span> <span class="o">&amp;&amp;</span> <span class="n">fe</span><span class="o">-&gt;</span><span class="n">mask</span> <span class="o">&amp;</span> <span class="n">mask</span> <span class="o">&amp;</span> <span class="n">AE_READABLE</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">fe</span><span class="o">-&gt;</span><span class="n">rfileProc</span><span class="p">(</span><span class="n">eventLoop</span><span class="p">,</span><span class="n">fd</span><span class="p">,</span><span class="n">fe</span><span class="o">-&gt;</span><span class="n">clientData</span><span class="p">,</span><span class="n">mask</span><span class="p">);</span>
                <span class="n">fired</span><span class="o">++</span><span class="p">;</span>
                <span class="n">fe</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">eventLoop</span><span class="o">-&gt;</span><span class="n">events</span><span class="p">[</span><span class="n">fd</span><span class="p">];</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">fe</span><span class="o">-&gt;</span><span class="n">mask</span> <span class="o">&amp;</span> <span class="n">mask</span> <span class="o">&amp;</span> <span class="n">AE_WRITABLE</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">fired</span> <span class="o">||</span> <span class="n">fe</span><span class="o">-&gt;</span><span class="n">wfileProc</span> <span class="o">!=</span> <span class="n">fe</span><span class="o">-&gt;</span><span class="n">rfileProc</span><span class="p">)</span> <span class="p">{</span>
                    <span class="n">fe</span><span class="o">-&gt;</span><span class="n">wfileProc</span><span class="p">(</span><span class="n">eventLoop</span><span class="p">,</span><span class="n">fd</span><span class="p">,</span><span class="n">fe</span><span class="o">-&gt;</span><span class="n">clientData</span><span class="p">,</span><span class="n">mask</span><span class="p">);</span>
                    <span class="n">fired</span><span class="o">++</span><span class="p">;</span>
                <span class="p">}</span>
            <span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p>在完成前面的处理后，Redis会继续调用<code>processTimeEvents()</code>处理时间事件。遍历整个时间事件链表，如果此时已经过了一段时间（阻塞等待或处理文件事件耗时），有时间事件发生，那么就调用对应时间事件的<code>timeProc</code>方法，将所有已经过时的时间事件处理掉：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">te</span><span class="o">-&gt;</span><span class="n">when</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">=</span> <span class="n">now</span><span class="p">)</span> <span class="p">{</span>
            <span class="p">...</span>
            <span class="n">retval</span> <span class="o">=</span> <span class="n">te</span><span class="o">-&gt;</span><span class="n">timeProc</span><span class="p">(</span><span class="n">eventLoop</span><span class="p">,</span> <span class="n">id</span><span class="p">,</span> <span class="n">te</span><span class="o">-&gt;</span><span class="n">clientData</span><span class="p">);</span>
            <span class="p">...</span>
            <span class="n">processed</span><span class="o">++</span><span class="p">;</span>
            <span class="p">...</span>
        <span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p>如果执行了文件事件之后还没有到最近的时间事件发生点，那么本次<code>aeMain()</code>循环中将没有时间事件被执行，进入下一次循环。</p>
<h2 id="命令执行前后发生了什么">命令执行前后发生了什么</h2>
<p>在客户端连接上Redis的时候，通过执行<code>connSetReadHandler(conn, readQueryFromClient)</code>，设置了当读事件发生时，使用<code>readQueryFromClient()</code>作为读事件的Handler。</p>
<p>在收到客户端的命令请求时，Redis进行一些检查和统计后，调用<code>read()</code>方法将连接中的数据读取进<code>client.querybuf</code>消息缓冲区中：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="kt">void</span> <span class="nf">readQueryFromClient</span><span class="p">(</span><span class="n">connection</span> <span class="o">*</span><span class="n">conn</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">...</span>
    <span class="n">nread</span> <span class="o">=</span> <span class="n">connRead</span><span class="p">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">conn</span><span class="p">,</span> <span class="n">c</span><span class="o">-&gt;</span><span class="n">querybuf</span><span class="o">+</span><span class="n">qblen</span><span class="p">,</span> <span class="n">readlen</span><span class="p">);</span>
    <span class="p">...</span>


<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="n">connRead</span><span class="p">(</span><span class="n">connection</span> <span class="o">*</span><span class="n">conn</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">buf</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">buf_len</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">conn</span><span class="o">-&gt;</span><span class="n">type</span><span class="o">-&gt;</span><span class="n">read</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="n">buf_len</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">int</span> <span class="n">connSocketRead</span><span class="p">(</span><span class="n">connection</span> <span class="o">*</span><span class="n">conn</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">buf</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">buf_len</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">conn</span><span class="o">-&gt;</span><span class="n">fd</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="n">buf_len</span><span class="p">);</span>
    <span class="p">...</span>
<span class="p">}</span>

</code></pre></div><p>然后进入<code>processInputBuffer(c)</code>开始读取输入缓冲区中的消息，最后进入<code>processCommand(c)</code>开始处理输入的命令。</p>
<p>在命令执行得到结果后，首先会存放在<code>client.buf</code>中，并且调用调用<code>addReply(client *c, robj *obj)</code>方法，将这个<code>client</code>对象追加到<code>server.clients_pending_write</code>列表中。此时当次的命令，或者说<code>AE_READABLE</code>事件就已经基本处理完毕了，除了一些额外的统计数据、后处理以外，不会再进行发送响应消息的动作。</p>
<p><img src="../2020/09/redis_result_to_reply-904x1024.png" alt="">
在当前<code>aeProcessEvents()</code>方法结束后，进入<strong>下一次的循环</strong>，第二次循环调用I/O多路复用接口等待文件事件发生前，Redis会检查<code>server.clients_pending_write</code>是否有客户端需要进行回复，若有，遍历指向各个待回复客户端的<code>server.clients_pending_write</code>列表，逐个将客户端从中删除，并将待回复的内容通过<code>writeToClient(c,0)</code>回复出去</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="kt">int</span> <span class="nf">writeToClient</span><span class="p">(</span><span class="n">client</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">handler_installed</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">...</span>
    <span class="n">nwritten</span> <span class="o">=</span> <span class="n">connWrite</span><span class="p">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">conn</span><span class="p">,</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">buf</span><span class="o">+</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">sentlen</span><span class="p">,</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">bufpos</span><span class="o">-</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">sentlen</span><span class="p">);</span>
    <span class="p">...</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="n">connWrite</span><span class="p">(</span><span class="n">connection</span> <span class="o">*</span><span class="n">conn</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">data_len</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">conn</span><span class="o">-&gt;</span><span class="n">type</span><span class="o">-&gt;</span><span class="n">write</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">data_len</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">int</span> <span class="n">connSocketWrite</span><span class="p">(</span><span class="n">connection</span> <span class="o">*</span><span class="n">conn</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">data_len</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">write</span><span class="p">(</span><span class="n">conn</span><span class="o">-&gt;</span><span class="n">fd</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">data_len</span><span class="p">);</span>
    <span class="p">...</span>
<span class="p">}</span>

</code></pre></div><h1 id="threaded-io模型">Threaded I/O模型</h1>
<h2 id="io问题与threaded-io的引入">I/O问题与Threaded I/O的引入</h2>
<p>如果要说Redis会有什么性能问题，那么从I/O角度，由于它没有像其他Database一样使用磁盘，所以不存在磁盘I/O的问题。在数据进入缓冲区前及从缓冲区写至Socket时，存在一定的网络I/O，特别是写I/O对性能影响比较大。以往我们会考虑做管道化来减小网络I/O的开销，或者将Redis部署成Redis集群来提升性能。</p>
<p>在Redis 6.0之后，由于Threaded I/O的引入，Redis开始支持对网络读写的线程化，让更多的线程参与进这部分动作中，同时保持命令的单线程执行。这样的改动从某种程度上说可以既提升性能，但又避免将命令执行线程化而需要引入锁或者其他方式解决并行执行的竞态问题。</p>
<h2 id="threaded-io在做什么">Threaded I/O在做什么</h2>
<p>在老版本的实现中，Redis将不同client的命令执行结果保存在各自的<code>client.buf</code>中，然后把待回复的<code>client</code>存放在一个列表里，最后在事件循环中逐个将<code>buf</code>的内容写至对应Socket。对应在新版本中，Redis使用多个线程完成这部分操作。</p>
<p><img src="../2020/09/redis_prepare_thread_io-1024x1024.png" alt="">
对读操作，Redis同样地为<code>server</code>对象新增了一个<code>clients_pending_read</code>属性，当读事件来临时，判断是否满足线程化读的条件，如果满足，那么执行延迟读操作，将这个<code>client</code>对象添加到<code>server.clients_pending_read</code>列表中。和写操作一样，留到下一次事件循环时使用多个线程完成读操作。</p>
<p><img src="../2020/09/redis_before_sleep-1024x811.png" alt=""></p>
<h1 id="threaded-io的实现与限制">Threaded I/O的实现与限制</h1>
<h2 id="init阶段">Init阶段</h2>
<p>在Redis启动时，如果满足对应参数配置，会进行I/O线程初始化的操作。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="kt">void</span> <span class="nf">initThreadedIO</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">server</span><span class="p">.</span><span class="n">io_threads_active</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">io_threads_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">io_threads_num</span> <span class="o">&gt;</span> <span class="n">IO_THREADS_MAX_NUM</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">serverLog</span><span class="p">(</span><span class="n">LL_WARNING</span><span class="p">,</span><span class="s">&#34;Fatal: too many I/O threads configured. &#34;</span>
                             <span class="s">&#34;The maximum number is %d.&#34;</span><span class="p">,</span> <span class="n">IO_THREADS_MAX_NUM</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p>Redis会进行一些常规检查，配置数是否符合开启多线程I/O的要求。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">server</span><span class="p">.</span><span class="n">io_threads_num</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">io_threads_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">listCreate</span><span class="p">();</span>
<span class="p">...</span>

</code></pre></div><p>创建一个长度为线程数的<code>io_threads_list</code>列表，列表的每个元素都是另一个列表L，L将会用来存放对应线程待处理的多个<code>client</code>对象。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">continue</span><span class="p">;</span>
<span class="p">...</span>

</code></pre></div><p>对于主线程，初始化操作到这里就结束了。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
        <span class="n">pthread_t</span> <span class="n">tid</span><span class="p">;</span>
        <span class="n">pthread_mutex_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">io_threads_mutex</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="nb">NULL</span><span class="p">);</span>
        <span class="n">io_threads_pending</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">io_threads_mutex</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span> <span class="cm">/* Thread will be stopped. */</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tid</span><span class="p">,</span><span class="nb">NULL</span><span class="p">,</span><span class="n">IOThreadMain</span><span class="p">,(</span><span class="kt">void</span><span class="o">*</span><span class="p">)(</span><span class="kt">long</span><span class="p">)</span><span class="n">i</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">serverLog</span><span class="p">(</span><span class="n">LL_WARNING</span><span class="p">,</span><span class="s">&#34;Fatal: Can&#39;t initialize IO thread.&#34;</span><span class="p">);</span>
            <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="n">io_threads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tid</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p><code>io_threads_mutex</code>是一个互斥锁列表，<code>io_threads_mutex[i]</code>即第<code>i</code>个线程的锁，用于后续阻塞I/O线程操作，初始化之后将其暂时锁定。然后再对每个线程执行创建操作，<code>tid</code>即其指针，保存至<code>io_threads</code>列表中。新的线程会一直执行<code>IOThreadMain</code>方法，我们将它放到最后讲解。</p>
<h2 id="readswrites">Reads/Writes</h2>
<p>多线程的读写主要在<code>handleClientsWithPendingReadsUsingThreads()</code>和<code>handleClientsWithPendingWritesUsingThreads()</code>中完成，因为两者几乎是对称的，所以这里只对读操作进行讲解，有兴趣的同学可以检查一下写操作有什么不同的地方以及为什么。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="kt">int</span> <span class="nf">handleClientsWithPendingReadsUsingThreads</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">server</span><span class="p">.</span><span class="n">io_threads_active</span> <span class="o">||</span> <span class="o">!</span><span class="n">server</span><span class="p">.</span><span class="n">io_threads_do_reads</span><span class="p">)</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">processed</span> <span class="o">=</span> <span class="n">listLength</span><span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">clients_pending_read</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">processed</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">tio_debug</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">&#34;%d TOTAL READ pending clients</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">processed</span><span class="p">);</span>
<span class="p">...</span>

</code></pre></div><p>同样，Redis会进行常规检查，是否启用线程化读写并且启用线程化读（只开启前者则只有写操作是线程化），以及是否有等待读取的客户端。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="n">listIter</span> <span class="n">li</span><span class="p">;</span>
    <span class="n">listNode</span> <span class="o">*</span><span class="n">ln</span><span class="p">;</span>
    <span class="n">listRewind</span><span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">clients_pending_read</span><span class="p">,</span><span class="o">&amp;</span><span class="n">li</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">item_id</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">while</span><span class="p">((</span><span class="n">ln</span> <span class="o">=</span> <span class="n">listNext</span><span class="p">(</span><span class="o">&amp;</span><span class="n">li</span><span class="p">)))</span> <span class="p">{</span>
        <span class="n">client</span> <span class="o">*</span><span class="n">c</span> <span class="o">=</span> <span class="n">listNodeValue</span><span class="p">(</span><span class="n">ln</span><span class="p">);</span>
        <span class="kt">int</span> <span class="n">target_id</span> <span class="o">=</span> <span class="n">item_id</span> <span class="o">%</span> <span class="n">server</span><span class="p">.</span><span class="n">io_threads_num</span><span class="p">;</span>
        <span class="n">listAddNodeTail</span><span class="p">(</span><span class="n">io_threads_list</span><span class="p">[</span><span class="n">target_id</span><span class="p">],</span><span class="n">c</span><span class="p">);</span>
        <span class="n">item_id</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p>这里将<code>server.clients_pending_read</code>的列表转化为方便遍历的链表，然后将列表的每个节点（<code>*client</code>对象）以类似Round-Robin的方式分配个各个线程，线程执行各个client的读写顺序并不需要保证，命令抵达的先后顺序已经由<code>server.clients_pending_read/write</code>列表记录，后续也会按这个顺序执行。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="n">io_threads_op</span> <span class="o">=</span> <span class="n">IO_THREADS_OP_READ</span><span class="p">;</span>
<span class="p">...</span>

</code></pre></div><p>设置状态标记，标识当前处于多线程读的状态。由于标记的存在，Redis的Threaded I/O瞬时只能处于读或写的状态，不能部分线程读，部分写。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">server</span><span class="p">.</span><span class="n">io_threads_num</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">count</span> <span class="o">=</span> <span class="n">listLength</span><span class="p">(</span><span class="n">io_threads_list</span><span class="p">[</span><span class="n">j</span><span class="p">]);</span>
        <span class="n">io_threads_pending</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p>为每个线程记录下各自需要处理的客户端数量。当不同线程读取到自己的pending长度不为0时，就会开始进行处理。注意<code>j</code>从1开始，意味着``的主线程的pending长度一直为0，因为主线程马上要在这个方法中同步完成自己的任务，不需要知道等待的任务数。</p>
<p><img src="../2020/09/redis_tio_variables-945x1024.png" alt=""></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="n">listRewind</span><span class="p">(</span><span class="n">io_threads_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="o">&amp;</span><span class="n">li</span><span class="p">);</span>
    <span class="k">while</span><span class="p">((</span><span class="n">ln</span> <span class="o">=</span> <span class="n">listNext</span><span class="p">(</span><span class="o">&amp;</span><span class="n">li</span><span class="p">)))</span> <span class="p">{</span>
        <span class="n">client</span> <span class="o">*</span><span class="n">c</span> <span class="o">=</span> <span class="n">listNodeValue</span><span class="p">(</span><span class="n">ln</span><span class="p">);</span>
        <span class="n">readQueryFromClient</span><span class="p">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">conn</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">listEmpty</span><span class="p">(</span><span class="n">io_threads_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="p">...</span>

</code></pre></div><p>主线程此时将自己要处理的client处理完。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">pending</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">server</span><span class="p">.</span><span class="n">io_threads_num</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
            <span class="n">pending</span> <span class="o">+=</span> <span class="n">io_threads_pending</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">pending</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tio_debug</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">&#34;I/O READ All threads finshed</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">);</span>
<span class="p">...</span>

</code></pre></div><p>陷入循环等待，<code>pending</code>等于各个线程剩余任务数之和，当所有线程都没有任务的时候，本轮I/O处理结束。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="k">while</span><span class="p">(</span><span class="n">listLength</span><span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">clients_pending_read</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">ln</span> <span class="o">=</span> <span class="n">listFirst</span><span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">clients_pending_read</span><span class="p">);</span>
        <span class="n">client</span> <span class="o">*</span><span class="n">c</span> <span class="o">=</span> <span class="n">listNodeValue</span><span class="p">(</span><span class="n">ln</span><span class="p">);</span>
        <span class="n">c</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="n">CLIENT_PENDING_READ</span><span class="p">;</span>
        <span class="n">listDelNode</span><span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">clients_pending_read</span><span class="p">,</span><span class="n">ln</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">CLIENT_PENDING_COMMAND</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">c</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="n">CLIENT_PENDING_COMMAND</span><span class="p">;</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">processCommandAndResetClient</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="n">C_ERR</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">continue</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">processInputBuffer</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p>我们已经在各自线程中将<code>conn</code>中的内容读取至对应client的<code>client.querybuf</code>输入缓冲区中，所以可以遍历<code>server.clients_pending_read</code>列表，串行地进行命令执行操作，同时将<code>client</code>从列表中移除。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="n">server</span><span class="p">.</span><span class="n">stat_io_reads_processed</span> <span class="o">+=</span> <span class="n">processed</span><span class="p">;</span>

    <span class="k">return</span> <span class="n">processed</span><span class="p">;</span>
<span class="p">}</span>

</code></pre></div><p>处理完成，将处理的数量加到统计属性上，然后返回。</p>
<h2 id="iothreadmain">IOThreadMain</h2>
<p>前面还有每个线程具体的工作内容没有解释，它们会一直陷在<code>IOThreadMain</code>的循环中，等待执行读写的时机。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="kt">void</span> <span class="o">*</span><span class="nf">IOThreadMain</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">myid</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">long</span> <span class="n">id</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span><span class="n">myid</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">thdname</span><span class="p">[</span><span class="mi">16</span><span class="p">];</span>

    <span class="n">snprintf</span><span class="p">(</span><span class="n">thdname</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">thdname</span><span class="p">),</span> <span class="s">&#34;io_thd_%ld&#34;</span><span class="p">,</span> <span class="n">id</span><span class="p">);</span>
    <span class="n">redis_set_thread_title</span><span class="p">(</span><span class="n">thdname</span><span class="p">);</span>
    <span class="n">redisSetCpuAffinity</span><span class="p">(</span><span class="n">server</span><span class="p">.</span><span class="n">server_cpulist</span><span class="p">);</span>
<span class="p">...</span>

</code></pre></div><p>照常执行一些初始化内容。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
    <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">1000000</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">io_threads_pending</span><span class="p">[</span><span class="n">id</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">break</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">io_threads_pending</span><span class="p">[</span><span class="n">id</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">io_threads_mutex</span><span class="p">[</span><span class="n">id</span><span class="p">]);</span>
            <span class="n">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">io_threads_mutex</span><span class="p">[</span><span class="n">id</span><span class="p">]);</span>
            <span class="k">continue</span><span class="p">;</span>
        <span class="p">}</span>


        <span class="n">serverAssert</span><span class="p">(</span><span class="n">io_threads_pending</span><span class="p">[</span><span class="n">id</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">tio_debug</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">&#34;[%ld] %d to handle</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">id</span><span class="p">,</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">listLength</span><span class="p">(</span><span class="n">io_threads_list</span><span class="p">[</span><span class="n">id</span><span class="p">]));</span>
<span class="p">...</span>

</code></pre></div><p>线程会检测自己的待处理的client列表长度，当等待队列长度大于0时往下执行，否则会到死循环起点。</p>
<p>这里利用互斥锁，让主线程有机会加锁，使得I/O线程卡在执行<code>pthread_mutex_lock()</code>，达到让I/O线程停止工作的效果。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
        <span class="n">listIter</span> <span class="n">li</span><span class="p">;</span>
        <span class="n">listNode</span> <span class="o">*</span><span class="n">ln</span><span class="p">;</span>
        <span class="n">listRewind</span><span class="p">(</span><span class="n">io_threads_list</span><span class="p">[</span><span class="n">id</span><span class="p">],</span><span class="o">&amp;</span><span class="n">li</span><span class="p">);</span>
        <span class="k">while</span><span class="p">((</span><span class="n">ln</span> <span class="o">=</span> <span class="n">listNext</span><span class="p">(</span><span class="o">&amp;</span><span class="n">li</span><span class="p">)))</span> <span class="p">{</span>
            <span class="n">client</span> <span class="o">*</span><span class="n">c</span> <span class="o">=</span> <span class="n">listNodeValue</span><span class="p">(</span><span class="n">ln</span><span class="p">);</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">io_threads_op</span> <span class="o">==</span> <span class="n">IO_THREADS_OP_WRITE</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">writeToClient</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="mi">0</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">io_threads_op</span> <span class="o">==</span> <span class="n">IO_THREADS_OP_READ</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">readQueryFromClient</span><span class="p">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">conn</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="n">serverPanic</span><span class="p">(</span><span class="s">&#34;io_threads_op value is unknown&#34;</span><span class="p">);</span>
            <span class="p">}</span>
        <span class="p">}</span>
<span class="p">...</span>

</code></pre></div><p>将<code>io_threads_list[i]</code>的客户端列表转化为方便遍历的链表，逐个遍历，借助<code>io_threads_op</code>标志判断当前是要执行多线程读还是多线程写，完成对自己要处理的客户端的操作。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="p">...</span>
        <span class="n">listEmpty</span><span class="p">(</span><span class="n">io_threads_list</span><span class="p">[</span><span class="n">id</span><span class="p">]);</span>
        <span class="n">io_threads_pending</span><span class="p">[</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">tio_debug</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">&#34;[%ld] Done</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">id</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

</code></pre></div><p>清空自己要处理的客户端列表，并且将自己的待处理数量修改为0，结束本轮操作。</p>
<h2 id="limitation">Limitation</h2>
<p>通过查看代码，使用上Threaded I/O的启用受以下条件影响：</p>
<ul>
<li>配置项<code>io-threads</code>需要大于1，否则会继续使用单线程操作读写I/O</li>
<li>配置项<code>io-threads-do-reads</code>控制读I/O是否使用线程化</li>
<li>对于延迟读取，由<code>postponeClientRead()</code>方法控制。方法中除了配置要求外，还需要当前client不能是主从模型的角色，也不能处于已经等待下次事件循环线程化读取（<code>CLIENT_PENDING_READ</code>）的状态。在这个方法中<code>client</code>对象会被添加到等待队列中，并且将client的状态改为<code>CLIENT_PENDING_READ</code>。</li>
<li>对于多线程写I/O，由<code>handleClientsWithPendingWritesUsingThreads()</code>中的<code>stopThreadedIOIfNeeded()</code>方法加以限制。除了对应配置项要满足要求外，<code>server.clients_pending_write</code>的长度需要大于等于配置线程数的两倍，例如配置使用6线程，当写队列长度小于12时会继续使用单线程I/O。</li>
<li>I/O线程在<code>initThreadedIO()</code>被创建前，互斥锁处于加锁状态，因此线程不能进行实际的任务处理。<code>server</code>对象的<code>io_threads_active</code>属性默认会处于关闭状态，在进行首次多线程写之前才会被开启。这意味着服务启动后的读操作仍然会使用单线程读，产生执行结果到写的pending list中，在第二次循环中，服务判断是否有配置启用TIO，将<code>server.io_threads_active</code>属性打开，然后进行多线程写操作，从下一次循环开始TIO才能被作用于读操作上。上一点说过写I/O会有配置和队列长度判定，在判定不需要TIO写时，会重新把<code>server.io_threads_active</code>关闭，意味着尽管你已经在配置文件里面打开TIO读，但是Redis仍然会根据负载时不时跳过使用它。</li>
</ul>
<h1 id="性能测试">性能测试</h1>
<p>我们编译了unstable版本的Redis进行性能测试，测试工具为Redis自带的redis-benchmark，统计输出的RPS值作为参考。</p>
<pre tabindex="0"><code>Server实例: AWS / m5.2xlarge / 8 vCPU / 32 GB
Benchmark Client实例: AWS / m5.2xlarge / 8 vCPU / 32 GB
Command: redis-benchmark -h 172.xx.xx.62 -p 6379 -c 100 -d 256 -t get,set -n 10000000 --threads 8

</code></pre><h2 id="threaded-io-off-vs-threaded-io-on">Threaded I/O off vs. Threaded I/O on</h2>
<p>我们对比了原有的单线程I/O以及开启2线程/4线程的Threaded I/O时的表现，结果如图所示。</p>
<p><img src="../2020/09/redis_tio_performance-945x1024.png" alt="">
在开启<code>io-threads-do-reads</code>选项的情况下，Threaded I/O作用于读操作，也能让性能有进一步提升，但是没有将写I/O线程化提升明显。另外我们还尝试使用了大体积Payload（<code>-d 8192</code>）进行测试，得出结果的提升百分比并没有太大差异。</p>
<h2 id="threaded-io-vs-redis-cluster">Threaded I/O vs. Redis Cluster</h2>
<p>以往开发者会通过在单台实例上部署Redis Cluster来尝试让Redis使用上更多的CPU资源，我们也尝试对比了一下这种情景下的表现。</p>
<p><img src="../2020/09/redis_tio_vs_cluster-1024x683.png" alt="">
在新版本中，redis-benchmark也得到了更新，开始支持对Redis Cluster的测试，通过开启<code>--cluster</code>参数即可检测集群模式和配置。我们在这一组对比测试中看到单实例构建集群的强大性能，在实际测试中，3个进程的CPU使用率均在80%-90%，说明仍有提升的空间。当改用测试参数<code>-c 512</code>时，集群能够跑出超过40万RPS的成绩。尽管测试与实际使用会有所区别，并且我们在构建集群的时候选择了不附带Slave，但是仍然能看出来在几种模型中，构建Cluster能真正使用上多线程进行网络I/O、命令执行，对性能的提升也是最大的。</p>
<h1 id="总结与思考">总结与思考</h1>
<p>Redis 6.0引入的Threaded I/O，将Socket读写延迟和线程化，在网络I/O的方向上给Redis带来了一定的性能提升，并且使用门槛比较低，用户无需做太多的变更，即可在不影响业务的情况下白嫖空闲的线程资源。</p>
<p>另一方面，从测试结果上看，这部分的提升可能还难以让处于Redis 5甚至Redis 3版本的用户有足够的动力进行升级，特别是考虑到很多业务场景中Redis的性能并没有差到成为瓶颈，而且新版本的福利也未经过大规模验证，势必会影响到企业级应用中更多用户关注的服务稳定性。同时，TIO的提升对比集群性能似乎还有一定的差距，这可能更加会让原本就处于集群架构的企业用户忽略这个功能。</p>
<p>但无论如何，用户肯定乐于见到更多的新功能、更多优化提升出现在Redis上。在保持一贯稳定性的前提下，本次的版本可以说是Redis从诞生至今最大的更新，不只有Threaded I/O，包括RESP3、ACLs和SSL，我们期待这些新Feature能够在更多的应用场景下得到推广、验证和使用，也希望未来的版本能够给用户带来更多的惊喜和更好的体验。</p>
<h1 id="further-reading-understanding-redis">Further Reading: Understanding Redis</h1>
<p>作为一位从来没有使用过C/类C语言的开发者，Redis简洁的代码和详尽的注释为我阅读和理解其实现提供了极大的帮助。在文末我想要分享一下自己学习Reids的一些途径、工具和方法。</p>
<p><code>README.md</code>应该是我们了解Redis的入口，而不是全局搜索<code>main()</code>方法。请关注<code>Redis internals</code>小节下的内容，这里介绍了Redis的代码结构，Redis每个文件都是一个“general idea”，其中<code>server.c</code>和<code>network.c</code>的部分逻辑和代码在本文已经介绍过了，持久化相关的<code>aof.c</code>和<code>rdb.c</code>、数据库相关的<code>db.c</code>、Redis对象相关的<code>object.c</code>、复制相关的<code>replication.c</code>等都值得留意。其他包括Redis的命令是以什么样的形式编码的，也能在<code>README.md</code>中找到答案，这样可以方便我们进一步阅读代码时快速定位。</p>
<p><a href="https://redis.io/documentation">Documentation主页</a>和<a href="https://github.com/redis/redis-doc">redis-doc repo</a>是Redis文档的集合处，请注意后者的<code>topics</code>目录下有非常多有趣的主题，我对“有趣”的定义是像这样的文章：</p>
<ul>
<li><a href="https://github.com/redis/redis-doc/blob/master/topics/cluster-spec.md">Redis Cluster Specification</a></li>
<li><a href="https://github.com/redis/redis-doc/blob/master/topics/cluster-spec.md">Redis server-assisted client side caching</a></li>
</ul>
<p>作为开发者，在深入学习的阶段，这些内容能让大家从“使用”变为“了解”，然后发现Redis原来能做更多的事情。所以如果缺乏时间阅读和调试源码，将<code>topics</code>下的60多篇文档看一遍，大概是了解Redis最快的方法。</p>
<p>最后，如果你能看到这里，大概也会对Redis的源码有那么一点兴趣。因为本身并不了解C语言，所以我大概率会选择借助一个IDE，在<code>main()</code>打上断点，然后流程的起点开始看，实际上我也确实是这么做的。另外几个代码的关键点，其实也在本文中出现过：</p>
<ul>
<li><code>main()</code>，起点</li>
<li><code>initServer()</code>，初始化</li>
<li><code>aeMain()</code>，事件循环</li>
<li><code>readQueryFromClient()</code>，读事件的Handler</li>
<li><code>processInputBuffer()</code>，命令处理的入口</li>
</ul>
<p>如果像本文一样想了解Network的内容，可以在<code>aeMain()</code>处打断点，然后关注中<code>network.c</code>中的方法；如果想关注具体命令相关的内容，可以在<code>processInputBuffer()</code>处打断点，然后关注<code>$command.c</code>或者类似文件中的方法，<code>README.md</code>文件里也已经介绍过命令方法的命名格式，定位非常容易。其余经常出现的其他动作，例如持久化、复制等，大概会出现在命令执行的前后，或者时间事件内，也可能在<code>beforeSleep()</code>中。<code>server.h</code>中定义的<code>redisServer</code>和<code>client</code>是Redis中两个非常重要的结构，在业务上很多内容都是转化为对它们的属性的相关操作，要特别留意。</p>
<p>除此以外，Antirez曾经在<a href="https://www.youtube.com/user/antirez">Youtube</a>上发布过一些开发的录播视频，<a href="https://www.youtube.com/c/Redislabs/videos">RedisLab</a>则有一些相对冷门使用场景的实践介绍，这些会比上面的其他学习来得更轻松些，最大的难处可能就是听懂演讲者们的口音，特别是Antirez本人，万幸Youtube的字幕功能非常强大，能解决不少麻烦。</p>
]]></content>
		</item>
		
		<item>
			<title>我的Join查询是如何得出结果的？</title>
			<link>https://jiekun.dev/posts/join-algorithm/</link>
			<pubDate>Sat, 08 Aug 2020 08:54:53 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/join-algorithm/</guid>
			<description>Join Algorithms 在需要连接多表数据时，我们通常会使用到JOIN操作。 Nested Loop Join Basic Nested Loop Join 假设现在有两个关系对集合，R和S，我们需要将它连接起来，连接通过一定的</description>
			<content type="html"><![CDATA[<h1 id="join-algorithms">Join Algorithms</h1>
<p>在需要连接多表数据时，我们通常会使用到<code>JOIN</code>操作。</p>
<h1 id="nested-loop-join">Nested Loop Join</h1>
<h2 id="basic-nested-loop-join">Basic Nested Loop Join</h2>
<p>假设现在有两个关系对集合，<code>R</code>和<code>S</code>，我们需要将它连接起来，连接通过一定的条件来指定，这个条件我们称为<strong>Join Predicate</strong>，即连接谓词:</p>
<pre tabindex="0"><code>JP(r, s) := r.x == s.x
</code></pre><p>这个连接谓词表明<code>R</code>与<code>S</code>依靠字段<code>x</code>相等作为条件进行连接，当满足条件时，<code>JP(r, s)</code>返回为<code>True</code>，否则为<code>False</code>。</p>
<p>下面用伪代码表述<strong>Nested Loop Join</strong>的处理过程：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># R</span>
<span class="c1"># S</span>
<span class="c1"># JP(r, s) := r.x == s.x</span>

<span class="k">def</span> <span class="nf">nested_loop_join</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">JP</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">R</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">S</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">JP</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
                <span class="n">outupt</span><span class="p">((</span><span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
</code></pre></div><p>可以看出Nested Loop Join的处理过程即是两个关系对集合<code>R</code>与<code>S</code>的求<strong>Cross Product</strong>过程，因此若<code>R</code>中有n个关系对，<code>S</code>中有m个关系对，他们的处理复杂度即为<code>O(m * n)</code>。</p>
<p><strong>Nested Loop Join</strong>的优势在于它不仅可以在等值连接（EquiJoin）中使用，还可以处理其他非等值连接：</p>
<ul>
<li>在NLJ中无需关注判定式<code>JP(r, s)</code>的实现</li>
<li>对于非等值连接，只判定式内部实现对应<strong>Join Predicate</strong>即可，外层循环无感知。如：<code>JP(r, s) := r.x &lt;= s.x</code></li>
</ul>
<h2 id="indexed-nested-loop-join">Indexed Nested Loop Join</h2>
<p>现在输入的情况稍作改变，我们不仅有<code>R</code>、<code>S</code>和连接谓词<code>JP(r, s)</code>，还知道在其中一个关系集合，无论是<code>R</code>还是<code>S</code>，的连接谓词的列<code>x</code>上有对应的索引：</p>
<pre tabindex="0"><code>IndexOnRX := catelog.get(indexes, R.x)
</code></pre><p><code>IndexOnRX</code>现在可以视为一个<code>R</code>上<code>x</code>列的索引查询方法，它可以接收查询值，并且返回一个集合，代表集合中的元素存在于<code>R</code>中。</p>
<p>下面用伪代码表述<strong>Indexed Nested Loop Join</strong>的处理过程：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># S</span>
<span class="c1"># JP(r, s)</span>
<span class="c1"># IndexOnRX</span>

<span class="k">def</span> <span class="nf">indexed_nested_loop_join</span><span class="p">(</span><span class="n">IndexOnRX</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">JP</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">S</span><span class="p">:</span>
        <span class="n">query_result_set</span> <span class="o">=</span> <span class="n">IndexOnRX</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">query_result_set</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output</span><span class="p">({</span><span class="n">s</span><span class="p">}</span> <span class="o">*</span> <span class="n">query_result_set</span><span class="p">)</span>
</code></pre></div><p>与NLJ不同，INLJ通过遍历其中1个关系对集合S，使用对应的索引查询得到另一个查询集合<strong>R的子集</strong>，如果有符合的case，将<code>{s} * query_result_set</code>结果追加到最后输出的集合中。因此在INLJ中，因为只遍历了其中一个关系对集合，查询复杂度可以视为<code>O(n)</code>。</p>
<h1 id="hash-join">Hash Join</h1>
<p>现在我们同样有两个关系对集合<code>R</code>和<code>S</code>，一个连接谓词<code>JP(r, s) := r.x == s.x</code>。
下面用伪代码来表述<strong>Simple Hash Join</strong>的处理过程：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># R</span>
<span class="c1"># S</span>
<span class="c1"># JP(r, s) := r.x == s.x</span>

<span class="k">def</span> <span class="nf">simple_hash_join</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">JP</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">)):</span>
    <span class="n">indexOnRX</span> <span class="o">:=</span> <span class="n">build_ht</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">S</span><span class="p">:</span>
        <span class="n">query_result_set</span> <span class="o">=</span> <span class="n">IndexOnRS</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">query_result_set</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output</span><span class="p">({</span><span class="n">s</span><span class="p">}</span> <span class="o">*</span> <span class="n">query_result_set</span><span class="p">)</span>
</code></pre></div><p>可以看出在循环和判定上，SHJ和INLJ非常相似，最大的区别在于SHJ使用了一个临时生成的Hash内存表作为<code>IndexOnRS</code>依据。由于使用Hash Table，因此SHJ相比之前的NLJ而言缺少了非等值查询的支持。同时在查询复杂度上，SHJ先遍历其中一个关系对集合生成HT，再遍历另一个关系对进行判定，因此为<code>O(m + n)</code></p>
<h1 id="sort-merge-join">Sort-Merge Join</h1>
<p>现在我们有两张表<code>Customer</code>和<code>City</code>，我们需要通过<code>Join</code>操作获取每个customer所在的city。</p>
<table>
<thead>
<tr>
<th>name</th>
<th>street</th>
<th>cityID</th>
<th></th>
<th></th>
<th></th>
<th>cityID</th>
<th>city</th>
</tr>
</thead>
<tbody>
<tr>
<td>n1</td>
<td>s1</td>
<td>0</td>
<td></td>
<td></td>
<td></td>
<td>0</td>
<td>A</td>
</tr>
<tr>
<td>n2</td>
<td>s2</td>
<td>0</td>
<td></td>
<td></td>
<td></td>
<td>1</td>
<td>B</td>
</tr>
<tr>
<td>n3</td>
<td>s3</td>
<td>0</td>
<td></td>
<td></td>
<td></td>
<td>3</td>
<td>C</td>
</tr>
<tr>
<td>n4</td>
<td>s4</td>
<td>1</td>
<td></td>
<td></td>
<td></td>
<td>5</td>
<td>D</td>
</tr>
<tr>
<td>n5</td>
<td>s5</td>
<td>1</td>
<td></td>
<td></td>
<td></td>
<td>7</td>
<td>E</td>
</tr>
<tr>
<td>n6</td>
<td>s6</td>
<td>5</td>
<td></td>
<td></td>
<td></td>
<td>9</td>
<td>F</td>
</tr>
<tr>
<td>n7</td>
<td>s7</td>
<td>5</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>n8</td>
<td>s8</td>
<td>7</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>n9</td>
<td>s9</td>
<td>9</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>n10</td>
<td>s10</td>
<td>9</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>n11</td>
<td>s11</td>
<td>9</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>我们按照以下原则进行<strong>Merge Join</strong>：</p>
<ul>
<li>使用两个指针，分别指向两表的<code>cityID</code>字段</li>
<li>当指针对应的值相等时，output一行结果</li>
<li>指针需要移动至下一行时，优先移动当前指向值较小的指针，若值相等时优先移动指向<code>Customer</code>表的指针</li>
</ul>
<p>输出结果为：</p>
<table>
<thead>
<tr>
<th>name</th>
<th>street</th>
<th>cityID</th>
<th>city</th>
</tr>
</thead>
<tbody>
<tr>
<td>n1</td>
<td>s1</td>
<td>0</td>
<td>A</td>
</tr>
<tr>
<td>n2</td>
<td>s2</td>
<td>0</td>
<td>A</td>
</tr>
<tr>
<td>n3</td>
<td>s3</td>
<td>0</td>
<td>A</td>
</tr>
<tr>
<td>n4</td>
<td>s4</td>
<td>1</td>
<td>B</td>
</tr>
<tr>
<td>n5</td>
<td>s5</td>
<td>1</td>
<td>B</td>
</tr>
<tr>
<td>n6</td>
<td>s6</td>
<td>5</td>
<td>D</td>
</tr>
<tr>
<td>n7</td>
<td>s7</td>
<td>5</td>
<td>D</td>
</tr>
<tr>
<td>n8</td>
<td>s8</td>
<td>7</td>
<td>E</td>
</tr>
<tr>
<td>n9</td>
<td>s9</td>
<td>9</td>
<td>F</td>
</tr>
<tr>
<td>n10</td>
<td>s10</td>
<td>9</td>
<td>F</td>
</tr>
<tr>
<td>n11</td>
<td>s11</td>
<td>9</td>
<td>F</td>
</tr>
</tbody>
</table>
<p>注意到这种Merge操作的前提是两表的连接谓词所在字段必须是排序的，因此这种连接算法称为<strong>Sort-Merge Join</strong>。</p>
<p>根据以上条件写出伪代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># R</span>
<span class="c1"># S</span>
<span class="c1"># JP(r, s)</span>

<span class="k">def</span> <span class="nf">sort_merge_join</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">JP</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">)):</span>
    <span class="n">sort</span><span class="p">(</span><span class="n">R</span> <span class="n">on</span> <span class="n">R</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
    <span class="n">sort</span><span class="p">(</span><span class="n">S</span> <span class="n">on</span> <span class="n">S</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
    <span class="n">pointer_r</span> <span class="o">=</span> <span class="n">R</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">pointer_s</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">while</span> <span class="n">pointer_r</span> <span class="o">!=</span> <span class="n">R</span><span class="o">.</span><span class="n">end</span> <span class="ow">and</span> <span class="n">pointer_s</span> <span class="o">!=</span> <span class="n">S</span><span class="o">.</span><span class="n">end</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pointer_r</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="n">pointer_s</span><span class="o">.</span><span class="n">x</span><span class="p">:</span>
            <span class="n">output</span><span class="p">((</span><span class="n">pointer_r</span><span class="p">,</span> <span class="n">pointer_s</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">pointer_r</span><span class="o">.</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="n">pointer_s</span><span class="o">.</span><span class="n">x</span><span class="p">:</span>
            <span class="n">pointer_r</span><span class="o">++</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pointer_s</span><span class="o">++</span>

    <span class="c1"># handle rest row here</span>
</code></pre></div><p>要注意如果将<code>Customer</code>表与<code>City</code>表位置互换，并且保持优先移动左表(<code>City</code>)表指针，我们输出的结果将会是不正确的。</p>
<p>另外，如果两表的排序字段都不是主键或唯一，输出的结果也会有遗漏的case。</p>
<p>因此，<strong>Sort-Merge Join</strong>算法有必须满足的前提条件：</p>
<ul>
<li>Join字段在其中一个表中必须唯一</li>
<li>保持优先移动ref表（即Join字段非唯一的表）</li>
</ul>
<p>最后估算查询复杂度，需要先进行排序，为<code>O(nlogn)</code>的复杂度，然后双指针遍历两表为<code>O(m+n)</code>的复杂度。</p>
<h1 id="hash-join-implementation-in-mysql">Hash Join Implementation in MySQL</h1>
<h2 id="in-memory-hash-join">In-memory Hash Join</h2>
<p>经典HJ算法包含两个阶段：</p>
<ul>
<li>build phase：指定两个需要Join的表其中之一为&quot;build&quot;表，读入内存中的Hash Table中，其中Hash值以EquiJoin的字段计算。</li>
<li>probe phase：另一个表作为Probe输入，当build阶段结束后，逐行读取Probe表，同样以Join的字段计算该行的Hash值，并在内存中的HT中进行查找，对于每个命中的匹配，输出一行Join结果。</li>
</ul>
<p>这种方案要求&quot;build&quot;输入可以被完整加载进内存，如果不行，可以通过以下方式来解决：</p>
<ul>
<li>从&quot;build&quot;表读取尽可能多的行数加载进内存</li>
<li>遍历整个&quot;probe&quot;表，输出匹配结果</li>
<li>清理In-memory的HT</li>
<li>继续读取&quot;build&quot;表的下一部分，重复操作</li>
</ul>
<p>这种方式缺点在于我们需要多次读&quot;probe&quot;表，所以不是理想的解决方案。因此我们还有On-disk的HJ方案。</p>
<h2 id="on-disk-hash-join">On-disk Hash Join</h2>
<p>On-disk HJ将两表都进行分块(partitioning)，并且要让每个块都可以完整加载进内存的HT中。分块同样由一个Hash Function计算Join列的Hash值来决定。分块完毕后，加载&quot;build&quot;表的第一个块进内存，并且遍历&quot;probe&quot;表的第一个块进行匹配。由于都是通过相同的Hash Function计算结果进行分块，我们可以知道Hash值相同的行肯定会落入同一块中。</p>
<p>注意这里要使用不同的Hash Function来计算分块用的Hash值与匹配用的Hash值，否则要么我们会得到很差的分块结果，要么会得到很差的HT。</p>
<p>当第一对的分块处理完后，清理内存中的HT缓存，继续加载后续的分块文件，遍历对应的&quot;probe&quot;块进行匹配，直到所有的分块处理完毕。</p>
<p>如果我们的数据集是非常不均匀的，某些&quot;build&quot;块可能就会放不进内存中，这种情况下，我们在In-memory Hash Join中介绍的逐段读取进内存，并多次扫&quot;probe&quot;块的思路就会被使用到，尽管它并不是最理想的方案。</p>
<h1 id="conclusion">Conclusion</h1>
<p>Join操作使用的基础算法：</p>
<ul>
<li>Nested Loop Join，可以视为两表相乘，嵌套循环逐行检查是否满足Join条件</li>
<li>Indexed Nested Loop Join，遍历部分表，并用遍历结果作为索引查询条件，借助索引查询</li>
<li>Hash Join，可以视为INLJ的特殊情况，区别在于Hash Join使用现有或临时生成的Hash值作为索引，此时不支持非等值连接</li>
<li>Sort-Merge Join，限定条件比较多，先根据Join字段排序，再合并两表，同样不支持非等值连接，否则会退化为NLJ</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>InnoDB中的B树与分裂</title>
			<link>https://jiekun.dev/posts/b_tree_page_split/</link>
			<pubDate>Wed, 05 Aug 2020 12:58:10 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/b_tree_page_split/</guid>
			<description>Tree Binary Search Tree 在二叉查找树中，左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。 6 / \ 3 7 / \ \ 2 5 8 利用这棵二叉树对各个节点进行查找，</description>
			<content type="html"><![CDATA[<h1 id="tree">Tree</h1>
<h2 id="binary-search-tree">Binary Search Tree</h2>
<p>在二叉查找树中，左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。</p>
<pre tabindex="0"><code>        6
       / \
      3   7
     / \   \
    2   5   8
</code></pre><p>利用这棵二叉树对各个节点进行查找，平均查找次数为<code>(1+2+3+3+2+3) / 6 = 2.3</code>次，比起[2，3，5，6，7，8]顺序查找次数<code>(1+2+3+4+5+6) / 6 = 3.3</code>次要少。</p>
<p>二叉查找树还可以这样构建：</p>
<pre tabindex="0"><code>    2
     \
      3
       \
        5
         \
          6
           \
            7
             \
              8
</code></pre><p>这时查找的平均次数退化为顺序查找次数。</p>
<p>因此如果想高性能地构造一棵二叉查找树，需要这棵二叉查找树是<strong>平衡</strong>的。</p>
<h2 id="balance-tree">Balance Tree</h2>
<p>平衡二叉树符合二叉查找树的定义，并且满足任何节点的两个子树高度最大差为1。</p>
<pre tabindex="0"><code>        6                     6
       / \                  /   \
      3   7                3     8
     / \   \              / \   / \
    2   5   8            2   5 7   9
             \
              9
</code></pre><p>在插入新节点后，平衡二叉树节点7的左右子树高度差为2，需要通过一次左旋操作来让树重新保持平衡。</p>
<p>但是有的情况可能需要旋转多次才能达到平衡。</p>
<pre tabindex="0"><code>      2             2             2               4    
     / \           / \           / \             / \   
    1   5         1   5         1   4           2   5  
       / \           / \           / \         / \   \ 
      4   9         4   9         3   5       1   3   9
                   /                   \                  
                  3                     9                 
</code></pre><p>除了插入操作，还有更新和删除操作都会导致平衡树需要进行旋转。因此维护一棵平衡树是有一定开销的。</p>
<h1 id="b-tree">B+ Tree</h1>
<p>B+树是：</p>
<ul>
<li>一棵n叉树(m-ary)</li>
<li>记录节点按照键值大小顺序存放在同一层叶子节点上，各叶子节点指针进行连接</li>
</ul>
<h2 id="b-tree插入操作">B+ Tree插入操作</h2>
<ul>
<li>Leaf Page未满、Index Page未满时，直接将记录插入到叶子节点</li>
<li>Leaf Page满、Index Page未满时，拆分Leaf Page，将中间的节点（指的是Leaf Page几个节点的中间）放入到Index Page中，小于中间节点的记录放左边，大于中间节点的记录放右边</li>
<li>Leaf Page满、Index Page满时，拆分Leaf Page，小于中间节点的记录放左边，大于中间节点的记录放右边；拆分Index Page，原理同上，此时树的高度+1</li>
</ul>
<h2 id="b-tree删除操作">B+ Tree删除操作</h2>
<ul>
<li>Leaf Page大于填充因子、Index Page大于填充因子，直接删除，如果该节点是Index Page节点，用该节点的右节点代替</li>
<li>Leaf Page小于填充因子、Index Page大于填充因子，合并Leaf Page和它的兄弟节点，同时更新Index Page</li>
<li>Leaf Page小于填充因子、Index Page小于填充因子，合并Leaf Page和它的兄弟节点，更新Index Page，合并Index Page和它的兄弟节点</li>
</ul>
<h2 id="示例">示例</h2>
<p>一棵高度为2，扇出值为5的B+树：</p>
<p><img src="../2020/08/1.jpg" alt="">
插入键值<code>28</code>，Leaf Page和Index Page都没满，直接插入：</p>
<p><img src="../2020/08/2.jpg" alt="">
插入键值<code>70</code>发现Leaf Page已满，这时页的键为<code>[50, 55, 60, 65, 70]</code>，中间值为<code>60</code>，则根据<code>60</code>来<strong>拆分</strong>叶子节点，并且将<code>60</code>放入Index Page中：</p>
<p><img src="../2020/08/3.jpg" alt="">
插入键值<code>95</code>，此时Leaf Page和Index Page都已满，Leaf Page为<code>[75, 80, 85, 90, 95]</code>，按照<code>85</code>拆分，并将<code>85</code>放入Index Page；Index Page为<code>[25, 50, 60, 75, 85]</code>，按照<code>60</code>拆分，并将<code>60</code>放入新的Index Page：</p>
<p><img src="../2020/08/4.jpg" alt="">
Rotation操作，Leaf Page已满但是左右兄弟节点没有满的情况下，不急于做拆分页的操作，将记录移到所在页的兄弟节点上。插入键值<code>70</code>时因为左Leaf Page未满，进行Rotation，<code>50</code>被Rotate到左页，<code>55</code>被Rotate上Index Page：</p>
<p><img src="../2020/08/5.jpg" alt="">
删除键值<code>70</code>，删除后Fill Factor大于50%，直接删除：</p>
<p><img src="../2020/08/6.jpg" alt="">
删除键值<code>25</code>，直接删除，但是<code>25</code>还是Index Page中的值，因此要将右侧键值<code>28</code>更新到Index Page：</p>
<p><img src="../2020/08/7.jpg" alt="">
删除键值<code>60</code>，删除后Fill Factor小于50%，发生<strong>合并</strong>操作，所在Leaf Page与左侧合并，并且更新Index Page，树高度降低：</p>
<p><img src="../2020/08/8.jpg" alt=""></p>
<h1 id="b-tree索引">B+ Tree索引</h1>
<p>B+树索引是B+树中数据库中的实现，具有高扇出性(fanout)，通常扇出值在100以上。</p>
<p>B+树索引的节点在逻辑上是顺序存储的，但是在物理上因为分裂和合并的缘故，并不一定是连续的。从根节点开始向下查找每次都是随机IO。B+树因为高扇出性，高度一般在2-4层，也就是说从根节点开始查找到对应的叶子节点<strong>最多</strong>需要2-4次随机IO。又由于B+树索引的上层是常驻内存的，因此通常只需要更少次的随机IO即可定位到目标的叶子节点。</p>
<p>页是B+树索引磁盘管理的最小单位，在查询某行数据时，需要加载行所在的页到缓冲区再在页内Fetch目标行。</p>
<h2 id="b-tree索引的分裂">B+ Tree索引的分裂</h2>
<p>考虑以下情况，如果页内存储的键值为<code>[1, 2, 3, 4, 5, 6, 7, 8]</code>，如果新增键值<code>9</code>时页满需要发生分裂，按照之前介绍的分裂方法，取<code>5</code>为分裂点，页分裂成<code>[1, 2, 3, 4]</code>和<code>[5, 6, 7, 8, 9]</code>两个页。如果后续的写入操作均为顺序写入，那么页<code>[1, 2, 3, 4]</code>就会永远填充不满，剩余的页同理，因此会导致页空间的浪费。</p>
<p>所以，B+树索引的分裂并不总是从页的中间记录开始。在InnoDB引擎的Page Header中，有以下部分用来保存插入的顺序信息：</p>
<ul>
<li><code>PAGE_LAST_INSERT</code>，记录上一次写入位置的指针</li>
<li><code>PAGE_DIRECTION</code>， 值为<code>PAGE_LEFT</code>、<code>PAGE_RIGHT</code>和<code>PAGE_NO_DIRECTION</code>之一</li>
<li><code>PAGE_N_DIRECTION</code>，表示连续向同一方向插入的数量</li>
</ul>
<p>通过这些信息，InnoDB引擎可以决定要向左还是向右分裂，分裂点记录为哪一个：</p>
<ul>
<li>在随机插入的情况下，取页中间记录作为分裂点的记录</li>
<li>在定位到插入记录的位置后，如果已经向同一方向插入记录数量为5，并且当前位置后还有3条记录，则分裂点的记录定位到当前位置后到第三条记录，否则分裂点就是当前待插入的记录</li>
</ul>
<p>向右分裂的示例：</p>
<p><img src="../2020/08/9.jpg" alt=""></p>
<h2 id="b-tree索引的管理">B+ Tree索引的管理</h2>
<p>通过<code>show index</code>命令可以查看表的索引情况：</p>
<pre tabindex="0"><code>mysql&gt; show index from a_real_secret_table_for_testing_000087\G
*************************** 1. row ***************************
        Table: a_real_secret_table_for_testing_000087         -- 索引所在表名
   Non_unique: 0                                              -- 是否唯一
     Key_name: PRIMARY                                        -- 索引名
 Seq_in_index: 1                                              -- 该列在索引中的顺序
  Column_name: id                                             -- 列名
    Collation: A                                              -- 列以什么方式存储在索引中，A：排序的
  Cardinality: 1637220                                        -- 索引中唯一值的数目的估计值
     Sub_part: NULL                                           -- 是否是列的部分被索引，如100即该列前100字符被索引
       Packed: NULL                                           -- 关键字如何被压缩
         Null:                                                -- 是否索引列含有NULL值
   Index_type: BTREE                                          -- 索引类型，InnoDB均为BTREE
      Comment:
Index_comment:

</code></pre><h2 id="cardinality值">Cardinality值</h2>
<p>Cardinality值与表的行数比应该尽可能接近1，否则说明这个索引列选择性小，可能需要考虑是否删除此索引，例如在用户表中的性别等。</p>
<p>Cardinality值非常关键，优化器会根据这个值来判断是否使用这个索引。它代表索引中唯一值的数目的估计值，因此真实值在每次<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>操作时都会改变，InnoDB不可能在每次写操作时都更新该值，因为这样做代价太大了，所以Cardinality是一个估计值，如果需要更新Cardinality信息，可以使用<code>ANALYZE TABLE</code>命令。</p>
<p>在InnoDB中，更新Cardinality值的策略为：</p>
<ul>
<li>表中1/16的数据已经发生过变化</li>
<li>stat_modified_counter &gt; 2,000,000,000</li>
</ul>
<p>在满足更新条件的情况下，InnoDB通过采样的方法统计Cardinality值：</p>
<ul>
<li>取得B+树索引中叶子节点的数量，记为P</li>
<li>随机取所有叶子节点中的8（默认，<code>innodb_stats_sample_pages</code>配置）个叶子节点，统计每个页不同值的个数，记为N0, N1, &hellip; ,N7</li>
<li>Cardinality预估值 = (N0 + N1 + &hellip; + N7) / 8 * P</li>
</ul>
<p>因此，Cardinality不是一个精确值，同时，即使没有数据改动，每次统计得到的值也可能会不同。</p>
<h2 id="online-schema-change">Online Schema Change</h2>
<p>在MySQL 5.5版本前，对索引的增删改这类DDL操作，MySQL的操作过程为：</p>
<ul>
<li>创建一张新的临时表，表结构为<code>ALTER</code>命令定义的新结构</li>
<li>将原表数据导入临时表</li>
<li>删除原表</li>
<li>临时表重命名为原表</li>
</ul>
<p>这意味着在对大表的索引进行添加删除操作时会需要很长时间，并且服务会对其他事务不可用。</p>
<p>Facebook用PHP脚本实现OSC：</p>
<ul>
<li>init，验证表的主键、触发器、外键等是否满足</li>
<li>createCopyTable，创建和原始表结构一样的新表</li>
<li>alterCopyTable，对新表进行<code>ALTER</code>操作，如添加索引或列</li>
<li>createDeltasTable，创建<code>deltas</code>表</li>
<li>createTriggers，对原表创建<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>操作对触发器，触发操作产生的记录会被写到<code>deltas</code>表</li>
<li>startSnpshotXact，开始OSC操作的事务</li>
<li>seletTableIntoOutfile，将原表中的数据写入外部文件</li>
<li>dropNCIndexs，导入数据到新表前，删除新表中的所有辅助索引</li>
<li>loadCopyTable，将导出的文件导入到新表</li>
<li>replayChanges，将OSC过程中原表的DML操作（保存在<code>deltas</code>表）的记录应用到新表中</li>
<li>recreateNCIndexes，重新创建辅助索引</li>
<li>replayChanges，再次进行DML日志的回放操作，这些操作是在重建辅助索引时产生的</li>
<li>swapTables，原子的<code>RENAME</code>操作互换新旧表名</li>
</ul>
<h1 id="与页和b-tree相关的查询case">与页和B+ Tree相关的查询Case</h1>
<p>示例的查询会使用索引吗 / 会使用哪个索引 / 为什么？</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="c1">-- Table Schema
</span><span class="c1"></span><span class="k">create</span><span class="w"> </span><span class="k">table</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">  </span><span class="n">id</span><span class="w"> </span><span class="nb">int</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">null</span><span class="w"> </span><span class="n">auto_increment</span><span class="w"> </span><span class="k">comment</span><span class="w"> </span><span class="s2">&#34;unique id&#34;</span><span class="p">,</span><span class="w">
</span><span class="w">  </span><span class="n">a</span><span class="w"> </span><span class="nb">int</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">null</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">comment</span><span class="w"> </span><span class="s2">&#34;column a&#34;</span><span class="p">,</span><span class="w">
</span><span class="w">  </span><span class="n">b</span><span class="w"> </span><span class="nb">varchar</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">null</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w"> </span><span class="k">comment</span><span class="w"> </span><span class="s2">&#34;column b&#34;</span><span class="p">,</span><span class="w">
</span><span class="w">  </span><span class="k">c</span><span class="w"> </span><span class="nb">int</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="k">null</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">comment</span><span class="w"> </span><span class="s2">&#34;column c&#34;</span><span class="p">,</span><span class="w">
</span><span class="w">  </span><span class="k">primary</span><span class="w"> </span><span class="k">key</span><span class="w"> </span><span class="p">(</span><span class="n">id</span><span class="p">),</span><span class="w">
</span><span class="w">  </span><span class="k">key</span><span class="w"> </span><span class="n">idx_a</span><span class="p">(</span><span class="n">a</span><span class="p">),</span><span class="w">
</span><span class="w">  </span><span class="k">key</span><span class="w"> </span><span class="n">idx_a_b</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w">
</span><span class="w"></span><span class="p">)</span><span class="w"> </span><span class="k">comment</span><span class="w"> </span><span class="s2">&#34;test table for index decision&#34;</span><span class="p">;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">-- Table record count
</span><span class="c1"></span><span class="n">mysql</span><span class="o">&gt;</span><span class="w"> </span><span class="k">select</span><span class="w"> </span><span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">t</span><span class="p">;</span><span class="w">
</span><span class="w"></span><span class="o">+</span><span class="c1">----------+
</span><span class="c1"></span><span class="o">|</span><span class="w"> </span><span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">+</span><span class="c1">----------+
</span><span class="c1"></span><span class="o">|</span><span class="w">   </span><span class="mi">500000</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">+</span><span class="c1">----------+
</span><span class="c1"></span><span class="mi">1</span><span class="w"> </span><span class="k">row</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">02</span><span class="w"> </span><span class="n">sec</span><span class="p">)</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">-- Table data sample
</span><span class="c1"></span><span class="n">mysql</span><span class="o">&gt;</span><span class="w"> </span><span class="k">select</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="k">limit</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w">
</span><span class="w"></span><span class="o">+</span><span class="c1">----+----------+--------------------------------------------------------------+----------+
</span><span class="c1"></span><span class="o">|</span><span class="w"> </span><span class="n">id</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">a</span><span class="w">        </span><span class="o">|</span><span class="w"> </span><span class="n">b</span><span class="w">                                                            </span><span class="o">|</span><span class="w"> </span><span class="k">c</span><span class="w">        </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">+</span><span class="c1">----+----------+--------------------------------------------------------------+----------+
</span><span class="c1"></span><span class="o">|</span><span class="w">  </span><span class="mi">1</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">74050441</span><span class="w"> </span><span class="o">|</span><span class="w">                                                              </span><span class="o">|</span><span class="w"> </span><span class="mi">83633927</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">2</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">74330977</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">JayiceJayiceJayiceJayiceJayiceJayiceJayiceJayiceJayiceJayice</span><span class="w"> </span><span class="o">|</span><span class="w">  </span><span class="mi">1986453</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">3</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">90869050</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">JayiceJayiceJayice</span><span class="w">                                           </span><span class="o">|</span><span class="w"> </span><span class="mi">13026881</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">4</span><span class="w"> </span><span class="o">|</span><span class="w">  </span><span class="mi">6235189</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">JayiceJayiceJayiceJayiceJayiceJayiceJayice</span><span class="w">                   </span><span class="o">|</span><span class="w">  </span><span class="mi">6147585</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">5</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">29282553</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">JayiceJayiceJayiceJayice</span><span class="w">                                     </span><span class="o">|</span><span class="w"> </span><span class="mi">51497909</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">6</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">30223437</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">JayiceJayiceJayice</span><span class="w">                                           </span><span class="o">|</span><span class="w"> </span><span class="mi">28159699</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">7</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">37207514</span><span class="w"> </span><span class="o">|</span><span class="w">                                                              </span><span class="o">|</span><span class="w"> </span><span class="mi">71102047</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">8</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">76961456</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">JayiceJayiceJayiceJayiceJayiceJayice</span><span class="w">                         </span><span class="o">|</span><span class="w"> </span><span class="mi">17116481</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w">  </span><span class="mi">9</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">87737033</span><span class="w"> </span><span class="o">|</span><span class="w">                                                              </span><span class="o">|</span><span class="w"> </span><span class="mi">70935248</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">|</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="mi">67230439</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Jayice</span><span class="w">                                                       </span><span class="o">|</span><span class="w"> </span><span class="mi">99513787</span><span class="w"> </span><span class="o">|</span><span class="w">
</span><span class="w"></span><span class="o">+</span><span class="c1">----+----------+--------------------------------------------------------------+----------+
</span><span class="c1"></span><span class="mi">10</span><span class="w"> </span><span class="k">rows</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">01</span><span class="w"> </span><span class="n">sec</span><span class="p">)</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c1">-- Query
</span><span class="c1"></span><span class="k">explain</span><span class="w"> </span><span class="k">select</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="k">where</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="o">???</span><span class="p">;</span><span class="w">
</span><span class="w"></span><span class="k">explain</span><span class="w"> </span><span class="k">select</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="k">where</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="o">???</span><span class="p">;</span><span class="w">
</span></code></pre></div>]]></content>
		</item>
		
		<item>
			<title>Shopee面试复盘</title>
			<link>https://jiekun.dev/posts/2020-03-28-shopee%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/</link>
			<pubDate>Sat, 28 Mar 2020 09:14:35 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-03-28-shopee%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/</guid>
			<description>背景 了解到Shopee最初是在其他dalao的面经、V2EX上。因为2月份字节跳动的面试失利，而且结合2020年年初整体环境的情况，所以打算</description>
			<content type="html"><![CDATA[<h1 id="背景">背景</h1>
<p>了解到Shopee最初是在其他dalao的面经、V2EX上。因为2月份字节跳动的面试失利，而且结合2020年年初整体环境的情况，所以打算做个100 Day Countdown复习再尝试的，不过综合考虑觉得金三银四的机会错过可能就没有了，最后在三月初的时候找dalao内推了Shopee的岗位。同期在考虑的还有网易和360的一些岗位，网易在广州的主要是游戏岗，技术栈上Match的程度会相对低一些，而且了解到部分目标岗位入职之后貌似是以Python为主，而我目前做的也是Python开发，但是更倾向于接触Go和Go的生态（云原生），这个也是优先考虑Shopee机会的原因之一。</p>
<h1 id="面试">面试</h1>
<p>因为赶上春招，所以大概面试官们都比较忙，投递之后大约过了2周HR电话联系，约了一面时间。</p>
<h2 id="一面1小时17分钟">一面（1小时17分钟）</h2>
<p>一面我要求在了一个比较晚的时间，因为Shopee晚上是不面试的，所以定在了下午大概下班前一点的时候，然而没有想到一聊就聊了接近80分钟，结束的时候已经接近7点了。</p>
<ul>
<li>自我介绍</li>
<li>介绍基本的项目架构，问了Elasticsearch在项目中的用途</li>
<li>每日新增数据量*00w，不算少了，用MySQL怎么样做的？
<ul>
<li>看具体业务，例如新增这块是某些业务数据的快照，用作趋势图</li>
<li>新增数据多，分策略处理，按业务分区，定时归档到oss</li>
</ul>
</li>
<li>除去归档之后数据还有多大？以什么样的方式检索？
<ul>
<li>除去归档之后的量级在千万级</li>
<li>虽然有千万，但是根据业务查询做Partition，每个tablespace不大，使用xx作为主键，查询也按照主键，速度可以接受</li>
</ul>
</li>
<li>对Percona和它MySQL的分支了解多少？它改表的工具有看过吗？原理能说一下吗，改表过程中一致性如何保证？
<ul>
<li>Percona的工具一般都是运维在用，自己RSS了他们的博客，阅读和翻译感兴趣的文章</li>
<li>pt-osc，改表通过创建新表，复制旧表数据最后原子操作<code>RENAME</code>替换完成。（答得不在点子上，最重要的通过Trigger保障过程中的一致性没有提出来）</li>
</ul>
</li>
<li>有做过分享过BloomFilter，分享的原理还是应用？
<ul>
<li>Both</li>
<li>概率型过滤器，业务上用做去重判定，有在团队里面推广，目前在新业务上准备尝试</li>
<li>Redis中使用Bitmap实现，对判断内容Hash置位，如果对应位置都已经置位过说明元素可能存在，反之必然不存在</li>
</ul>
</li>
<li>用过Redis的哪些数据结构？redis-cell是什么？
<ul>
<li>除了基础的5种结构以外，还尝试过HyperLogLog，布隆过滤器，redis-cell，stream</li>
<li>redis-cell是一个外挂模块，漏斗模型限流</li>
</ul>
</li>
<li>有用过Redis的Cluster吗？了解原理吗？如果有节点挂了会怎么样？
<ul>
<li>业务使用Redis的部分数据量比较少所以用不上，自己有尝试过</li>
<li>基于槽分配，将集群划分成16384个槽，分配给不同节点，当所有槽分配完毕的时候集群上线</li>
<li>如果用官方工具创建类似典型的三主三从集群，主节点挂掉之后会自动有从节点顶上</li>
</ul>
</li>
<li>用Redis不同的数据结构都实现过什么业务？
<ul>
<li>HyperLogLog，和BloomFilter相似，场景为概率型的计数，例如超大量的每日访问IP数（PV），代替set类型</li>
<li>ZSET，做过排行榜</li>
<li>String，做日常缓存</li>
</ul>
</li>
<li>了解Redis HASH结构的实现吗？怎么保证查找的复杂度是O(1)？
<ul>
<li>底层是一个字典</li>
<li>Emmm…（场面一度尴尬，觉得很基础又一时说不上来，最后猜测是Hash之后通过内存地址查找所以是O(1)）不太了解</li>
</ul>
</li>
</ul>
<p>然后聊到这里附近的时候远程聊天网络原因断开了一下orz，多给了一点点思考的时间，虽然重连之后还是答得不太满意。</p>
<ul>
<li>有用过短域名服务吗，能说一下吗？
<ul>
<li>（简历上写了一个TinyURL系统架构设计的博客，不知道面试官是看到了所以对这方面感兴趣，还是这么凑巧他想问一个我设计过的架构）</li>
<li>方案：自增ID + Base62</li>
<li>细节：自增ID肯定是唯一的，问题在于如何保证在分布式系统中不同节点的自增ID没有重复，使用ZooKeeper提前对号段进行划分，应用节点自行获取和内部维护</li>
<li>比较：MD5、UUID、自增Base62，各有优势，使用HASH的方案需要考虑冲突问题，UUID太长</li>
</ul>
</li>
<li>大访问量的情况下这个业务怎么设计？
<ul>
<li>短链有失效时间吗？（一天内访问非常频繁，后面急剧下降）</li>
<li>那将生成的数据放到Cache中设置1天TTL，Cache不存在回MySQL查（这里有遗漏的点没有答好，场景下会产生大量的短链长链对应关系，数据量级也需要考虑和处理，不可能无限增长下去，面试官提问的时候有强调到，但是回答之后貌似刚好也和我一样漏掉了XD）</li>
</ul>
</li>
<li>如果要求长域名一样的时候对应短域名也一样怎么设计？
<ul>
<li>每次回表查关系，但是这样不理想</li>
<li>思路是判定的时候需要查询，那么就想办法降低查询次数，没出现过的URL肯定会对应新短链，那么结合BloomFilter判定是否曾经出现过，如果出现过再回表确认真的出现还是BloomFilter的误判</li>
</ul>
</li>
<li>有试过BloomFilter数据量比较大的时候占用Redis空间有多少吗？
<ul>
<li>很低，但是不知道具体数字（这里是个超级大坑，一面没有深究，二面的时候被追问细节，然而当初是想一二面一起复盘所以orz）</li>
</ul>
</li>
<li>业务已经很久，数据量大，需要做分表或者归档，会怎么做？
<ul>
<li>归档貌似不行，旧数据还是要可用</li>
<li>分表按照业务场景，查询是围绕短链ID，根据短链ID做hash分表而不是自增ID，这里视情况可能需要设计上用短链ID作为主键</li>
</ul>
</li>
<li>用Python里面的数据结构实现一个有序集合，思路
<ul>
<li>（答得不是很好，问到了讲的几个思路的复杂度的计算，自己打个50分不及格）</li>
<li>List + Dict（期望小于O(n)可以吗？）</li>
<li>…（求求自己回去多看看数据结构）</li>
<li>SkipList（真的不会，于是开始胡扯…）</li>
</ul>
</li>
<li>写SQL：找出A表存在，B表不存在的id
<ul>
<li>写了一个<code>NOT IN</code>，强调性能不佳</li>
<li>补充一个<code>LEFT JOIN WHERE IS NULL</code>的方案</li>
<li>小表驱动大表</li>
</ul>
</li>
<li>MySQL事务隔离级别？你们用的级别？可重复读是什么意思？
<ul>
<li>4个</li>
<li>可重复读</li>
<li>解释了一下Read Commited里面不可重复读的场景，可重复读解决了这种问题，但是会存在幻读问题;强调InnoDB中使用Next-Key Locking，在Repeatable Read中就已经解决了幻读问题，解释了一下Gap Lock和Record Lock</li>
</ul>
</li>
<li>了解乐观锁与悲观锁吗？
<ul>
<li>描述了一下以及讲一下怎么使用乐观锁</li>
</ul>
</li>
<li>了解InnoDB的索引实现？B+树和B树有什么区别？
<ul>
<li>B+树</li>
<li>高扇出性，层数少、叶子节点带指针、B+树数据全部在叶子节点，B树索引节点也存数据</li>
</ul>
</li>
<li>SQL题：哪个SQL能用上全部索引</li>
<li>都是在用Python是吗？还会其他语言吗？
<ul>
<li>读书的时候写PHP，现在在学Go</li>
</ul>
</li>
<li>对Python装饰器的理解？
<ul>
<li>（写了3行代码表达装饰器是对方法进行前置处理和后处理的夹心饼结构）</li>
<li>-（更好的表达应该是强调将被装饰对象作为参数传递，因为它是First Class Object，同时执行前后进行额外的逻辑，最后返回）</li>
</ul>
</li>
<li>写了一小段代码，问如何调用装饰器内部的定义的方法</li>
<li>写了一小段闭包的代码，问执行结果
<ul>
<li>答了一个错误的执行结果和正确的闭包概念</li>
<li>（我确认我是清晰理解了闭包的概念，但是思考的时候多操了一份心，又考虑了一些mutable object和immutable object的事情，结果就答错了结果，气坏了）</li>
</ul>
</li>
<li>Python的functools和itertools有用过什么吗？Collections用到什么？
<ul>
<li>有用过，但是一时想不起来里面的方法/对象了，经常用Collections</li>
<li>用到defaultdict、OrderedDict、Counter等等</li>
</ul>
</li>
<li>进程与线程</li>
<li>Python的多线程可以用到多核，一般多线程用来做什么，多线程多进程用的什么库？</li>
<li>了解HTTPS加密过程吗？讲一下握手的过程</li>
<li>浏览器的缓存了解多少？自己建站静态文件会加缓存吗？</li>
<li>编程题：Word Break和翻转二叉树</li>
<li>有什么问题想问吗？
<ul>
<li>对我的建议</li>
<li>技术分享</li>
<li>开源文化</li>
</ul>
</li>
</ul>
<p>一面结束之后过了几天接到HR电话，约了第二面的时间。</p>
<h2 id="二面45分钟">二面（45分钟）</h2>
<p>二面是部门负责人面，问的问题相对少一些，但是抓的细节比较多，因为自己准备的方向（有一些知识点没有太细致的见解，因为不是科班背景，所以花了很多时间拓宽知识储备的广度，相对而言深度就只针对特定方向做了准备）没有在对应的点上，所以答得稀烂。</p>
<ul>
<li>自我介绍</li>
<li>介绍基本的业务</li>
<li>数据存储用的是什么？</li>
<li>项目主要的难点是什么？快照是怎么做的，增量还是全量？全部数据（指的是动态和静态数据）都做快照吗？</li>
<li>这些表都有多大？</li>
<li>讲解一些表的设计的结构，字段类型</li>
</ul>
<p>这里面试官对我描述的表的数据行数和体积有一些疑问，于是花了一点时间探讨，按照要求对描述的表进行了数据量的计算，最后得出来的结果和我提出的体积有比较大的差异。主要体现出来平时对业务数据量的预估和设计经验不够丰富，缺乏细致和准确性。面试的时候如果这些内容和对方经验值出入比较大被质疑，不可避免会拉低面试官的评价结果。然后引起了面试官一连串的疑问，包括像如果数据量没有描述的这么大，为什么要做分区？惭愧orz</p>
<ul>
<li>为了优化性能的话，是要控制表的大小还是控制表的行数？</li>
<li>Redis能够讲一下吗？</li>
<li>大概讲一下BloomFilter？</li>
<li>BloomFilter的错误率有多少？（从这里开始后面就一直爆炸了）
<ul>
<li>可以自己配置，受Bitmap长度和Hash函数影响</li>
</ul>
</li>
<li>具体会有多大？比如要让错误率在1/10000以下？</li>
<li>具体和长度什么关系？和Hash函数个个数关系？</li>
<li>Hash函数一般选择用多少个？
<ul>
<li>（Orz这里我的理解和面试官的理解有所出入，我理解的模型是通过一个Hash函数计算出3个Bitmap需要置位的位置，而面试官认为的应该是通过3个不同的Hash函数计算出3个需要置位的位置，实际上都一样是需要计算3个置位的位置）</li>
</ul>
</li>
<li>一段递归代码，讲输出的结果
<ul>
<li>写了正确的递归表达式，但是计算复杂度没有出结果</li>
</ul>
</li>
<li>递推式是正确的，时间复杂度？我们学算法的时候时间复杂度是怎么算的？
<ul>
<li>（非常惭愧没有掌握计算过程，噗甩锅跨专业，一定好好补充这块的知识）</li>
</ul>
</li>
</ul>
<p>二面技术问题基本就到这里结束了，大约30分钟，毫无疑问时间太短是个Bad Smell，可能意味着面试官已经认为不符合要求，打算结束。</p>
<p>面试全程都在“答不上来”和“不了解”之间切换，然后就到了跟面试官聊人生聊理想的环节，主要关注出来看工作机会的目的和考虑之类的问题。最后也解答了一下我的问题，问到面试官对我的建议，那么当然就是反复强调的细节了，技术细节需要更深入了解，惭愧。</p>
<p>挂掉二面通话之后感觉非常糟糕，很多问题看似简单（orz实际上真的不难）没有答得对甚至就没有能答出来，需要继续加油。</p>
<p>二面结束几个小时之后接到了HR的电话，约了聊人生的时间。</p>
<h2 id="hr面30分钟">HR面（30分钟）</h2>
<p>二面和HR面都是在同一天的，有点意外因为二面的表现实在是太糟糕了，不过也可能是因为需要综合评定，所以还有后续的流程要走完。HR面也是常规的一些问题提出来要了解，以及解答疑问，就不再详细描述了。</p>
<h1 id="总结">总结</h1>
<p>整体来说考核的难度都比较正常，不过二面里面业务的掌握程度还是有所欠缺，一面里面的一些场景设计大概也不是特别理想。所以遵从面试官的建议，需要细抠技术细节，希望能够保持学习和成长。</p>
<p>面试感受：Pending有点久，大概是因为赶上毕业的同学们春招。<br>
面试难度：正常，基础和业务结合。</p>
<p>最后许愿结果满意XD</p>
]]></content>
		</item>
		
		<item>
			<title>Redis 6.0 ACL基于Bitmap实现</title>
			<link>https://jiekun.dev/posts/redis-6-acl/</link>
			<pubDate>Sat, 14 Mar 2020 14:00:46 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/redis-6-acl/</guid>
			<description>Redis 6.0在4月30日就要和大家正式见面了，现在redis.io上已经提供了RC版本。在之前的博客中，已经介绍过权限控制新功能的一些用法，主要</description>
			<content type="html"><![CDATA[<p>Redis 6.0在4月30日就要和大家正式见面了，现在<a href="https://redis.io">redis.io</a>上已经提供了RC版本。在<a href="https://bytedance-hire.me/archives/235">之前的博客</a>中，已经介绍过权限控制新功能的一些用法，主要来源于作者Antirez在Redis Day上的一些演示。Antirez在最后提到，ACL的主要实现是基于Bitmap，因此对性能影响是可以忽略不计的。当时大致猜想了一下实现的思路，那么现在离发布已经很近了，作者也对ACL Logging进行了一些补充，不妨一起来看一下。</p>
<h1 id="user结构">user结构</h1>
<p>server.h中定义了对应的<code>user</code>结构保存用户的ACL信息，包括：</p>
<ul>
<li>用户名</li>
<li>flag，主要是一些特殊状态，例如用户的启用与禁用、整体控制（所有命令可用与否、所有键可访问与否）、免密码等</li>
<li>可用命令（allowed_commands），一个长整型数。每一位代表命令，如果用户允许使用这个命令则置位1</li>
<li>可用子命令（allowed_subcommands），一个指针数组，值也为指针，数组与可用命令一一对应，值为一个SDS数组，SDS数组中存放的是这个命令可用的子命令</li>
<li>用户密码</li>
<li>可用的key patterns。如果这个字段为<code>NULL</code>，用户将不能使用任何Key，除非flag中指明特殊状态如<code>ALLKEYS</code></li>
</ul>
<pre tabindex="0"><code>typedef struct user {
    sds name;
    uint64_t flags;
    uint64_t allowed_commands[USER_COMMAND_BITS_COUNT/64];
    sds **allowed_subcommands;
    list *passwords;
    list *patterns;
} user;

</code></pre><p>补充一下一些新鲜的字段描述，<code>allowed_commands</code>实际上是一个（默认）长度为1024的位图，它的index对应各个命令的ID，在历史版本中命令结构<code>redisCommand</code>是通过名字（<code>name</code>）来查找的，<code>id</code>为这个版本中新增的属性，专门用于ACL功能。</p>
<pre tabindex="0"><code>truct redisCommand {
    ...
    int id;
};

</code></pre><p><code>user</code>这个结构对应的是<code>client</code>结构的”user”字段，熟悉Redis的同学应该对<code>client</code>也有所了解，就不再赘述了。</p>
<h1 id="acl操作选读">ACL操作选读</h1>
<p>ACL的命令很多，总体而言都是围绕着<code>user</code>对象展开的，因此从中挑选了几个函数来看一下具体是如何操作<code>user</code>对象。</p>
<p>一个需要铺垫的通用方法就是<code>ACLGetUserCommandBit</code>，ACL操作中都会涉及到获取用户的命令位图，<code>ACLGetUserCommandBit()</code>接收一个<code>user</code>结构和命令ID，根据ID定位出命令在<code>allowed_commands</code>中的位置，通过位运算返回<strong>用户是否有该命令权限</strong>。</p>
<pre tabindex="0"><code>int ACLGetUserCommandBit(user *u, unsigned long id) {
    uint64_t word, bit;
    if (ACLGetCommandBitCoordinates(id,&amp;word,&amp;bit) == C_ERR) return 0;
    return (u-&gt;allowed_commands[word] &amp; bit) != 0;
}

</code></pre><p>当用户进行Redis操作时，例如<code>set</code>操作，操作的命令会保存在<code>client</code>结构的<code>*cmd</code>字段中，<code>*cmd</code>字段就是一个<code>redisCommand</code>结构的指针，<code>redisCommand</code>结构包含了命令的<code>id</code>，因此在使用时通过<code>ACLGetUserCommandBit(u, cmd-&gt;id)</code>传入。</p>
<h2 id="创建用户">创建用户</h2>
<p>创建用户分为两步，首先需要创建一个<code>user</code>，通过调用<code>ACLCreateUser(const char *name, size_t namelen)</code>实现，返回的是一个<code>user</code>对象的指针。在创建时，会在<code>server.h</code>定义的<code>Users</code>中查找是否有同名用户，也是本次功能新增的，因为旧版本中只有”default”用户。此时这个用户拥有名称，flag被初始化为禁用用户，其余的属性均为Null或空list等。</p>
<p>然后，通过调用<code>ACLSetUser(user *u, const char *op, ssize_t oplen)</code>，调整传入用户<code>u</code>的对应属性，调整内容放在名为<code>op</code>操作的参数中。这个函数非常长，主要是针对各种不同的“操作” switch case处理，节选部分如下：</p>
<pre tabindex="0"><code>int ACLSetUser(user *u, const char *op, ssize_t oplen) {
    if (oplen == -1) oplen = strlen(op);
    /* Part1 - 处理用户状态(flag)操作 */
    // 控制用户启用状态
    if (!strcasecmp(op,&quot;on&quot;)) {
        u-&gt;flags |= USER_FLAG_ENABLED;
        u-&gt;flags &amp;= ~USER_FLAG_DISABLED;
    } else if (!strcasecmp(op,&quot;off&quot;)) {
        u-&gt;flags |= USER_FLAG_DISABLED;
        u-&gt;flags &amp;= ~USER_FLAG_ENABLED;
    // 控制全局键、命令等可用与否
    } else if (!strcasecmp(op,&quot;allkeys&quot;) ||
               !strcasecmp(op,&quot;~*&quot;))
    {
        u-&gt;flags |= USER_FLAG_ALLKEYS;
        listEmpty(u-&gt;patterns);
    }
    ...


    /* Part2 - 操作用户密码增删改查 */
    // &gt; 和 &amp;lt; 等控制密码的改动删除等
    else if (op[0] == '&gt;' || op[0] == '#') {
        sds newpass;
        if (op[0] == '&gt;') {
            newpass = ACLHashPassword((unsigned char*)op+1,oplen-1);
        }


    /* Part3 - 操作用户可用命令的范围 */
    else if (op[0] == '+' &amp;&amp; op[1] != '@') {
        if (strchr(op,'|') == NULL) {
            if (ACLLookupCommand(op+1) == NULL) {
                errno = ENOENT;
                return C_ERR;
            }
            unsigned long id = ACLGetCommandID(op+1);
            // 根据传入的id参数设置对应allowed_commands位图的值
            ACLSetUserCommandBit(u,id,1);
            // 新调整的命令的子命令数组会被重置
            ACLResetSubcommandsForCommand(u,id);
        }
    }

</code></pre><p>补充一下具体调用例子，其实Redis的默认用户就是按照这套流程创建的：初始化名为“default”的空白无权限用户，然后为这个用户设置上所有权限：</p>
<pre tabindex="0"><code>DefaultUser = ACLCreateUser(&quot;default&quot;,7);
ACLSetUser(DefaultUser,&quot;+@all&quot;,-1);
ACLSetUser(DefaultUser,&quot;~*&quot;,-1);
ACLSetUser(DefaultUser,&quot;on&quot;,-1);
ACLSetUser(DefaultUser,&quot;nopass&quot;,-1);

</code></pre><h2 id="拦截不可用命令键">拦截不可用命令/键</h2>
<p>命令/键拦截操作非常简单：</p>
<ul>
<li>判断命令/键是否可用
<ul>
<li>如果不可用，ACL Log处理以及返回错误</li>
</ul>
</li>
</ul>
<h3 id="acl判断">ACL判断</h3>
<p>我们先看一下“不可用”的判断逻辑，然后再回到命令执行流程中看判断方法的调用。</p>
<p>判断函数同样非常长，展示完后会进行总结：</p>
<pre tabindex="0"><code>int ACLCheckCommandPerm(client *c, int *keyidxptr) {
    user *u = c-&gt;user;
    uint64_t id = c-&gt;cmd-&gt;id;
    // 命令相关的全局flag的检查，若满足则跳过后续部分
    if (!(u-&gt;flags &amp; USER_FLAG_ALLCOMMANDS) &amp;&amp;
        c-&gt;cmd-&gt;proc != authCommand)
    {
        // 即使当前命令没有在allowed_commands中，还要检查子命令是否可用
        // 以免出现仅开放了部分子命令权限的情况
        if (ACLGetUserCommandBit(u,id) == 0) {
            ...
            // 遍历子命令
            long subid = 0;
            while (1) {
                if (u-&gt;allowed_subcommands[id][subid] == NULL)
                    return ACL_DENIED_CMD;
                if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,
                                u-&gt;allowed_subcommands[id][subid]))
                    break; // 子命令可用，跳出循环
                subid++;
            }
        }
    }

    // 键相关的全局flag检查，若满足则跳过后续部分
    if (!(c-&gt;user-&gt;flags &amp; USER_FLAG_ALLKEYS) &amp;&amp;
        (c-&gt;cmd-&gt;getkeys_proc || c-&gt;cmd-&gt;firstkey))
    {
        int numkeys;
        // 先拿到当前要进行操作的Key
        int *keyidx = getKeysFromCommand(c-&gt;cmd,c-&gt;argv,c-&gt;argc,&amp;numkeys);
        for (int j = 0; j &amp;lt; numkeys; j++) {
            listIter li;
            listNode *ln;
            listRewind(u-&gt;patterns,&amp;li);

            // 检查当前user所有的关于Key的匹配Pattern
            // 如果有任意命中则跳出，否则判定不可用
            int match = 0;
            while((ln = listNext(&amp;li))) {
                sds pattern = listNodeValue(ln);
                size_t plen = sdslen(pattern);
                int idx = keyidx[j];
                if (stringmatchlen(pattern,plen,c-&gt;argv[idx]-&gt;ptr,
                                   sdslen(c-&gt;argv[idx]-&gt;ptr),0))
                {
                    match = 1;
                    break;
                }
            }
            if (!match) {
                if (keyidxptr) *keyidxptr = keyidx[j];
                getKeysFreeResult(keyidx);
                return ACL_DENIED_KEY;
            }
        }
        getKeysFreeResult(keyidx);
    }
    return ACL_OK;
}

</code></pre><p>那么为了方便喜欢跳过代码的同学看结论：</p>
<ul>
<li>ACL限制围绕<code>user</code>的各个字段进行</li>
<li>全局的flag优先级最高，例如设置为所有键可用，所有命令可用，会跳过后续的可用命令遍历和可用键Pattern匹配</li>
<li>即使在allowed_commands位图中没有被置位，命令也可能可用，因为它是个子命令，而且命令只开放了部分子命令的使用权限</li>
<li>键通过遍历所有定义了的Pattern检查，如果有匹配上说明可用</li>
<li>先判断操作是否可用，再判断键（包括全局flag也在操作之后）是否可用，两种判断分别对应不同返回整数值：<code>ACL_DENIED_CMD</code>、<code>ACL_DENIED_KEY</code></li>
</ul>
<h3 id="命令执行流程中的调用">命令执行流程中的调用</h3>
<p>判断逻辑之后到何时调用这套判断。我们先来复习一下Redis如何执行命令：</p>
<ul>
<li>用户操作</li>
<li>客户端RESP协议（Redis 6.0中有RESP3新协议记得关注）压缩发送给服务端</li>
<li>服务端解读消息，存放至<code>client</code>对象的对应字段中，例如<code>argc</code>、<code>argv</code>等存放命令和参数等内容</li>
<li><strong>执行前检查（各种执行条件）</strong></li>
<li>执行命令</li>
<li><strong>执行后处理（慢查询日志、AOF等）</strong></li>
</ul>
<p>目前执行命令的方法是在<code>server.c</code>中的<code>processCommand(client *c)</code>，传入<code>client</code>对象，执行，返回执行成功与否。我们节选其中关于ACL的部分如下：</p>
<pre tabindex="0"><code>int processCommand(client *c) {
    ...
    int acl_keypos;
    int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
    if (acl_retval != ACL_OK) {
        addACLLogEntry(c,acl_retval,acl_keypos,NULL);
        flagTransaction(c);
        if (acl_retval == ACL_DENIED_CMD)
            addReplyErrorFormat(c,
                &quot;-NOPERM this user has no permissions to run &quot;
                &quot;the '%s' command or its subcommand&quot;, c-&gt;cmd-&gt;name);
        else
            addReplyErrorFormat(c,
                &quot;-NOPERM this user has no permissions to access &quot;
                &quot;one of the keys used as arguments&quot;);
        return C_OK;
    }
    ...

</code></pre><p>在命令解析之后，真正执行之前，通过调用<code>ACLCheckCommandPerm</code>获取判断结果，如果判定不通过，进行以下操作：</p>
<ul>
<li>记录ACL不通过的日志，这个是作者在RC1之后新增的功能，还在Twitch上进行了直播开发，有兴趣的同学可以在Youtube上看到录播</li>
<li>如果当前处于事务（MULTI）过程中，将client的<code>flag</code>置为<code>CLIENT_DIRTY_EXEC</code></li>
<li>根据命令还是键不可用，返回给客户端不同的信息</li>
</ul>
<p>因此这次ACL功能影响的是执行命令前后的操作。</p>
<h3 id="其他功能对acl的调用">其他功能对ACL的调用</h3>
<p>通过搜索可以发现一共有3处调用了<code>ACLCheckCommandPerm</code>方法：</p>
<pre tabindex="0"><code>/home/duck/study/redis/src/multi.c:
  179  
  180          int acl_keypos;
  181:         int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
  182          if (acl_retval != ACL_OK) {
  183              addACLLogEntry(c,acl_retval,acl_keypos,NULL);

/home/duck/study/redis/src/scripting.c:
  608      /* Check the ACLs. */
  609      int acl_keypos;
  610:     int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
  611      if (acl_retval != ACL_OK) {
  612          addACLLogEntry(c,acl_retval,acl_keypos,NULL);

/home/duck/study/redis/src/server.c:
 3394       * ACLs. */
 3395      int acl_keypos;
 3396:     int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
 3397      if (acl_retval != ACL_OK) {
 3398          addACLLogEntry(c,acl_retval,acl_keypos,NULL);

</code></pre><p>形式都是大同小异，了解一下即可。总结一下需要判定ACL的位置：</p>
<ul>
<li>正常命令执行流程中</li>
<li>MULTI事务执行过程中</li>
<li>Lua脚本</li>
</ul>
<h1 id="总结">总结</h1>
<p>补充一张图来描述新增的ACL功能相关的结构（点击放大查看）：</p>
<p><img src="%22./2020/03/Redis_ACL_user-1024x535.png" alt=""></p>
<p>图中部分的表达可能与实际的数据结构有所差异，主要原因是代码理解和C语言的语法掌握不到位所致。</p>
<p>阅读代码的过程中留意到，对命令的限制是通过Bitmap来实现的，而对Key的限制是通过特定Pattern来实现的。当对Key的限制Pattern数量特别多时，是否会因为匹配Pattern而对性能造成影响，例如超多次的<code>stringmatchlen()</code>执行。当然这一块内容似乎确实没有想到什么提升非常大的判断方式，后续也会继续关注ACL的相关改进。</p>
]]></content>
		</item>
		
		<item>
			<title>Elasticsearch节点选举、分片及Recovery</title>
			<link>https://jiekun.dev/posts/2020-03-14-elasticsearch%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE%E5%88%86%E7%89%87%E5%8F%8Arecovery/</link>
			<pubDate>Sat, 14 Mar 2020 07:58:10 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-03-14-elasticsearch%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE%E5%88%86%E7%89%87%E5%8F%8Arecovery/</guid>
			<description>隔了挺长一段时间没有更新，主要是因为近段时间忙于业务和刷题，想来刷题除了Po题解和Explanation也是没有什么特别之处，除非钻研得特别</description>
			<content type="html"><![CDATA[<p>隔了挺长一段时间没有更新，主要是因为近段时间忙于业务和刷题，想来刷题除了Po题解和Explanation也是没有什么特别之处，除非钻研得特别深入，所以（@#$%^&amp;找理由）。</p>
<h1 id="关于elasticsearch">关于Elasticsearch</h1>
<p>Elasticsearch其实官网的文档特别齐全，所以关于用法没有什么特别好写的，看博客不如RTFM。但是文档特别全的情况下，很多时候又缺少对一些具体细节的描述，一句话说就是不知其所以然。所以今天写的博客内容理应是无关使用的，不涉及命令与操作，大概会更有意义一些吧。</p>
<h1 id="概述">概述</h1>
<p>以Elasticsearch（下称ES）集群启动过程作为索引来展开，ES想要从Red转为Green，需要经历以下过程：</p>
<ul>
<li>主节点选举。集群启动需要从已知的活跃机器中选取主节点，因为这是PacificA算法的思想——主从模式，使用Master节点管理元信息，数据则去中心化。这块使用类似Bully的算法。</li>
<li>元信息选举。主节点确认后，需要从各节点的元信息中获取最新版本的元信息。由Gateway模块负责。</li>
<li>主副分片选举。由Allocation模块负责，各分片的多个副本中选出主分片和副分片，记录他们所属的节点，重构内容路由表。</li>
<li>恢复分片数据。因为启动可能包含之前没有来得及刷盘的数据，副分片也可能落后于新选出的主分片。</li>
</ul>
<h1 id="bully算法与主节点选举">Bully算法与主节点选举</h1>
<h2 id="bully算法">Bully算法</h2>
<p>特地查了一下Bully的意思——“仗势欺人者，横行霸道者”，所以这个霸道选举算法如其名，简单暴力地通过<strong>选出ID最大的候选者</strong>来完成。在Bully算法中有几点假设：</p>
<ul>
<li>系统是处于同步状态的</li>
<li>进程任何时间都可能失效，包括在算法执行过程中</li>
<li>进程失败则停止，并通过重新启动来恢复</li>
<li>有能够进行失败检测的机制</li>
<li>进程间的消息传递是可靠的</li>
<li>每个进程知道自己的ID和地址，以及其他所有的进程ID和地址</li>
</ul>
<p>它的选举通过以下几类消息：</p>
<ul>
<li>选举消息：用来声明一次选举</li>
<li>响应消息：响应选举消息</li>
<li>协调消息：胜利者向参与者发送胜利声明</li>
</ul>
<p>设想以下场景，集群中存在ID为1、2、3的节点，通过Bully算法选举出了3为主节点，此时之前因为网络分区无法联系上的4节点加入，通过Bully算法成了新的主节点，后续失联的5节点加入，同样成为新主节点。这种不稳定的状态在ES中通过优化选举发起的条件来解决，当主节点确定后，在失效前不进行新一轮的选举。另外其他分布式应用一样，ES通过Quorum来解决脑裂的问题。</p>
<h2 id="elasticsearch主节点选举">Elasticsearch主节点选举</h2>
<p>ES的选举与Bully算法有所出入，它选举的是<strong>ID最小</strong>的节点，当然这并没有太大影响。另外目前版本中ES的排序影响因素还有集群状态，对应一个状态版本号，排序中会优先将版本号高的节点放在最前。</p>
<p>在选举过程中有几个概念：</p>
<ul>
<li>临时Master节点：某个节点认可的Master节点</li>
<li>activeMasters列表：不同节点了解到的其他节点范围可能不一样，因此他们可能各自认可不同的Master节点，这些临时Master节点的集合称为activeMasters列表</li>
<li>masterCanditates列表：所有满足Master资格（一般不满足例原因如配置了某些节点不能作为主节点）的节点列表</li>
<li>正式Master节点：票数足够时临时Master节点确立为真正Master节点</li>
</ul>
<p>某个节点ping所有节点，获取一份节点列表，并将自己加入其中。通过这份列表查看当前活跃的Master列表，也就是每个节点认为当前的Master节点，加入<strong>activeMasters列表</strong>中。同样，通过过滤原始列表中不符合Master资格的节点，形成<strong>masterCandidates列表</strong>。</p>
<p>如果activeMasters列表不为空，按照ES的（近似）Bully算法选举自己认为的Master节点；如果activeMasters列表空，从masterCandidates列表中选举，但是此时需要判断当前候选人数是否达到Quorum。ES使用具体的比较Master的逻辑如下：</p>
<pre tabindex="0"><code>/**
 * compares two candidates to indicate which the a better master.
 * A higher cluster state version is better
 * 比较两个候选节点以得出更适合作为Master的节点。
 * 优先以集群状态版本作为排序
 *
 * @return -1 if c1 is a batter candidate, 1 if c2.
 * @c1更合适则返回-1，c2更合适则返回1
 */
public static int compare(MasterCandidate c1, MasterCandidate c2) {
    // we explicitly swap c1 and c2 here. the code expects &quot;better&quot; is lower in a sorted
    // list, so if c2 has a higher cluster state version, it needs to come first.
    // 先比较版本
    int ret = Long.compare(c2.clusterStateVersion, c1.clusterStateVersion);
    if (ret == 0) {
        // 比较节点
        ret = compareNodes(c1.getNode(), c2.getNode());
    }
    return ret;
}

/** master nodes go before other nodes, with a secondary sort by id **/
 private static int compareNodes(DiscoveryNode o1, DiscoveryNode o2) {
    if (o1.isMasterNode() &amp;&amp; !o2.isMasterNode()) {
        // 如果o1是主节点
        return -1;
    }
    if (!o1.isMasterNode() &amp;&amp; o2.isMasterNode()) {
        // 如果o2是主节点
        return 1;
    }
    // ID比较
    return o1.getId().compareTo(o2.getId());
}

</code></pre><p>确定之后进行投票，ES的投票是通过发送Join请求进行的，票数即为当前连接数。</p>
<p>如果临时Master为当前节点，则当前节点等待Quorum连接数，若配置时间内不满足，则选举失败，进行新一轮选举；若满足，发布新的clusterState。</p>
<p>如果临时Master节点不是本节点，则向Master发送Join请求，等待回复。Master如果得到足够票数，会先发布状态再确认请求。</p>
<h1 id="主副分片选举与allocation模块">主副分片选举与Allocation模块</h1>
<p>分片的决策由Master节点完成，需要确认的内容包括：</p>
<ul>
<li>哪些分片应该分配到哪个节点上（平衡）</li>
<li>分片的多个副本中哪个应该成为主分片（数据完整）</li>
</ul>
<h2 id="allocators">allocators</h2>
<p>Allocation模块中，allocators负责对分片作出优先选择，例如：</p>
<ul>
<li>平衡分片，节点列表按照它们的分片数排序，分片少的靠前，优先将新分片分配至靠前节点</li>
<li>主副分片，按照：节点上如果有完整的分片副本，主分片才能够指定到这个节点；节点上如果有（不一定需要完整）分片副本，副分片可以优先分配在这个节点（然后从主分片恢复数据）。</li>
<li>具体包括：
<ul>
<li>primaryShardAllocator：找到拥有分配最新数据的节点</li>
<li>replicaShardAllocator：找到拥有这个分片数据的节点</li>
<li>BalancedShardsAllocator：找到拥有最少分片个数的节点</li>
</ul>
</li>
</ul>
<h2 id="deciders">deciders</h2>
<p>作出选择后，需要通过deciders判断分片是否真的可以指定在这个节点，例如：</p>
<ul>
<li>磁盘空间限制</li>
<li>配置限制</li>
<li>避免主副分片落在同一节点</li>
<li>具体包括：
<ul>
<li>SameShardAllocationDecider：避免同节点</li>
<li>AwarenessAllocationDecider：分散存储shard</li>
<li>ShardsLimitAllocationDecider：同一节点允许同index的shard数目</li>
<li>ThrottlingAllocationDecider：recovery阶段的限速配置影响</li>
<li>ConcurrentRebalanceAllocationDecider：重新分片的并发控制</li>
<li>DiskThresholdDecider：磁盘空间</li>
<li>RebalanceOnlyWhenActiveAllocationDecider：是否所有shard都处于active状态</li>
<li>FilterAllocationDecider：接口动态设置的限定参数</li>
<li>ReplicaAfterPrimaryActiveAllocationDecider：主分片分配完毕才开始分配副分片</li>
<li>ClusterRebalanceAllocationDecider：集群中active的shard的状态</li>
</ul>
</li>
</ul>
<h2 id="主分片选举">主分片选举</h2>
<p>分片经过指定节点后有allocation id，并且有inSyncAllocationIds列表记录哪些分片是处于“in-sync”状态的。主分片的选举通过是否处于in-sync列表来进行。</p>
<p>在历史版本中，分片有对应的版本号，但是如果使用版本号进行选举，如果拥有最新数据版本的分片还未启动，那么就会有历史版本的分片被选为主分片，例如只有一个活跃分片时它必定会被选为主分片。</p>
<p>通过将in-sync列表的分片遍历各个decider，如果有任一deny发生，则拒绝本次分配。决策结束之后可能会有多个节点，取第一个节点上的分片作为主分片。</p>
<h2 id="分片模型">分片模型</h2>
<p>ES中使用Sequence ID标记写操作，以得到索引操作的顺序。现在考虑这种情况：由于网络原因，主分片产生的SID=145的操作转发到副分片上，但是没有传达成功，此时主分片被另一个副分片取代，也产生了一个SID=145（因为这个副分片最新的SID是144）的操作，转发给其他副分片。转发过程中，原来网络分区的主分片恢复，它的旧SID=145操作继续发送给其他副分片，那么分片副本中就有部分收到了旧主发的145操作，部分收到了新主发的145操作。</p>
<p>因此，除了Sequence ID以外，ES使用Primary Terms来标记主分片，每次新主分片产生时，Primary Terms加1，副分片会拒绝旧的Primary Terms发来的操作。</p>
<p>主节点为分片分配Primary Terms、Allocation ID，其中各个满足in-sync状态的分片的Allocation ID构成inSyncAllocationIds列表；Sequence ID由主分片为写操作分配，副分片拒绝Primary Terms+Sequence ID落后的操作。</p>
<h1 id="分片数据recovery">分片数据Recovery</h1>
<p>ES（大致的）存储模型在官网上有描述有图，所以就不多费时间描述了。</p>
<h2 id="主分片recovery">主分片Recovery</h2>
<p>主分片因为处于in-sync list中，需要恢复的数据只有未进行fsync刷盘的部分，也就是refresh之后，变得可被索引，但是没有进行flush生成新的commit point持久化到磁盘的部分。这部分数据在translog中，因此需要将数据从translog进行恢复。</p>
<p>经过一系列的校验（是否主分片、分片状态是否异常等）工作后，从分片读取最后一次提交（commit）的段（segment）信息，获取其中版本号，更新当前索引版本。然后验证元信息中的checksum和实际值是否匹配，避免分片受损。</p>
<p>根据最后一次commit的信息，确认translog中哪些数据需要进行reply，执行具体的写操作，结束后进行refresh，和正常写操作一样，让数据转移到文件系统缓存中，变得可被索引到，但是没有fsync。</p>
<p>最后进行一次refresh更新分片状态，恢复完毕。</p>
<h2 id="副分片recovery">副分片Recovery</h2>
<p>副分片恢复需要根据当前数据状态（进度）决定，如果Sequence ID满足，可以直接从主分片的Translog中恢复缺失部分；如果不满足，需要拉取主分片的Lucene索引和Translog进行恢复。</p>
<p>主分片一般先Recovery，结束后接受新业务的操作，如何保证副分片需要的Translog不清理？在最初的1.x版本中，ES阻止refresh操作保留translog，但是这样会产生很大的translog；在2.0-5.x版本中，引入了translog.view的概念，translog被分为多个文件，维护一个引用文件的列表，同时recovery通过translog.view获取这些文件的引用，因为文件引用的存在translog不能被清理，直到view关闭（没有引用）。6.0版本中引入了TranslogDeletingPolicy概念，维护活跃的translog文件，通过将translog做快照来保持translog不被清理。</p>
<p>副分片的恢复由两个阶段构成：</p>
<ul>
<li>phase1：在主分片上获取translog保留锁，此时translog不会被清理；将Lucene索引做快照，数据复制到副本节点。完成后，副分片可以启动Engine开始接受请求。</li>
<li>phase2：对translog做快照，这部分包含了从phase1开始到执行translog快照期间的新增数据，发送到副分片进行reply。</li>
</ul>
<p>前面提过，如果可以基于SID进行恢复，跳过phase1；如果主副分片有同样的syncid且doc数相同，跳过phase1。</p>
<p>什么是syncid？当分片5分钟（可配置）没有写入操作就会被标记为inactive，执行synced flush，生成一个syncid，相同syncid意味着分片是相同的Lucene索引。</p>
<h2 id="恢复过程中的主副分片一致性">恢复过程中的主副分片一致性</h2>
<p>恢复时，因为主副分片恢复时间不一致，主分片先进行Recovery，然后副分片才能基于主分片进行Recovery，所以主分片可以工作之后，副分片可能还在恢复中，此时主分片会向副分片发送写请求，因此恢复reply与主分片可能会同时（或者不按发生顺序）对同一个doc进行操作。ES中通过doc的版本号解决这个问题，当收到一个版本号低于doc当前版本号的操作时，会放弃本次操作。对于特定的doc，只有最新一次操作生效。</p>
<h1 id="总结">总结</h1>
<p>Elasticsearch是个易用又复杂的分布式项目，其中很多分布式相关的设计和思想都值得学习和借鉴。在拉取代码时发现项目体积接近1GB：</p>
<pre tabindex="0"><code>uck@duck-MS-7A34:~/study/tmp$ du -sh elasticsearch/
949M    elasticsearch/

</code></pre><p>因此其中很多模块都没有了解清楚，希望以后可以保持学习的新鲜感，继续摸索更多的内容。</p>
]]></content>
		</item>
		
		<item>
			<title>字节跳动一面复盘 &amp; Redis多线程IO模型源码学习</title>
			<link>https://jiekun.dev/posts/2020-02-22-%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E4%B8%80%E9%9D%A2%E5%A4%8D%E7%9B%98-redis%E5%A4%9A%E7%BA%BF%E7%A8%8Bio%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</link>
			<pubDate>Sat, 22 Feb 2020 12:42:24 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-02-22-%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E4%B8%80%E9%9D%A2%E5%A4%8D%E7%9B%98-redis%E5%A4%9A%E7%BA%BF%E7%A8%8Bio%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</guid>
			<description>面试 上周参加了字节跳动的面试，也是18年毕业后的首次面试，整场下来一共70分钟，面试官非常Nice，无奈自己太过紧张，很多准备好的知识点都没</description>
			<content type="html"><![CDATA[<h1 id="面试">面试</h1>
<p>上周参加了字节跳动的面试，也是18年毕业后的首次面试，整场下来一共70分钟，面试官非常Nice，无奈自己太过紧张，很多准备好的知识点都没有能够准确传达意思。</p>
<p>面试中因为在简历上有提到Redis相关的内容，那么毫无疑问就会被问到了。先从经典的问题开始：Reids为什么这么快？那自然会回答诸如单线程、IO多路复用等固定套路，然后这里因为一直有关注Redis的相关新闻，知道Redis 6.0年末发布了RC1版本，其中新特性包括多线程IO，那么自然想在面试中提及一下。面试官应该对这点比较感兴趣，于是就继续探讨了这个多线程IO的模型。</p>
<ul>
<li>Q：Redis 6多线程是指什么？</li>
<li>A：Redis这边将部分处理流程改为多线程，具体来说是..</li>
<li>Q：是指查询是多线程吗？</li>
<li>A：应该说是处理请求的最后部分改为了多线程，因为这些部分涉及到数据的IO，是整个（Redis）模型中最耗时的部分，所以改成了多线程；这部分之前的比如用户请求进来、将请求放入一个队列中，还是单线程的。（注意这部分回答是错误的，实际上Redis是将网络IO的部分做成了多线程，后文继续分析）</li>
<li>Q：如果我有一个SET操作的话，是单线程还是多线程？</li>
<li>A：多线程。（回答也是错的）</li>
<li>Q：那如果是，因为Redis都是内存操作，如果多线程操作一个数据结构的话会有问题吗？</li>
<li>A：Emm，目前我理解的模型上看确实会有问题，比如并发改同一个Key，那可能Redis有对应处理这些问题比如进行加锁处理。（确实不了解，回答也自然是错的）</li>
<li>Q：好，下一个问题..</li>
</ul>
<p>这里先总结一下：</p>
<ul>
<li>因为Antirez在Redis Day介绍过，所以就了解到了有这么个新Feature，但是具体的实现因为没有看过源码，所以实际上对这个多线程模型的理解是有偏差的。</li>
<li>如果对这些点没有十足的把握的话，面试中尝试自己思考和解决这样的问题实际上还是会比较扣分，首先如果猜错了的话肯定不行，其次即使是猜对了也很难有足够的知识储备去复述出完整的模型出来，也会让自己一边思考一边表达起来很费劲。</li>
</ul>
<p>于是坑坑洼哇地坚持完了70分钟的面试，再总结一下做得不足的地方，因为是1.5Year经验，面试官主要考察：</p>
<ul>
<li>现有的业务的一些设计细节的问题：要提前准备好你想介绍给面试官的业务系统，个人认为应该从业务中选出一两个难度比较大的点会比较合适。这次面试没有能够拿出对应的业务来介绍，是准备不到位。</li>
<li>数据库的基础知识：这块觉得回答得还可以，不过有的时候因为准备的东西比较多，会经常想充分地展现和描述，有的时候可能会比较冗长，也是表达不够精确的问题。</li>
<li>计算机网络的基础知识：不是科班毕业，没有能够答完美，实际上问题并不难。</li>
<li>计算机系统的基础知识：同上。</li>
<li>一道算法题：字节跳动给的算法题还是偏简单和经典的，建议多刷题和看Discussion总结。</li>
</ul>
<p>所以就这样结束了第一次的社招面试，整体来说几个方向的基础知识需要回去再多写多看就可以了，然后表达上尽量控制时间和范围，深入的内容如果面试官希望和你继续探讨，自然会发问，如果没问，可以提及但是不应该直接展开讲。</p>
<h1 id="redis的threaded-io">Redis的Threaded IO</h1>
<p>面试结束后马上知道这块的回答有问题，检查果然如此。所以也就借这个机会将Threaded IO对应的源码看了一遍，后续如果有机会的话，希望能跟下一位面试官再来探讨这个模型。</p>
<h2 id="综述">综述</h2>
<p>本次新增的代码位于<code>networking.c</code>中，很显然多线程生效的位置就能猜出来是在网络请求上。作者希望改进读写缓冲区的性能，而不是命令执行的性能主要原因是：</p>
<ul>
<li>读写缓冲区的在命令执行的生命周期中是占了比较大的比重</li>
<li>Redis更倾向于保持简单的设计，如果在命令执行部分改用多线程会不得不处理各种问题，例如并发写入、加锁等</li>
</ul>
<p>那么将读写缓冲区改为多线程后整个模型大致如下：</p>
<p><img src="../2020/02/Threaded-IO-1-1024x1016.png" alt=""></p>
<h2 id="具体模型">具体模型</h2>
<h3 id="线程初始化initthreadedio">线程初始化(initThreadedIO)</h3>
<p>首先，如果用户没有开启多线程IO，也就是<code>io_threads_num == 1</code>时直接按照单线程模型处理；如果超过线程数<code>IO_THREADS_MAX_NUM</code>上限则异常退出。</p>
<p>紧接着Redis使用listCreate()创建io_threads_num个线程，并且对主线程（id=0）以外的线程进行处理：</p>
<ul>
<li>初始化线程的等待任务数为0</li>
<li>获取锁，使得线程不能进行操作</li>
<li>将线程tid与Redis中的线程id（for循环生成）进行映射</li>
</ul>
<pre tabindex="0"><code>/* Initialize the data structures needed for threaded I/O. */
void initThreadedIO(void) {
    io_threads_active = 0; /* We start with threads not active. */

    /* Don't spawn any thread if the user selected a single thread:
     * we'll handle I/O directly from the main thread. */
    // 如果用户没有开启多线程IO直接返回 使用主线程处理
    if (server.io_threads_num == 1) return;
    // 线程数设置超过上限
    if (server.io_threads_num &gt; IO_THREADS_MAX_NUM) {
        serverLog(LL_WARNING,&quot;Fatal: too many I/O threads configured. &quot;
                             &quot;The maximum number is %d.&quot;, IO_THREADS_MAX_NUM);
        exit(1);
    }

    /* Spawn and initialize the I/O threads. */
    // 初始化io_threads_num个对应线程
    for (int i = 0; i &amp;lt; server.io_threads_num; i++) {
        /* Things we do for all the threads including the main thread. */
        io_threads_list[i] = listCreate();
        if (i == 0) continue; // Index 0为主线程

        /* Things we do only for the additional threads. */
        // 非主线程则需要以下处理
        pthread_t tid;
        // 为线程初始化对应的锁
        pthread_mutex_init(&amp;io_threads_mutex[i],NULL);
        // 线程等待状态初始化为0
        io_threads_pending[i] = 0;
        // 初始化后将线程暂时锁住
        pthread_mutex_lock(&amp;io_threads_mutex[i]);
        if (pthread_create(&amp;tid,NULL,IOThreadMain,(void*)(long)i) != 0) {
            serverLog(LL_WARNING,&quot;Fatal: Can't initialize IO thread.&quot;);
            exit(1);
        }
        // 将index和对应线程ID加以映射
        io_threads[i] = tid;
    }
}

</code></pre><h3 id="读事件到来readqueryfromclient">读事件到来（readQueryFromClient）</h3>
<p>Redis需要判断是否满足Threaded IO条件，执行<code>if (postponeClientRead(c)) return;</code>，执行后会将Client放到等待读取的队列中，并将Client的等待读取Flag置位：</p>
<pre tabindex="0"><code>int postponeClientRead(client *c) {
    if (io_threads_active &amp;&amp; // 线程是否在不断(spining)等待IO
        server.io_threads_do_reads &amp;&amp; // 是否多线程IO读取
        !(c-&gt;flags &amp; (CLIENT_MASTER|CLIENT_SLAVE|CLIENT_PENDING_READ)))
    {//client不能是主从，且未处于等待读取的状态
        c-&gt;flags |= CLIENT_PENDING_READ; // 将Client设置为等待读取的状态Flag
        listAddNodeHead(server.clients_pending_read,c); // 将这个Client加入到等待读取队列
        return 1;
    } else {
        return 0;
    }
}

</code></pre><p>这时server维护了一个<code>clients_pending_read</code>，包含所有处于读事件pending的客户端列表。</p>
<h3 id="如何分配client给threadhandleclientswithpendingreadsusingthreads">如何分配client给thread（handleClientsWithPendingReadsUsingThreads）</h3>
<p>首先，Redis检查有多少等待读的client：</p>
<pre tabindex="0"><code>istLength(server.clients_pending_read)

</code></pre><p>如果长度不为0，进行While循环，将每个等待的client分配给线程，当等待长度超过线程数时，每个线程分配到的client可能会超过1个：</p>
<pre tabindex="0"><code>int item_id = 0;
while((ln = listNext(&amp;li))) {
    client *c = listNodeValue(ln);
    int target_id = item_id % server.io_threads_num;
    listAddNodeTail(io_threads_list[target_id],c);
    item_id++;
}

</code></pre><p>并且修改每个线程需要完成的数量（初始化时为0）：</p>
<pre tabindex="0"><code>for (int j = 1; j &amp;lt; server.io_threads_num; j++) {
    int count = listLength(io_threads_list[j]);
    io_threads_pending[j] = count;
}

</code></pre><p>等待处理直到没有剩余任务：</p>
<pre tabindex="0"><code>hile(1) {
    unsigned long pending = 0;
    for (int j = 1; j &amp;lt; server.io_threads_num; j++)
        pending += io_threads_pending[j];
    if (pending == 0) break;
}

</code></pre><p>最后清空client_pending_read：</p>
<pre tabindex="0"><code>istRewind(server.clients_pending_read,&amp;li);
while((ln = listNext(&amp;li))) {
    client *c = listNodeValue(ln);
    c-&gt;flags &amp;= ~CLIENT_PENDING_READ;
    if (c-&gt;flags &amp; CLIENT_PENDING_COMMAND) {
        c-&gt;flags &amp;= ~ CLIENT_PENDING_COMMAND;
        processCommandAndResetClient(c);
    }
    processInputBufferAndReplicate(c);
}
listEmpty(server.clients_pending_read);

</code></pre><h3 id="如何处理读请求">如何处理读请求</h3>
<p>在上面的过程中，当任务分发完毕后，每个线程按照正常流程将自己负责的Client的读取缓冲区的内容进行处理，和原来的单线程没有太大差异。</p>
<p>每轮处理中，需要将各个线程的锁开启，并且将相关标志置位：</p>
<pre tabindex="0"><code>void startThreadedIO(void) {
    if (tio_debug) { printf(&quot;S&quot;); fflush(stdout); }
    if (tio_debug) printf(&quot;--- STARTING THREADED IO ---\n&quot;);
    serverAssert(io_threads_active == 0);
    for (int j = 1; j &amp;lt; server.io_threads_num; j++)
        // 解开线程的锁定状态
        pthread_mutex_unlock(&amp;io_threads_mutex[j]);
    // 现在可以开始多线程IO执行对应读/写任务
    io_threads_active = 1;
}

</code></pre><p>同样结束时，首先需要检查是否有剩余待读的IO，如果没有，将线程锁定，标志关闭：</p>
<pre tabindex="0"><code>void stopThreadedIO(void) {
    // 需要停止的时候可能还有等待读的Client 在停止前进行处理
    handleClientsWithPendingReadsUsingThreads();
    if (tio_debug) { printf(&quot;E&quot;); fflush(stdout); }
    if (tio_debug) printf(&quot;--- STOPPING THREADED IO [R%d] [W%d] ---\n&quot;,
        (int) listLength(server.clients_pending_read),
        (int) listLength(server.clients_pending_write));
    serverAssert(io_threads_active == 1);
    for (int j = 1; j &amp;lt; server.io_threads_num; j++)
        // 本轮IO结束 将所有线程上锁
        pthread_mutex_lock(&amp;io_threads_mutex[j]);
    // IO状态设置为关闭
    io_threads_active = 0;
}

</code></pre><h3 id="其他补充">其他补充</h3>
<p>Redis的Threaded IO模型中，每次所有的线程都只能进行读或者写操作，通过<code>io_threads_op</code>控制，同时每个线程中负责的client依次执行：</p>
<pre tabindex="0"><code>// 每个thread有可能需要负责多个client
listRewind(io_threads_list[id],&amp;li);
while((ln = listNext(&amp;li))) {
    client *c = listNodeValue(ln);
    if (io_threads_op == IO_THREADS_OP_WRITE) {
        // 当前全局处于写事件时，向输出缓冲区写入响应内容
        writeToClient(c,0);
    } else if (io_threads_op == IO_THREADS_OP_READ) {
        // 当前全局处于读事件时，从输入缓冲区读取请求内容
        readQueryFromClient(c-&gt;conn);
    } else {
        serverPanic(&quot;io_threads_op value is unknown&quot;);
    }
}

</code></pre><p>每个线程执行<code>readQueryFromClient</code>，将对应的请求放入一个队列中，单线程执行，最后类似地由多线程将结果写入客户端的buffer中。</p>
<h2 id="总结">总结</h2>
<p>Threaded IO将服务读Client的输入缓冲区和将执行结果写入输出缓冲区的过程改为了多线程的模型，同时保持同一时间全部线程均处于读或者写的状态。但是命令的具体执行仍是以单线程（队列）的形式，因为Redis希望保持简单的结构避免处理锁和竞争的问题，并且读写缓冲区的时间占命令执行生命周期的比重较大，处理这部分的IO模型会给性能带来显著的提升。</p>
]]></content>
		</item>
		
		<item>
			<title>短链生成系统设计——Counter&#43;ZooKeeper&#43;Base62</title>
			<link>https://jiekun.dev/posts/2020-02-15-%E7%9F%AD%E9%93%BE%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-counterzookeeperbase62/</link>
			<pubDate>Sat, 15 Feb 2020 05:02:40 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-02-15-%E7%9F%AD%E9%93%BE%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-counterzookeeperbase62/</guid>
			<description>我们最后设计出的系统架构如图所示，如果想了解最后的结论可以跳到最后一小节。这个系统理论上可以支持大流量的生成请求，分布式部署便于扩展。当然在</description>
			<content type="html"><![CDATA[<p>我们最后设计出的系统架构如图所示，如果想了解最后的结论可以跳到最后一小节。这个系统理论上可以支持大流量的生成请求，分布式部署便于扩展。当然在使用的存储方案性能上没有过多的讨论，因为这次的重点是解决“唯一”、“分布式”的ID问题。</p>
<h2 id="准备设计">准备设计</h2>
<p>设计一个系统之前，我们应该对系统的需求有所了解。对于短链系统，首先应该有以下思考：</p>
<ul>
<li>我们需要什么样的短链接，具体是多短？</li>
<li>短链系统的请求量有多大？</li>
<li>这是个单实例还是分布式系统？</li>
</ul>
<p>首先我们可以做一些假设，例如参考Twitter有3亿访问/月，我们假设有它的10%，也就是3千万/月，平均每日100万。</p>
<p>然后再来假设生成的短链，一般格式为<code>domain/unique_id</code>，例如<code>s-url.com/D28CZ63</code>，我们假设Unique ID的长度最多为7位。</p>
<p>下面我们根据这些假设条件来完成这个系统的设计。</p>
<h2 id="数据量计算">数据量计算</h2>
<p>根据上面的假设，首先每个原始URL可以按照2KB估算（2048字符），而短URL可以按照17Byte估算；我们可能还需要记录创建时间和过期时间，分别是7Byte。因此可以大致估算每行记录的大小应该为2.031KB。</p>
<p>我们一共有30M月访问，<code>30M * 2.031KB = 60.7GB</code>，<strong>每月约60GB数据</strong>，因此一年内估算为<strong>0.7TB</strong>，<strong>5年3.6TB</strong>数据量。</p>
<h2 id="唯一id算法">唯一ID算法</h2>
<p>我们需要的是一个短的（7位）唯一ID生成方案。考虑Base62和MD5，Base62即使用0-9A-Za-z一共62个字符，MD5使用0-9a-z，一般输出长度为32的字符串。</p>
<p>使用MD5的话，因为输出长度固定，我们可能需要截取其前7位来作为唯一ID，这种情况下，首先不同的输入可能会输出相同的MD5，其次，不同的MD5的前7位也可能是相同的。这样的话会产生不少的Collision，需要业务上进行保障。而使用MD5的好处，也恰恰是如果不同用户提交相同输入，那么可以得到相同的ID而不需要重复生成新的短链ID，但是同样需要业务进行处理和保证。</p>
<p>对于Base62，每一位有62个可能字符串，7位则是<code>62^7=3521614606208</code>种组合，每秒产生1000个ID的话也足够使用110年。同时在短URL的要求上，Base62接受输入，产生的输出长度会根据输入变化，因此不需要进行截取，而只需要想办法将7位ID的所有情况消耗完毕就可以满足大部分场景的要求。Base62伪代码如下：</p>
<pre tabindex="0"><code>f base62_encode(deci):
    s = '0-9A-Za-z'
    hash_str = ''
    while deci &gt; 0:
        hash_str = s[deci % 62] + hash_str
        deci /= 62
    return hash_str

</code></pre><h2 id="存储选择">存储选择</h2>
<p>一般我们会考虑使用RDBMS比如MySQl，或者NoSQL比如Redis。在关系型数据库中，横向扩展会比较麻烦，例如MySQL进行分表和分库，我们可能需要多个实例，而扩展需要一开始就设想好，但是这一点在NoSQL中会相对比较容易，例如使用一个Redis的Cluster，或许向里面添加节点会相对容易一点。而使用NoSQL我们可能需要考虑数据的最终一致性，还有数据的持久化等问题。</p>
<p>同时根据业务场景，从性能上考虑如果在高峰期有大量短链生成请求需要写入到MySQL或许表现会比Redis差一些。</p>
<p>对于将“长URL-短URL”的映射关系写入数据库的步骤，重点是确保这个短URL没有被其他长URL使用过。如果使用过，那么你需要想办法使用新的字符串生成这个短URL。</p>
<p>先来想一下，这是一个两步操作，首先查询是否存在，然后写入。如果这是个串行，那么是可行的。如果这是一个并行操作，很显然，你可能查询的时候发现没有存在这个短URL，而其他Session也查到了同样的结果，最后大家都认为可以写入，然后写入过程中晚写的一方就会出问题。</p>
<p>在RDBMS中我们可能可以通过一些提供的方法来解决这个问题，例如<code>INSERT_IF_NOT_EXISTS</code>，但是在NoSQL中是没有这些方法的，因为它的设计是要实现最终一致性，所以不会提供这种支持。</p>
<h2 id="基于以上分析和假设的方案">基于以上分析和假设的方案</h2>
<p>我们需要确定的内容主要是：</p>
<ul>
<li>生成算法</li>
<li>存储选择</li>
</ul>
<p>目前罗列出来的方案主要包括：MD5，Base62，以及MySQL和Redis。</p>
<p>如果使用MD5的话，需要使用能够解决哈希冲突的RDBMS，因为这个步骤在NoSQL上处理比较麻烦，所以会有MD5+MySQL的组合。这套组合实际上性能并不太满足需求，并且在扩展上会相对另外一组组合难度大些。</p>
<p>那么另外一种就是我们打算使用的方案：Base62+Redis。如何将7位Base62的所有情况都用尽，我们可以采用一个计数器，从0-62^7的数字转为Base62，作为短链ID使用。这个方案在单实例上是很容易的，并且可以保证冲突问题。那么如何实现它的可扩展性呢？</p>
<p>在接入大流量的情况下，我们必然需要部署多点的ID生成服务，那么根据思路，我们需要对应的计数来转换成Base62的唯一ID，如果不同的服务拿到了同样的计数，那么就会生成相同的ID，造成冲突，且因为分布式的部署，仍然能够正常写入。</p>
<p>因此现在问题转化为如何让不同的服务拿到正确的计数。因为总的数字段是已知的（0-62^7），一个很简单的方法就是我们提前将这些数字进行分段，每个ID生成服务都拿到不同段的数字本地使用。例如：</p>
<pre tabindex="0"><code>0-100000
100001-200000
200001-300000
300001-400000
400001-500000
500001-600000
...

</code></pre><p>当服务的计数消耗完毕后，继续向计数分配的服务请求下一段可用的数字。例如目前有3个ID生成服务A、B、C，在最初的分配中A拿到了0-100000号码段，B拿到了100001-200000，C拿到了200001-300000。当A使用完之后，询问分配服务，拿到下一段300001-400000。如此即可解决计数器分布式部署的问题。</p>
<p>在数字段分配的业务场景，很容易想到使用ZooKeeper实现，因为ZooKeeper是分布式架构，保障单点故障时仍然可以正确地分配计数号码，这样我们不用重复造轮子实现自己的高可用的分发服务。</p>
<h2 id="2020-03-03号段生成与获取">2020-03-03：号段生成与获取</h2>
<p>补充这一段主要因为很想尝试一下，ZK对于自己来说还是太过陌生，于是就花了点时间测试。</p>
<h3 id="初始化">初始化</h3>
<pre tabindex="0"><code>import json
from kazoo.client import KazooClient

zk = KazooClient(hosts='127.0.0.1:2181')
zk.start()
exist = zk.exists(&quot;/url-shortener&quot;)
if exist:
    quit()

# Node not exist. Initializing with counter range
zk.create(&quot;/url-shortener&quot;)

uid_length = 7
start = 62 ** uid_length
end = start + 100000
data = json.dumps({
    &quot;start&quot;: start,
    &quot;end&quot;: end
}).encode(&quot;utf-8&quot;)
zk.create(&quot;/url-shortener/range-&quot;, value=data, sequence=True)

children = zk.get_children(&quot;/url-shortener&quot;)
int(children)

</code></pre><p>连接上本地的ZK，如果目录已经存在，说明已经完成过初始化了，直接结束。</p>
<p>初始化过程也就是根据配置参数初始化对应的起始数值，因为我需要一个7位长度的ID，对应base62的数值起始位置是<code>62 ** 7</code>。号段长度可以分配，号段太长的话，如果有应用的节点挂掉，则有可能浪费掉一段；号段太短，则应用节点需要频繁向ZK询问取号。这里设置为100000。</p>
<p>拿到号段始末后，初始化一个顺序的znode，顺序是因为我可以提前生成一堆znode保存数据，Client直接取即可。不过这里测试过62^7-62^8的范围实在是太大了，按照区间长度为100000来分配的话需要预先初始化<code>(62^8 - 62^7) / 100000 = 2148184909</code>个节点，完全没有必要。先初始化1个节点，然后让Client取的时候自动生成下一段即可。</p>
<h3 id="取号">取号</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">from</span> <span class="nn">kazoo.client</span> <span class="kn">import</span> <span class="n">KazooClient</span>
<span class="n">zk</span> <span class="o">=</span> <span class="n">KazooClient</span><span class="p">(</span><span class="n">hosts</span><span class="o">=</span><span class="s1">&#39;127.0.0.1:2181&#39;</span><span class="p">)</span>
<span class="n">zk</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">lock</span> <span class="o">=</span> <span class="n">zk</span><span class="o">.</span><span class="n">Lock</span><span class="p">(</span><span class="s2">&#34;/url-shortener-lock&#34;</span><span class="p">,</span> <span class="s2">&#34;get_range&#34;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_range</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">lock</span><span class="p">:</span>
        <span class="n">exist</span> <span class="o">=</span> <span class="n">zk</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&#34;/url-shortener&#34;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">exist</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;ZK path not exist!&#34;</span><span class="p">)</span>

        <span class="n">children</span> <span class="o">=</span> <span class="n">zk</span><span class="o">.</span><span class="n">get_children</span><span class="p">(</span><span class="s2">&#34;/url-shortener/&#34;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">children</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">children</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">node_path</span> <span class="o">=</span> <span class="s2">&#34;/url-shortener/</span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">stat</span> <span class="o">=</span> <span class="n">zk</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">node_path</span><span class="p">)</span>
            <span class="n">seq_range</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&#34;utf-8&#34;</span><span class="p">))</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">seq_range</span><span class="p">[</span><span class="s2">&#34;start&#34;</span><span class="p">]</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">seq_range</span><span class="p">[</span><span class="s2">&#34;end&#34;</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Process </span><span class="si">%d</span><span class="s2"> gets range: </span><span class="si">%d</span><span class="s2">-</span><span class="si">%d</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">(),</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>
            <span class="c1"># generating next range</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">end</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">100000</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
                <span class="s2">&#34;start&#34;</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
                <span class="s2">&#34;end&#34;</span><span class="p">:</span> <span class="n">end</span>
            <span class="p">})</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span>
            <span class="n">zk</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s2">&#34;/url-shortener/range-&#34;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">sequence</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">zk</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">node_path</span><span class="p">)</span>
            <span class="n">children</span> <span class="o">=</span> <span class="n">zk</span><span class="o">.</span><span class="n">get_children</span><span class="p">(</span><span class="s2">&#34;/url-shortener&#34;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Running out of range!&#34;</span><span class="p">)</span>
    <span class="k">return</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">get_range</span><span class="p">()</span>

</code></pre></div><p>取号逻辑也很简单，暂时还没有完善异常处理。检查指定的Path下是否有znode可用，如果没有的话可能是异常或号段用完，对应处理一下即可。然后获取znode的值，作为自己目前的号段范围。</p>
<p>生成下一个号段，那么就用上一段的末尾加上固定长度就行，同样创建一个znode，删除旧的节点。</p>
<p>原来确实是这么考虑的，不过发现，如果有多个Client同时尝试获取range，因为读znode和写znode和删除znode并不是原子操作，多个节点读到znode信息后，用作自己的range（已重复），创建新znode（创建了多个顺序的，内容相同的znode），删除znode（只有1个会操作成功，其余出错），所以数据都是错的。</p>
<p>既然用到了ZK，那么顺便来用一下ZK的分布式锁，原理就是创建对应的用作锁的顺序znode，序号靠后的client需要注册对应的watcher等待前一把锁释放（删除），当前面的锁释放（或挂掉，临时znode自动删除）触发watcher后，后面的client获得锁。kazoo已经为我们实现好了对应的逻辑，在执行过程中，可以看到<code>/url-shortener-lock</code>路径下的znode：</p>
<pre tabindex="0"><code>[zk: localhost:2181(CONNECTED) 121] ls /url-shortener-lock
[1f5cda205022418c8b7db432a667dfd5__lock__0000000342, 9dffb44d40a74bbc969c4c64616b77d2__lock__0000000344, a829fbf9835c46bbaa4af4dda02aa9c1__lock__0000000343]

</code></pre><p>我们运行了3个并行的进程，因此有3个znode被创建，只有其中1个能执行临界区的代码。执行结果就是各自获取到了不同的range，符合期望：</p>
<pre tabindex="0"><code>(zk) duck@duck-MS-7A34:~/src/apache-zookeeper-3.5.7-bin/script$ ./run_consume.sh 
Process 14188 gets range: 3521648606548-3521648706548
Process 14186 gets range: 3521648706549-3521648806549
Process 14187 gets range: 3521648806550-3521648906550
All done
</code></pre>]]></content>
		</item>
		
		<item>
			<title>Redis哨兵故障转移</title>
			<link>https://jiekun.dev/posts/2020-01-31-redis%E5%93%A8%E5%85%B5%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB/</link>
			<pubDate>Fri, 31 Jan 2020 13:26:45 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-01-31-redis%E5%93%A8%E5%85%B5%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB/</guid>
			<description>下线标记 Sentinel定期向Master节点发送PING命令，若在限定时间内没有收到有效回复，则会将该节点状态中的flags字段设为SRI</description>
			<content type="html"><![CDATA[<h2 id="下线标记">下线标记</h2>
<p>Sentinel定期向Master节点发送<code>PING</code>命令，若在限定时间内没有收到有效回复，则会将该节点状态中的flags字段设为<code>SRI_S_DOWN</code>，即标记为主观下线状态，同时尝试向其他Sentinel询问节点状态。</p>
<p>Sentinel使用：</p>
<pre tabindex="0"><code>SENTINEL is-master-down-by-addr &amp;lt;ip&gt; &amp;lt;port&gt; &amp;lt;current_epoch&gt; &amp;lt;runid&gt;

</code></pre><p>来询问其他Sentinel是否同意主服务器已下线，其他Sentinel按照以下格式回复:</p>
<pre tabindex="0"><code>1) &amp;lt;down_state&gt;
2) &amp;lt;leader_runid&gt;
3) &amp;lt;leader_epoch&gt;

</code></pre><p>若down_state为1，则说明同意下线状态。</p>
<p>当有足够的Sentinel同意下线数量，Sentinel会将该Master节点状态中的flags字段设为<code>SRI_O_DOWN</code>，表示进入客观下线状态。</p>
<h2 id="选举领头sentinel">选举领头Sentinel</h2>
<p>当有Master节点被标记为客观下线，监视这个下线Master节点的各个Sentienl会进行协商，选举领头Sentinel进行故障转移操作。</p>
<p>所有的该Master节点的Sentinel都有被选为领头节点的资格。每次选举中不管是否成功，Sentinel配置中的纪元epoch都要加1。</p>
<p>在每个epoch内，各个Sentinel都可能成为领头，局部领头一旦设置，在当前epoch内就不能改变。</p>
<p>每个发现Master节点进入客观下线的Sentinel都会要求其他Sentinel将自己设置为局部领头Sentinel。当一个Sentinel向对方发送<code>is-master-down-by-addr</code>命令且ip参数为<code>*</code>时，即表示希望对方将自己设置为领头。设置规则为先到先得，后续的申请都会被拒绝。对方收到申请后会响应命令回复，回复中的leader_runid和leader_epoch分别记录了局部领头的运行id和配置纪元。源Sentinel会判断对方响应的runid和epoch是否与自己对应，如果对应则说明对方将自己设置为局部领头。当某个Sentinel被半数以上的Sentinel设置为局部领头，那么这个Sentinel成为领头Sentinel。</p>
<p>如果在时限内没有Sentinel拿到半数以上投票，则开始一个新的纪元重新进行选举。</p>
<h2 id="故障转移">故障转移</h2>
<p>领头Sentinel确定后，领头Sentinel对下线的Master节点进行故障转移：</p>
<ul>
<li>从下线Master节点的从服务器中挑选一个转为主服务器</li>
<li>让已经下线的节点的从服务器改为复制新的主服务器</li>
<li>将已经下线的节点设置为新的Master的从服务器</li>
</ul>
<p>选择新Master服务器按照如下规则逐步过滤：</p>
<ul>
<li>删除已经下线的从服务器</li>
<li>删除最近5秒内没有回复过领头Sentinel的INFO命令的从服务器</li>
<li>删除与已下线主服务器断开连接超过<code>down-after-milliseconds</code> * 10毫秒的从服务器，以保证从服务器没有过早与主服务器断开连接</li>
<li>根据从服务器的优先级进行排序，优先级相同则按照复制偏移量排序，最后按照runid进行排序</li>
</ul>
<p>Sentinel向新选出的主服务器发送<code>slaveof no one</code>命令，并且持续发送<code>INFO</code>命令观察服务器的角色是否从role变为master。</p>
<p>当新Master的角色改变后，Sentinel向其他从服务器发送<code>slaveof</code>命令使他们复制新的主服务器。</p>
<p>当旧的Master上线后，Sentinel也会向它发送<code>slaveof</code>命令，让他成为从服务器。</p>
]]></content>
		</item>
		
		<item>
			<title>TCP补充笔记</title>
			<link>https://jiekun.dev/posts/2020-01-21-tcp%E8%A1%A5%E5%85%85%E7%AC%94%E8%AE%B0/</link>
			<pubDate>Tue, 21 Jan 2020 05:50:32 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-01-21-tcp%E8%A1%A5%E5%85%85%E7%AC%94%E8%AE%B0/</guid>
			<description>春节假期期间补充学习的内容，查缺补漏，先从TCP开始。 选择确认的重传（SACK） TCP头部包含一个可选的选项变量，如图所示： 其中可以用来填充</description>
			<content type="html"><![CDATA[<p>春节假期期间补充学习的内容，查缺补漏，先从TCP开始。</p>
<h2 id="选择确认的重传sack">选择确认的重传（SACK）</h2>
<p>TCP头部包含一个可选的选项变量，如图所示：</p>
<p><img src="../2020/01/tcp_option.jpg" alt="">
其中可以用来填充以下内容：</p>
<p><img src="../2020/01/tcp_option_list.jpg" alt="">
在数据传输过程中，因为TCP抵达的顺序是不予保证的，因此接收方必然会有收到乱序数据的情况。</p>
<p>在没有SACK的情况下，接收方在缺失数据时，会一直进行ACK并附带期望的SEQ，发送方在重复（duptrash常量，默认3次）收到同一个序列号时会断定有包在传输过程中丢失，然后进行重传。</p>
<p>如果TCP发送方能够了解接收方当前的空洞，它就能在报文段丢失或者接收方遗漏的时候更好地进行重传工作，且减少不必要的重传。在丢包严重的情况下，SACK可以在一个RTT内填补多个空缺。</p>
<p>ACK号与接收端缓存中的其他数据之间的间隔称为“空缺”，序列号高于“空缺”的数据称为“失序数据”。一个ACK可以包含三四个告知失序数据的SACK信息，每个SACK信息包含32位序列号，代表接收端存储的失序数据的<strong>起始至最后一个序列号</strong>。</p>
<h3 id="sack接收端">SACK接收端</h3>
<p>第一个SACK块内包含的时最近接收到的报文段的序列号范围，其余SACK块包含的内容也按照接收的先后顺序依次排列。也就是说，最新一个块中包含的内容除了包含最近接收的序列号信息，还需要重复之前SACK块。这样可以为防止SACK丢失提供一些备份，若SACK不会丢失，每个SACK中包含一个SACK块即可实现SACK全部功能。</p>
<h3 id="sack发送端">SACK发送端</h3>
<p>合理利用接收到的SACK块进行丢失重传，称为选择性重传。一种方法是当接收到相应序列号范围的ACK时，则在其重传缓存中标记该报文段的选择重传成功。</p>
<p>当发送端收到SACK时，可以选择发送新数据或重传旧数据。通过SACK提供的序列号范围可以推断需要重传的空缺数据。最常用、最简单的方法是使发送端首先填补接收端的空缺，然后继续发送新数据。</p>
<p>SACK发送端不能在收到一个SACK后立即清空其重传缓存中的数据，因为接收端告诉发送端一段SACK范围，其后可能会“食言”。只有当ACK号大于缓存序列号时才能将缓存清除。</p>
<h2 id="普通的重传timer-based和fast-retransmit">普通的重传（Timer-based和Fast Retransmit）</h2>
<h3 id="基于计时器的重传">基于计时器的重传</h3>
<p>基于计时器的重传需要RTT的测量值，而这个测量值的确定算法较为复杂，后文再详细描述。</p>
<p>当TCP发送端拿到RTT测量值，就可以设置RTO。</p>
<p>发送单记录需要被计时的报文段序列号，如果收到了报文的ACK，那么计时器取消；若在设定的RTO内没有收到ACK，将会触发超时重传。发送端会降低当前数据的发送率来对此快速响应：</p>
<ul>
<li>基于拥塞控制机制，减小发送窗口（cwnd）大小</li>
<li>每一个重传报文被再次重传时，增大RTO的退避因子：RTO=γRTO，其中γ初始为1，随着重传加倍增长：2、4、8等。一旦接收到ACK则重置为1。</li>
</ul>
<p>下面再来说一下RTT的测量，RTT即round-trip time，TCP接收端在收到数据后会返回确认信息，因此可以在这个信息中携带一个字节的数据来测量传输该确认信息所需的时间。每个测量结果称为RTT样本。TCP需要根据一段时间内的样本建立好估计值，再根据估计值设置RTO。</p>
<p>经典方法采用如下公式计算得到平滑的RTT估计值（SRTT）：</p>
<pre tabindex="0"><code>SRTT ← α(SRTT) + (1 − α) RTTs

</code></pre><p>基于现存值和新的RTTs得到更新结果，常量α为平滑因子。</p>
<p>标准方法采用如下算式，其中M代表RTT测量值（前面称RTTs）：</p>
<pre tabindex="0"><code>tt ← (1 - g)(srtt) + (g)M
rttvar ← (1 - h)(rttvar) + (h)(|M - srtt|)
RTO = srtt + 4(rttvar)

</code></pre><h3 id="快速重传">快速重传</h3>
<p>快速重传机制基于接收端的反馈信息来引发重传，更加及时有效修复丢包情况。当接收到失序报文段时，TCP需要立即生成确认信息（重复ACK）。重复ACK到达发送端表明先前发送的某个分组已经丢失，当然也可能仅是失序到达。通常我们无法区分，TCP等待一定数目（duptresh）的重复ACK后，就决定数据是否丢失并触发快速重传。</p>
<h2 id="nagle算法与延时ack">Nagle算法与延时ACK</h2>
<h3 id="nagle">Nagle</h3>
<p>假设有如下场景：每次TCP的数据部分非常小，TCP头部和IP头部体积固定为40字节，那么这些小包因为有效的应用数据占比甚微，就会造成很高的网络传输代价。</p>
<p>John Nagle提出了一种算法，当一个TCP连接中有在传数据，则长度小于SMSS的报文段都不能发送，直到所有在传数据收到ACK。并且，在ACK后，TCP需要收集这些小的数据，将其整合到一个报文段中发送。</p>
<p><img src="../2020/01/tcp_nagle.jpg" alt="">
在Nagle开启下，传输的包数量更少，但是长度更大，同时传输时延也更长。</p>
<h3 id="延时确认">延时确认</h3>
<p>TCP并不是对每个到来的数据包都返回ACK，通常会积累一段时间发送TCP，减少ACK传输数目。对于批量数据传输通常为2:1的比例。</p>
<h3 id="结合">结合</h3>
<p>如果直接将Nagle和延时ACK结合，接收端会尝试等待，看是否有更多的ACK可以捎带进行应答，而发送端因为Nagle的存在，在没有接收到ACK前不能进行发送，就会产生死锁。死锁在延时ACK计时器超时后就会解除，但是在死锁期间传输连接处于空闲状态，性能会变差。</p>
<p>某些情况下，例如ssh传输，就可以禁用Nagle算法。</p>
<h2 id="拥塞控制">拥塞控制</h2>
<p>反映网络传输能力的变量称为拥塞窗口（congestion window），记作cwnd，通告窗口（advertisement window）记为awnd，实际发送端可用的窗口为：</p>
<pre tabindex="0"><code>W = min(cwnd, awnd)

</code></pre><p>因此还没有收到ACK回复的数据量（称为在外数据值）不能多于W。</p>
<p>然而cwnd、awnd等值需要动态调节，因此并不能准确获取。W值不能过大或过小，我们希望有一个最佳窗口大小。</p>
<h3 id="获得cwnd">获得cwnd</h3>
<p>获得最佳值的方法是以越来越快的速度发送数据，直到出现数据丢失或网络阻塞。一般可以以awnd启动或者慢速启动，因为直接以awnd启动会影响其他连接性能，所以通常避免过快启动。</p>
<h3 id="慢启动">慢启动</h3>
<p>一个新的TCP连接建立或者检测到重传超时导致的丢包时，需要执行慢启动。慢启动的目的是让TCP使用拥塞避免探寻更多带宽前得到cwnd值，以及帮助TCP建立ACK时钟。</p>
<p>TCP在SYN后开始慢启动，称为初始窗口（Initial Window，IW）。初始值设为一个SMSS值或稍大。假设没有出现丢包，第一个数据段的ACK到达，慢启动算法会以min(N, SMSS)来增加cwnd值。N是指在传输数据中通过这一ACK确认的字节数（不包括ACK号小于之前收到ACK号的数据）。</p>
<p>那么在接收到1个数据段的ACK后，cwnd就会变为2，发送2个数据段。在接收到对应的新ACK后，cwnd就会变为4，以此类推。</p>
<p><img src="../2020/01/tcp_slow_start.jpg" alt="">
然而因为ACK并不是每一次都会累积发送端一次发送的包进行ACK，例如，发送端在cwnd变为4后，发送了4个包，而接收端在接收前两个包后进行ACK（长度为2），接收到后两个包后进行ACK（长度也为2），那么此时min(N, SMSS)因为N为2个MSS，并非发出去的4个MSS，所以cwnd = cwnd + 2，而不是 cwnd = cwnd * 2的指数增长。具体见下图的两种增长曲线：</p>
<h3 id="拥塞避免">拥塞避免</h3>
<p>通过慢启动，cwnd会快速增长，帮助建立一个慢启动阈值。一旦确定慢启动阈值，TCP会进入拥塞避免阶段，cwnd每次增长值近似于成功传输的数据段大小。更准确说，每接收一个新的ACK，cwnd会做一下更新：</p>
<pre tabindex="0"><code>nd(t+1) = cwnd(t) + SMSS * SMSS/cwnd(t)

</code></pre><p>通常认为，拥塞避免阶段窗口随时间线性增长，慢启动阶段呈指数增长。</p>
<p>当cwnd &lt; ssthresh，使用慢启动算法；反之使用拥塞避免。</p>
<p>慢启动阈值在重传时按照下式改变：</p>
<pre tabindex="0"><code>thresh = max(flight size/2, 2*SMSS)
</code></pre>]]></content>
		</item>
		
		<item>
			<title>[翻译] UUID方案很受欢迎，但是于性能不利</title>
			<link>https://jiekun.dev/posts/2019-12-28-%E7%BF%BB%E8%AF%91-uuid%E6%96%B9%E6%A1%88%E5%BE%88%E5%8F%97%E6%AC%A2%E8%BF%8E%E4%BD%86%E6%98%AF%E4%BA%8E%E6%80%A7%E8%83%BD%E4%B8%8D%E5%88%A9/</link>
			<pubDate>Sat, 28 Dec 2019 10:23:47 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-28-%E7%BF%BB%E8%AF%91-uuid%E6%96%B9%E6%A1%88%E5%BE%88%E5%8F%97%E6%AC%A2%E8%BF%8E%E4%BD%86%E6%98%AF%E4%BA%8E%E6%80%A7%E8%83%BD%E4%B8%8D%E5%88%A9/</guid>
			<description>在网上搜索UUID方案和MySQL，你能查到一大堆结果，比如： 存储UUID和Generated Columns 在MySQL中存储UUID值 InnoDB中的</description>
			<content type="html"><![CDATA[<p>在网上搜索UUID方案和MySQL，你能查到一大堆结果，比如：</p>
<ul>
<li><a href="https://www.percona.com/blog/2017/05/03/uuid-generated-columns/">存储UUID和Generated Columns</a></li>
<li><a href="https://www.percona.com/blog/2014/12/19/store-uuid-optimized-way/">在MySQL中存储UUID值</a></li>
<li><a href="https://www.percona.com/blog/2015/04/03/illustrating-primary-key-models-in-innodb-and-their-impact-on-disk-usage/">InnoDB中的主键模型及它们对磁盘使用的影响</a></li>
<li><a href="http://www.mysqltutorial.org/mysql-uuid/">MySQL UUID Smackdown: UUID与整型的主键对比</a></li>
<li><a href="http://mysql.rjweb.org/doc.php/uuid">GUID/UUID性能突破</a></li>
<li><a href="https://www.percona.com/blog/2007/03/13/to-uuid-or-not-to-uuid/">用还是不用UUID？</a></li>
</ul>
<p>所以对于资料如此完善的话题还需要更多讨论吗？很明显是要的。尽管很多文章都是提醒人们少用UUID方案，但它们还是很受欢迎。受欢迎的原因是UUID值可以很方便地由远程设备生成，并且冲突概率非常低。这篇文章里我的目标是总结其他人写的内容，并且尽可能提出一些新的观点。</p>
<h2 id="什么是uuid方案">什么是UUID方案？</h2>
<p>UUID即全局唯一标识符（Universally Unique IDentifier），在<a href="https://tools.ietf.org/html/rfc4122">RFC 4122</a>定义。它的格式是128位，16进制，由“-”分割成5部分。典型的UUID值如下：</p>
<pre tabindex="0"><code>yves@laptop:~$ uuidgen 
83fda883-86d9-4913-9729-91f20973fa52

</code></pre><p>官方来说，一共有5类UUID值，版本1-5,但最常见的是：基于时间的版本（版本1或版本2）和纯随机的版本（版本3）。基于时间的UUID方案将1970年1月1日以来的10ns数量编码成7.5字节（60位），分割为“time-low”-“time-mid”-“time-hi”的样式。空缺的4位是用在time-hi段作为prefix。这样前三段的64位就定下来了。后两段是时间序列即一个随时间改动而增加的值，和宿主唯一标识符（host unique identifier）。大多数时候，当前宿主网络的MAC地址都会被用来当作唯一标识符。</p>
<p>在使用基于时间的UUID时，有几个重要的点需要考虑：</p>
<ul>
<li>在前三段的值生成后，就可以用来确认大致的时间</li>
<li>在连续的UUID值中会有大量重复的段</li>
<li>第一段“time-low”每过429秒就会耗尽重置</li>
<li>MySQL UUID函数产生的是版本1的值</li>
</ul>
<p>以下是使用“uuidgen”Unix工具产生的基于时间的UUID值：</p>
<pre tabindex="0"><code>yves@laptop:~$ for i in $(seq 1 500); do echo &quot;$(date +%s): $(uuidgen -t)&quot;; sleep 1; done
1573656803: 572e4122-0625-11ea-9f44-8c16456798f1
1573656804: 57c8019a-0625-11ea-9f44-8c16456798f1
1573656805: 586202b8-0625-11ea-9f44-8c16456798f1
...
1573657085: ff86e090-0625-11ea-9f44-8c16456798f1
1573657086: 0020a216-0626-11ea-9f44-8c16456798f1
...
1573657232: 56b943b2-0626-11ea-9f44-8c16456798f1
1573657233: 57534782-0626-11ea-9f44-8c16456798f1
1573657234: 57ed593a-0626-11ea-9f44-8c16456798f1
...

</code></pre><p>第一段的值（在t=1573657086）重置，第二段值会增加。每过大约429秒就会在第一段看到类似的值。第三段值每年变1次。最后一段值在同一台的宿主机上是固定的，就是我的笔记本上的MAC地址：</p>
<pre tabindex="0"><code>yves@laptop:~$ ifconfig | grep ether | grep 8c
      ether 8c:16:45:67:98:f1  txqueuelen 1000  (Ethernet)

</code></pre><p>另一种常见的UUID版本是版本4，纯随机。默认情况下，Unix“uuidgen”工具生成的是版本4的UUID值：</p>
<pre tabindex="0"><code>yves@laptop:~$ for i in $(seq 1 3); do uuidgen; done
6102ef39-c3f4-4977-80d4-742d15eefe66
14d6e343-028d-48a3-9ec6-77f1b703dc8f
ac9c7139-34a1-48cf-86cf-a2c823689a91

</code></pre><p>唯一重复的值是版本“4”，在第三段的开头。其余的124位都是随机的。</p>
<h2 id="uuid值有什么问题">UUID值有什么问题？</h2>
<p>为了理解UUID用作主键的影响，首先要复习一下InnoDB是如何组织数据的。InnoDB将表中的行存储在主键的B树中，在数据库中我们称之为聚簇索引。聚簇索引自动将数据行按主键顺序排列。</p>
<p>当你插入一行随机主键值的数据，InnoDB需要找到这行应该属于哪一页，如果页没在缓冲池中则将其加载进缓冲池，插入数据行，最后将脏页刷回磁盘。纯随机值加上大表使得B树上的每个叶子节点都有机会插入行，而没有热点数据页。数据行不按照主键顺序（译注：主键顺序指主键顺序的末端）插入会导致页的分裂，进一步导致页的填充因子降低。在缓冲池中，有新数据插入的页称为脏页。而缓冲池中的页在被刷回磁盘前再次有新数据需要写入的概率很低。所以大部分时间中，每次插入操作会导致两次IO过程——一次读取和一次写入。所以首先UUID会对IO操作的比例造成影响，而这个又是伸缩性的主要限制因素。</p>
<p>获得高性能的唯一方法就是使用低延迟和高耐久的存储介质。然而这又是一个对性能造成影响的因素。因为聚簇索引的存在，辅助索引需要使用主键值作为指针。主键B树的叶子节点存储数据行，而辅助索引的叶子节点存储主键值。</p>
<p>我们假定有一个UUID作主键的表，并且有5个辅助索引，一共10亿行数据。如果你读了前面的段落，你会知道每行主键值被存了6次。也就是说一共6亿的36字节字符串值，216GB。这只是冰山一角而已，因为表通常还会有外键，显式或者隐式地指向其他表。当表是基于UUID设计的时候，列或者索引需要以<code>char(36)</code>来容纳数据。最近我分析了一个基于UUID的表，发现70%的存储空间都用来存放UUID值。</p>
<p>不止这些，UUID还有第三点影响。整型在CPU中一次性可以比较8字节，而UUID是逐字节比较的。数据库很少会受限于CPU性能，但是不管怎么样这都会提高查询的延迟。如果你不信，来看看整型和字符串的性能对比：</p>
<pre tabindex="0"><code>mysql&gt; select benchmark(100000000,2=3);
+--------------------------+
| benchmark(100000000,2=3) |
+--------------------------+
|                        0 |
+--------------------------+
1 row in set (0.96 sec)

mysql&gt; select benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='df878007-80da-11e9-93dd-00163e000003');
+----------------------------------------------------------------------------------------------------+
| benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='df878007-80da-11e9-93dd-00163e000003') |
+----------------------------------------------------------------------------------------------------+
|                                                                                                  0 |
+----------------------------------------------------------------------------------------------------+
1 row in set (27.67 sec)

</code></pre><p>当然，上面的例子是最坏的情况，但也体现出两者的差距。整型的比对能比字符串型快28倍。而且就算字符串从第一位就开始不同，测试仍比整型慢2.5倍：</p>
<pre tabindex="0"><code>mysql&gt; select benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='ef878007-80da-11e9-93dd-00163e000003');
+----------------------------------------------------------------------------------------------------+
| benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='ef878007-80da-11e9-93dd-00163e000003') |
+----------------------------------------------------------------------------------------------------+
|                                                                                                  0 |
+----------------------------------------------------------------------------------------------------+
1 row in set (2.45 sec)

</code></pre><p>下面我们来看下这些问题的几种解决方案。</p>
<h2 id="值的长度">值的长度</h2>
<p>UUID、哈希、token值一般都是十六进制的形式。因此每一字节的可能情况有16种，这远算不上高效。如果用其他形式会怎么样呢，比如base64或者直接用二进制？节约了多少空间？性能影响怎么样？</p>
<p>首先我们来尝试改用base64。每一字节有64种情况，所以base64需要用3个字节来表示真实值的2个字节。UUID值包含16字节的数据，除以3余数是1，所以base64编码后末尾加了“=”。</p>
<pre tabindex="0"><code>mysql&gt; select to_base64(unhex(replace(uuid(),'-','')));
+------------------------------------------+
| to_base64(unhex(replace(uuid(),'-',''))) |
+------------------------------------------+
| clJ4xvczEeml1FJUAJ7+Fg==                 |
+------------------------------------------+
1 row in set (0.00 sec)

</code></pre><p>如果被编码的内容长度已知，像UUID，也可以直接把无用的“==”移除。UUID编码成base64之后长度为22。</p>
<p>下一个尝试是将数据存储为二进制。这是最优方案但是对于用户来说值的可读性较差。</p>
<p>所以，长度对性能的影响如何？为了战士说明，我向如下表中插入随机的，未转成其他编码的UUID值：</p>
<pre tabindex="0"><code>CREATE TABLE `data_uuid` (
  `id` char(36) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

</code></pre><p>而对base64，id列定义为<code>char(22)</code>，二进制的id列定义为<code>binary(16)</code>。数据库服务器的缓冲池大小为128M，IOPs限制至500。插入均以单线程操作。</p>
<p><img src="../2019/12/001-zhujiekun-rates_vs_sizes.png" alt="">
此场景下，写入速率开始时受CPU性能限制，随着表的增大超过缓冲池大小，写入速率变为受IO限制。这和预期的一样。使用更小长度的值代替UUID使得更多的行可以放入缓冲池中，但长远来看，因为随机插入顺序的原因，对性能的帮助很小。如果你在使用随机UUID作为主键，那么性能将受限于内存大小。</p>
<h2 id="方案1使用伪随机顺序节省iops">方案1：使用伪随机顺序节省IOPs</h2>
<p>如我们所见，最大的问题是值的随机性。任何一个叶子节点都有可能插入新数据行。所以除非整个表都加载到缓冲池，不然每次插入都会等同于一次读IO和一次写IO。我的同事David Ducos给出了一个<a href="https://www.percona.com/blog/2017/05/03/uuid-generated-columns/">好的解决方案</a>，但是一些客户不希望看到UUID值有被反解的可能性，比如说通过值获取到一个时间戳。</p>
<p>那按照固定时间间隔内在几个字节上使用同样的prefix来减少随机性又如何？在这段时间内，表中只有某一部分可以对应得上这个prefix，这部分会被放入内存以减少读IO。这样可以提高某个页在刷回磁盘前收到第二次写请求的可能性，降低写入负载。考虑下面的UUID生成方案：</p>
<pre tabindex="0"><code>function if exists f_new_uuid; 
delimiter ;;
CREATE DEFINER=`root`@`%` FUNCTION `f_new_uuid`() RETURNS char(36)
    NOT DETERMINISTIC
BEGIN
    DECLARE cNewUUID char(36);
    DECLARE cMd5Val char(32);


    set cMd5Val = md5(concat(rand(),now(6)));
    set cNewUUID = concat(left(md5(concat(year(now()),week(now()))),4),left(cMd5Val,4),'-',
        mid(cMd5Val,5,4),'-4',mid(cMd5Val,9,3),'-',mid(cMd5Val,13,4),'-',mid(cMd5Val,17,12));

    RETURN cNewUUID;
END;;
limiter ;

</code></pre><p>UUID的前四个字符由当前年和周的值MD5得到。这个值会在一周内都保持不变。剩余的UUID值通过MD5一个随机值和1us精度的当前时间生成。第三段以“4”开头，意味着这是版本4的UUID。一共有65536种可能的前缀，所以一周内只有表的1/65536行会被读取到内存，避免插入时的读IO压力。这让管理更加容易，1TB的表只需要16MB存放在缓冲池中就能支撑起插入操作。</p>
<h2 id="方案2">方案2：</h2>
<p>即使使用伪随机的UUID值，以<code>binary(16)</code>存储，这还是个很大的数据类型，会让数据的体积暴涨。要记得InnoDB中主键值是辅助索引的指针。那如果用一张映射表来存储UUID值会怎么样？映射表定义如下：</p>
<pre tabindex="0"><code>CREATE TABLE `uuid_to_id` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `uuid` char(36) NOT NULL,
  `uuid_hash` int(10) unsigned GENERATED ALWAYS AS (crc32(`uuid`)) STORED NOT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_hash` (`uuid_hash`)
) ENGINE=InnoDB AUTO_INCREMENT=2590857 DEFAULT CHARSET=latin1;

</code></pre><p>要注意<code>uuid_to_id</code>表并没有要求uuid列值唯一。<code>idx_hash</code>索引更像是作为一个布隆过滤器使用。如果没有匹配中，我们可以知道UUID值不存在表上。但如果有匹配中的话，我们还需要去检验是否真的有匹配的UUID。为了完成这点，我们写一个SQL函数：</p>
<pre tabindex="0"><code>DELIMITER ;;
CREATE DEFINER=`root`@`%` FUNCTION `f_uuid_to_id`(pUUID char(36)) RETURNS int(10) unsigned
    DETERMINISTIC
BEGIN
        DECLARE iID int unsigned;
        DECLARE iOUT int unsigned;

        select get_lock('uuid_lock',10) INTO iOUT;

        SELECT id INTO iID
        FROM uuid_to_id WHERE uuid_hash = crc32(pUUID) and uuid = pUUID;

        IF iID IS NOT NULL THEN
            select release_lock('uuid_lock') INTO iOUT;
            SIGNAL SQLSTATE '23000'
                SET MESSAGE_TEXT = 'Duplicate entry', MYSQL_ERRNO = 1062;
        ELSE
            insert into uuid_to_id (uuid) values (pUUID);
            select release_lock('uuid_lock') INTO iOUT;
            set iID = last_insert_id();
        END IF;

        RETURN iID;
END ;;
DELIMITER ;

</code></pre><p>函数检查UUID值是否曾经存在在<code>uuid_to_id</code>表中，如果存在则返回对应的id至，否则插入UUID，返回<code>last_insert_id</code>。为了避免并发插入同一个UUID值，我加了一个数据库锁。数据库锁限制了方案的伸缩性。如果你的业务不允许段时间内重复提交多次，那可以把锁去掉。我也有另一个无锁版本的函数，并且使用了一个数据行仅会保存数秒的用于去重的小表。如果有兴趣可以查看我的<a href="https://github.com/y-trudeau/blog_data/tree/master/YetAnotherPostAboutUUIDs">github</a></p>
<h2 id="替代方案的测试结果">替代方案的测试结果</h2>
<p>现在让我们来看一下几种替代方案的插入速率。</p>
<p><img src="../2019/12/001-zhujiekun-alternate_solutions.png" alt="">
伪顺序的表现不错。我修改了UUID前缀的算法让它在1分钟内保持不变，而不是一周，这样更符合测试场景。但是要记住即使伪顺序的方案性能过得去，它仍会让表变得很大，性能收益也没有那么理想。</p>
<p>使用整型映射的方案，尽管插入速率更低，毕竟需要额外的DMLs，但将表从冗长的UUID值中解放了出来。表使用整型作为主键，映射关系可以将所有UUID伸缩性的担忧抛开。而且，即使是在CPU性能和IOPS受限的小型虚拟机中，UUID映射方案也达到了4000插入/秒。这意味着每小时可以写入140万行的数据，每日3450行，一年1260亿行。这样的速率应该能满足大部分需求。唯一的增长限制因素是hash索引的体积，当hash索引太大而放不进缓冲池中的时候，性能就会开始下降。</p>
<h2 id="其他非uuid的方案">其他非UUID的方案？</h2>
<p>当然，还有其他方案生成唯一ID。MySQL的<code>UUID_SHORT()</code>函数的方法就很有意思。远程设备，比如手机，可以使用UTC时间来代替服务器运行时间。例如：</p>
<pre tabindex="0"><code>(Seconds since January 1st 1970) &amp;lt;&amp;lt; 32
+ (lower 2 bytes of the wifi MAC address) &amp;lt;&amp;lt; 16
+ 16_bits_unsigned_int++;

</code></pre><p>16位计数器需要初始化一个随机值，并且允许耗尽后循环。两台设备生成同一ID的可能性很小，这需要发生在几乎同一时间，两个设备有着同样的低位MAC地址并且16位计数器值的也一致才行。</p>
<h2 id="备注">备注</h2>
<p>文章的所有相关数据都可以在我的<a href="https://github.com/y-trudeau/blog_data/tree/master/YetAnotherPostAboutUUIDs">github</a>找到。</p>
<h2 id="more">More</h2>
<p><a href="https://kalasearch.cn/community/tutorials/mysql-use-uuid-or-int-as-primary-key/">MySQL主键应该用UUID还是INT类型</a></p>
]]></content>
		</item>
		
		<item>
			<title>SYN Flood Attack</title>
			<link>https://jiekun.dev/posts/2019-12-26-syn-flood-attack/</link>
			<pubDate>Thu, 26 Dec 2019 14:03:53 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-26-syn-flood-attack/</guid>
			<description>什么是SYN Flood SYN Flood，又称TCP Flood，是利用TCP协议三次握手消耗目标服务器资源的DDoS攻击。客户端通过伪造SYN包，使用伪造</description>
			<content type="html"><![CDATA[<h2 id="什么是syn-flood">什么是SYN Flood</h2>
<p>SYN Flood，又称TCP Flood，是利用TCP协议三次握手消耗目标服务器资源的DDoS攻击。客户端通过伪造SYN包，使用伪造的源IP地址，因为服务端收到请求后会对SYN进行响应——发送SYN和ACK包，但是对方的地址是伪造的因此不会响应，服务端会重试几次后丢弃这个连接。这样会导致服务端对多个伪造的SYN包在重试响应，无暇理睬正常的连接请求。</p>
<h2 id="实践">实践</h2>
<h3 id="初步尝试">初步尝试</h3>
<p>根据定义，需要向特定服务发送大量的TCP SYN包，因此需要利用一些发包工具。通过搜索找到<a href="https://github.com/antirez/hping">hping工具</a>，作者是antirez（Redis作者）。以下是安装及文档中部分实践使用到的参数：</p>
<pre tabindex="0"><code>uck@duck-MS-7A34:~$ sudo apt install hping3
duck@duck-MS-7A34:~$ sudo hping --help
usage: hping3 host [options]
  -i  --interval  wait (uX for X microseconds, for example -i u1000)
      --fast      alias for -i u10000 (10 packets for second)
      --faster    alias for -i u1000 (100 packets for second)
      --flood      sent packets as fast as possible. Don't show replies.
IP
  -a  --spoof      spoof source address
  --rand-dest      random destionation address mode. see the man.
  --rand-source    random source address mode. see the man.
UDP/TCP
  -s  --baseport   base source port             (default random)
  -p  --destport   [+][+]&amp;lt;port&gt; destination port(default 0) ctrl+z inc/dec
  -S  --syn        set SYN flag

</code></pre><p>尝试攻击部署在阿里云的个人博客：</p>
<pre tabindex="0"><code>uck@duck-MS-7A34:~$ sudo hping3 -i u1000 -S -p 443 120.25.247.125
HPING 120.25.247.125 (enp33s0 120.25.247.125): S set, 40 headers + 0 data bytes
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=0 win=29200 rtt=15.8 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=1 win=29200 rtt=14.7 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=2 win=29200 rtt=13.6 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=3 win=29200 rtt=12.6 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=4 win=29200 rtt=11.5 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=5 win=29200 rtt=10.5 ms
...

</code></pre><p>此时可以在ECS上看到网络情况，通过netstat命令查看到处于SYN_RECV的大量TCP连接，如图所示：</p>
<p><img src="../2019/12/001-zhujiekun-SYN_RECV.png" alt=""></p>
<h3 id="暴力发包">暴力发包</h3>
<p>尝试将攻击频率调快：<code>sudo hping3 -i u1 -S -p 443 120.25.247.125</code>，然后在ECS上查看当前的SYN包个数：</p>
<pre tabindex="0"><code>uck@iZwz92ujq5zpxvm1vtq0gtZ:~$ netstat -n | grep SYN | wc -l
128

</code></pre><p>只有128个TCP半连接，与发包数量相差很大。猜测是系统配置限制了总TCP连接数上限或者半连接状态连接数上限。</p>
<p>通过查询相关文档，找到系统配置：</p>
<pre tabindex="0"><code>uck@iZwz92ujq5zpxvm1vtq0gtZ:~$ vim /etc/sysctl.conf
vm.swappiness = 0
net.ipv4.neigh.default.gc_stale_time = 120

# see details in https://help.aliyun.com/knowledge_detail/39428.html
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.lo.arp_announce = 2
net.ipv4.conf.all.arp_announce = 2

# see details in https://help.aliyun.com/knowledge_detail/41334.html
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 128
net.ipv4.tcp_synack_retries = 2

net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
net.ipv6.conf.eth0.disable_ipv6 =1

kernel.sysrq = 1

</code></pre><p>其中一项<code>net.ipv4.tcp_max_syn_backlog = 128</code>可能是有关项，并且通过查阅文件中提供的阿里云文档，得到参数和它相关参数的具体描述：</p>
<ul>
<li><code>net.ipv4.tcp_max_syn_backlog</code>：该参数决定了系统中处于SYN_RECV状态的TCP连接数量。SYN_RECV状态指的是当系统收到SYN后，作为SYN+ACK响应后等待对方回复三次握手阶段中的最后一个ACK的阶段。对于还未获得对方确认的连接请求，可保存在队列中的最大数目。如果服务器经常出现过载，可以尝试增加这个数字。默认为1024。</li>
<li><code>net.core.somaxconn</code>：该参数定义了系统中每一个端口最大的监听队列的长度，是个全局参数。该参数和net.ipv4.tcp_max_syn_backlog有关联，后者指的是还在三次握手的半连接的上限，该参数指的是处于ESTABLISHED的数量上限。当backlog大于net.core.somaxconn时，以net.core.somaxconn参数为准。</li>
</ul>
<p>那么将他们都改成一个特别大的数值然后保存，再尝试SYN Flood，结果如下：</p>
<ul>
<li>因为发包占用了很多的流量所以本机无法SSH上ECS查看</li>
<li>通过阿里云的管理面板查看到TCP包一共64000个，其中NON_ESTABLISHED状态的包占了几乎全部数量</li>
<li>访问https的博客地址无法响应</li>
</ul>
<p><img src="../2019/12/001-zhujiekun-TCP_connection_count.png" alt=""></p>
<h3 id="持续监控">持续监控</h3>
<p>在持续发包一段时间后，发现TCP连接数下降至约500个，并且博客站点重新可以访问。因为时间原因没有尝试其他的手段，主要推测可能是现有的系统（也可能是协议层、云服务商等）对暴力SYN Flood攻击有判断和校验，丢弃特定特征的包（相同IP、端口或者其他指纹）。</p>
<p>因为ECS地理位置离测试地点较近，所以通常延迟非常低。在SYN状态TCP连接数量从64k下降到500时，站点可以进行访问但是观察到速度比原来明显缓慢，通过这点猜测DoS攻击有生效但是受限于使用的发起攻击的设备流量条件不足以拖跨服务。</p>
<h2 id="延伸思考">延伸思考</h2>
<p>因为设备条件问题，虽然可以观察到大量半连接的TCP状态，但是离DoS（Denial of Service）还是有很大的差距，消耗不完目标的网络带宽或系统资源。那是否有方案通过小流量产生大流量（放大）的攻击呢？</p>
<h3 id="memcached-ddos">Memcached DDoS</h3>
<p>当Memcached服务器接收到GET请求，它从内存获取相关信息组织起一个RESPONSE，然后通过连续的UDP包进行返回。通常来说GET请求的体积和RESPONSE的体积大小可以相差很多倍。</p>
<p>攻击者可以利用这点，先向Memcached服务器插入随机的大体积数据，然后向服务器请求。根据CloudFlare的报告，这样会导致一个巨大的流量放大倍数，例如15 byte的请求可以引起134KB的响应。当Memcached响应的对象指向攻击目标机器的时候，目标机器就会收到海量的UDP包，从而可能导致拒绝服务。</p>
]]></content>
		</item>
		
		<item>
			<title>[翻译] 理解MySQL 8中的HASH JOIN</title>
			<link>https://jiekun.dev/posts/2019-12-23-%E7%BF%BB%E8%AF%91-%E7%90%86%E8%A7%A3mysql-8%E4%B8%AD%E7%9A%84hash-join/</link>
			<pubDate>Mon, 23 Dec 2019 12:18:11 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-23-%E7%BF%BB%E8%AF%91-%E7%90%86%E8%A7%A3mysql-8%E4%B8%AD%E7%9A%84hash-join/</guid>
			<description>原文标题：Understanding Hash Joins in MySQL 8 原文链接：https://www.percona.com/blog/2019/10/30/un</description>
			<content type="html"><![CDATA[<blockquote class="wp-block-quote">
  <p>
    原文标题：Understanding Hash Joins in MySQL 8<br /> 原文链接：https://www.percona.com/blog/2019/10/30/understanding-hash-joins-in-mysql-8/<br /> 作者：Tibor Korocz<br /> 译者：2014BDuck<br /> 翻译时间：2019-12-23
  </p>
</blockquote>
<p>在MySQL 8.0.18中有个新功能叫Hash Joins。我打算研究一下它是如何运作的和在什么场景下它能够帮到我们。你可以在<a href="https://dev.mysql.com/worklog/task/?id=2241">这里</a>了解它的底层原理。</p>
<p>更上层的解释：如果使用join查询，它会基于其中一个表在内存构建一个哈希表，然后一行一行读另一个表，计算其哈希值到内存哈希表中进行查找。</p>
<h2 id="很好但性能上带给我们什么好处呢">很好，但性能上带给我们什么好处呢？</h2>
<p>首先，它只会在没有索引的字段上生效，所以它是个实时的表扫描。通常我们不推荐在没有索引的列上join查询，因为这很慢。这种情况下Hash Joins就有它的优势，因为它用的是内存哈希表而不是嵌套循环（Nested Loop）。</p>
<p>让我们来做些测试。首先创建如下表：</p>
<pre tabindex="0"><code>CREATE TABLE `t1` (
`id` int(11) NOT NULL AUTO_INCREMENT ,
`c1` int(11) NOT NULL DEFAULT '0',
`c2` int(11) NOT NULL DEFAULT '0',
PRIMARY KEY (`id`),
KEY `idx_c1` (`c1`)
) ENGINE=InnoDB;

CREATE TABLE `t2` (
`id` int(11) NOT NULL AUTO_INCREMENT ,
`c1` int(11) NOT NULL DEFAULT '0',
`c2` int(11) NOT NULL DEFAULT '0',
PRIMARY KEY (`id`),
KEY `idx_c1` (`c1`)
) ENGINE=InnoDB;

</code></pre><p>我向两个表都插入了131072行随机数据。</p>
<pre tabindex="0"><code>mysql&gt; select count(*) from t1;
+----------+
| count(*) |
+----------+
| 131072   |
+----------+

</code></pre><h2 id="测试1-8211-hash-joins">测试1 – Hash Joins</h2>
<p>基于没有索引的表c2执行Join查询。</p>
<pre tabindex="0"><code>mysql&gt; explain format=tree select count(*) from t1 join t2 on t1.c2 = t2.c2\G
*************************** 1. row ***************************
EXPLAIN: -&gt; Aggregate: count(0)
-&gt; Inner hash join (t2.c2 = t1.c2) (cost=1728502115.04 rows=1728488704)
-&gt; Table scan on t2 (cost=0.01 rows=131472)
-&gt; Hash
-&gt; Table scan on t1 (cost=13219.45 rows=131472)

1 row in set (0.00 sec)

</code></pre><p>我们使用<code>explain format=tree</code>来查看Hash Join是否生效，默认情况下(explain)会误导说这会是个嵌套循环。我已经提了<a href="https://bugs.mysql.com/bug.php?id=97299">bug report</a>，在工单中你可以看到开发者回复：</p>
<blockquote class="wp-block-quote">
  <p>
    解决方法就是不要用传统的<code>EXPLAIN</code>。
  </p>
</blockquote>
<p>因此在旧的explain中这不会被修复，我们要使用新的查询方式。</p>
<p>回到语句上，我们可以看到它使用Hash Join了，但性能有多快？</p>
<pre tabindex="0"><code>mysql&gt; select count(*) from t1 join t2 on t1.c2 = t2.c2;
+----------+
| count(*) |
+----------+
| 17172231 |
+----------+
1 row in set (0.73 sec)

</code></pre><p>17000000多行数据，0.73秒。看起来很不错。</p>
<h2 id="测试2-8211-非hash-joins">测试2 – 非Hash Joins</h2>
<p>我们现在用优化器的开关或hint关掉Hash Join。</p>
<pre tabindex="0"><code>mysql&gt; select /*+ NO_HASH_JOIN (t1,t2) */ count(*) from t1 join t2 on t1.c2 = t2.c2;
+----------+
| count(*) |
+----------+
| 17172231 |
+----------+
1 row in set (13 min 36.36 sec)

</code></pre><p>同样的查询使用了超过13分钟。非常大的差距，可以看到Hash Join性能提升明显。</p>
<h2 id="测试3-8211-索引join">测试3 – 索引Join</h2>
<p>让我们来创建索引，看看基于索引的join速度如何。</p>
<pre tabindex="0"><code>te index idx_c2 on t1(c2);
create index idx_c2 on t2(c2);

mysql&gt; select count(*) from t1 join t2 on t1.c2 = t2.c2;
+----------+
| count(*) |
+----------+
| 17172231 |
+----------+
1 row in set (2.63 sec)

</code></pre><p>2.6秒。在这个测试用例中Hash Join比基于索引的Join还要快。</p>
<p>然而，我可以在索引可用的情况下，通过<code>ignore index</code>强制优化器使用Hash Join：</p>
<pre tabindex="0"><code>mysql&gt; explain format=tree select count(*) from t1 ignore index (idx_c2) join t2 ignore index (idx_c2) on t1.c2 = t2.c2 where t1.c2=t2.c2\G
*************************** 1. row ***************************
EXPLAIN: -&gt; Aggregate: count(0)
-&gt; Inner hash join (t2.c2 = t1.c2) (cost=1728502115.04 rows=17336898)
-&gt; Table scan on t2 (cost=0.00 rows=131472)
-&gt; Hash
-&gt; Table scan on t1 (cost=13219.45 rows=131472)

1 row in set (0.00 sec)

</code></pre><p>我在想即使索引存在的情况下，优化器也能够根据提示使用Hash Join，这样我们就不需要在各种表上<code>ignore index</code>了。我已经提了<a href="https://bugs.mysql.com/bug.php?id=97302">feature request</a>。</p>
<p>然而，如果你有认真阅读我提的<a href="https://bugs.mysql.com/bug.php?id=97299">bug report</a>，你会看到MySQL的开发者有表明这可能是不必要的：</p>
<blockquote class="wp-block-quote">
  <p>
    块嵌套循环（Block Nested-Loop）在某些情况下完全不会起作用，这时提示（hint）会被忽略。
  </p>
</blockquote>
<p>这意味着他们在未来可能打算移除块钱套循环Join，使用Hash Join代替。</p>
<h2 id="限制">限制</h2>
<p>我们可以看到Hash Join很强大，但也有些限制：</p>
<ul>
<li>我提到过它只在没有索引的列上其作用（或者需要手动忽略索引）</li>
<li>只有Join条件是“=”的情况才会生效</li>
<li><code>LEFT JOIN</code>和<code>RIGHT JOIN</code>不生效</li>
</ul>
<p>我还期望看到Hash Join使用次数的统计，所以我又提了<a href="https://bugs.mysql.com/bug.php?id=97301">另一个feature request</a></p>
<h2 id="总结">总结</h2>
<p>Hash Join是个很强大的join查询方式，我们应该重点关注它，未来如果有更多Feature我也不会感到惊讶。理论上，它应该也能用来做<code>LEFT JOIN</code>和<code>RIGHT JOIN</code>，我们在bug report的评论里面也能看到Oracle在未来也打算使用Hash Join。</p>
]]></content>
		</item>
		
		<item>
			<title>[翻译] InnoDB中的页合并与分裂</title>
			<link>https://jiekun.dev/posts/2019-12-22-%E7%BF%BB%E8%AF%91-innodb%E4%B8%AD%E7%9A%84%E9%A1%B5%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E8%A3%82/</link>
			<pubDate>Sun, 22 Dec 2019 14:53:53 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-22-%E7%BF%BB%E8%AF%91-innodb%E4%B8%AD%E7%9A%84%E9%A1%B5%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E8%A3%82/</guid>
			<description>原文标题：InnoDB Page Merging and Page Splitting 原文链接：https://www.percona.com/blog/2017/04/10/innodb-pa</description>
			<content type="html"><![CDATA[<blockquote class="wp-block-quote">
  <p>
    原文标题：InnoDB Page Merging and Page Splitting<br /> 原文链接：https://www.percona.com/blog/2017/04/10/innodb-page-merging-and-page-splitting/<br /> 作者：Marco Tusa<br /> 译者：2014BDuck<br /> 翻译时间：2019-12-22
  </p>
</blockquote>
<p>如果你找过任何一位MySQL顾问，问他对你的语句和/或数据库设计的建议，我保证他会跟你讲主键设计的重要性。特别是在使用InnoDB引擎的情景，他们肯定会给你解释索引合并和页分裂这些。这两个方面与性能息息相关，你应该在任何设计索引（不止是主键索引）的时候都将他们考虑在内。</p>
<p>你可能觉得这些听起来挺莫名其妙，没准你也没错。这不是容易的事，特别是讲到关于内部实现的时候。通常你都不会需要处理这些事情，并且你也不想去着手他们。</p>
<p>但是有时候这些问题又是必须搞清楚的。如果有这种情况，那这篇文章正适合你。</p>
<p>我尝试用这篇文章将一些最不清晰、InnoDB内部的操作解释清楚：索引页的创建、页合并和页分裂。</p>
<p>在InnoDB中，数据即索引（译注：索引组织数据）。你可能听过这种说法，但它具体是什么样的？</p>
<h2 id="文件表file-table结构">文件表（File-Table）结构</h2>
<p>假设你已经装好了MySQL最新的5.7版本（译注：文章发布于17年4月），并且你创建了一个<code>windmills</code>库（schema）和<code>wmills</code>表。在文件目录（通常是<code>/var/lib/mysql/</code>）你会看到以下内容：</p>
<pre tabindex="0"><code>ta/
  windmills/
      wmills.ibd
      wmills.frm

</code></pre><p>这是因为从MySQL 5.6版本开始<code>innodb_file_per_table</code>参数默认设置为1。该配置下你的每一个表都会单独作为一个文件存储（如果有分区也可能有多个文件）。</p>
<p>目录下要注意的是这个叫<code>wmills.ibd</code>的文件。这个文件由多个段（segments）组成，每个段和一个索引相关。</p>
<p>文件的结构是不会随着数据行的删除而变化的，但段则会跟着构成它的更小一级单位——区的变化而变化。区仅存在于段内，并且每个区都是固定的1MB大小（页体积默认的情况下）。页则是区的下一级构成单位，默认体积为16KB。</p>
<p>按这样算，一个区可以容纳最多64个页，一个页可以容纳2-N个行。行的数量取决于它的大小，由你的表结构定义。InnoDB要求页至少要有两个行，因此可以算出行的大小最多为8000 bytes。</p>
<p>听起来就像俄罗斯娃娃（Matryoshka dolls）一样是么，没错！下面这张图能帮助你理解：</p>
<p><img src="../2019/12/001-zhujiekun-segment_extent-722x1024.jpg" alt=""></p>
<h2 id="根分支与叶子">根，分支与叶子</h2>
<p>每个页（逻辑上讲即叶子节点）是包含了2-N行数据，根据主键排列。树有着特殊的页区管理不同的分支，即内部节点（INodes）。</p>
<p><img src="../2019/12/001-zhujiekun-bplustree-1024x471.jpg" alt="">
上图仅为示例，后文才是真实的结构描述。</p>
<p>具体来看一下：</p>
<pre tabindex="0"><code>ROOT NODE #3: 4 records, 68 bytes
 NODE POINTER RECORD ≥ (id=2) → #197
 INTERNAL NODE #197: 464 records, 7888 bytes
 NODE POINTER RECORD ≥ (id=2) → #5
 LEAF NODE #5: 57 records, 7524 bytes
 RECORD: (id=2) → (uuid=&quot;884e471c-0e82-11e7-8bf6-08002734ed50&quot;, millid=139, kwatts_s=1956, date=&quot;2017-05-01&quot;, location=&quot;For beauty's pattern to succeeding men.Yet do thy&quot;, active=1, time=&quot;2017-03-21 22:05:45&quot;, strrecordtype=&quot;Wit&quot;)

</code></pre><p>下面是表结构：</p>
<pre tabindex="0"><code>CREATE TABLE `wmills` (
  `id` bigint(11) NOT NULL AUTO_INCREMENT,
  `uuid` char(36) COLLATE utf8_bin NOT NULL,
  `millid` smallint(6) NOT NULL,
  `kwatts_s` int(11) NOT NULL,
  `date` date NOT NULL,
  `location` varchar(50) COLLATE utf8_bin DEFAULT NULL,
  `active` tinyint(2) NOT NULL DEFAULT '1',
  `time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `strrecordtype` char(3) COLLATE utf8_bin NOT NULL,
  PRIMARY KEY (`id`),
  KEY `IDX_millid` (`millid`)
) ENGINE=InnoDB;

</code></pre><p>所有的B树都有着一个入口，也就是根节点，在上图中#3就是根节点。根节点（页）包含了如索引ID、INodes数量等信息。INode页包含了关于页本身的信息、值的范围等。最后还有叶子节点，也就是我们数据实际所在的位置。在示例中，我们可以看到叶子节点#5有57行记录，共7524 bytes。在这行信息后是具体的记录，可以看到数据行内容。</p>
<p>这里想引出的概念是当你使用InnoDB管理表和行，InnoDB会将他们会以分支、页和记录的形式组织起来。InnoDB不是按行的来操作的，它可操作的最小粒度是页，页加载进内存后才会通过扫描页来获取行/记录。</p>
<p>现在页的结构清楚了吗？好，我们继续。</p>
<h2 id="页的内部原理">页的内部原理</h2>
<p>页可以空或者填充满（100%），行记录会按照主键顺序来排列。例如在使用<code>AUTO_INCREMENT</code>时，你会有顺序的ID 1、2、3、4等。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_1.jpg" alt="">
页还有另一个重要的属性：<code>MERGE_THRESHOLD</code>。该参数的默认值是50%页的大小，它在InnoDB的合并操作中扮演了很重要的角色。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_2.jpg" alt="">
当你插入数据时，如果数据（大小）能够放的进页中的话，那他们是按顺序将页填满的。</p>
<p>若当前页满，则下一行记录会被插入下一页（NEXT）中。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_4.jpg" alt="">
根据B树的特性，它可以自顶向下遍历，但也可以在各叶子节点水平遍历。因为每个叶子节点都有着一个指向包含下一条（顺序）记录的页的指针。</p>
<p>例如，页#5有指向页#6的指针，页#6有指向前一页（#5）的指针和后一页（#7）的指针。</p>
<p>这种机制下可以做到快速的顺序扫描（如范围扫描）。之前提到过，这就是当你基于自增主键进行插入的情况。但如果你不仅插入还进行删除呢？</p>
<h2 id="页合并">页合并</h2>
<p>当你删了一行记录时，实际上记录并没有被物理删除，记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_3.jpg" alt="">
当页中删除的记录达到<code>MERGE_THRESHOLD</code>（默认页体积的50%），InnoDB会开始寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_4.jpg" alt="">
在示例中，页#6使用了不到一半的空间，页#5又有足够的删除数量，现在同样处于50%使用以下。从InnoDB的角度来看，它们能够进行合并。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_5.jpg" alt="">
合并操作使得页#5保留它之前的数据，并且容纳来自页#6的数据。页#6变成一个空页，可以接纳新数据。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_6.jpg" alt="">
如果我们在UPDATE操作中让页中数据体积达到类似的阈值点，InnoDB也会进行一样的操作。</p>
<p>规则就是：页合并发生在删除或更新操作中，关联到当前页的相邻页。如果页合并成功，在<code>INFOMATION_SCHEMA.INNODB_METRICS</code>中的<code>index_page_merge_successful</code>将会增加。</p>
<h2 id="页分裂">页分裂</h2>
<p>前面提到，页可能填充至100%，在页填满了之后，下一页会继续接管新的记录。但如果有下面这种情况呢？</p>
<p><img src="../2019/12/001-zhujiekun-Locality_7.jpg" alt="">
页#10没有足够空间去容纳新（或更新）的记录。根据“下一页”的逻辑，记录应该由页#11负责。然而：</p>
<p><img src="../2019/12/001-zhujiekun-Locality_9.jpg" alt="">
页#11也同样满了，数据也不可能不按顺序地插入。怎么办？</p>
<p>还记得之前说的链表吗（译注：指B+树的每一层都是双向链表）？页#10有指向页#9和页#11的指针。</p>
<p>InnoDB的做法是（简化版）：</p>
<ol>
<li>创建新页</li>
<li>判断当前页（页#10）可以从哪里进行分裂（记录行层面）</li>
<li>移动记录行</li>
<li>重新定义页之间的关系</li>
</ol>
<p><img src="../2019/12/001-zhujiekun-Locality_8.jpg" alt="">
新的页#12被创建：</p>
<p><img src="../2019/12/001-zhujiekun-Locality_10.jpg" alt="">
页#11保持原样，只有页之间的关系发生了改变：</p>
<ul>
<li>页#10相邻的前一页为页#9，后一页为页#12</li>
<li>页#12相邻的前一页为页#10，后一页为页#11</li>
<li>页#11相邻的前一页为页#10，后一页为页#13</li>
</ul>
<p>（译注：页#13可能本来就有，这里意思为页#10与页#11之间插入了页#12）</p>
<p>这样B树水平方向的一致性仍然满足，因为满足原定的顺序排列逻辑。然而从物理存储上讲页是乱序的，而且大概率会落到不同的区。</p>
<p>规律总结：页分裂会发生在插入或更新，并且造成页的错位（dislocation，落入不同的区）</p>
<p>InnoDB用<code>INFORMATION_SCHEMA.INNODB_METRICS</code>表来跟踪页的分裂数。可以查看其中的<code>index_page_splits</code>和<code>index_page_reorg_attempts/successful</code>统计。</p>
<p>一旦创建分裂的页，唯一（译注：实则仍有其他方法，见下文）将原先顺序恢复的办法就是新分裂出来的页因为低于合并阈值（merge threshold）被删掉。这时候InnoDB用页合并将数据合并回来。</p>
<p>另一种方式就是用<code>OPTIMIZE</code>重新整理表。这可能是个很重量级和耗时的过程，但可能是唯一将大量分布在不同区的页理顺的方法。</p>
<p>另一方面，要记住在合并和分裂的过程，InnoDB会在索引树上加写锁（x-latch）。在操作频繁的系统中这可能会是个隐患。它可能会导致索引的锁争用（index latch contention）。如果表中没有合并和分裂（也就是写操作）的操作，称为“乐观”更新，只需要使用读锁（S）。带有合并也分裂操作则称为“悲观”更新，使用写锁（X）。</p>
<h2 id="我的主键">我的主键</h2>
<p>好的主键不仅对于数据查找很重要，而且也影响写操作时数据在区上的分布（也就是与页分裂和页合并操作相关）。</p>
<p>在第一个测试中我使用的是是自增主键，第二个测试主键是基于一个1-200的ID与自增值的，第三个测试也是1-200的ID不过与UUID联合。</p>
<p>插入操作时，InnoDB需要增加页，视为“分裂”操作：</p>
<p><img src="../2019/12/001-zhujiekun-split_1.jpg" alt="">
表现因不同主键而异。</p>
<p>在头两种情况中数据的分布更为紧凑，也就是说他们拥有更好的空间利用率。对比半随机（semi-random）特性的UUID会导致明显的页稀疏分布（页数量更多，相关分裂操作更多）。</p>
<p>在页合并的情况中，尝试合并的次数因主键类型的不同而表现得更加不一致。</p>
<p><img src="../2019/12/001-zhujiekun-merges_1-1024x542.jpg" alt="">
在插入-更新-删除操作中，自增主键有更少的合并尝试次数，成功比例比其他两种类型低9.45%。UUID型主键（图表的右一侧）有更多的合并尝试，但是合并成功率明显更高，达22.34%，因为数据稀疏分布让很多页都有部分空闲空间。</p>
<p>在辅助索引与上面主键索引相似的情况下，测试的表现也是类似的。</p>
<h2 id="总结">总结</h2>
<p>MySQL/InnoDB不断地进行这些操作，你可能只能了解到很少的信息。但他们可能给你造成伤害，特别是比起用SSD，你还在用传统的机械存储（spindle storage）的时候（顺便提一下SSD会有另外的问题）。</p>
<p>坏消息就是我们用什么参数或者魔法去改变服务端。但好消息是我们可以在设计的时候做很多（有帮助）的事。</p>
<p>恰当地使用主键和设计辅助索引，并且记住不要滥用（索引）。如果你已经预计到会有很多插入/删除/更新操作，规划一个合适的时间窗来管理（整理）表。</p>
<p>有个很重要的点，InnoDB中你不会有断断续续的行记录，但是你会在页-区的维度上遇到这些问题。忽略表的管理工作会导致需要在IO层面、内存层面和InnoDB缓冲池层面做更多工作。</p>
<p>你必须不时（at regular intervals）重建一些表。可以采用一些技巧，比如分区和外部的工具（pt-osc）。不要让表变得过大和过于碎片化（fragmented）。</p>
<p>磁盘空间浪费？需要读多个表去获取需要的数据而不是一次搞定？每次搜索导致明显更多的读操作？那是你的锅，不要找借口！</p>
<p>Happy MySQL to everyone!</p>
<h2 id="感谢">感谢</h2>
<p>Laurynas Biveinis: 感谢花时间向我解释一些内部实现。</p>
<p>Jeremy Cole: 感谢他的项目<a href="https://github.com/jeremycole/innodb_ruby">InnoDB_ruby</a> (我经常用上）。</p>
]]></content>
		</item>
		
		<item>
			<title>InnoDB——锁、事务和复制</title>
			<link>https://jiekun.dev/posts/2019-12-16-innodb-%E9%94%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%A4%8D%E5%88%B6/</link>
			<pubDate>Mon, 16 Dec 2019 13:17:56 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-16-innodb-%E9%94%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%A4%8D%E5%88%B6/</guid>
			<description>锁 数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。 InnoDB存储引擎中的锁 共享锁（S Lock），允许事务读一行</description>
			<content type="html"><![CDATA[<h1 id="锁">锁</h1>
<p>数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。</p>
<h2 id="innodb存储引擎中的锁">InnoDB存储引擎中的锁</h2>
<ul>
<li>共享锁（S Lock），允许事务读一行数据</li>
<li>排他锁（X Lock），允许事务删除或更新一行数据</li>
</ul>
<p>兼容性：</p>
<ul>
<li>S与S可以兼容</li>
<li>X不与任何锁兼容</li>
</ul>
<p>InnoDB支持多粒度锁定，也就是允许行级和表级的锁同时存在。实现方式为通过意向锁（Intention Lock）：如果需要对最细粒度进行加锁，需要在上层粒度加意向锁。</p>
<p>具体举例，如果需要对行加X锁，需要对表、页依次加IX锁。当意向锁遇到等待时，必须等待结束后才能继续对下级加锁。如准备加对一行有S锁的行加S锁，行记录因为原来就有S锁，所以表和页都已经存在了IS锁，首先新的IS锁加在表上，因为IS、IS锁兼容，可以加上；然后再看页锁，同样IS、IS兼容，可以加上；最后看行锁IS与S兼容，那么行记录可以加上S锁。对同样这行有S锁的行加X锁，先加表IX锁，IX与IS兼容，可以加上，页同样，最后IX锁与行记录上的S锁不兼容，因此要等待S锁释放后才能加上X锁。</p>
<h3 id="一致性非锁定读">一致性非锁定读</h3>
<p>一致性非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi version）的方式来读取当前执行时间数据库中行的数据。在行记录正在执行DELETE或UPDATE时执行读操作，不会等待锁释放，而是会去读undo段中的行的快照数据。</p>
<p>在不同的事务隔离级别下，读取方式不同，不是每个事务隔离级别都采用非锁定的一致性读，即使使用CNR，对快照数据的定义也不一样。快照数据就是undo段中的历史版本，一行记录可能有多个版本，一般称为行多版本技术，由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control，MVCC）。</p>
<p>在事务隔离级别READ COMMITTED下，非一致性读总是读取被锁定行的最新一份快照数据，而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-16-19-28-11.png" alt="">
表中所示的事务执行过程，在READ COMMITED中会话A可以SELECT到0个id=1的结果，因为已经被会话B所更新；而在REPEATABLE READ中因为读取的是事务开始前的快照，因此结果不会发生变化（可重复读）。</p>
<h3 id="一致性锁定读">一致性锁定读</h3>
<p>REPEATABLE READ隔离级别下，InnoDB的SELECT操作使用一致性非锁定读，但支持两种一致性锁定读操作：</p>
<ul>
<li>SELECT…FOR UPDATE (X Lock)</li>
<li>SELECT…LOCK IN SHARE MODE (S Lock)</li>
</ul>
<h2 id="锁的算法">锁的算法</h2>
<p>InnoDB存储引擎有3种行锁的算法：</p>
<ul>
<li>Record Lock：单个行记录上的锁</li>
<li>Gap Lock：间隙锁，锁定一个范围，但不包括记录本身</li>
<li>Next-Key Lock：Gap Lock+Record Lock，锁定一个范围和记录本身</li>
</ul>
<p>InnoDB对于行的查询都是采用Next-Key Lock，例如索引有10，11，13，和20，那么可锁定的区间有：</p>
<ul>
<li>(-∞, 10]</li>
<li>(10, 11]</li>
<li>(11, 13]</li>
<li>(13, 20]</li>
<li>(20, +∞)</li>
</ul>
<p>Next-Key Lock的设计是为了解决Phantom Problem。除了Next-Key Lock还有Previous-Key Lock，区别在于区间的开闭。</p>
<pre tabindex="0"><code>CREATE TABLE z(a INT,b INT,PRIMARY KEY(a),KEY(b));
INSERT INTO z SELECT 1,1;
INSERT INTO z SELECT 3,1;
INSERT INTO z SELECT 5,3;
INSERT INTO z SELECT 7,6;
INSERT INTO z SELECT 10,8;

</code></pre><p>现在z表中有如下数据：</p>
<pre tabindex="0"><code>mysql&gt; SELECT * FROM z;
+----+------+
| a  | b    |
+----+------+
|  1 |    1 |
|  3 |    1 |
|  5 |    3 |
|  7 |    6 |
| 10 |    8 |
+----+------+

</code></pre><p>开启一个事务，锁定b=3行：</p>
<pre tabindex="0"><code>mysql&gt; SELECT * FROM z WHERE b=3 FOR UPDATE;
+---+------+
| a | b    |
+---+------+
| 5 |    3 |
+---+------+
1 row in set (0.00 sec)

</code></pre><p>由于Next-Key Lock的存在，现在在辅助索引上3所处的区间被上锁，也就是(1,3]。需要注意的是InnoDB还会对3的下一个区间加上gap lock，也就是(3,6)。那么此时如果往这些区间内做其他操作会被阻塞：</p>
<pre tabindex="0"><code>mysql&gt; INSERT INTO z SELECT 6,5;

</code></pre><p>在列a上由于是唯一索引列，Next-Key Lock会降级为Record Lock，因此在索引a上的锁定只针对a=5这一行。</p>
<p>Gap Lock的作用是为了阻止多个事务将记录插入到同一范围内，这会导致Phantom Problem的产生。</p>
<p>InnoDB只在能够定位到唯一行的情况下将Next-Key Lock降级为Record Lock，也就是特别需要强调唯一索引由多个列组成的情况，查询其中部分列仍会使用Next-Key Lock。</p>
<p>Phantom Problem是指在同一事务下，连续执行两次SQL会导致不同的结果，第二次的SQL语句会返回之前不存在的行。</p>
<pre tabindex="0"><code>+---+
| a |
+---+
| 1 |
+---+
| 2 |
+---+
| 5 |
+---+
SELECT * FROM t WHERE a&gt;2 FOR UPDATE;

</code></pre><p>Next-Key Locking这里锁住的不仅仅是a=5这个行，而是锁定(2,+∞)这个范围，因此此时如果使用的是REPEATABLE READ的话是无法向这个范围内INSERT数据的，不会存在Phantom Problem。而如果是COMMITTED READ则允许写入，例如下次执行的时候可能就会新增了一条a=4的记录。</p>
<h2 id="锁问题">锁问题</h2>
<ul>
<li>脏读，就是在读到另一个事务中未提交的数据，违反数据库的隔离性</li>
<li>不可重复读，事务内读取同一数据集合，由于另一个事务的修改，事务两次读到的数据可能是不一样的，违反了数据库事务一致性的要求</li>
<li>丢失更新，在事务中不使用SELECT…FOR UPDATE的查询，在SELECT和UPDATE之间由其他事务进行了SELECT，在UPDATE COMMIT之后，其他事务也进行UPDATE（基于它自己的SELECT结果）和COMMIT，那么就相当与地一个事务的UPDATE没有其作用，需要操作串行化或者FOR UPDATE加锁解决</li>
</ul>
<h2 id="死锁">死锁</h2>
<p>死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。</p>
<p>死锁举例：</p>
<ul>
<li>A SELECT a=1 FOR UPDATE</li>
<li>B SELECT a=2 FOR UPDATE</li>
<li>A SELECT a=2 FOR UPDATE（阻塞，等待B释放）</li>
<li>B SELECT a=1 FOR UPDATE（阻塞，等待A释放）</li>
</ul>
<p>在InnoDB中会话A会得到记录为2的这个资源，因为B会被因死锁而回滚。</p>
<h2 id="锁升级">锁升级</h2>
<p>Lock Escalation是指将当前锁的粒度降低，如将1000个行锁升级为一个页锁。InnoDB不存在锁升级问题。</p>
<h1 id="事务">事务</h1>
<p>InnoDB中的事务完全符合ACID特性：</p>
<ul>
<li>原子性（atomicity）</li>
<li>一致性（consistency）</li>
<li>隔离性（isolation）</li>
<li>持久性（durability）</li>
</ul>
<p>通过在事务中使用<code>SAVE WORK</code>函数可以建立保存点。保存点可以通过<code>ROLLBACK WORK: n</code>来回滚。</p>
<h2 id="事务的实现">事务的实现</h2>
<p>事务的隔离性由上一章讲的锁来实现。原子性、一致性、持久性通过数据库的redo log和undo log来完成。redo log称为重做日志，用来保证事务的原子性和持久性；undo log用来保证事务的一致性。</p>
<p>redo log和undo log不是相互的逆过程，redo log是物理日志，而undo log是操作的逆向操作，是逻辑日志。</p>
<h3 id="redo">redo</h3>
<p>redo log是用来实现事务的持久性，即ACID中的D，由内存中的redo log buffer和磁盘的redo log file组成。</p>
<p>当事务提交时，必须将所有日志写入重做日志文件进行持久化，待事务的COMMIT操作完成才算完成。重做日志指的是redo log和undo log，redo log是用来保证事务的吃就行，undo log用来帮助事务回滚及MVCC的功能。redo log基本顺序写，而undo log是需要进行随机读写的。</p>
<p>在每次将重做日志缓冲写入重做日志文件后，InnoDB都调用一次fsync操作，确保日志写入重做日志文件。磁盘性能决定了事务提交的性能。</p>
<p>在数据库中还有一种二进制日志（binlog），用来进行POINT-IN-TIME的恢复和主从复制环境的建立。redo log是在InnoDB存储引擎层产生，bin log是在MySQL数据库的上层产生，并且不只是对InnoDB引擎的；同时bin log是逻辑日志，记录的是对应的SQL语句，redo log是物理格式的日志，记录的是每个页的修改；binlog只在事务提交完成后一次写入，redo log在事务进行中不断地被写入，因此redo log不是随事务提交的顺序进行写入的。</p>
<p>redo log是物理日志，因此它是幂等的，而bin log由于是逻辑日志，如INSERT等操作不是幂等的，所以它不能被重复执行。</p>
<h3 id="undo">undo</h3>
<p>在对数据库进行修改时，InnoDB存储引擎不但会产生redo，还会产生一定量的undo。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。</p>
<p>与redo log放在文件不同，undo放在数据库内部的一个特殊段中，称为undo段，位于共享表空间中。</p>
<p>undo是逻辑日志，回滚时修改会被逻辑地取消，数据结构和页本身在回滚之后可能不太相同，因为这个过程中可能有其他并发的事务，因此不能将一个页回滚到事务开始的样子。InnoDB回滚时实际上是做与之前相反的工作，例如对于INSERT会回滚一个DELETE操作。</p>
<p>undo除了回滚以外的另一个作用是MVCC，若记录被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读。</p>
<p>undo log会产生redo log，因为undo log也需要持久性的保护。</p>
<p>事务提交后不能马上删除undo log及undo log所在的页，因为可能还有其他事务需要通过undo log得到行记录之前的版本。事务提交时会将undo log放入一个链表，是否可删除由purge线程来判断。</p>
<h3 id="purge">purge</h3>
<pre tabindex="0"><code>DELETE FROM t WHERE a=1;

</code></pre><p>DELETE操作仅是将主键列中等于1的记录delete flag设为1,记录还存在在B+树上。purge用于最终完成delete和update操作，因为MVCC所以记录不能立即处理。若该行记录已经不被其他任何事务引用，那么就可以进行真正的DELETE操作。</p>
<h3 id="group-commit">group commit</h3>
<p>事务非只读的话，需要在提交时执行fsync操作，保证重做日志都写入磁盘。但是fsync性能是有限的，为了提高效率，数据库提供了group commit功能，一次fsync可以刷新确保多个事务日志写入文件。</p>
<p>BLGC是指：</p>
<ul>
<li>Flush阶段，将每个事务的bin log写入内存</li>
<li>Sync阶段，将内存的bin log刷到磁盘，若有多个事务，通过一次fsync完成bin log的写入（BLGC）</li>
<li>Commit阶段，leader根据顺序调用存储引擎层事务的提交</li>
</ul>
<h1 id="复制">复制</h1>
<p>复制是MySQL数据库提供的一种高可用高性能的解决方案。因为不是InnoDB实现，所以使用来传递数据的文件不是redo log而是bin log：</p>
<ul>
<li>主服务器将数据更改记录到bin log中</li>
<li>从服务器将bin log复制到自己的中继日志（relay log）中</li>
<li>从服务器重做中继日志中的日志，把更改应用到自己的数据库上，达到数据的最终一致性</li>
</ul>
<p>从服务器有两个线程，一个是I/O线程，负责读取主服务器的二进制日志，并将其保存为relay log，一个是SQL线程，负责执行relay log。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-16-21-12-53.png" alt=""></p>
]]></content>
		</item>
		
		<item>
			<title>InnoDB——架构、日志、表和索引</title>
			<link>https://jiekun.dev/posts/2019-12-15-innodb-%E6%9E%B6%E6%9E%84%E6%97%A5%E5%BF%97%E8%A1%A8%E5%92%8C%E7%B4%A2%E5%BC%95/</link>
			<pubDate>Sun, 15 Dec 2019 13:40:15 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-15-innodb-%E6%9E%B6%E6%9E%84%E6%97%A5%E5%BF%97%E8%A1%A8%E5%92%8C%E7%B4%A2%E5%BC%95/</guid>
			<description>前言 写这篇博文是为了将自己学习完InnoDB的内容梳理一遍。InnoDB是个很复杂很庞大的存储引擎，其中的细节显然是不可能通过一篇文章或者笔</description>
			<content type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>写这篇博文是为了将自己学习完InnoDB的内容梳理一遍。InnoDB是个很复杂很庞大的存储引擎，其中的细节显然是不可能通过一篇文章或者笔记完整地描述出来的，所以这里主要目的是“补漏”，也就是将以前学习MySQL没有了解到的InnoDB“专属”的内容进行梳理和记录。</p>
<p>学习的主要来源是姜承尧老师的《MySQL技术内幕——InnoDB存储引擎》一书，国内除了这本书以外，也鲜有对InnoDB进行详细介绍的书籍。应用固然重要，但是正确理解技术本身才能够从根本上解决问题。最近这段时间看的技术向的书不少，其中不乏一些夸夸其谈，滥竽充数的书，尤其在架构设计书中最为明显，部分作者直接使用官方文档的图文翻译来填充内容，如果没有个人观点和核心的代码剖析，这些书就是IT书架上的混子。当然，从姜老师这本书可以读得出来，代码、配图和很多细节的描述都是出自一个有多年技术积累的专家之手，在现在大量浑水摸鱼的IT图书市场上就显得特别的宝贵。</p>
<p>有几句话姜老师在前言中提及到，我认为特别重要：</p>
<ul>
<li>不要相信任何的“神话”，学会自己思考</li>
<li>不要墨守成规，大部分人都知道的事情可能是错误的</li>
<li>不要相信网上的传言，去测试，根据自己的实践做出决定</li>
<li>花时间充分地思考，敢于提出质疑</li>
</ul>
<p>这些都是作为开发者特别需要做到的，所以花时间充分地思考，是我在这篇博客最想做到的事情，希望能够通过思考真正掌握书中的内容。</p>
<h1 id="innodb架构模型">InnoDB架构模型</h1>
<p><img src="../2019/12/Screenshot-from-2019-12-15-13-59-54.png" alt="">
内存池：</p>
<ul>
<li>维护所有进程/线程需要访问的多个内部数据结构</li>
<li>缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里缓存</li>
<li>redo log缓冲</li>
</ul>
<p>后台线程：</p>
<ul>
<li>负责刷新内存池中的数据，保证缓冲池中的内存缓存是最近的数据</li>
<li>将修改的数据文件刷到磁盘文件</li>
<li>保证发生异常的情况下InnoDB能够恢复到正常运行状态</li>
</ul>
<h2 id="内存">内存</h2>
<p><img src="../2019/12/Screenshot-from-2019-12-15-14-10-04.png" alt=""></p>
<h3 id="缓冲池">缓冲池</h3>
<p>设置原因：CPU与磁盘速度之间的鸿沟。</p>
<p>在数据库中读取页的操作，先从磁盘读取到缓冲池中，读取相同页的时候判断是否在缓冲池中直接命中。</p>
<p>缓冲池中缓存的数据页类型有：</p>
<ul>
<li>索引页</li>
<li>数据页</li>
<li>undo页</li>
<li>insert buffer</li>
<li>自适应哈希索引</li>
<li>引擎的锁信息</li>
<li>数据字典信息</li>
</ul>
<p>缓冲池允许有多个，通过参数配置，默认为1。</p>
<h3 id="lru-listfree-listflush-list">LRU List、Free List、Flush List</h3>
<p>最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。</p>
<p>InnoDB中设置了<code>midpoint</code>位置，读取到新的页，虽然是“Recently Used”，但是先插入到midpoint位置而不是前端，默认配置下处于LRU列表长度的5/8处，midpoint前的列表称为new列表，midpoint后的列表称为old列表。使用midpoint优化的原因是在读取页的时候，因为会导致尾端的页被刷出LRU列表，如果直接在前端插入大量的页（一般为索引或扫描操作）会将LRU列表大量页刷出，而这部分插入的操作可能仅是一次性的，因此需要先将这些页放在midpoint位置，然后后续如果确实频繁使用再加入LRU列表的热端。</p>
<p>Free列表表示可用的页，如果Free列表有可用的空闲页，就会将页从Free列表中删除、加入LRU列表中；如果没有，则要从LRU列表尾端淘汰，将内存分配给新的页。可以理解成LRU长度增加，Free长度就减少，Free没有的时候还需要插页面就需要从LRU淘汰。</p>
<p>在LRU列表中的页被修改后，称为dirty page，缓冲区与磁盘中的数据不一致，这时候通过<code>CHECKPOINT</code>机制刷回磁盘，Flush列表中的页即为脏页列表，脏页既存在于LRU列表中也存在与Flush列表中，前者保证页的可用性，后者管理页刷回磁盘。</p>
<h2 id="checkpoint">Checkpoint</h2>
<p>Checkpoint是为了解决：</p>
<ul>
<li>缩短数据库的恢复时间，宕机后不需要重做所有日志，而是从Checkpoint开始</li>
<li>缓冲池不够用时，溢出尾端页，若为脏页，将脏页刷新回磁盘</li>
<li>redo log不需要时，会被覆盖重用；需要使用就会强制产生Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置</li>
</ul>
<p>InnoDB使用LSN（Log Sequence Number）来标记版本，Checkpoint也有LSN。</p>
<p>Checkpint有两种：</p>
<ul>
<li>Sharp Checkpoint，发生在数据库关闭时将所有脏页数据刷新回磁盘</li>
<li>Fuzzy Checkpoint，刷新部分脏页回磁盘</li>
</ul>
<p>Fuzzy Checkpoint发生在：</p>
<ul>
<li>Master Thread Checkpoint，以每秒或者每10秒的速度刷新一定比例的脏页回磁盘</li>
<li>FLUSH_LRU_LIST Checkpoint，为了保证LRU列表有空闲页（数量可配置）可供使用</li>
<li>Async/Sync Flush Checkpoint，定义：</li>
</ul>
<pre tabindex="0"><code>ync_water_mark = 75% * total_redo_log_file_size
sync_water_mark = 90% * total_redo_log_file_size

</code></pre><p>在checkpoint age（redo_lsn – checkpoint_lsn）大于async水位的时候触发Async Flush，大于sync水位的时候触发Sync Flush，保证刷完后age小于async水位</p>
<h2 id="master-thread">Master Thread</h2>
<p>InnoDB主要工作都是在Master Thread中完成的，内部由多个循环组成：</p>
<ul>
<li>主循环（loop）</li>
<li>后台循环（background loop）</li>
<li>刷新循环（flush loop）</li>
<li>暂停循环（suspend loop）</li>
</ul>
<p>主循环执行每秒操作和每10秒操作。每秒操作包括：</p>
<ul>
<li>日志缓冲刷新到磁盘，即使事务还没提交（总是，因此再大的事务提交时间也很短）</li>
<li>合并插入缓冲（可能，IO小于5% innodb_io_capacity的时候执行）</li>
<li>至多刷新innodb_io_capacity个InnoDB的缓冲池中的脏页到磁盘（可能，判断阈值）</li>
<li>如果上一步没有超过阈值，又开启了自适应刷新，通过函数判断合适的数量脏页刷新到磁盘</li>
<li>如果用户没有活动，切到后台循环（可能）</li>
</ul>
<p>每10秒操作包括：</p>
<ul>
<li>刷新100个脏页到磁盘（可能，IO小于200次的时候执行）</li>
<li>合并至多5% innodb_io_capacity插入缓冲（总是）</li>
<li>将日志缓冲刷新到磁盘（总是）</li>
<li>删除无用的undo页（总是，因为undo页需要保留给MVCC，如果确认无用会在这里删除掉）</li>
<li>刷新innodb_io_capacity个或10% innodb_io_capacity个脏页到磁盘（总是，判断脏页比例，如果超过70%刷innodb_io_capacity个，小于70%刷10% innodb_io_capacity个）</li>
</ul>
<p>后台循环操作包括：</p>
<ul>
<li>删除无用的undo页（总是）</li>
<li>合并innodb_io_capacity个插入缓冲（总是）</li>
<li>跳回到主循环（总是）</li>
<li>不断刷新innodb_io_capacity个页直到符合条件（可能，在flush loop完成）</li>
</ul>
<p>如果flush loop也没有事情可以做，切换到suspend loop，挂起Master Thread，等待事件发生。</p>
<p>伪代码：</p>
<pre tabindex="0"><code>void master_thread() {
  goto loop;
  loop：
  for (int i = 0; i &amp;lt; 10; i++) {
    thread_sleep(1) //sleep 1 second
    do log buffer flush to disk
    if (last_one_second_ios &amp;lt; 5 % innodb_io_capacity)
      do merge 5 % innodb_io_capacity insert buffer
      if (buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct)
        do buffer pool flush 100 % innodb_io_capacity dirty page
    else if enable adaptive flush
    do buffer pool flush desired amount dirty page
    if (no user activity)
      goto backgroud loop
  }
  if (last_ten_second_ios &amp;lt; innodb_io_capacity)
    do buffer pool flush 100 % innodb_io_capacity dirty page
    do merge 5 % innodb_io_capacity insert buffer
    do log buffer flush to disk
    do full purge
    if (buf_get_modified_ratio_pct &gt; 70 % )
      do buffer pool flush 100 % innodb_io_capacity dirty page
  else
    dobuffer pool flush 10 % innodb_io_capacity dirty page
  goto loop
  background loop:
    do full purge
    do merge 100 % innodb_io_capacity insert buffer
    if not idle:
    goto loop:
    else :
      goto flush loop
  flush loop:
    do buffer pool flush 100 % innodb_io_capacity dirty page
    if (buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct)
      go to flush loop
  goto suspend loop
  suspend loop:
    suspend_thread()
  waiting event
  goto loop;
}

</code></pre><h2 id="innodb关键特性">InnoDB关键特性</h2>
<h3 id="insert-buffer">Insert Buffer</h3>
<p>插入缓冲和数据页一样，也是物理页的一个组成部分。</p>
<p>在B+树上数据是按照聚集索引的值顺序存放的，在非聚集索引中插入数据则是离散的，因此随机读取导致插入性能下降。InnoDB在非聚集索引的插入或者更新操作时，不是一次直接插入索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入，若不在则放到一个Insert Buffer对象中，再通过一定频率进行Insert Buffer和辅助索引页子节点的merge操作，这样通常能够将多个插入合并到一个操作中（因为在同一个索引页中），提高非聚集索引的插入性能。</p>
<p>Insert Buffer的使用需要同时满足两个条件：</p>
<ul>
<li>索引是辅助索引</li>
<li>索引不是唯一的</li>
</ul>
<p>Insert Buffer在发生宕机的时候因为没有合并到非聚集索引中去，恢复可能需要很长时间。同时索引不是唯一的目的是为了避免去非聚集索引中判断唯一性，如果需要判断那么就需要离散读取，Insert Buffer就失去了意义。</p>
<p>InnoDB从1.0.x版本引入Change Buffer作为升级，对INSERT、DELETE、UPDATE操作都进行缓冲，对应Insert Buffer、Delete Buffer、Purge Buffer。对记录的Update操作分为两个过程：标记删除、真正删除，Delete Buffer对应第一个过程，Purge Buffer对应第二个过程。</p>
<p>Merge Insert Buffer可能发生在以下几种情况：</p>
<ul>
<li>辅助索引页被读取到缓冲池时，如执行SELECT操作时，检查Insert Buffer Bitmap页确认该辅助索引页是否有记录存放在Insert Buffer B+树中</li>
<li>Insert Buffer Bitmap页追查到该辅助索引页已经没有可用空间（小于1/32页）时，强制一个读取辅助索引页进行合并</li>
<li>Master Thread</li>
</ul>
<h3 id="两次写">两次写</h3>
<p>在写某个页到表中时发生宕机，页只写了部分，称为部分写失效。redo log是物理操作的记录，如偏移量800,写’aaaa’，因为页本身发生损坏，所以重做没有意义，因此需要一个页的副本，通过页的副本还原页，再进行重做，这就是doublewrite。</p>
<p>在对缓冲池的脏页进行刷新时，并不直接写磁盘，通过memcpy将脏页先复制到doublewrite buffer，之后通过doublewrite buffer分两次，每次1MB顺序地写入共享表空间的物理磁盘上，然后调用fsync函数同步磁盘，避免缓冲写带来的问题。</p>
<h3 id="自适应哈希索引">自适应哈希索引</h3>
<p>构造AHI（Adaptive Hash Index）的要求是对页的连续访问模式必须是一样的，并且以该模式访问了100次，页通过该模式访问了N次，N=页中记录/16。</p>
<h3 id="异步io">异步IO</h3>
<p>用户请求可能需要扫描多个索引页，进行多次IO操作。在扫描完一个页后进行下一次扫描是没有必要的，用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后等待所有IO操作完成，这就是AIO。</p>
<p>AIO的优势是可以进行IO Merge操作，将连续的IO操作合并为1个IO请求。</p>
<h3 id="刷新邻接页">刷新邻接页</h3>
<p>当刷新一个脏页时，InnoDB会检测该页所在的区（extent）的所有页，如果是脏页，则一起进行刷新，通过AIO可以合并成一个IO操作。</p>
<h1 id="文件">文件</h1>
<p>组成MySQL和InnoDB的文件有很多类：</p>
<ul>
<li>参数文件</li>
<li>日志文件</li>
<li>socket文件</li>
<li>pid文件</li>
<li>MySQL表结构文件</li>
<li>存储引擎文件</li>
</ul>
<h2 id="二进制日志">二进制日志</h2>
<p>binary log记录了对MySQL数据库执行更改的所有操作，但是不包括SELECT和SHOW这类操作，但是操作没有导致数据库发生变化也可能会被写入bin log中，如UPDATE结果为<code>0 row affected</code>的语句。</p>
<p>bin log主要有以下作用：</p>
<ul>
<li>恢复</li>
<li>复制</li>
<li>审计</li>
</ul>
<p>当使用事务的表存储引擎时，所有未提交的bin log会被记录到一个缓存中去，等待事务提交时将缓存中的日志写入bin log文件，缓存默认大小为32k，并且是基于session的，也就是说MySQL会给不同session分配不同的缓存，因此缓存不能设置太大；当bin log超过缓存大小时，会被写入临时文件中去，因此该值也不能设置得太小。</p>
<p>如果当前数据库是slave角色，它不会将从master取得并执行的bin log写入自己的bin log中去，通过配置也可以开启写入以实现master-&gt;slave-&gt;slave的架构。</p>
<p>binlog_format控制bin log的格式，可以为STATMENT、ROW和MIXED：</p>
<ul>
<li>STATMENT格式记录的是SQL语句</li>
<li>ROW记录表的行更改情况</li>
<li>MIXED默认使用STATMENT格式，一些情况下使用ROW格式</li>
</ul>
<h2 id="innodb表空间文件">InnoDB表空间文件</h2>
<p>InnoDB将存储的数据按照tablespace存放，默认10MB、名为ibdata1的文件，设置innodb_data_file_path后所有基于InnoDB的表的数据都会记录到该tablespace中，若设置了innodb_file_per_table，每个InnoDB的表都会产生一个独立的表空间：表名.ibd。</p>
<h2 id="innodb重做日志文件">InnoDB重做日志文件</h2>
<p>默认情况下ib_logfile0和ib_logfile1是redo log file，他们记录了InnoDB存储引擎的事务日志，实例失败时可以使用重做日志回复到掉电前的时刻来保证数据的完整性。</p>
<p>redo log和bin log的区别在于：</p>
<ul>
<li>bin log是MySQL层面的日志，记录的是所有（包括不同引擎）的日志；而redo log只记录InnoDB引擎本身的日志</li>
<li>bin log记录的是一个事物的具体操作内容，是逻辑日志；redo log记录的是关于每个页的更改的物理情况</li>
<li>bin log仅在事务提交前进行提交，只写磁盘一次；redo log在事务进行的过程中不断有redo entry被写入redo log中</li>
</ul>
<h1 id="表">表</h1>
<h2 id="索引组织表">索引组织表</h2>
<p>InnoDB中一个很重要的概念就是表都是根据主键顺序组织存放的，成为索引组织表（index organized table）。没有显式定义主键的时候会按照如下方式选择或创建主键：</p>
<ul>
<li>非空唯一索引，如有多个，按照定义索引的顺序取第一个</li>
<li>无符合条件，自动创建6字节大小的主键</li>
</ul>
<h2 id="innodb逻辑存储结构">InnoDB逻辑存储结构</h2>
<p>InnoDB中数据被放在tablespace中，由段（segment）、区（extent）、页（page）组成。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-15-16-17-01.png" alt="">
默认情况下InnoDB有一个tablespace ibdata1，通过设置innodb_file_per_table也可以改为每个表内的数据（数据、索引和插入缓冲Bitmap）放到单独的tablespace，这种情况下其他类型的数据（如回滚信息、插入缓冲索引页、系统事务信息、double write buffer等）仍在共享表空间中，因此共享表空间仍会一直增大。</p>
<p>表空间是由各个段组成的，因为InnoDB是索引组织表，索引段就是B+树的非叶子节点，数据段是B+树的叶子节点。</p>
<p>区是连续的页组成的空间，每个区的大小为1MB，为了保证区中页的连续性，InnoDB会一次从磁盘申请4-5个区，默认情况下一个页16KB，一个区中有64个连续的页。</p>
<p>页是InnoDB磁盘管理的最小单位。常见页类型有：</p>
<ul>
<li>数据页（B-tree Node）</li>
<li>undo页（Undo Log Page）</li>
<li>系统页（System Page）</li>
<li>事务数据页（Transaction System Page）</li>
<li>插入缓冲位图页（Insert Buffer Bitmap）</li>
<li>插入缓冲空闲列表页（Insert Buffer Free List）</li>
<li>未压缩的二进制大对象页（Uncompressed BLOB Page）</li>
<li>压缩的二进制大对象页（Compressed BLOB Page）</li>
</ul>
<p>InnoDB是row-oriented，每个页最多允许存放16KB/2-200行记录。</p>
<h2 id="innodb行记录格式">InnoDB行记录格式</h2>
<p>InnoDB提供了Compact和Redundant两种格式来存放行记录数据，默认为Compact。一个页中存放的行数据越多，其性能就越高。</p>
<p>Compact行记录的存储方式为：</p>
<table class="wp-block-table">
  <tr>
    <th>
      变长字段长度列表
    </th>
<pre><code>&lt;th&gt;
  NULL标记位
&lt;/th&gt;

&lt;th&gt;
  记录头信息
&lt;/th&gt;

&lt;th&gt;
  列1数据
&lt;/th&gt;

&lt;th&gt;
  列2数据
&lt;/th&gt;

&lt;th&gt;
  …
&lt;/th&gt;
</code></pre>
  </tr>
</table>
<ul>
<li>变长字段长度列表，顺序按照列的顺序逆序放置，若列长度小于255字节则用1字节表示，否则用2字节表示</li>
<li>NULL标志位，指示该行中是否有NULL值，有则用1表示</li>
<li>record header，固定占用5字节</li>
<li>每个列的数据，NULL不占该部分任何空间，事务ID列和回滚指针列也包含在内，若没有主键还会增加一个6字节的rowid列</li>
</ul>
<p>InnoDB可以将某些数据存储在真正的数据页之外，如BLOB这类大对象列。要注意的是BLOB可以不将数据放在溢出页面，VARCHAR类型也有可能被存放为溢出数据。</p>
<p>首先VARCHAR类型上限是65535字节，但是因为有别的开销，所以实际测试发现最大长度为65532：</p>
<pre tabindex="0"><code>mysql &gt; CREATE TABLE test(
-&gt; a VARCHAR(65535)
-&gt; )CHARSET=latin1 ENGINE=InnoDB;
ERROR 1118(42000):Row size too large.The maximum row size for the used table type,not counting BLOBs,is 65535.You have to change some columns to TEXT or BLOBs

</code></pre><pre tabindex="0"><code>mysql &gt; CREATE TABLE test(
-&gt; a VARCHAR(65532)
-&gt; )CHARSET=latin1 ENGINE=InnoDB;
Query OK,0 rows affected(0.15 sec)

</code></pre><p>如果没有将SQL_MODE设为严格模式，会抛出warning并转换为TEXT类型。</p>
<p>上述创建的65532的表字符类型为latin1,如果转换为UTF-8：</p>
<pre tabindex="0"><code>mysql&gt; CREATE TABLE test(
-&gt; a VARCHAR(65532)
-&gt; )CHARSET=UTF8 ENGINE=InnoDB;
ERROR 1074(42000):Column length too big for column'a'(max=21845);use BLOB or TEXT instead

</code></pre><p>因此VARCHAR(N)中的N指的是字符的长度，而限制的65535是字节长度。</p>
<p>要注意的是，65535长度是指所有VARCHAR列的长度总和，如果列的长度超过这个长度，依然无法创建。</p>
<p>InnoDB的页为16KB，即16384字节，实际上是不能存放65532字节长度的数据的，此时插入长度为65532的记录，会观察到tablespace中有一个数据页节点B-tree Node，另外有Uncompressed BLOB Page，而实际上数据页中只保存了VARCHAR(65532)的前768字节的前缀数据，之后是偏移量，指向行溢出页。</p>
<p>InnoDB中每页至少要有两条行数据，如果页中只放得下一条记录，那么InnoDB就会自动将行数据存到溢出页中。同样如果TEXT或BLOB类型的数据能够保证一个页能存放两条记录，那么他们也是可以放在数据页中的。</p>
<p>对于多字节的字符编码，CHAR类型不再代表固定长度的字符串，如UTF-8下的CHAR(10)列，最小可以存储10字节的字符，最大可以存储30字节的字符，因此对于多字节编码的CHAR数据类型，InnoDB在内部将其视为变长字符类型。</p>
<h2 id="分区表">分区表</h2>
<p>分区的过程是将一个表或索引分解为多个更小、更可管理的部分。逻辑上的一个表或索引由数十个物理分区组成。</p>
<p>MySQL不支持垂直分区，并且是局部分区索引，即一个分区中既存放了数据又存放了索引，而全局分区，数据存放在各个分区中，索引放在一个对象中，目前并不支持。</p>
<p>分区主要应该用于数据库高可用性的管理，如果使用不当会对性能产生负面的影响。</p>
<p>目前MySQL支持以下几种类型的分区：</p>
<ul>
<li>RANGE：基于一个给定的连续区间的列值被放入分区</li>
<li>LIST：和RANGE类似，但是面向的是离散的值</li>
<li>HASH：根据用户自定义的表达式的返回值来进行分区，不能为负数</li>
<li>KEY：根据MySQL提供的哈希函数来进分区</li>
</ul>
<p>如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分。</p>
<h3 id="range">RANGE</h3>
<pre tabindex="0"><code>CREATE TABLE t(
id INT
)ENGINE=INNDB
PARTITION BY RANGE(id)(
PARTITION p0 VALUES LESS THAN(10),
PARTITION p1 VALUES LESS THAN(20));

</code></pre><p>分区后表不再由一个ibd文件组成：</p>
<pre tabindex="0"><code>mysql&gt; system ls-lh/usr/local/mysql/data/test2/t*
-rw-rw----1 mysql mysql 8.4K 7月31 14:11/usr/local/mysql/data/test2/t.frm
-rw-rw----1 mysql mysql 28 7月31 14:11/usr/local/mysql/data/test2/t.par
-rw-rw----1 mysql mysql 96K 7月31 14:12/usr/local/mysql/data/test2/t#P#p0.ibd
-rw-rw----1 mysql mysql 96K 7月31 14:12/usr/local/mysql/data/test2/t#P#p1.ibd

</code></pre><p>对于插入不在分区中定义的值时MySQL会抛出一个异常，也可以通过对分区添加一个MAXVALUE值的分区来解决。</p>
<p>通过分区，可以在管理上直接删除某些数据的分区，而不需要<code>DELETE...WHERE...</code>：</p>
<pre tabindex="0"><code>mysql&gt; alter table sales drop partition p2008;
Query OK,0 rows affected(0.18 sec)
Records:0 Duplicates:0 Warnings:0

</code></pre><p>在查询特定条件时，如果可以只搜索部分分区，SQL优化器不搜索所有分区称为Partition Pruning。启用分区后，应该根据分区的特性来编写最优的SQL语句。</p>
<h3 id="list">LIST</h3>
<p>LIST分区和RANGE分区很相似，只是分区列的值是离散而非连续的：</p>
<pre tabindex="0"><code>mysql&gt; CREATE TABLE t(
-&gt; a INT,
-&gt; b INT)ENGINE=INNODB
-&gt; PARTITION BY LIST(b)(
-&gt; PARTITION p0 VALUES IN(1,3,5,7,9),
-&gt; PARTITION p1 VALUES IN(0,2,4,6,8)
-&gt; );
Query OK,0 rows affected(0.26 sec)

</code></pre><p>在插入多个数据行时遇到分区未定义的值，MyISAM会将之前的行数据都插入，之后的数据不插入；但InnoDB则会视为一个事物，因此没有任何数据插入。</p>
<h3 id="hash分区">HASH分区</h3>
<pre tabindex="0"><code>CREATE TABLE t_hash(
a INT,
b DATETIME
)ENGINE=InnoDB
PARTITION BY HASH(YEAR(b))
PARTITIONS 4;

</code></pre><p>表示将表t按照日期列b分为4个区，因为：</p>
<pre tabindex="0"><code>MOD(YEAR('2010-04-01'), 4)
=MOD(2010,4)
=2

</code></pre><p>因此’2010-04-01’这条数据将会被放入分区p2中。</p>
<p>如果PARTITIONS没有声明，那分区数量将默认为1。</p>
<h3 id="key分区">KEY分区</h3>
<p>KEY分区和HASH分区类似，不过HASH分区使用用户定义的函数进行分区，KEY分区使用MySQL数据库提供的函数进行分区，这些函数基于和<code>PASSWORD()</code>一样的运算法则：</p>
<pre tabindex="0"><code>mysql&gt; CREATE TABLE t_key(
-&gt; a INT,
-&gt; b DATETIME)ENGINE=InnoDB
-&gt; PARTITION BY KEY(b)
-&gt; PARTITIONS 4;
Query OK,0 rows affected(0.43 sec)

</code></pre><h3 id="columns分区">COLUMNS分区</h3>
<p>MySQL5.5开始支持COLUMNS分区，可以直接使用非整型数进行分区，而其他几种必须为整型或转化为整型：</p>
<pre tabindex="0"><code>CREATE TABLE t_columns_range(
a INT,
b DATETIME
)ENGINE=INNODB
PARTITION BY RANGE COLUMNS(B)(
PARTITION p0 VALUES LESS THAN('2009-01-01'),
PARTITION p1 VALUES LESS THAN('2010-01-01')
);

</code></pre><h3 id="子分区">子分区</h3>
<p>MySQL允许在RANGE和LIST的分区上再进行HASH或KEY的子分区：</p>
<pre tabindex="0"><code>mysql&gt; CREATE TABLE ts(a INT,b DATE)engine=innodb
-&gt; PARTITION BY RANGE(YEAR(b))
-&gt; SUBPARTITION BY HASH(TO_DAYS(b))
-&gt; SUBPARTITIONS 2(
-&gt; PARTITION p0 VALUES LESS THAN(1990),
-&gt; PARTITION p1 VALUES LESS THAN(2000),
-&gt; PARTITION p2 VALUES LESS THAN MAXVALUE
-&gt; );
Query OK,0 rows affected(0.01 sec)

</code></pre><pre tabindex="0"><code>mysql&gt; system ls-lh/usr/local/mysql/data/test2/ts*
-rw-rw----1 mysql mysql 8.4K Aug 1 15:50/usr/local/mysql/data/test2/ts.frm
-rw-rw----1 mysql mysql 96 Aug 1 15:50/usr/local/mysql/data/test2/ts.par
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p0#SP#p0sp0.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p0#SP#p0sp1.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p1#SP#p1sp0.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/
ts#P#p1#SP#p1sp1.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p2#SP#p2sp0.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p2#SP#p2sp1.ibd

</code></pre><h3 id="分区问题">分区问题</h3>
<p>分区中总是视NULL值是小于任何一个非NULL值。对于RANGE分区，NULL值会落在最左边的分区；对于HASH和KEY，任何分区函数都会将含有NULL值的记录返回为0。</p>
<p>对于不满足Partition Pruning的分区，对于一张大表，一般B+树需要2-3次磁盘IO，而如果需要扫描多个分区，如10个分区，每个分区查询开销为2-3次IO，则一共需要20-30次IO，有可能会带来严重的性能问题。</p>
<h1 id="索引与算法">索引与算法</h1>
<p>InnoDB支持以下几种常见的索引：</p>
<ul>
<li>B+树索引</li>
<li>全文索引</li>
<li>哈希索引</li>
</ul>
<p>B+树索引并不能找到一个给定键值的具体行，它只能找到被查找数据行所在的页，然后数据库通过把页读入到内存，再在内存中进行查找，最后得到想要的数据。</p>
<h2 id="b树">B+树</h2>
<p>B+树是为磁盘或者其他直接存取辅助设备设计的一种平衡查找树，所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接。</p>
<h3 id="b树的插入操作">B+树的插入操作</h3>
<p>B+树的插入必须保证插入后的叶子节点中的记录依然排序：</p>
<ul>
<li>Leaf Page未满、Index Page未满时，直接将记录插入到叶子节点</li>
<li>Leaf Page满、Index Page未满时，拆分Leaf Page，将中间的节点（指的是Leaf Page几个节点的中间）放入到Index Page中，小于中间节点的记录放左边，大于中间节点的记录放右边</li>
<li>Leaf Page满、Index Page满时，拆分Leaf Page，小于中间节点的记录放左边，大于中间节点的记录放右边；拆分Index Page，原理同上，此时树的高度+1</li>
</ul>
<p>因为拆分页操作意味着磁盘的操作，所以应该尽量减少。因此，B+树同样提供了类似平衡二叉树的旋转（Rotation）功能。当Leaf Page已满，而左右兄弟节点没满时，B+树不会急于去做拆分页的操作，而是将记录移到所在页的兄弟节点上，通常左兄弟会被首先检查用来做旋转操作。</p>
<h3 id="b树的删除操作">B+树的删除操作</h3>
<p>与插入通过“满”来控制不同，删除通过使用填充因子来控制树的变化。50%是填充因子可设的最小值。B+树的删除同样要保证删除后叶子节点中的记录依然排序：</p>
<ul>
<li>Leaf Page大于填充因子、Index Page大于填充因子，直接删除，如果该节点是Index Page节点，用该节点的右节点代替</li>
<li>Leaf Page小于填充因子、Index Page大于填充因子，合并Leaf Page和它的兄弟节点，同时更新Index Page</li>
<li>Leaf Page小于填充因子、Index Page小于填充因子，合并Leaf Page和它的兄弟节点，更新Index Page，合并Index Page和它的兄弟节点</li>
</ul>
<h3 id="b树索引">B+树索引</h3>
<p>B+树索引具有高扇出性，高度一般都在2-4层，说明查找某一键值的行记录最多只需要2-4次IO。</p>
<p>B+树索引可以分为聚集索引和辅助索引，区别在于叶子节点存放的是否是一整行的信息。</p>
<h4 id="聚集索引">聚集索引</h4>
<p>聚集索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-15-20-40-05.png" alt="">
数据只能按照一颗B+树来排序，因此每张表只能拥有一个聚集索引，由于定义了数据的逻辑顺序，按照聚集索引能够特别快地针对范围值查找。数据页上存放的是完整的每行的记录，而非数据页的索引页中存放的是键值和指向数据页的偏移量，而不是一个完整的行记录。</p>
<h4 id="辅助索引">辅助索引</h4>
<p>辅助索引的叶子节点除了包含键值意外，每个叶子节点中的索引行还包含了一个书签，用来告诉InnoDB存储引擎哪里可以找到与索引对应的行数据。由于InnoDB存储引擎是索引组织表，因此辅助索引的数千就是相应行数据的聚集索引键。</p>
<p>如果在一棵高度为3的辅助索引树中查找数据，那需要对这棵辅助索引树便利3次找到制定的主键，如果聚集索引树的高度同样为3，那还需要对聚集索引进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问以得到最终的一个数据页。</p>
<h4 id="b树索引的分裂">B+树索引的分裂</h4>
<p>在前面讲到的B+树的插入删除，和数据库中B+树索引的情况可能有所不同，因为B+树索引页的分裂并不总是从页的中间记录开始的，这样会导致页空间的浪费，例如自增ID列上：</p>
<pre tabindex="0"><code>1、2、3、4、5、6、7、8、9

</code></pre><p>现在需要插入10，按照之前的理论应该是将记录5作为分裂点记录，得到P1、P2：</p>
<pre tabindex="0"><code>P1：1、2、3、4
P2：5、6、7、8、9、10

</code></pre><p>由于是自增ID，现在P1永远不会有新数据，浪费了空间；P2又会再次进行分裂。</p>
<p>InnoDB的Page Header中有以下几个部分用来保存插入的顺序信息：</p>
<ul>
<li>PAGE_LAST_INSERT</li>
<li>PAGE_DIRECTION</li>
<li>PAGE_N_DIRECTION</li>
</ul>
<p>通过这些信息，InnoDB决定向左还是向右分裂，同时决定分裂点记录是哪一个。若插入是随机的则取中间记录，若往一个方向插入的记录数量为5,并且目前已经定位到的记录之后还有3条记录，则分裂点记录为定位到的记录后的第三条记录，否则分裂点记录就是待插入的记录。在自增时页的分裂通常都会在记录自身，避免前面的浪费空间的情况。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-15-20-51-31.png" alt=""></p>
<h4 id="fast-index-creation">Fast Index Creation</h4>
<p>在对辅助索引的创建，InnoDB会对创建索引的表加上一个S锁，这样创建过程中只能对该表进行读操作，这改变了以前创建索引时，MySQL通过创建新临时表再导入数据的方式（会导致服务不可用）的情况。</p>
<h3 id="cardinality">Cardinality</h3>
<p>Cardinality是一个预估值，代表索引中不重复记录数量的预估值，Cardinality/n_rows_in_table应该尽可能接近1（高选择性），太小的时候用户应该考虑是否还需要创建这个索引。</p>
<p>Cardinality在不同引擎都有，因此对Cardinality的统计是放在存储引擎层进行的。数据库对于Cardinality的统计是通过采样进行的。</p>
<p>Cardinality的更新发生在INSERT和UPDATE操作中，因为不可能每次操作都要更新Cardinality信息，InnoDB内部对Cardinality信息的更新策略为：</p>
<ul>
<li>表中1/16的数据已发生过变化</li>
<li>stat_modified_counter &gt; 2000000000</li>
</ul>
<p>具体采样的方法是默认对8个叶子节点进行采样：</p>
<ul>
<li>取得B+树索引中叶子节点的数量A</li>
<li>随机取B+树中8个叶子节点，统计每个页不同的个数P1、P2、…、P8</li>
<li>Cardinality = (P1 + … + P8) * A / 8</li>
</ul>
<p>因为采样8个叶子节点是随机的，因此Cardinality每次取得的值可能不同。在目前的InnoDB版本中欧给你采样数量是可以配置的，同时对于采样结果中的NULL值也可以配置为忽略（不统计）、多个NULL统计为1个不重复值、多个NULL记为多个不重复值。</p>
<h3 id="b树索引的应用">B+树索引的应用</h3>
<h4 id="联合索引">联合索引</h4>
<p>联合索引与单个索引创建方法一样，其实和之前讨论的单个键值的B+树并没有什么不同，键值都是排序的，按照索引指定列的顺序进行存放。</p>
<p>要注意的是，在优化器选择索引的时候，例如在某个表(a,b)上有索引a和索引(a,b)，当查询where a=xx的时候，优化器会选择使用索引a而不用索引(a,b)，因为该索引只包含了单个键值，理论上一个页能够存放的数据应该更多，通过扫描更少的页就能拿到对应的记录。</p>
<h4 id="覆盖索引">覆盖索引</h4>
<p>通过在辅助索引中就能直接查到记录，而不用查询聚集索引中的记录，叫做覆盖索引。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，其大小要远小于聚集索引，因此可以减少大量的IO操作。</p>
<h4 id="优化器选择不用索引的情况">优化器选择不用索引的情况</h4>
<pre tabindex="0"><code>SELECT * FROM orderdetails WHERE orderid&gt;10000 AND orderid&amp;lt;102000;

</code></pre><p>假设这个表上有(orderid, productid)联合主键，orderid辅助索引，最后在EXPLAIN中看到优化器选择了主键的聚集索引，也就是表扫描（table scan），而非orderid辅助索引扫描（index scan），因为用户需要查整行信息，而orderid不能覆盖到我们要查询的信息，还需要根据书签进行查找，从顺序的scan操作变成了离散读操作。如果数量较少的情况下优化器会选择辅助索引，如果占比较大（一般20%左右）的时候，优化器因为顺序读离散读的问题，还是会选择用聚集索引来查找数据。</p>
<h4 id="multi-range-read优化">Multi-Range Read优化</h4>
<p>MRR优化目的是为了减少磁盘的随机访问：</p>
<ul>
<li>在使用辅助索引时，首先根据得到的查询结果，按照主键进行排序，并且按照主键顺序进行书签查找，</li>
<li>减少缓冲池中页被替换的次数</li>
<li>批量处理对键值的查询操作</li>
</ul>
<h4 id="index-condition-pushdown优化">Index Condition Pushdown优化</h4>
<p>在根据查询取出索引数据时，尽管索引对某些查询可能没有帮助（例如LIKE），但是可以在取出时就进行过滤数据，而不需要等全部取出后再进行过滤。Extra列Using index condition提示优化器选择了ICP优化。</p>
]]></content>
		</item>
		
		<item>
			<title>[听译]Redis 6.0新特性——ACLs</title>
			<link>https://jiekun.dev/posts/2019-11-24-redis-6-0%E6%96%B0%E7%89%B9%E6%80%A7-acls/</link>
			<pubDate>Sun, 24 Nov 2019 11:58:26 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-11-24-redis-6-0%E6%96%B0%E7%89%B9%E6%80%A7-acls/</guid>
			<description>在2019年纽约的Redis Day上，Salvatore Sanfilippo（AKA Antirez）介绍了即将发布的Redis 6.0的新特性</description>
			<content type="html"><![CDATA[<p>在2019年纽约的Redis Day上，Salvatore Sanfilippo（AKA Antirez）介绍了即将发布的Redis 6.0的新特性。</p>
<h2 id="acls简介">ACLs简介</h2>
<p>在过去的十年中，Redis都会有这样的问题：</p>
<p>用户执行<code>FLUSHALL</code>，OK现在整个数据库就空了，或者执行<code>DEBUG SEGFAULT</code>，然后Redis的进程就crash退出了。</p>
<p>在以前解决这个问题的办法可能是在Redis配置中将危险命令进行rename：</p>
<pre tabindex="0"><code>name-command FLUSHALL &quot;&quot;

</code></pre><p>这样将命令更名为随机字符串或者直接屏蔽掉，以满足需要。</p>
<p>缺少危险命令管理就会导致很多问题，比如当你使用网络上的一些库的时候，你压根就不知道别人会不会在里面加些<code>FLUSHALL</code>这样的命令，或者你也可以每次用外部代码都进行一轮Code Review。</p>
<p>当有了ACLs之后，你就可以控制比如：</p>
<p>这个连接只允许使用<code>RPOP</code>，<code>LPUSH</code>这些命令，其他命令都无法调用。</p>
<p>是不是很方便？来看看ACLs是怎么工作的。</p>
<h2 id="最佳实践">最佳实践</h2>
<p>首先你要做的是定义用户。</p>
<p>当登录的时候，旧版本中默认用户（defaule user）是可以做任何事的，在Redis 6.0中你可以定义默认用户：</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; ACL setuser antirez on &gt;password1 &gt;password2 &gt;foobar +@all ~*

</code></pre><p><code>setuser</code>…<code>on</code>表示启用此用户，off则是只定义一个不可用（unaccessable）的用户。</p>
<p><code>&gt;password1 &gt;password2 &gt;foobar</code>表示设置了3个密码，可以用来做密码轮换策略。</p>
<p><code>+@all</code>表示用户可以使用所有权限，<code>+</code>后面跟命令权限如<code>+get</code>，或者<code>+@</code>后面跟某一类权限。</p>
<p><code>~*</code>表示可用（accessable）的键名，这里是<code>*</code>也就是所有键都可被访问。</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; ACL WHOAMI
&quot;default&quot;

</code></pre><p>现在是处于默认用户下的，切换用户：</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; AUTH antirez foobar
OK

</code></pre><p>在以前AUTH后面是直接跟密码的，现在是用户名和密码。</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; ACL WHOAMI
&quot;antirez&quot;

</code></pre><p>因为之前给这个用户设置的是所有命令可用+所有键可见，所以现在跟default用户没有什么区别：</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; GET foo
(nil)
127.0.0.1:6379&gt; SET foo bar
OK

</code></pre><p>现在去掉一些权限：</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; ACL setuser antirez -SET

</code></pre><p>把这个用户的<code>SET</code>权限去掉后，就不能进行这个操作了：</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; GET foo
&quot;bar&quot;
127.0.0.1:6379&gt; SET foo 123
(error) NOPERM this user has no permissions to run the 'set' command or its subcommand

</code></pre><p>再来查看一下现在的ACL list：</p>
<pre tabindex="0"><code>127.0.0.1:6379&gt; ACL list
1) &quot;user antirez on &gt;password1 &gt;password2 &gt;foobar ~* +@all -set&quot;
2) &quot;user default on nopass ~* +@all&quot;

</code></pre><p>类似的，你也可以限制用户可以用任何命令但是却只能看部分键，如<code>object*</code>。</p>
<h2 id="备注">备注</h2>
<p>ACLs的实现使用了一些小技巧，像用上了命令的位图（commands’ bitmaps），以便让它不会在速度上有所下降。<br>
不使用ACLs的话就和原来的Redis 5一样，使用ACLs当然会有一些额外的开销，但是它们非常小，你在benchmarks中不会察觉到新旧版本的区别。</p>
]]></content>
		</item>
		
		<item>
			<title>Docker原理</title>
			<link>https://jiekun.dev/posts/2019-11-17-docker%E5%8E%9F%E7%90%86/</link>
			<pubDate>Sun, 17 Nov 2019 04:57:23 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-11-17-docker%E5%8E%9F%E7%90%86/</guid>
			<description>Docker原理 主题一：Docker容器的资源隔离和限制管理 概述 Docker是基于Go实现的，它使用了namespaces来为不同容器提供独</description>
			<content type="html"><![CDATA[<h2 id="docker原理">Docker原理</h2>
<h3 id="主题一docker容器的资源隔离和限制管理">主题一：Docker容器的资源隔离和限制管理</h3>
<h4 id="概述">概述</h4>
<p>Docker是基于Go实现的，它使用了<code>namespaces</code>来为不同容器提供独立环境。简单来说，当创建一个容器时，Docker创建了容器的一系列<code>namespaces</code>，不同容器只能在它所在的<code>namespaces</code>内操作相关资源，而察觉不到其他<code>namespaces</code>内存在的资源。<br>
同时，Docker还使用了<code>control groups</code>(<code>cgroups</code>)来实现对资源使用的限制。</p>
<h4 id="namespaces">namespaces</h4>
<p>从内核版本4.10开始，Linux有7种<code>namespace</code>:</p>
<ul>
<li>Mount</li>
<li>Process ID</li>
<li>Network</li>
<li>Interprocess Communication</li>
<li>UTS</li>
<li>User ID</li>
<li>Control group</li>
</ul>
<p>在<code>/proc/$PID/ns</code>下可以看到对应的<code>namespaces</code>链接:</p>
<pre tabindex="0"><code># root@duck-MS-7A34:/proc/1172/ns# ll
total 0
dr-x--x--x 2 root root 0 11月 13 17:42 ./
dr-xr-xr-x 9 gdm  gdm  0 11月 13 17:41 ../
lrwxrwxrwx 1 root root 0 11月 13 17:42 cgroup -&gt; 'cgroup:[4026531835]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 ipc -&gt; 'ipc:[4026531839]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 mnt -&gt; 'mnt:[4026531840]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 net -&gt; 'net:[4026531992]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 pid -&gt; 'pid:[4026531836]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 pid_for_children -&gt; 'pid:[4026531836]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 user -&gt; 'user:[4026531837]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 uts -&gt; 'uts:[4026531838]'

</code></pre><p>如果两个进程指向的<code>namespace</code>编号相同，就说明它们在同一个<code>namespace</code>下。查看宿主机的其他进程的ns发现是指向同样编号的ns。</p>
<p>在容器内查看：</p>
<pre tabindex="0"><code># root@duck-MS-7A34:/proc/1172# docker run -it ubuntu /bin/bash
# root@a21f7e39c31c:/proc/1/ns# ls -l
total 0
lrwxrwxrwx 1 root root 0 Nov 13 09:44 cgroup -&gt; 'cgroup:[4026531835]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 ipc -&gt; 'ipc:[4026532665]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 mnt -&gt; 'mnt:[4026532663]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 net -&gt; 'net:[4026532669]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 pid -&gt; 'pid:[4026532667]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 pid_for_children -&gt; 'pid:[4026532667]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 user -&gt; 'user:[4026531837]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 uts -&gt; 'uts:[4026532664]'

</code></pre><p>可见容器内的进程是指向不同的namespaces的，他们之间的资源互不可见。</p>
<h4 id="cgroups">cgroups</h4>
<p>cgroups是设计来为不同用户层面的资源管理提供一个统一化的接口，主要功能有：</p>
<ul>
<li>资源限制</li>
<li>优先级分配</li>
<li>资源统计</li>
<li>任务控制</li>
</ul>
<p>cgroups的实现本质就是给任务挂上钩子，当任务运行的过程中涉及某种资源时，会触发钩子上所附带的子系统进行检测。</p>
<p>以Memory相关控制为例，cgroup有对应的配置文件：</p>
<pre tabindex="0"><code># root@duck-MS-7A34:/sys/fs/cgroup/memory# ls
cgroup.clone_children  init.scope                  memory.kmem.max_usage_in_bytes      memory.kmem.tcp.usage_in_bytes   memory.numa_stat            memory.swappiness      system.slice
cgroup.event_control   memory.failcnt              memory.kmem.slabinfo                memory.kmem.usage_in_bytes       memory.oom_control          memory.usage_in_bytes  tasks
cgroup.procs           memory.force_empty          memory.kmem.tcp.failcnt             memory.limit_in_bytes            memory.pressure_level       memory.use_hierarchy   user.slice
cgroup.sane_behavior   memory.kmem.failcnt         memory.kmem.tcp.limit_in_bytes      memory.max_usage_in_bytes        memory.soft_limit_in_bytes  notify_on_release
ker                 memory.kmem.limit_in_bytes  memory.kmem.tcp.max_usage_in_bytes  memory.move_charge_at_immigrate  memory.stat                 release_agent

</code></pre><p>这些以资源开头（比如memory.limit_in_bytes）的文件就是相关的配置文件。</p>
<p>当进程需要申请更多内存时，就会触发cgroup的用量检测，超过cgroup规定的限额就会拒绝用户的内存申请。如果进程需要的内存超过了它所属cgroup最大限额后，如果设置了OOM Control，那么进程就会收到OOM信号并结束，否则会被挂起，直到cgroup中其他进程释放了足够多的内存资源为止。</p>
<p>再如memory.limit_in_bytes和memory.soft_limit_in_bytes控制，当进程超过了软限制之后，如果有其他进程需要申请资源，系统会优先回收超额的进程占用的内存资源。</p>
]]></content>
		</item>
		
		<item>
			<title>Docker入门实践</title>
			<link>https://jiekun.dev/posts/2019-11-17-docker%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</link>
			<pubDate>Sun, 17 Nov 2019 04:54:19 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-11-17-docker%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</guid>
			<description>Docker实践 学习背景 没有接触过容器 不太了解微服务 偶尔使用Linux 概述 什么是Docker？不妨先来看一下为什么需要Docker： 微服务 微</description>
			<content type="html"><![CDATA[<h2 id="docker实践">Docker实践</h2>
<h3 id="学习背景">学习背景</h3>
<ul>
<li>没有接触过容器</li>
<li>不太了解微服务</li>
<li>偶尔使用Linux</li>
</ul>
<h3 id="概述">概述</h3>
<p>什么是Docker？不妨先来看一下为什么需要Docker：</p>
<h4 id="微服务">微服务</h4>
<p>微服务是模块化的，每个不同的服务独立运行，因此需要满足能够独立部署和一定的可伸缩性。在部署过程中每一处的人为操作都伴随着出错的风险，所以必须有方法来消除这种服务部署的风险。</p>
<p>Docker为这种使用场景提供了解决方案，使用容器（Container）来部署微服务可以做到：</p>
<ul>
<li>将部署过程标准化和自动化</li>
<li>环境隔离，满足微服务的独立运行要求</li>
</ul>
<h4 id="cicd">CI/CD</h4>
<p>CI是不断提交代码并且打包编译，然后自动使用测试用例验证来保障改动内容对功能的影响的一种实践；CD是CI的延伸，它将通过CI验证的内容自动地发布和部署到指定环境。构建CI/CD时一般会需要做到：</p>
<ul>
<li>环境可控</li>
<li>快速高效部署，流程化执行</li>
<li>可并行运行测试</li>
</ul>
<p>使用Docker可以满足以上的需求，使开发者专注于开发而运维专注于项目部署。</p>
<h3 id="get-started-with-docker">Get started with Docker</h3>
<p><a href="https://github.com/praqma-training/docker-katas">docker-katas</a>项目中有一些Docker的基本知识讲解和实践，主要包括Docker的各种常用概念及命令，如：</p>
<ul>
<li>Docker的镜像（Images）、容器（Containers）、守护进程（Docker daemon）、客户端（Docker client）、公共仓库（Docker Hub）等概念</li>
<li>镜像的拉取（<code>pull</code>）、容器的创建与运行（<code>run</code>）等命令</li>
</ul>
<p>在完成docker-katas练习后，基于这些内容以及参考相关书籍，本次实践的目标是实现一套简单的服务，需要包括：</p>
<ul>
<li>使用Docker的数据卷（Volume）来进行数据的共享</li>
<li>使用Docker的网络来使几个容器间可以进行数据交互</li>
<li>使用Docker的端口转发</li>
</ul>
<h4 id="volume">Volume</h4>
<p>Docker通过数据卷来实现不同容器间、容器与宿主机间数据的共享。最容易想到的场景就是在宿主机上修改服务的配置文件然后运行在不同的容器间，这里配置一套Redis服务使得容器的redis-server使用本地的配置文件运行。</p>
<p>以Redis镜像创建容器，将本地的配置文件<code>/data/redis-master/redis.conf</code>挂载到容器的<code>/data/redis.conf</code>中，并且执行<code>redis-server /data/redis.conf</code>命令启动redis-server。</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker run -d --name redis-master -v /data/redis-master/redis.conf:/data/redis.conf redis redis-server /data/redis.conf

</code></pre><p>因为redis-master使用<code>-d</code>后台运行，因此redis.conf中的后台运行需要改为关闭：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo vim /data/redis-master.conf
aemonize no

</code></pre><p>现在可以看到容器服务的运行状态：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
f45e340eb1ba        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up 56 minutes       6379/tcp                 redis-master

</code></pre><h4 id="容器间连接">容器间连接</h4>
<p>Docker容器可以通过<code>--link</code>连接其他的容器，具体示例如下。<br>
因为之前已经创建过一个名为redis-master的容器了，现在再创建一台基于ubuntu镜像的容器，并且与redis-master连接：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker run -it --name ubuntu1 --link redis-master:redis-master ubuntu /bin/bash

</code></pre><p>创建完毕后在这个ubuntu1容器上查看<code>/etc/hosts</code>发现：</p>
<pre tabindex="0"><code># root@5e0ca7fa39ef:/# cat /etc/hosts
172.17.0.2  redis-master f45e340eb1ba

</code></pre><p>因此在ubuntu1中可以通过redis-master访问另一台容器。</p>
<p>现在为之前创建的redis-master容器配置上两个slave节点。</p>
<p>和之前类似，需要让新的redis容器使用本地的配置，因此需要<code>-v</code>参数；并且需要让slave节点连接上master节点，因此需要<code>--link redis-master:redis-master</code>参数；slave配置与master类似，但是要加上<code>slaveof redis-master</code>的配置项：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker run -d --name redis-slave1 -v /data/redis-slave/redis.conf:/data/redis.conf --link redis-master:master redis redis-server /data/redis.conf
# duck@duck-MS-7A34:~$ sudo docker run -d --name redis-slave2 -v /data/redis-slave/redis.conf:/data/redis.conf --link redis-master:master redis redis-server /data/redis.conf

</code></pre><p>现在docker管理中可以看到3个容器在运行中：</p>
<pre tabindex="0"><code>uck@duck-MS-7A34:~$ sudo docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS                    NAMES
bf991586e7c3        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up About an hour           6379/tcp                 redis-slave2
2831c5a828da        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up About an hour           6379/tcp                 redis-slave1
f45e340eb1ba        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up About an hour           6379/tcp                 redis-master

</code></pre><p>进入redis-master中查看Redis状态：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker exec -it f45e340eb1ba /bin/bash
# root@f45e340eb1ba:/data# redis-cli
## 127.0.0.1:6379&gt; info

</code></pre><p>在返回的内容中可以看到</p>
<pre tabindex="0"><code># Replication
role:master
connected_slaves:2
slave0:ip=172.17.0.3,port=6379,state=online,offset=6682,lag=1
slave1:ip=172.17.0.4,port=6379,state=online,offset=6682,lag=1
master_replid:d7713802a61c75bd794c282accda8add66631804
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:6682
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
l_backlog_histlen:6682

</code></pre><p>创建一个键检查是主从同步是否正常：</p>
<pre tabindex="0"><code># 127.0.0.1:6379&gt; set 1 1

</code></pre><p>进入redis-slave1中查看Redis状态：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker exec -it 2831c5a828da /bin/bash
# root@2831c5a828da:/data# redis-cli
# 127.0.0.1:6379&gt; info

</code></pre><p>其中主从Replication部分显示当前节点工作在slave模式：</p>
<pre tabindex="0"><code># Replication
role:slave
master_host:master
master_port:6379
master_link_status:up
master_last_io_seconds_ago:2
master_sync_in_progress:0
slave_repl_offset:6556
slave_priority:100
slave_read_only:1
connected_slaves:0
master_replid:d7713802a61c75bd794c282accda8add66631804
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:6556
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:15
l_backlog_histlen:6542

</code></pre><p>查看数据同步是否正常：</p>
<pre tabindex="0"><code># 127.0.0.1:6379&gt; keys *
1) &quot;1&quot;

</code></pre><h4 id="app与haproxy">App与HAProxy</h4>
<p>最后再来加上两个App服务以及使用HAProxy进行Round-Robin的负载均衡。</p>
<p>创建两个Django容器，我们需要在本地修改代码，因此需要使用<code>-v</code>将代码目录与本地目录连通；App需要连接Redis数据库，因此需要<code>--link</code>连接Redis主节点：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker run -it -d --name app1 --link redis-master:db -v /data/App1:/usr/src/app django /bin/bash
# duck@duck-MS-7A34:~$ sudo docker run -it -d --name app2 --link redis-master:db -v /data/App2:/usr/src/app django /bin/bash

</code></pre><p>之后进入容器中，安装对应包及根据Django的命令创建一系列的内容，主要包括：</p>
<ul>
<li>pip安装redis</li>
<li>Django创建项目redisweb</li>
<li>Django生成应用helloworld</li>
</ul>
<p>完成之后可以在我们宿主机挂在的目录看到有对应的文件：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:/data/app1$ tree
.
└── dockerweb
    └── redisweb
        ├── db.sqlite3
        ├── helloworld
        │   ├── admin.py
        │   ├── apps.py
        │   ├── __init__.py
        │   ├── migrations
        │   │   └── __init__.py
        │   ├── models.py
        │   ├── tests.py
        │   └── views.py
        ├── manage.py
        └── redisweb
            ├── __init__.py
            ├── settings.py
            ├── urls.py
            └── wsgi.py

</code></pre><p>其中我们在redisweb/helloworld/views.py中添加对应的逻辑并且配置好路由urls.py和项目设置settings.py，最后通过<code>python manage.py runserver 0.0.0.0:8001</code>命令启动，就可以进行访问。</p>
<p>接下来创建HAProxy容器，HAProxy需要和App1和App2连接，因此加上<code>--link</code>参数；并且为了让容器的端口和宿主机的映射起来，添加<code>-p</code>参数；HAProxy的配置为了方便编辑，同样加上<code>-v</code>与本地配置目录互联：</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~$ sudo docker run -it -d --name HAProxy --link app1:app1 --link app2:app2 -p 6301:6301 -v /data/haproxy:/tmp haproxy /bin/bash

</code></pre><p>HAProxy配置修改好后，在容器中使用配置启动HAProxy：</p>
<pre tabindex="0"><code># root@8ef76bd496c3:/usr/local/sbin# haproxy -f haproxy.cfg

</code></pre><h3 id="访问测试">访问测试</h3>
<p>因为之前已经将HAProxy容器的6301端口与本地6301端口映射，现在可以访问本地的6301端口查看HAProxy工作状态：</p>
<p><img src="../2019/11/001-zhujiekun-haproxy.png" alt="">
然后再来访问Apps查看负载均衡是否生效：</p>
<p><img src="../2019/11/001-zhujiekun-app-lb-1024x610.png" alt=""></p>
<h3 id="容器应用搭建总结">容器应用搭建总结</h3>
<p>假如这套应用改用传统的云服务（虚拟机）进行搭建，则会在部署上浪费额外的时间，例如：</p>
<ul>
<li>云服务启动时间</li>
<li>各种软件包的安装时间，如Redis，HAProxy，Django环境配置</li>
<li>不同实例间的配置时间，如在实例上配置Host文件连接其他内网机器</li>
</ul>
<p>通过改用Docker拉取镜像创建容器的方式实现，使得整个流程大为精简，免除了许多冗余的重复配置操作，特别适合独立的微服务构建。</p>
<h3 id="docker-katas1练习"><a href="https://github.com/praqma-training/docker-katas">docker-katas</a>练习</h3>
<p>因为练习与Django App实践有部分内容重复，因此只选取了部分练习展示。</p>
<h4 id="07-building-an-image">07-building-an-image</h4>
<p>了解使用Dockerfile创建镜像和镜像的分层。</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~/script$ cat Dockerfile
# The base image
FROM ubuntu:latest

# Install python and pip
RUN apt-get update &amp;&amp; apt-get install -y \
 python-pip \
 python-dev \
 build-essential

# Install Python modules needed by the Python app
COPY requirements.txt /usr/src/app/
RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt

# Copy files required for the app to run
COPY app.py /usr/src/app/

# Declare the port number the container should expose
EXPOSE 5000

# Run the application
WORKDIR /usr/src/app
CMD [&quot;env&quot;, &quot;FLASK_APP=app.py&quot;, &quot;&amp;&amp;&quot;, &quot;flask&quot;, &quot;run&quot;, &quot;--host=0.0.0.0&quot;]

</code></pre><pre tabindex="0"><code># duck@duck-MS-7A34:~/script$ sudo docker container run -p 8888:5000 --name myfirstapp myfirstapp
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
172.17.0.1 - - [13/Nov/2019 02:58:50] &quot;GET / HTTP/1.1&quot; 200 -
172.17.0.1 - - [13/Nov/2019 02:58:50] &quot;GET /favicon.ico HTTP/1.1&quot; 404 -

</code></pre><h4 id="09-multi-container">09-multi-container</h4>
<p>在多个容器构成的应用中，每次都手动管理各个容器非常麻烦，依靠Docker compose将这些逻辑汇聚在一起方便定义和运行。</p>
<p>使用Docker composer运行WP应用</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~/script$ cat docker-compose.yaml 
version: '3.1'

networks:
  if_wordpress:

services:
  wordpress_container:
    image: wordpress
    networks: 
      - if_wordpress
    ports: 
      - 8080:80
    environment:
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_HOST: mysql_container

  mysql_container:
    image: mysql:5.7
    networks: 
      - if_wordpress
    ports:
      - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD: wordpress

</code></pre><pre tabindex="0"><code># duck@duck-MS-7A34:~/script$ sudo docker-compose up -d
Creating network &quot;script_if_wordpress&quot; with the default driver
Creating script_wordpress_container_1 ... done
Creating script_mysql_container_1     ... done
# duck@duck-MS-7A34:~/script$ curl 127.0.0.1:8080/wp-admin/install.php?step=1
&amp;lt;!DOCTYPE html&gt;
&amp;lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;en-US&quot; xml:lang=&quot;en-US&quot;&gt;
&amp;lt;head&gt;
    &amp;lt;meta name=&quot;viewport&quot; content=&quot;width=device-width&quot; /&gt;
    &amp;lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;
    &amp;lt;meta name=&quot;robots&quot; content=&quot;noindex,nofollow&quot; /&gt;
    &amp;lt;title&gt;WordPress › Installation&amp;lt;/title&gt;
    &amp;lt;link rel='stylesheet' id='dashicons-css'  href='http://127.0.0.1:8080/wp-includes/css/dashicons.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='buttons-css'  href='http://127.0.0.1:8080/wp-includes/css/buttons.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='forms-css'  href='http://127.0.0.1:8080/wp-admin/css/forms.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='l10n-css'  href='http://127.0.0.1:8080/wp-admin/css/l10n.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='install-css'  href='http://127.0.0.1:8080/wp-admin/css/install.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;/head&gt;

</code></pre><h4 id="10-multi-stage-builds">10-multi-stage-builds</h4>
<p>分Stage build镜像可以减少镜像体积</p>
<pre tabindex="0"><code># duck@duck-MS-7A34:~/script/goapp$ sudo docker image ls
REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE
goapp               2.0                 fa4ad66bd1d1        2 seconds ago        7.56MB
&amp;lt;none&gt;              &amp;lt;none&gt;              1d51fc13798f        5 seconds ago        361MB

</code></pre>]]></content>
		</item>
		
		<item>
			<title>理解Chrome请求流程</title>
			<link>https://jiekun.dev/posts/2019-10-27-%E7%90%86%E8%A7%A3chrome%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B/</link>
			<pubDate>Sun, 27 Oct 2019 09:17:37 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-10-27-%E7%90%86%E8%A7%A3chrome%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B/</guid>
			<description>Timing Tab Chrome的DevTools中提供了对请求的时间分析，如配图所示。 对每个请求，Chrome统计了它们不同阶段的通信时间，包括： Queueing Stalled DNS Lookup</description>
			<content type="html"><![CDATA[<h1 id="timing-tab">Timing Tab</h1>
<p>Chrome的DevTools中提供了对请求的时间分析，如配图所示。</p>
<p>对每个请求，Chrome统计了它们不同阶段的通信时间，包括：</p>
<ul>
<li>Queueing</li>
<li>Stalled</li>
<li>DNS Lookup</li>
<li>Proxy negotiation</li>
<li>Initial Connection /Connecting</li>
<li>SSL</li>
<li>Request sent</li>
<li>ServiceWorker Preparation</li>
<li>Request to ServiceWorker</li>
<li>Waiting(TTFB)</li>
<li>Content Download</li>
<li>Receiving Push</li>
<li>Reading Push</li>
</ul>
<h3 id="queueing">Queueing</h3>
<p>Queueing意味着请求没有马上发生，加入队列排队等候。导致这种情况一般可能的原因有：</p>
<ul>
<li>有更高优先级的请求</li>
<li>请求等待即将被释放的TCP socket</li>
<li>与当前域名的TCP连接数已满上限6个（仅对HTTP/1.0和HTTP/1.1生效）</li>
<li>浏览器正在分配磁盘缓存（一般非常短暂）</li>
</ul>
<p>要注意的是第三点中的6个TCP连接数上限在不同浏览器中也不相同，根据<a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.1.4">HTTP协议</a>的规定限制数量应为2个，但是各浏览器有不同的标准：</p>
<pre tabindex="0"><code>
| Browser | Maximum connections |
|---------|---------------------|
| IE7     | 2                   |
| IE8/IE9 | 6                   |
| IE10    | 8                   |
| IE11    | 13                  |
| FireFox | 6                   |
| Chrome  | 6                   |
| Safari  | 6                   |
| Opera   | 6                   |
| iOS     | 6                   |
| Android | 6                   |
---------------------------------

</code></pre><h3 id="stalled">Stalled</h3>
<p>当请求被放入队列后，就会有阻塞的时长。Stalled描述的是请求被发送之前等待的时长，一般就是Queueing中的原因导致的。除此之外，Stalled还包含了代理协商的时长。</p>
<h3 id="dns-lookup">DNS Lookup</h3>
<p>进行DNS查找（域名解析）的时长。每次请求一个新的域名的时候，需要进行一次完整的域名解析过程。</p>
<h3 id="proxy-negotiation">Proxy negotiation</h3>
<p>浏览器与代理服务器进行协商的过程。</p>
<h3 id="initial-connection-connecting">Initial Connection /Connecting</h3>
<p>建立连接的时长，包括TCP握手/重试的时长和SSL协商的时长。</p>
<h3 id="ssl">SSL</h3>
<p>完成SSL握手的时长。</p>
<h3 id="request-sendingsent">Request sending/sent</h3>
<p>发布请求的过程时间，一般非常快。</p>
<h3 id="serviceworker-preparation">ServiceWorker Preparation</h3>
<p>浏览器启动Service Worker的时长。</p>
<h3 id="request-to-serviceworker">Request to ServiceWorker</h3>
<p>请求被发送至Service Worker的时长。</p>
<h3 id="waitingttfb">Waiting(TTFB)</h3>
<p>等待最初相应的时长，A.K.A Time To First Byte。这个时长等于请求发送至服务器的延迟、响应返回至客户端的延迟、服务器处理请求的时间之和。</p>
<h3 id="content-download">Content Download</h3>
<p>浏览器接收完整相应的时长。</p>
<h3 id="receiving-push">Receiving Push</h3>
<p>浏览器接收服务器（HTTP/2）推送数据的时长。</p>
<h3 id="reading-push">Reading Push</h3>
<p>浏览器读取接收到数据的时长。</p>
<p>结合上图为例，可以看到请求图中接口的时间消耗：</p>
<ul>
<li>请求放入队列花费1.94ms</li>
<li>请求在队列中被阻塞了2.25ms直至开始发送请求</li>
<li>域名解析花费0.41ms</li>
<li>与服务器建立连接，花费72.11ms，其中，完成SSL协商，花费的38.24ms是包含在72.11ms内的</li>
<li>发送请求，花费0.17ms</li>
<li>发送后到接收第一个响应数据间隔了36.07ms</li>
<li>完成响应报文的下载花费了2.00ms</li>
</ul>
<p>本次请求一共花了115.16ms（数据求和为114.95ms，推断各阶段间有细微执行时间没有统计到）。</p>
<h2 id="full-request-process">Full Request Process</h2>
<p>现在结合Chrome的DevTools信息，再来更新一下从请求到页面展示的流程，以用户在浏览器中输入www.baidu.com为例，其中Chrome相关内容加粗显示：</p>
<ul>
<li>请求准备部分
<ul>
<li>用户在浏览器中输入www.baidu.com，按下回车</li>
<li><strong>Chrome开始准备请求，如果满足被Queued规则的话放入队列中等待</strong></li>
<li><strong>此时Chrome会分配磁盘的缓存空间为后续缓存操作做准备</strong></li>
<li><strong>队列任务等待结束，开始准备发送请求；非队列任务准备发送请求</strong></li>
<li>Chrome查询是否有可用的磁盘或内存缓存：
<ul>
<li>如有且新鲜，则获取缓存内容，跳过解析和发起请求过程</li>
<li>如果没有缓存，继续按照后续步骤发起请求</li>
</ul>
</li>
</ul>
</li>
<li>域名解析部分
<ul>
<li>浏览器解析URL，获取协议、路径和端口号</li>
<li>浏览器组装一个HTTP请求报文</li>
<li>浏览器进行域名解析，获取主机的IP地址，主要通过：
<ul>
<li>浏览器对域名解析结果的缓存</li>
<li>本机对域名解析结果的缓存</li>
<li>hosts文件</li>
<li>路由器缓存</li>
<li>ISP DNS缓存</li>
<li>DNS递归查询</li>
</ul>
</li>
</ul>
</li>
<li>发起请求部分
<ul>
<li>获取到IP后打开一个socket，与目标建立TCP连接，进行三次握手，细节太多受限篇幅不在此叙述，<strong>花费时间即为Initial Connection中减去SSL相关的部分</strong></li>
<li>如果为HTTPS请求，进行SSL握手，<strong>花费时间为Timing中SSL部分</strong></li>
<li>发送HTTP请求</li>
</ul>
</li>
<li>接收响应部分
<ul>
<li>服务器检查HTTP请求头是否包含缓存验证信息：
<ul>
<li>验证缓存新鲜，返回304</li>
<li>验证不通过，处理请求并准备HTTP相应</li>
</ul>
</li>
<li>HTTP响应通过建立的TCP连接发送给浏览器，首个报文抵达时间即为<strong>Waiting(TTFB)，完整接收时长为Waiting+Content Download时长</strong></li>
<li>浏览器视情况保留TCP连接或进行四次挥手结束连接</li>
<li>浏览器根据响应状态码进行处理</li>
<li>如果响应资源可以缓存，进行缓存</li>
<li>对压缩（如gzip）的响应进行解码</li>
</ul>
</li>
<li>处理响应资源，假设资源为HTML文档（后续过程可能没有严格的先后顺序）：
<ul>
<li>构建DOM树</li>
<li>针对构建过程中遇到的图片、样式、js启动下载</li>
<li>构建CSSOM树</li>
<li>根据DOM树和CSSOM树构建渲染树</li>
<li>JS解析</li>
<li>显示页面</li>
</ul>
</li>
</ul>
<h1 id="ref">Ref</h1>
<p><a href="https://developers.google.com/web/tools/chrome-devtools/network/understanding-resource-timing">Understanding Resource Timing</a></p>
<p><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=12066">chromium.org – Issue: Match Firefox’s per-host connection limit of 15</a></p>
<p><a href="https://developers.google.com/web/fundamentals/primers/service-workers">Service Worker</a></p>
]]></content>
		</item>
		
		<item>
			<title>BTW, I use Arch</title>
			<link>https://jiekun.dev/posts/2019-10-24-btw-i-use-arch/</link>
			<pubDate>Thu, 24 Oct 2019 03:19:30 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-10-24-btw-i-use-arch/</guid>
			<description>rm -rf当然是假的啊，怎么可能失败？ ArchLinux Installation Intro ArchLinux是Linux的一个发行版。 特点 滚动更新 Package管理：pacman 极简安装 高</description>
			<content type="html"><![CDATA[<p><img src="../2019/10/001-zhujiekun-screens.jpg" alt="">
rm -rf当然是假的啊，怎么可能失败？</p>
<h1 id="archlinux-installation">ArchLinux Installation</h1>
<h2 id="intro">Intro</h2>
<p>ArchLinux是Linux的一个发行版。</p>
<h3 id="特点">特点</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Rolling_release">滚动更新</a></li>
<li>Package管理：<a href="https://en.wikipedia.org/wiki/Arch_Linux#Pacman">pacman</a></li>
<li>极简安装</li>
<li>高度个性化</li>
</ul>
<h3 id="缺点">缺点</h3>
<ul>
<li>社区相对更小</li>
<li>出问题修复耗费时间</li>
<li>滚动更新带来的不稳定性</li>
</ul>
<h2 id="environment">Environment</h2>
<pre tabindex="0"><code>CPU.........: Intel(R) Core(TM) i3-4150 CPU @ 3.50GHz
MOTHERBOARD.: B85M-DS3H-A Gigabyte Technology Co., Ltd.
MEMORY......: 8GB
STORAGE.....: 120GB SSD

</code></pre><h2 id="installation-note">Installation Note</h2>
<p>安装过程参照官方文档<a href="https://wiki.archlinux.org/index.php/Installation_guide">Installation guide</a>及DistroTube的视频<a href="https://www.youtube.com/watch?v=HpskN_jKyhc&amp;t=606s">Arch Linux Installation Guide (2019)</a>即可顺利完成。</p>
<h3 id="history-commands">History Commands</h3>
<pre tabindex="0"><code># 检查联网
ping www.baidu.com
timedatectl set-ntp true

# 划分磁盘
cfdisk
mkfs.ext4 /dev/sda1
mkswap /dev/sda2
swapon /dev/sda2

# 安装部分必要的包
vim /etc/pacman.d/mirrorlist
pacstrap /mnt base linux linux-firmware

# 生成fstab分区记录文件
genfstab -U /mnt &gt;&gt; /mnt/etc/fstab

# 切换至新系统root
arch-chroot /mnt

pacman -S vim

# 时区和主机设置
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
hwclock --systohc
locale-gen
vim /etc/locale.conf
vim /etc/hostname
vim /etc/hosts

passwd

# 补充安装网络相关内容
pacman -S net-tools
pacman -S dhcpcd
# 启动dhcpcd
systemctl enable dhcpcd

# 创建普通用户 &amp; sudo权限
useradd -m duck
pacman -S sudo
usermod -aG wheel,audio,video,storage duck
vim /etc/sudoers
passwd duck

# 安装grub 生成引导文件
pacman -S grub
grub-install /dev/sda
grub-mkconfig -o /boot/grub/grub.cfg

exit
boot

</code></pre><h3 id="troubleshooting">Troubleshooting</h3>
<h4 id="legacy-vs-uefi">Legacy vs UEFI</h4>
<p>Legacy BIOS是基于<a href="https://en.wikipedia.org/wiki/Option_ROM">option ROMs</a>的，ROM顾名思义是一些只读的信息，是厂商在设备出厂时写入的，通过读取option ROMs中的信息加载硬件。如果硬件升级后，也需要有对应的options ROMs才能够正常使用。不同厂商提供的信息不一样，没有通用标准，大小为64KB。</p>
<p>UEFI借助将驱动存放至文件系统中而非option ROMs解决这个问题。驱动可以以光盘、闪存等形式存在，由UEFI接口处理这些信息，保证兼容性。</p>
<p>延伸阅读： <a href="https://pediaa.com/difference-between-uefi-and-legacy-boot/">Difference Between UEFI and Legacy Boot</a></p>
<p>本次安装过程中在BIOS设置了使用Legacy模式启动。</p>
<h4 id="分区划分">分区划分</h4>
<p>安装过程中使用了cfdisk代替fdisk进行分区，分区设置如下：</p>
<ul>
<li>创建Primary分区并设置”Bootable”</li>
<li>创建Primary分区，类型设置为swap</li>
</ul>
<h1 id="awesomewm-setup">AwesomeWM Setup</h1>
<h2 id="xorg">Xorg</h2>
<p>Xorg是Linux系统上一个知名的display server。图形化界面（graphical interface）和窗口管理（windows manager）都是基于display server的。因此首先在安装AwesomeWM之前需要有Xorg。</p>
<h2 id="awesome-windows-manager">Awesome Windows Manager</h2>
<p>AwesomeWM顾名思义是个窗口管理工具。</p>
<h2 id="xinit">xinit</h2>
<p>xinit允许用户手动启动一个Xorg display server。通常来说就用用来启动WM或者GI的。</p>
<h2 id="准备工作">准备工作</h2>
<p>基于上述内容，开始配置之前需要安装：</p>
<pre tabindex="0"><code>udo pacman -S xorg xorg-xinit awesome

</code></pre><p>当然，除了三件套以外还有一些相关的包，例如字体相关包，awesome默认设置了nano为编辑器，因此需要安装nano，默认设置了xtrem为终端，因此还需要安装xtrem等。</p>
<h2 id="配置">配置</h2>
<p>awesome通过xinit运行，因此要修改xinit的配置文件让它从默认运行的WM（或者其他）改为运行awesome。</p>
<h3 id="xinit配置">xinit配置</h3>
<p>xinit配置在<code>/etc/X11/xinit/xinitrc</code>文件，复制一份到家目录下并更名：</p>
<pre tabindex="0"><code>/etc/X11/xinit/xinitrc ~/.xinitrc
mv /etc/X11/xinit/xinitrc /etc/X11/xinit/xinitrc.bak

</code></pre><p>这样xinit运行（startx)的时候会读取家目录下的配置。</p>
<p>vim打开.xinitrc有如下内容</p>
<pre tabindex="0"><code>#!/bin/sh

userresources=$HOME/.Xresources
usermodmap=$HOME/.Xmodmap
sysresources=/etc/X11/xinit/.Xresources
sysmodmap=/etc/X11/xinit/.Xmodmap

# merge in defaults and keymaps

if [ -f $sysresources ]; then







    xrdb -merge $sysresources

fi

if [ -f $sysmodmap ]; then
    xmodmap $sysmodmap
fi

if [ -f &quot;$userresources&quot; ]; then







    xrdb -merge &quot;$userresources&quot;

fi

if [ -f &quot;$usermodmap&quot; ]; then
    xmodmap &quot;$usermodmap&quot;
fi

# start some nice programs

if [ -d /etc/X11/xinit/xinitrc.d ] ; then
 for f in /etc/X11/xinit/xinitrc.d/?*.sh ; do
  [ -x &quot;$f&quot; ] &amp;&amp; . &quot;$f&quot;
 done
 unset f
fi

xec awesome

</code></pre><p>默认示例配置中最后一段打开了3个不同大小的小窗口，其他内容直接省略，只需要保留<code># start some nice programs</code>后的内容，运行程序修改为awesome：</p>
<pre tabindex="0"><code>#!/bin/sh
# start some nice programs

if [ -d /etc/X11/xinit/xinitrc.d ] ; then
 for f in /etc/X11/xinit/xinitrc.d/?*.sh ; do
  [ -x &quot;$f&quot; ] &amp;&amp; . &quot;$f&quot;
 done
 unset f
fi

xec awesome

</code></pre><p>xinit配置完毕，执行startx即可运行配置中的内容。</p>
<h3 id="awesome配置">awesome配置</h3>
<p>awesome配置分为两部分：</p>
<ul>
<li>awesome全局配置</li>
<li>theme配置</li>
</ul>
<h4 id="awesome全局配置">awesome全局配置</h4>
<p>这部分配置控制awesome选择的主题、默认软件（编辑器、浏览器、终端等），是个lua脚本，示例文件在<code>/etc/xdg/awesome/rc.lua</code>，同样在家目录创建一份配置：</p>
<pre tabindex="0"><code>mkdir ~/.config
mkdir ~/.config/awesome
 /etc/xdg/awesome/rc.lua ~/.config/awesome/rc.lua

</code></pre><h4 id="theme配置">theme配置</h4>
<p>这部分配置控制具体的主题样式，包括各种图标、热键Mapping、颜色、壁纸、控件等等，通过改动theme配置可以实现高度自定义的awesome界面，示例文件目录在<code>/usr/share/awesome/</code>下，默认有：</p>
<ul>
<li>icons，图标</li>
<li>lib，lua脚本目录</li>
<li>themes，主题文件夹，默认包括几个示例主题<br>
将默认的配置复制到家目录下：</li>
</ul>
<pre tabindex="0"><code>usr/share/awesome/* ~/.config/awesome/

</code></pre><h4 id="具体配置及效果示例">具体配置及效果示例</h4>
<p>awesome默认使用xtrem作为终端，没有安装的情况下进入桌面是无法使用终端的。这里改用rxvt-unicode作为终端：</p>
<pre tabindex="0"><code># 安装rxvt-unicode
sudo pacman -S rxvt-unicode

# 修改rc.lua
vim ~/.config/awesome/rc.lua

</code></pre><p>搜索关键词terminal并将：</p>
<pre tabindex="0"><code>terminal     = &quot;xtrem&quot;

</code></pre><p>修改为：</p>
<pre tabindex="0"><code>terminal     = &quot;urxvtc&quot;

</code></pre><p>awesome默认主题为default，并且提供了几个内置主题，将主题修改为sky：</p>
<pre tabindex="0"><code>vim ~/.config/awesome/rc.lua

</code></pre><p>搜索关键词theme并将：</p>
<pre tabindex="0"><code>utiful.init(gears.filesystem.get_themes_dir() .. &quot;default/theme.lua&quot;)

</code></pre><p>修改为：</p>
<pre tabindex="0"><code>utiful.init(&quot;/home/duck/.config/awesome/themes/sky/theme.lua&quot;)

</code></pre><p>原代码使用lib中的gears.filesystem.get_themes_dir()方法拿到主题文件夹路径，正确配置之后可以直接修改主题名即可，这里示例使用了绝对路径。</p>
<p>主题默认壁纸在主题文件夹内，修改壁纸为自定义的图片：</p>
<pre tabindex="0"><code>vim ~/.config/awesome/themes/sky/theme.lua

</code></pre><p>搜索关键词wallpaper并将：</p>
<pre tabindex="0"><code>theme.wallpaper = themes_path .. &quot;sky/sky-background.png&quot;

</code></pre><p>修改为：</p>
<pre tabindex="0"><code>utiful.init(&quot;/home/duck/.config/awesome/themes/sky/my_background.png&quot;)

</code></pre><p>完成之后启动awesomeWM：</p>
<pre tabindex="0"><code>tartx

</code></pre><p>即可看到效果。</p>
<h2 id="小结">小结</h2>
<p>awesomeWM可以理解为一个针对键盘操作而设计的窗口管理工具，通过使用awesomeWM可以快速完成各种终端管理，提高工作效率。通过配置awesome的主题可以添加很多控件，如日历、天气等，自定义出专属的生产工具。</p>
<h1 id="linux-booting-process">Linux Booting Process</h1>
<p><img src="../2019/10/001-zhujiekun-Stages-of-Linux-Boot-Process.jpg" alt="">
Linux启动过程可以分为6个阶段</p>
<h2 id="bios">BIOS</h2>
<p>BIOS主要进行系统完整性检查，它会查找和执行对应的boot loader程序，比如在CD-ROM中找boot loader、在硬盘中找boot loader等。当查找到boot loader后，加载boot loader进内存，控制权交至boot loader。</p>
<h2 id="mbr">MBR</h2>
<p>MBR即Master Boot Record，位于bootable磁盘的第一个扇区。MBR大小小于512bytes，由三部分组成：</p>
<ul>
<li>主boot loader信息，在最前面的446bytes中</li>
<li>分区表信息，在随后的64bytes中</li>
<li>MBR校验信息，在最后的2bytes中</li>
</ul>
<p>它包含了GRUB相关信息，简单来说MBR加载和执行GRUB的boot loader。</p>
<h2 id="grub">GRUB</h2>
<p>GRUB即Grand Unified Bootloader，它负责加载和执行内核和文件镜像。如果安装了多个内核的话可以允许用户选择加载的内核，否则按照配置问价加载默认项，配置即之前grub-mkconfig生成的文件：</p>
<pre tabindex="0"><code>#
# DO NOT EDIT THIS FILE
#
# It is automatically generated by grub-mkconfig using templates
# from /etc/grub.d and settings from /etc/default/grub
#

### BEGIN /etc/grub.d/00_header ###
insmod part_gpt
insmod part_msdos
if [ -s $prefix/grubenv ]; then
  load_env
fi
if [ &quot;${next_entry}&quot; ] ; then
   set default=&quot;${next_entry}&quot;
   set next_entry=
   save_env next_entry
   set boot_once=true
else
   set default=&quot;0&quot;
fi

if [ x&quot;${feature_menuentry_id}&quot; = xy ]; then
  menuentry_id_option=&quot;--id&quot;
else
  menuentry_id_option=&quot;&quot;
fi

export menuentry_id_option

if [ &quot;${prev_saved_entry}&quot; ]; then
  set saved_entry=&quot;${prev_saved_entry}&quot;
  save_env saved_entry
  set prev_saved_entry=
  save_env prev_saved_entry
  set boot_once=true
fi

function savedefault {
  if [ -z &quot;${boot_once}&quot; ]; then
    saved_entry=&quot;${chosen}&quot;
    save_env saved_entry
  fi
}

function load_video {
  if [ x$feature_all_video_module = xy ]; then
    insmod all_video
  else
    insmod efi_gop
    insmod efi_uga
    insmod ieee1275_fb
    insmod vbe
    insmod vga
    insmod video_bochs
    insmod video_cirrus
  fi
}

if [ x$feature_default_font_path = xy ] ; then
   font=unicode
else
insmod part_msdos
insmod ext2
set root='hd0,msdos1'
if [ x$feature_platform_search_hint = xy ]; then
  search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
else
  search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
fi
    font=&quot;/usr/share/grub/unicode.pf2&quot;
fi

if loadfont $font ; then
  set gfxmode=auto
  load_video
  insmod gfxterm
  set locale_dir=$prefix/locale
  set lang=en_US
  insmod gettext
fi
terminal_input console
terminal_output gfxterm
if [ x$feature_timeout_style = xy ] ; then
  set timeout_style=menu
  set timeout=5
# Fallback normal timeout code in case the timeout_style feature is
# unavailable.
else
  set timeout=5
fi
### END /etc/grub.d/00_header ###

### BEGIN /etc/grub.d/10_linux ###
menuentry 'Arch Linux' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
    load_video
    set gfxpayload=keep
    insmod gzio
    insmod part_msdos
    insmod ext2
    set root='hd0,msdos1'
    if [ x$feature_platform_search_hint = xy ]; then
      search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
    else
      search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
    fi
    echo    'Loading Linux linux ...'
    linux   /boot/vmlinuz-linux root=UUID=0a869b77-d317-4b40-8fb1-ffa44721cce6 rw  loglevel=3 quiet
    echo    'Loading initial ramdisk ...'
    initrd  /boot/initramfs-linux.img
}
submenu 'Advanced options for Arch Linux' $menuentry_id_option 'gnulinux-advanced-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
    menuentry 'Arch Linux, with Linux linux' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-linux-advanced-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
        load_video
        set gfxpayload=keep
        insmod gzio
        insmod part_msdos
        insmod ext2
        set root='hd0,msdos1'
        if [ x$feature_platform_search_hint = xy ]; then
          search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
        else
          search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
        fi
        echo    'Loading Linux linux ...'
        linux   /boot/vmlinuz-linux root=UUID=0a869b77-d317-4b40-8fb1-ffa44721cce6 rw  loglevel=3 quiet
        echo    'Loading initial ramdisk ...'
        initrd  /boot/initramfs-linux.img
    }
    menuentry 'Arch Linux, with Linux linux (fallback initramfs)' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-linux-fallback-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
        load_video
        set gfxpayload=keep
        insmod gzio
        insmod part_msdos
        insmod ext2
        set root='hd0,msdos1'
        if [ x$feature_platform_search_hint = xy ]; then
          search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
        else
          search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
        fi
        echo    'Loading Linux linux ...'
        linux   /boot/vmlinuz-linux root=UUID=0a869b77-d317-4b40-8fb1-ffa44721cce6 rw  loglevel=3 quiet
        echo    'Loading initial ramdisk ...'
        initrd  /boot/initramfs-linux-fallback.img
    }
}

### END /etc/grub.d/10_linux ###

### BEGIN /etc/grub.d/20_linux_xen ###
### END /etc/grub.d/20_linux_xen ###

### BEGIN /etc/grub.d/30_os-prober ###
### END /etc/grub.d/30_os-prober ###

### BEGIN /etc/grub.d/40_custom ###
# This file provides an easy way to add custom menu entries.  Simply type the
# menu entries you want to add after this comment.  Be careful not to change
# the 'exec tail' line above.
### END /etc/grub.d/40_custom ###

### BEGIN /etc/grub.d/41_custom ###
if [ -f  ${config_directory}/custom.cfg ]; then
  source ${config_directory}/custom.cfg
elif [ -z &quot;${config_directory}&quot; -a -f  $prefix/custom.cfg ]; then
  source $prefix/custom.cfg;
fi
### END /etc/grub.d/41_custom ###

</code></pre><h2 id="kernel">Kernel</h2>
<p>内核负责根据grub.cfg中声明的<code>root='hd0,msdos1'</code>挂载文件系统，并且执行<code>/sbin/init</code>的程序。因为init是第一个被Linux内核执行的程序，所以<code>ps aux | grep init</code>的pid为1。</p>
<pre tabindex="0"><code>t         1  0.0  0.0 165304 10528 ?        Ss   11:45   0:13 /sbin/init splash

</code></pre><p>grub.cfg中有一行：</p>
<pre tabindex="0"><code>initrd  /boot/initramfs-linux.img

</code></pre><p>initrd即初始化RAM Disk，使用initramfs-linux.img镜像，作为临时的root文件系统，直到启动后真正的文件系统挂载。initrd同时还包括了一些必要的驱动，让内核可以获取分区和硬件等信息。</p>
<h2 id="init">Init</h2>
<p>查看/etc/inittab文件来决定Linux运行的Level，具体包括以下7个Level：</p>
<ul>
<li>0 – halt</li>
<li>1 – Single user mode</li>
<li>2 – Multiuser, without NFS</li>
<li>3 – Full multiuser mode</li>
<li>4 – unused</li>
<li>5 – X11</li>
<li>6 – reboot</li>
</ul>
<p>Init根据文件决定默认的initlevel，加载所有相关的程序。</p>
<h2 id="runlevel">Runlevel</h2>
<p>Linux启动时，你会看到各种服务启动，比如“starting sendmail …. OK”，这些都是Runlevel的程序，不同的runlevel在相应的目录中：</p>
<pre tabindex="0"><code># Run level ?
 /etc/rc.d/rc?.d/

</code></pre><p>在目录下有“S”和“K”开头的程序，S代表startup的时候运行，K代表kill的时候运行。</p>
<h1 id="linux-command-analysis">Linux Command Analysis</h1>
<p>以<code>free</code>命令为例分析执行过程。</p>
<h2 id="free">free</h2>
<p>free命令源码参考<a href="https://github.com/soarpenguin/procps-3.0.5/blob/master/free.c">procps</a>。节选如下：</p>
<pre tabindex="0"><code>int main(int argc, char **argv)
{
    int c, flags = 0, unit_set = 0;
    struct commandline_arguments args;

    /*
     * For long options that have no equivalent short option, use a
     * non-character as a pseudo short option, starting with CHAR_MAX + 1.
     */
    enum {
        SI_OPTION = CHAR_MAX + 1,
        KILO_OPTION,
        MEGA_OPTION,
        GIGA_OPTION,
        TERA_OPTION,
        PETA_OPTION,
        TEBI_OPTION,
        PEBI_OPTION,
        HELP_OPTION
    };

    static const struct option longopts[] = {
        {  &quot;bytes&quot;, no_argument,        NULL,  'b'      },
        {  &quot;kilo&quot;,  no_argument,        NULL,  KILO_OPTION  },
        {  &quot;mega&quot;,  no_argument,        NULL,  MEGA_OPTION  },
        {  &quot;giga&quot;,  no_argument,        NULL,  GIGA_OPTION  },
        {  &quot;tera&quot;,  no_argument,        NULL,  TERA_OPTION  },
        {  &quot;peta&quot;,  no_argument,        NULL,  PETA_OPTION  },
        {  &quot;kibi&quot;,  no_argument,        NULL,  'k'      },
        {  &quot;mebi&quot;,  no_argument,        NULL,  'm'      },
        {  &quot;gibi&quot;,  no_argument,        NULL,  'g'      },
        {  &quot;tebi&quot;,  no_argument,        NULL,  TEBI_OPTION  },
        {  &quot;pebi&quot;,  no_argument,        NULL,  PEBI_OPTION  },
        {  &quot;human&quot;, no_argument,        NULL,  'h'      },
        {  &quot;si&quot;,    no_argument,        NULL,  SI_OPTION    },
        {  &quot;lohi&quot;,  no_argument,        NULL,  'l'      },
        {  &quot;total&quot;, no_argument,        NULL,  't'      },
        {  &quot;seconds&quot;,   required_argument,  NULL,  's'      },
        {  &quot;count&quot;, required_argument,  NULL,  'c'      },
        {  &quot;wide&quot;,  no_argument,        NULL,  'w'      },
        {  &quot;help&quot;,  no_argument,        NULL,  HELP_OPTION  },
        {  &quot;version&quot;,   no_argument,        NULL,  'V'      },
        {  NULL,    0,          NULL,  0        }
    };

    /* defaults */
    args.exponent = 0;
    args.repeat_interval = 1000000;
    args.repeat_counter = 0;

#ifdef HAVE_PROGRAM_INVOCATION_NAME
    program_invocation_name = program_invocation_short_name;
#endif
    setlocale (LC_ALL, &quot;&quot;);
    bindtextdomain(PACKAGE, LOCALEDIR);
    textdomain(PACKAGE);
    atexit(close_stdout);

    while ((c = getopt_long(argc, argv, &quot;bkmghltc:ws:V&quot;, longopts, NULL)) != -1)
        switch (c) {
        case 'b':
                check_unit_set(&amp;unit_set);
            args.exponent = 1;
            break;
        case 'k':
                check_unit_set(&amp;unit_set);
            args.exponent = 2;
            break;
        case 'm':
                check_unit_set(&amp;unit_set);
            args.exponent = 3;
            break;
        case 'g':
                check_unit_set(&amp;unit_set);
            args.exponent = 4;
            break;
        case TEBI_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 5;
            break;
        case PEBI_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 6;
            break;
        case KILO_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 2;
            flags |= FREE_SI;
            break;
        case MEGA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 3;
            flags |= FREE_SI;
            break;
        case GIGA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 4;
            flags |= FREE_SI;
            break;
        case TERA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 5;
            flags |= FREE_SI;
            break;
        case PETA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 6;
            flags |= FREE_SI;
            break;
        case 'h':
            flags |= FREE_HUMANREADABLE;
            break;
        case SI_OPTION:
            flags |= FREE_SI;
            break;
        case 'l':
            flags |= FREE_LOHI;
            break;
        case 't':
            flags |= FREE_TOTAL;
            break;
        case 's':
            flags |= FREE_REPEAT;
            errno = 0;
            args.repeat_interval = (1000000 * strtod_nol_or_err(optarg, &quot;seconds argument failed&quot;));
            if (args.repeat_interval &amp;lt; 1)
                xerrx(EXIT_FAILURE,
                     _(&quot;seconds argument `%s' is not positive number&quot;), optarg);
            break;
        case 'c':
            flags |= FREE_REPEAT;
            flags |= FREE_REPEATCOUNT;
            args.repeat_counter = strtol_or_err(optarg,
                _(&quot;failed to parse count argument&quot;));
            if (args.repeat_counter &amp;lt; 1)
              error(EXIT_FAILURE, ERANGE,
                  _(&quot;failed to parse count argument: '%s'&quot;), optarg);
            break;
        case 'w':
            flags |= FREE_WIDE;
            break;
        case HELP_OPTION:
            usage(stdout);
        case 'V':
            printf(PROCPS_NG_VERSION);
            exit(EXIT_SUCCESS);
        default:
            usage(stderr);
        }

    do {

        meminfo();
        /* Translation Hint: You can use 9 character words in
         * the header, and the words need to be right align to
         * beginning of a number. */
        if (flags &amp; FREE_WIDE) {
            printf(_(&quot;              total        used        free      shared     buffers       cache   available&quot;));
        } else {
            printf(_(&quot;              total        used        free      shared  buff/cache   available&quot;));
        }
        printf(&quot;\n&quot;);
        printf(&quot;%-7s&quot;, _(&quot;Mem:&quot;));
        printf(&quot; %11s&quot;, scale_size(kb_main_total, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_main_used, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_main_free, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_main_shared, flags, args));
        if (flags &amp; FREE_WIDE) {
            printf(&quot; %11s&quot;, scale_size(kb_main_buffers, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_main_cached, flags, args));
        } else {
            printf(&quot; %11s&quot;, scale_size(kb_main_buffers+kb_main_cached, flags, args));
        }
        printf(&quot; %11s&quot;, scale_size(kb_main_available, flags, args));
        printf(&quot;\n&quot;);
        /*
         * Print low vs. high information, if the user requested it.
         * Note we check if low_total == 0: if so, then this kernel
         * does not export the low and high stats. Note we still want
         * to print the high info, even if it is zero.
         */
        if (flags &amp; FREE_LOHI) {
            printf(&quot;%-7s&quot;, _(&quot;Low:&quot;));
            printf(&quot; %11s&quot;, scale_size(kb_low_total, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_low_total - kb_low_free, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_low_free, flags, args));
            printf(&quot;\n&quot;);

            printf(&quot;%-7s&quot;, _(&quot;High:&quot;));
            printf(&quot; %11s&quot;, scale_size(kb_high_total, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_high_total - kb_high_free, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_high_free, flags, args));
            printf(&quot;\n&quot;);
        }

        printf(&quot;%-7s&quot;, _(&quot;Swap:&quot;));
        printf(&quot; %11s&quot;, scale_size(kb_swap_total, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_swap_used, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_swap_free, flags, args));
        printf(&quot;\n&quot;);

        if (flags &amp; FREE_TOTAL) {
            printf(&quot;%-7s&quot;, _(&quot;Total:&quot;));
            printf(&quot; %11s&quot;, scale_size(kb_main_total + kb_swap_total, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_main_used + kb_swap_used, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_main_free + kb_swap_free, flags, args));
            printf(&quot;\n&quot;);
        }
        fflush(stdout);
        if (flags &amp; FREE_REPEATCOUNT) {
            args.repeat_counter--;
            if (args.repeat_counter &amp;lt; 1)
                exit(EXIT_SUCCESS);
        }
        if (flags &amp; FREE_REPEAT) {
            printf(&quot;\n&quot;);
            usleep(args.repeat_interval);
        }
    } while ((flags &amp; FREE_REPEAT));

    exit(EXIT_SUCCESS);
}

</code></pre><p>可以观察到命令主要做了几件事：</p>
<ul>
<li>执行meminfo()方法</li>
<li>根据输入参数，进行格式转换、单位转换等</li>
</ul>
<p>meminfo()方法并不在free.c中，全局查找定位到sysinfo.c文件中：</p>
<pre tabindex="0"><code>void meminfo(void){
  char namebuf[32]; /* big enough to hold any row name */
  int linux_version_code = procps_linux_version();
  mem_table_struct findme = { namebuf, NULL};
  mem_table_struct *found;
  char *head;
  char *tail;
  static const mem_table_struct mem_table[] = {
  {&quot;Active&quot;,       &amp;kb_active},       // important
  {&quot;Active(file)&quot;, &amp;kb_active_file},
  {&quot;AnonPages&quot;,    &amp;kb_anon_pages},
  {&quot;Bounce&quot;,       &amp;kb_bounce},
  {&quot;Buffers&quot;,      &amp;kb_main_buffers}, // important
  {&quot;Cached&quot;,       &amp;kb_page_cache},  // important
  {&quot;CommitLimit&quot;,  &amp;kb_commit_limit},
  {&quot;Committed_AS&quot;, &amp;kb_committed_as},
  {&quot;Dirty&quot;,        &amp;kb_dirty},        // kB version of vmstat nr_dirty
  {&quot;HighFree&quot;,     &amp;kb_high_free},
  {&quot;HighTotal&quot;,    &amp;kb_high_total},
  {&quot;Inact_clean&quot;,  &amp;kb_inact_clean},
  {&quot;Inact_dirty&quot;,  &amp;kb_inact_dirty},
  {&quot;Inact_laundry&quot;,&amp;kb_inact_laundry},
  {&quot;Inact_target&quot;, &amp;kb_inact_target},
  {&quot;Inactive&quot;,     &amp;kb_inactive},     // important
  {&quot;Inactive(file)&quot;,&amp;kb_inactive_file},
  {&quot;LowFree&quot;,      &amp;kb_low_free},
  {&quot;LowTotal&quot;,     &amp;kb_low_total},
  {&quot;Mapped&quot;,       &amp;kb_mapped},       // kB version of vmstat nr_mapped
  {&quot;MemAvailable&quot;, &amp;kb_main_available}, // important
  {&quot;MemFree&quot;,      &amp;kb_main_free},    // important
  {&quot;MemTotal&quot;,     &amp;kb_main_total},   // important
  {&quot;NFS_Unstable&quot;, &amp;kb_nfs_unstable},
  {&quot;PageTables&quot;,   &amp;kb_pagetables},   // kB version of vmstat nr_page_table_pages
  {&quot;ReverseMaps&quot;,  &amp;nr_reversemaps},  // same as vmstat nr_page_table_pages
  {&quot;SReclaimable&quot;, &amp;kb_slab_reclaimable}, // &quot;slab reclaimable&quot; (dentry and inode structures)
  {&quot;SUnreclaim&quot;,   &amp;kb_slab_unreclaimable},
  {&quot;Shmem&quot;,        &amp;kb_main_shared},  // kernel 2.6.32 and later
  {&quot;Slab&quot;,         &amp;kb_slab},         // kB version of vmstat nr_slab
  {&quot;SwapCached&quot;,   &amp;kb_swap_cached},
  {&quot;SwapFree&quot;,     &amp;kb_swap_free},    // important
  {&quot;SwapTotal&quot;,    &amp;kb_swap_total},   // important
  {&quot;VmallocChunk&quot;, &amp;kb_vmalloc_chunk},
  {&quot;VmallocTotal&quot;, &amp;kb_vmalloc_total},
  {&quot;VmallocUsed&quot;,  &amp;kb_vmalloc_used},
  {&quot;Writeback&quot;,    &amp;kb_writeback},    // kB version of vmstat nr_writeback
  };
  const int mem_table_count = sizeof(mem_table)/sizeof(mem_table_struct);
  unsigned long watermark_low;
  signed long mem_available, mem_used;

  FILE_TO_BUF(MEMINFO_FILE,meminfo_fd);

  kb_inactive = ~0UL;
  kb_low_total = kb_main_available = 0;

  head = buf;
  for(;;){
    tail = strchr(head, ':');
    if(!tail) break;
    *tail = '\0';
    if(strlen(head) &gt;= sizeof(namebuf)){
      head = tail+1;
      goto nextline;
    }
    strcpy(namebuf,head);
    found = bsearch(&amp;findme, mem_table, mem_table_count,
        sizeof(mem_table_struct), compare_mem_table_structs
    );
    head = tail+1;
    if(!found) goto nextline;
    *(found-&gt;slot) = (unsigned long)strtoull(head,&amp;tail,10);
nextline:
    tail = strchr(head, '\n');
    if(!tail) break;
    head = tail+1;
  }
  if(!kb_low_total){  /* low==main except with large-memory support */
    kb_low_total = kb_main_total;
    kb_low_free  = kb_main_free;
  }
  if(kb_inactive==~0UL){
    kb_inactive = kb_inact_dirty + kb_inact_clean + kb_inact_laundry;
  }
  kb_main_cached = kb_page_cache + kb_slab_reclaimable;
  kb_swap_used = kb_swap_total - kb_swap_free;

  /* if kb_main_available is greater than kb_main_total or our calculation of
     mem_used overflows, that's symptomatic of running within a lxc container
     where such values will be dramatically distorted over those of the host. */
  if (kb_main_available &gt; kb_main_total)
    kb_main_available = kb_main_free;
  mem_used = kb_main_total - kb_main_free - kb_main_cached - kb_main_buffers;
  if (mem_used &amp;lt; 0)
    mem_used = kb_main_total - kb_main_free;
  kb_main_used = (unsigned long)mem_used;

  /* zero? might need fallback for 2.6.27 &amp;lt;= kernel &amp;lt;? 3.14 */
  if (!kb_main_available) {
#ifdef __linux__
    if (linux_version_code &amp;lt; LINUX_VERSION(2, 6, 27))
      kb_main_available = kb_main_free;
    else {
      FILE_TO_BUF(VM_MIN_FREE_FILE, vm_min_free_fd);
      kb_min_free = (unsigned long) strtoull(buf,&amp;tail,10);

      watermark_low = kb_min_free * 5 / 4; /* should be equal to sum of all 'low' fields in /proc/zoneinfo */

      mem_available = (signed long)kb_main_free - watermark_low
      + kb_inactive_file + kb_active_file - MIN((kb_inactive_file + kb_active_file) / 2, watermark_low)
      + kb_slab_reclaimable - MIN(kb_slab_reclaimable / 2, watermark_low);

      if (mem_available &amp;lt; 0) mem_available = 0;
      kb_main_available = (unsigned long)mem_available;
    }
#else
      kb_main_available = kb_main_free;
#endif /* linux */
  }
}

</code></pre><p>主要进行了：</p>
<ul>
<li>定义数据格式mem_table_struct</li>
<li>执行FILE_TO_BUF(MEMINFO_FILE, meminfo_fd)，这里的MEMINFO_FILE在上文有定义<code>#define MEMINFO_FILE &quot;/proc/meminfo&quot;</code>，meminfo_fd同样有定义为-1</li>
<li>后续主要对stdout内容进行计算，例如<code>mem_used = kb_main_total - kb_main_free - kb_main_cached - kb_main_buffers</code>，以及异常数值处理，例如当上面计算得出的mem_used为负值时，重新以<code>mem_used = kb_main_total - kb_main_free</code>计算</li>
</ul>
<p>FILE_TO_BUF方法具体没有找到定义，在sysinfo.c中有一段相关注释代码如下：</p>
<pre tabindex="0"><code>#define FILE_TO_BUF(filename, fd) do{               \
    static int local_n;                     \
    if (fd == -1 &amp;&amp; (fd = open(filename, O_RDONLY)) == -1) {    \
    fputs(BAD_OPEN_MESSAGE, stderr);            \
    fflush(NULL);                       \
    _exit(102);                     \
    }                               \
    lseek(fd, 0L, SEEK_SET);                    \
    if ((local_n = read(fd, buf, sizeof buf - 1)) &amp;lt; 0) {    \
    perror(filename);                   \
    fflush(NULL);                       \
    _exit(103);                     \
    }                               \
    buf[local_n] = '\0';                    \
}while(0)

</code></pre><p>可以看到FILE_TO_BUF()主要进行了：</p>
<ul>
<li>fd默认-1，表示未打开</li>
<li>尝试打开对应文件（如/proc/meminfo），赋给fd，成功则fd改变，否则fputs打开失败消息，退出</li>
<li>打开成功，读取fd内容，放入buf中</li>
</ul>
<p>总结free命令从读取/proc/meminfo到显示过程：</p>
<ul>
<li>尝试打开/proc/meminfo，成功则暂存至变量，失败退出</li>
<li>读取暂存的变量，根据定义的数据结构，将各个值放至对应字段</li>
<li>根据读取的数值，计算一些统计值，如已使用内存=总内存-可用内存，并进行对应的异常处理</li>
<li>处理完毕的数据，根据free命令的参数，进行格式转换，如：kb、gb间的转换；根据-h参数决定是否添加单位；根据参数决定字段是否要显示等</li>
<li>输出格式化（类似表格形式）后的内容</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>理解AMQP协议和RabbitMQ的性能和可靠平衡</title>
			<link>https://jiekun.dev/posts/2019-09-26-%E7%90%86%E8%A7%A3amqp%E5%8D%8F%E8%AE%AE%E5%92%8Crabbitmq%E7%9A%84%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%AF%E9%9D%A0%E5%B9%B3%E8%A1%A1/</link>
			<pubDate>Thu, 26 Sep 2019 14:09:28 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-26-%E7%90%86%E8%A7%A3amqp%E5%8D%8F%E8%AE%AE%E5%92%8Crabbitmq%E7%9A%84%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%AF%E9%9D%A0%E5%B9%B3%E8%A1%A1/</guid>
			<description>前言 在之前的博客中，已经使用Pika包实践操作过RabbitMQ了，借用了几个不同的Exchange实现不同功能的生产-消费模式，但是对Ra</description>
			<content type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>在之前的博客中，已经使用Pika包实践操作过RabbitMQ了，借用了几个不同的Exchange实现不同功能的生产-消费模式，但是对RabbitMQ的细节还缺乏更进一步的理解。今天从AMQP协议起更仔细地来看一下MQ背后的实现。</p>
<h1 id="amqp协议">AMQP协议</h1>
<p>RabbitMQ通过AMQP协议通信，这就类似于HTTP客户端和服务器进行通信一样。<br>
在AMQP中，客户端和服务器之间的通信数据是拆成帧（frame）的结构。</p>
<h5 id="对话启动">对话启动</h5>
<p>需要对话首先要建立连接：</p>
<p><img src="../2019/09/1-1.png" alt="">
客户端先发送协议头（protocol header）给服务器，服务器收到后，返回<code>Connection.Start</code>给客户端，客户端确认后返回<code>Connection.StartOk</code>给服务器，完成回话启动。</p>
<h5 id="信道">信道</h5>
<p>AMQP规范定义了通信的信道，一个AMQP连接可以有多个信道，允许客户端和服务器之间进行多次会话。</p>
<h5 id="amqp帧结构">AMQP帧结构</h5>
<p>上面留意到，建立连接时服务器和客户端的相应都有共同部分<code>Connection</code>，因为AMQP命令是分为类和方法，用点（.）连接。连接时，<code>Connection</code>是使用的类，<code>Start</code>和<code>StartOk</code>是方法。</p>
<p>AMQB的帧由以下组件组成：</p>
<ul>
<li>帧类型</li>
<li>信道</li>
<li>帧大小（字节）</li>
<li>帧有效载荷</li>
<li>结束字节标记（0xce）</li>
</ul>
<p><img src="../2019/09/2.png" alt="">
AMQP的帧有五种类型：</p>
<ul>
<li>协议头帧，也就是上面建立连接使用，仅使用一次</li>
<li>方法帧，携带发送或接收的请求或相应</li>
<li>内容头帧，消息的大小和属性</li>
<li>消息体帧，消息的内容</li>
<li>心跳帧，双向均可发送，确保连接两端可用和正常工作</li>
</ul>
<p>下面来看一下这几种类型的帧如何组成消息。</p>
<ul>
<li>除了建立连接以外，AMQP在通信时，首先使用方法帧构建RPC请求所需的类、方法和参数。按照上文的帧结构，现在构造一个帧：
<ul>
<li>帧类型为方法帧（1）</li>
<li>信道0</li>
<li>有效载荷大小为41</li>
<li>有效载荷为类、方法、参数等</li>
</ul>
</li>
<li>以0xce结尾</li>
</ul>
<p><img src="../2019/09/3.png" alt=""></p>
<ul>
<li>方法帧通知对方后，继续构造一个内容头帧，告知对方接下来要发送的消息大小和属性：
<ul>
<li>帧类型为内容头帧（2）</li>
<li>信道1</li>
<li>有效载荷大小为45</li>
<li>有效载荷为：消息体大小55，被设置的属性为144（内容类型）和200（app_id），被设置的属性的值分别为application/json和Test，timestamp属性为1014206880，投递模式为1</li>
</ul>
</li>
<li>以0xce结尾</li>
</ul>
<p><img src="../2019/09/4.png" alt="">
注意内容头帧声明的这些属性是在BasicProperty映射表中的。</p>
<ul>
<li>内容头帧通知对方后，继续构造一个消息体帧发送具体消息：
<ul>
<li>帧类型为消息体帧（3）</li>
<li>信道为1</li>
<li>有效载荷大小为55（对应内容头帧中的55）</li>
<li>有效载荷为一段JSON格式的字符串</li>
</ul>
</li>
<li>以0xce结尾</li>
</ul>
<p><img src="../2019/09/5.png" alt="">
注意AMQP协议是不会理会消息中的内容的，不对消息进行解析，即使知道对方是JSON格式内容。</p>
<h5 id="使用amqp协议">使用AMQP协议</h5>
<p>了解完AMQP协议的格式后，来看一下如何使用AMQP协议。<br>
首先，需要声明一个交换器（Exchange）。交换器在AMQP规范中有自己的类，使用Exchange.Declear命令创建交换器，服务端使用Exchange.DeclearOk进行响应：</p>
<p><img src="../2019/09/6.png" alt="">
然后再创建一个队列（Queue）。同样Queue.Declear和Queue.DeclearOk完成。注意声明队列的时候多次发送同一个Queue.Declear不会有作用，只有第一次Declear会被处理，后续再Declear同样内容无效，Declear同名不同属性队列也无效。</p>
<p><img src="../2019/09/7.png" alt="">
现在我们有交换器和队列，在之前的博客中我们知道，消息是发送给Exchange的，然后Exchange推送至队列中。Exchange和Queue的关系需要进行绑定。使用Queue.Bind和Queue.BindOk命令将Queue绑定至Exchange。</p>
<p><img src="../2019/09/8.png" alt="">
现在所有准备工作都完成了，我们来发布消息到RabbitMQ。通过上文可知，发送消息需要发送方法帧、内容头帧和（至少一个）消息体帧。其中方法帧在发布消息时应该是对应Basic类的Publish方法。</p>
<p><img src="../2019/09/9.png" alt="">
当RabbitMQ收到消息后，它会尝试将方法帧中的交换器名称和配置交换器的数据库进行匹配。如果配置中不存在交换器，将会自动丢弃该消息。如果希望确保投递消息成功，发布时mandatory标志需要设置为true，或者使用投递确认机制。<br>
RabbitMQ收到的消息将会以FIFO的顺序放入队列，并且放入队列的是消息的引用而不是消息本身，这样可以允许一个消息放入多个队列中。<br>
RabbitMQ可以将这些消息保存在内存中或写入磁盘，取决于Basic.Properties中指定的delivery-mode属性。</p>
<p>再来看一下如何从RabbitMQ中消费消息。<br>
与Basic.Publish类似，首先客户端发送Basic.Consume命令，服务端返回Basic.ConsumeOk，消费者进入活跃状态。然后服务端开始向消费者发送消息，以Basic.Deliver为方法帧，加上内容头和消息体帧发送消息。直到消费者发送Basic.Cancel或者触发一些事件前，服务端都会一直发送消息。</p>
<p><img src="../2019/09/10.png" alt="">
在发送Basic.Consume时，可以设置no_ack=false，这样消费者必须对每条消息发送Basic.Ack进行确认，否则RabbitMQ就会连续发送消息直到Basic.Cancel。</p>
<p><img src="../2019/09/11.png" alt="">
当发送Basic.Ack相应帧的时候，消费者必须在Basic.Deliver方法帧中传递一个投递标签（delivery tag）的参数。</p>
<h1 id="amqp的basicproperties">AMQP的Basic.Properties</h1>
<p>在内容头帧中，有包含很多消息属性，如上文提到的属性144，值为application/json，实际上属性144就是代表content-type。通过这些属性来对消息体进行描述。来看一下Basic.Properties都有哪些属性：</p>
<p><img src="../2019/09/12.png" alt="">
本文不打算一一解释各个属性，它们在需要使用时都可以通过文档查询到。下面选取几个常见的属性简单介绍。</p>
<ul>
<li>expiration，时间戳，超过后消息会被服务器丢弃。</li>
<li>delivery-mode，1表示非持久化消息，2表示持久化消息，性能相关。</li>
<li>header，自定义消息头，值为键值对，通过header属性可以结合header类型的Exchange实现自定义的消息路由。</li>
<li>priority，优先级，如果存在更高优先级的消息，消费者将更早获取到。</li>
</ul>
<p><img src="../2019/09/13.png" alt=""></p>
<h1 id="消息发布的性能权衡">消息发布的性能权衡</h1>
<p>《深入RabbitMQ》中有一幅图简单描述了RabbitMQ实现高性能和可靠投递时的设置组合：</p>
<p><img src="../2019/09/14.png" alt="">
通过结合不同的组合，我们可以从RabbitMQ上榨取最好的性能或者保障更可靠的消息传递。</p>
<p>下面介绍几个实现不同需求的设置。</p>
<h5 id="mandatory">mandatory</h5>
<p>mandatory标志是和Basic.Publish一起传递的参数，告诉RabbitMQ如果消息不可路由，将它通过Basic.Return返回给消费者。</p>
<h5 id="发布者确认替代事务">发布者确认替代事务</h5>
<p>为了确认RabbitMQ收到消息，在发送消息前，发送Confirm.Select命令，等待RabbitMQ返回Confirm.SelectOk以开启投递确认。开启后，对于每条发布的消息，服务器都会返回Basic.Ack响应，或者Baskc.Nack并让发布者决定如何处理。</p>
<p><img src="../2019/09/15.png" alt=""></p>
<h5 id="备用交换器处理无法路由的消息">备用交换器处理无法路由的消息</h5>
<p>声明一个Exchange作为备用交换器，然后在声明<strong>其他</strong>交换器时使用参数<code>alternate-exchange=备用交换器</code>。备用交换器（AE）类型设定为fanout，当消息在Exchange上无法路由时，它将会由AE路由至死信队列。</p>
<p><img src="../2019/09/16.png" alt=""></p>
<h5 id="事务">事务</h5>
<p>在没有确认投递（Confirm.Select）的情况下，事务是确保消息被成功投递的唯一方法。AMQP事务（TX）的使用是：</p>
<ul>
<li>发送TX.Select，相应TX.SelectOk</li>
<li>Basic.Publish</li>
<li>TX.Commit和TX.CommitOk<br>
在Basic.Publish后如果有异常，可以通过TX.Rollback处理。</li>
</ul>
<h5 id="ha队列">HA队列</h5>
<p>HA队列作为RabbitMQ的高可用实现，通过RabbitMQ集群，在创建Queue时设置HA策略，开启HA队列。当消息发布到高可用队列中，该消息会被发送到集群中的每台服务器，一旦消息在任何节点完成消费，那么消息的所有副本将立即从其他节点中删除。</p>
<p><img src="../2019/09/17.png" alt=""></p>
<h5 id="delivery-mode">delivery-mode</h5>
<p>通过设置delivery-mode=2，消息会被持久化到硬盘。持久化会导致性能问题。当消息引用不存在任何队列中，RabbitMQ将从硬盘中删除消息。</p>
<h5 id="rabbitmq回推">RabbitMQ回推</h5>
<p>发布者有可能大量发送消息，如果不进行处理，有可能会拖垮服务。<br>
在旧版本中，发布者发布过快，将会收到一条Channel.Flow让发布者产生阻塞，直到接收到另一条Channel.Flow命令为止。<br>
但是对于不礼貌的发布者而言，无视Channel.Flow命令继续发送仍然会导致问题。RabbitMQ团队使用TCP背压机制来解决这个问题，通过停止接受TCP的低层数据来防止被拖垮。<br>
在内部RabbitMQ有一套信用机制，接收到消息时会扣除一点信用值，完成处理返还信用值。当信用值不足时，当前连接的消息会被跳过直到它有足够的信用值为止。<br>
RabbitMQ还有通知客户端已被阻塞的方法：Connection.Blocked和Connection.Unblocked。</p>
<h1 id="rabbitmq和消费者">RabbitMQ和消费者</h1>
<p>上面聊完发布者和RabbitMQ，现在轮到消费者和RabbitMQ了。</p>
<h5 id="拉取和消费">拉取和消费</h5>
<p>消费者获取消息可以通过Basic.Get和Basic.Consume，下面来比较一下这两者：</p>
<ul>
<li>Basic.Get类似于轮询，如果有消息可消费，返回Basic.GetOk和内容头、消息体；如果没有消息可消费，返回Basic.GetEmpty。</li>
<li>Basic.Consume开启消费者活动状态，RabbitMQ如果有消息即可向消费者进行推送：Basic.Deliver，视情况消费者再返回Basic.Ack。</li>
<li>Basic.Consume的性能比Basic.Get更好，Get的轮询影响吞吐量，并且它不知道什么时候会有新的消息，所以要一直询问。</li>
</ul>
<h5 id="no-ack">no-ack</h5>
<p>消费者发送Basic.Consume的时候，可以带上no-ack标志，表示消费消息不需要进行ack确认，提高性能。<br>
如果不开启no-ack，RabbitMQ会等待消费者发送Basic.Ack确认消息，如果不得到确认，消息将不会被消费掉。</p>
<h5 id="服务质量设置控制消费者预取">服务质量设置控制消费者预取</h5>
<p>如果消息要一条一条确认，那会比较麻烦。通过QoS设置，在确认消息之前，消费者可以预先接收一定数量的消息。<br>
使用QoS的好处就是不用每次都确认消息，通过Basic.Ack设置multiple属性为True，可以让RabbitMQ知道消费者想确认之前未确认的消息。</p>
<h5 id="消费者使用事务">消费者使用事务</h5>
<p>和生产者一样使用TX类，可能会对性能有影响。</p>
<p><img src="../2019/09/18.png" alt=""></p>
<h5 id="拒绝消息">拒绝消息</h5>
<p>Basic.Reject命令告知服务端，消费者无法对投递的消息进行处理。类似的还有RabbitMQ团队扩展的Basic.Nack命令，与Basic.Reject功能类似，但是支持像Basic.Ack一样对多消息进行处理。</p>
<p>死信交换器（DLX）是对AMQP规范的扩展。DLX是用来保存被拒绝的消息。一旦拒绝了一个不重新发送的消息，RabbitMQ将把消息路由到队列的<code>x-dead-letter-exchange</code>参数中指定的交换器。</p>
<p><img src="../2019/09/19.png" alt="">
使用DLX，首先需要声明一个Exchange（图中的x），在声明Queue的时候将Queue的<code>x-dead-letter-exchange</code>指定为x即可。</p>
<h5 id="控制队列">控制队列</h5>
<p>在RabbitMQ可以定义很多不同的队列行为，如：</p>
<ul>
<li>自动销毁自己</li>
<li>只允许一个消费者消费</li>
<li>消息自动过期</li>
<li>保持消息数量有限</li>
<li>将旧消息推出堆栈</li>
</ul>
<p>临时队列<br>
有的时候我们会希望在没有消费者连接队列时，自动删除这个队列。创建自动删除队列非常简单，只需要在Queue.Declear中将<code>auto_delete</code>标志设置为True。</p>
<p>只允许单个消费者<br>
RabbitMQ鼓励多个消费者进行消费，当然它也还是可以支持消费者独占队列的。通过设置<code>exclusive</code>属性为True可以确保只有单个消费者进行消费，队列会在消费者断开连接后自动删除。</p>
<p>自动过期队列<br>
之前有提到过的消息的<code>expiration</code>参数，现在通过设置<code>x-expires</code>参数，可以声明一个自动过期队列。不过需要注意，自动过期队列只有在没有消费者的情况下才会过期，否则只有在发出了Basic.Cancel之后才会自动删除。如果队列在TTL内收到了Basic.Get请求，那么队列的过期设置会无效。</p>
<p>永久队列<br>
如果需要重启后仍可用的队列，需要在声明时设置<code>durable</code>为True。务必要将队列持久化和消息持久化区分开来，相对应的，消息持久化是<code>delivery-mode</code>设置为2。当队列持久化设置之后，需要通过Queue.Delete删除。</p>
<p>队列中的消息自动过期<br>
对于不重要的消息，可以在没被消费的情况下，不需要存在太久。对于队列而言，设置<code>x-message-ttl</code>可以规定队列中的所有消息最大生存时间。</p>
<p>队列最大长度<br>
从RabbitMQ 3.1.0开始，可以指定队列的最大长度，超过最大值时，添加新消息的同时就会删除位于队列最前端的消息，也就是确保队列中为最近新增的n个消息。通过设置<code>x-max-length</code>参数可以实现这个功能。</p>
<p><img src="../2019/09/20.png" alt=""></p>
<h1 id="rabbitmq消息路由模式">RabbitMQ消息路由模式</h1>
<p>消息路由在之前的博客中已经介绍过了，RabbitMQ中主要有几种基本的Exchange：</p>
<ul>
<li>Direct，匹配routing_key</li>
<li>Fanout，广播至所有Queue</li>
<li>Topic，模式匹配routing_key</li>
<li>Headers</li>
</ul>
<p>其中Headers之前的博客是没有使用过的，在这里简略介绍一下。</p>
<p>之前提到过，在Basic.Publish时可以给消息添加各种headers属性，就像HTTP的请求头字段一样。Headers的Exchange通过设定一些header字段，如果消息的header能够匹配Exchange的header，则可以发布到对应的Queue中去。简单来说，就是通过headers来匹配路由的方式。</p>
<h1 id="总结">总结</h1>
<p>本文主要对AMQP协议进行了介绍，同时协议（以及RabbitMQ自行扩展的规范）中的各个设置可能会对MQ的性能和可靠性产生影响，这些内容也从发布者和消费者的角度进行了介绍，以满足不同性能、可靠性要求的业务。</p>
<p>深入了解RabbitMQ，很显然真正的消息队列应用与简单的Radis用作消息队列差异是非常大的，RabbitMQ实现了很多简单队列原生不支持的功能，例如优先级队列、自销毁队列、队列可靠性保障、拉取与消费模式等。在消息队列的场景中，如果有可靠性的要求，应该避免再使用自建的简单队列和造轮子再保障SLA，将对应业务转移至专业的MQ上来。</p>
]]></content>
		</item>
		
		<item>
			<title>Redis分布式锁的实现——RedLock</title>
			<link>https://jiekun.dev/posts/2019-09-21-redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0-redlock/</link>
			<pubDate>Sat, 21 Sep 2019 10:36:07 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-21-redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0-redlock/</guid>
			<description>文章配图是RedLock Python实现的作者optimuspaul的头像。 在分布式应用中经常会存在一些并发的问题，当多个请求想要处理同样的</description>
			<content type="html"><![CDATA[<p><img src="../2019/09/redlock-py.png%22" alt=""></p>
<p>文章配图是RedLock Python实现的作者<a href="https://github.com/SPSCommerce/redlock-py/commits?author=optimuspaul">optimuspaul</a>的头像。</p>
<p>在分布式应用中经常会存在一些并发的问题，当多个请求想要处理同样的资源时，比如某个操作需要读取资源，根据读取结果进行修改，再写入，若这个步骤没有原子性，多个请求同时进行这样的操作，那就会变得非常混乱。通常来说可以依靠Redis来实现简单的分布式锁机制。</p>
<h2 id="redis分布式锁setnx">Redis分布式锁SETNX</h2>
<p>基于之前的描述，当多个请求需要处理同样的内容时，我们为了确保只有其中一个请求被执行，那么可以借助Redis生成一把锁。并发请求向Redis申请锁，申请成功的人占用本次操作的执行权。因为Redis单线程的特性，一次只处理一个请求，因此后续申请锁的操作都可以被排除。具体代码如下：</p>
<pre tabindex="0"><code>t resource_name value ex 5 nx&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>意味着：</p>
<ul>
<li>插入一个名为resource_name的键，它的值为value</li>
<li>TTL 5秒</li>
<li>只有这个键不存在的情况下才能插入成功</li>
</ul>
<p>因为nx参数的存在，过期时间内执行相同的操作不会返回1，意味着插入不成功（没申请到锁）。</p>
<h3 id="简易实现的问题">简易实现的问题</h3>
<p>现在来看一下上面的设计有什么问题。</p>
<h5 id="超时">超时</h5>
<p>假设现在clinet1拿到了锁，在执行一段时间后超过了设定的ttl，锁过期，client2向Redis执行语句申请锁，因为锁不存在所以client2成功申请到了锁。此时client1仍在继续执行未完成的操作，相当于存在client1和client2共同操作资源的行为。</p>
<p>对于这种问题，当前的锁机制是无法解决的，需要：</p>
<ul>
<li>避免在分布式中处理超长的任务</li>
<li>适当延长TTL并在执行完后及时对锁DEL</li>
<li>业务上进行处理</li>
<li>取消TTL，改为由client控制锁的DEL</li>
</ul>
<p>对于最后一种方案，因为client控制锁的归还（del），如果在执行del命令时发生异常，redis服务器没有接收到，或者client出错，没有执行del，将会造成死锁，因为锁会持续存在，其他client不能够正常获取到锁。</p>
<h5 id="锁被其他线程释放">锁被其他线程释放</h5>
<p>对于上面的设计，不安全的地方在于，若其他线程执行<code>del resource_name</code>操作，那么看起来可以立刻获取一把新锁，从而达到无视锁机制的效果。</p>
<p>为此，在锁的设计上，value需要设计成一个unique值，在del操作前，业务上需要确认del的键的值是否匹配，若不匹配，应该取消del操作。</p>
<p>因此，简单的分布式锁的使用应该修改为：</p>
<pre tabindex="0"><code>t resource_name unique_value px 5000 nx&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="redis集群分布式锁redlock">Redis集群分布式锁RedLock</h2>
<p>现在继续来考虑一些简易锁的异常问题：</p>
<ul>
<li>client1申请到了锁，Redis记录了这把锁</li>
<li>Redis服务发生异常退出</li>
<li>Redis服务恢复，但是丢失数据（假设锁没有及时持久化）</li>
<li>client2尝试申请锁，因为Redis没有锁存在，因此申请成功</li>
<li>client1、client2一起操作资源</li>
</ul>
<p>由于服务的不可靠，简易锁的实现在特殊情况下会失效。为此，Redis作者提供了一种基于Redis集群的分布式锁——<a href="https://redis.io/topics/distlock">RedLock</a>：</p>
<blockquote class="wp-block-quote">
  <p>
    We propose an algorithm, called Redlock, which implements a DLM which we believe to be safer than the vanilla single instance approach. We hope that the community will analyze it, provide feedback, and use it as a starting point for the implementations or more complex or alternative designs.
  </p>
</blockquote>
]]></content>
		</item>
		
		<item>
			<title>基于Redis的缓存装饰器及缓存预热设计</title>
			<link>https://jiekun.dev/posts/2019-09-08-%E5%9F%BA%E4%BA%8Eredis%E7%9A%84python%E7%BC%93%E5%AD%98%E8%A3%85%E9%A5%B0%E5%99%A8%E5%8F%8A%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD%E8%AE%BE%E8%AE%A1/</link>
			<pubDate>Sun, 08 Sep 2019 05:27:22 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-08-%E5%9F%BA%E4%BA%8Eredis%E7%9A%84python%E7%BC%93%E5%AD%98%E8%A3%85%E9%A5%B0%E5%99%A8%E5%8F%8A%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD%E8%AE%BE%E8%AE%A1/</guid>
			<description>业务背景 业务上使用的是类似MVC的架构，具体而言通过view层控制接口，logic层控制业务逻辑，models模型映射数据库。在logic层</description>
			<content type="html"><![CDATA[<h2 id="业务背景">业务背景</h2>
<p>业务上使用的是类似MVC的架构，具体而言通过view层控制接口，logic层控制业务逻辑，models模型映射数据库。在logic层，使用了Redis缓存装饰器对满足参数要求的方法执行结果进行缓存，降低复杂逻辑页面、数据量大页面的请求执行耗时。</p>
<p>对于这种使用场景，当缓存失效时，因为缓存使用的位置都是复杂逻辑，再次生成缓存需要数据库层面执行，如果这一步是由用户触发（也就是cache失效后第一位用户请求的时候生成缓存），那对这位用户来说请求时间就会很长甚至504超时。因此，有必要设计缓存的自动预热以及手动预热，前者是为了避免由用户触发生成缓存的长时间等待，后者是为了特殊时候（如数据更新后，缓存还没到期）手动更新缓存。</p>
<h2 id="原有的缓存装饰器">原有的缓存装饰器</h2>
<pre tabindex="0"><code>f redis_cache(ttl=None, cache_name=None, **kwargs):
    &quot;&quot;&quot;
    Redis缓存装饰器 用于Logics层函数执行结果缓存
    全局配置: config/localsettings.py REDIS_ON = True
    使用示例和说明：

    @redis_cache(ttl=3600, cache_name=&quot;&quot;, arg1=1, arg2=20)
    def sample_method(arg1, arg2, arg3, arg4, arg5)

    ttl: 缓存失效3600秒
    cache_name: 函数功能名
    kwargs：参数中对应满足kwargs时进行缓存，示例中当函数参数包含args=1，args2=20时缓存
    缓存规则：logic_cache:function_name:参数作为键名进行缓存，示例：
    logic_cache:sample_method:arg1:1:arg2:20:arg3:rank:arg4:people:arg5:food

    :param ttl: 过期时间
    :param cache_name: 函数功能名 用于清理缓存时显示 方便非技术同时使用
    :param kwargs: 命中何种参数时进行缓存 示例 **{'arg1': 1, 'arg2': 20}
    :return: 返回函数执行结果 / 缓存结果
    &quot;&quot;&quot;
    def decorator(func):
        cache_serv = cache

        @wraps(func)
        def returned_wrapper(*args, **innerkwargs):
            try:
                func_name = func.func_name
                default_kwargs = kwargs
                is_cache_target = cache_target_judger(default_kwargs, innerkwargs)
                # Cache Target
                if REDIS_ON and is_cache_target:
                    colon = ':'
                    redis_key_prefix_list = ['logic_cache', func_name]
                    for each in innerkwargs:
                        redis_key_prefix_list.append(each + ':' + str(innerkwargs[each]))
                    redis_key_str = colon.join(redis_key_prefix_list)

                    result = cache_serv.get(redis_key_str)
                    # Cache Exist:
                    if result is not None:
                        print(func_name + ': This is Cache')
                        return result
                    # Cache Not Exist / Force Update
                    else:
                        cache_data = func(*args, **innerkwargs)
                        cache = cache_serv.set(redis_key_str, cache_data, ttl)
                        if cache_name is not None:
                            redis_key_name_prefix_list = ['cache_name', func_name]
                            redis_key_name_str = ':'.join(redis_key_name_prefix_list)
                            cache = cache_serv.set(redis_key_name_str, cache_name, ttl)
                        print(func_name + ': Add to Cache now')
                        return cache_data
                # SQL/ES Target
                else:
                    direct_run_data = func(*args, **innerkwargs)
                    print(func_name + ': Not Cache Target')
                    return direct_run_data
            except Exception as e:
                logging.error(&quot;Redis decorator error: {}&quot;.format(e))
                direct_run_data = func(*args, **innerkwargs)
                print('Error Happened')
                return direct_run_data

        return returned_wrapper

    return decorator


def cache_target_judger(default_kwargs, innerkwargs):
    &quot;&quot;&quot;
    缓存判断 返回Bool值
    判断是否为缓存目标
    :param default_kwargs:
    :param innerkwargs:
    :return:
    &quot;&quot;&quot;
    return all(item in innerkwargs.iteritems() for item in default_kwargs.iteritems())

</code></pre><p>先来说明一下原有缓存的逻辑，其实实现非常简单：</p>
<p>对于如下使用：</p>
<pre tabindex="0"><code>@redis_cache(ttl=3600, cache_name='示例功能', arg1=1, arg2=20)
def sample_method(arg1, arg2, arg3, arg4):
        pass

sample_method(arg1=1, arg2=20, arg3='hello', arg4='world')

</code></pre><h4 id="判定缓存目标">判定缓存目标</h4>
<p>在调用sample_method时，传入参数<code>arg1=1, arg2=20, arg3='hello', arg4='world'</code>，也就是<code>returned_wrapper(*args, **innerkwargs)</code>中的innerkwargs，代表方法的参数（字典形式）。<br>
在使用装饰器的时候，装饰器参数ttl, cache_name, 后面的都是kwargs，代表装饰器的参数（字典形式）。</p>
<p>现在将kwargs和innerkwargs比较，如果kwargs是innerkwargs的子集，也就是说innerkwargs满足kwargs的约束，说明这是一个要缓存的目标。以示例说明，redis_cache中kwargs是:<code>{'arg1': 1, 'arg2': 20}</code>，sample_method被捕获到的innerkwargs是<code>{'arg1':1, 'arg2': 20, 'arg3':  'hello', 'arg4': 'world'}</code>。因为满足了kwargs要求的arg1=1和arg2=20，因此这个sample_method的请求是需要被缓存的。</p>
<p>如果在这一步中判断不是要被缓存的那说明Redis中必然不存在这个缓存，则直接执行方法获返回结果即可。</p>
<h4 id="生成缓存键">生成缓存键</h4>
<p>显然，每个不同的函数调用的参数都不一样，我们需要使用当前调用的全部参数作为Redis键名以避免重复。<br>
设计键名为：</p>
<pre tabindex="0"><code>前缀 + 方法名 + 方法参数键值对

</code></pre><p>不使用hash是因为前期缺少cache_name注释的情况下无法通过redis键名（如果是hash）判断出这个缓存对应的功能。<br>
这里也会有小问题，如果方法名一样的方法在不同位置有出现的话也可能让键名重复。</p>
<h4 id="获取生成缓存">获取/生成缓存</h4>
<p>有了缓存的键名之后，就可以到Redis中查看这个键是否存在，因此尝试取出这个键：<br>
<code>result = cache_serv.get(redis_key_str)</code></p>
<ul>
<li>如果result不存在，说明缓存不存在，对本次调用需要执行方法，并将结果set进Redis中，并返回执行结果。</li>
<li>如果result存在，说明缓存存在，对本次调用可以返回缓存结果。</li>
</ul>
<h4 id="小结">小结</h4>
<p>通过上述的方法，已经可以实现一个缓存的装饰器，并且控制方法参数级别的缓存判定。</p>
<h2 id="缓存系统改造">缓存系统改造</h2>
<h4 id="允许更新缓存">允许更新缓存</h4>
<p>旧方案的缓存生命周期是从第一次触发生成时刻至缓存过期时刻。对于这种对方法的缓存，要达到预热（更新）的效果，其实只要在判定上作小调整：<br>
在生成了缓存键名之后，原思路是看是否有result，有则取缓存，无则生成缓存。这里只需要改造成：</p>
<ul>
<li>当需要无视规则强制生成缓存的时候，执行函数并生成缓存。</li>
</ul>
<p>这个改动非常简单，在调用方法时，传入一个force_update参数：</p>
<pre tabindex="0"><code>@redis_cache(ttl=3600, cache_name='示例功能', arg1=1, arg2=20)
def sample_method(arg1, arg2, arg3, arg4):
        pass

sample_method(arg1=1, arg2=20, arg3='hello', arg4='world', force_update=True)

</code></pre><ul>
<li>这个force_update要在装饰器执行func之前处理，因为<code>sampe_method</code>的定义中没有这个参数，因此当执行func的时候传的参数必须仍然只有前面几个。因此装饰器中加上：</li>
</ul>
<pre tabindex="0"><code>force_update = innerkwargs.pop('force_update', False)

</code></pre><ul>
<li>正常调用不会包含这个方法，但是仍然会经过装饰器，因此默认False</li>
<li>使用pop方法保证这个参数不会进入实际执行方法的过程中</li>
</ul>
<p>有了force_update标志之后，对是否需要执行方法并写入缓存的判定就要修改一下：</p>
<ul>
<li>从<code>if result is not None:</code>改为<code>if result is not None and not force_update:</code></li>
</ul>
<p>这样当有force_update的时候也会继续执行方法和写缓存的操作。</p>
<h4 id="缓存定时预热">缓存定时预热</h4>
<p>既然需要实现定时更新，那只要定时执行一下sample_method，并且加上force_update参数强制使它更新就行。</p>
<p>因此是否可以做一个定时脚本：</p>
<pre tabindex="0"><code>* */2 * * * python update_cache.py

</code></pre><p>update_cache.py内容如下：</p>
<pre tabindex="0"><code>if __name__ == '__main__':
    sample_method1(arg1=1, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method2(arg1=2, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method3(arg1=3, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method4(arg1=4, arg2=2, arg3='hello', arg4='world', force_update=True)

</code></pre><p>这样就实现了缓存的定时更新</p>
<h4 id="缓存手动预热">缓存手动预热</h4>
<p>思路：手动预热只需要将crontab定时改为（支持）手动触发即可，具体可以设计成一个调用接口。</p>
<p>抱歉，如果是这样设计，这套缓存系统就会面临类似缓存穿透的问题。</p>
<p>缓存穿透，故名思意就是请求不经过缓存，直接打在数据库上执行，在特定期间如果有大量的请求经数据库执行会给数据库造成很大压力。在我们的业务中，使用缓存的地方都是原来较为缓慢的查询，如果让大量请求同时执行SQL的话对MySQL负载时比较高的。</p>
<p>设想如果手动预热做成接口，意味着这个接口对应的sample_method的执行是不经过缓存层的而是直接在数据库执行，如果这个接口同一时间有多人调用的话，就会在SQL同时执行多个复杂查询，影响性能。</p>
<p>因此，为了让缓存手动预热对数据库更加友好，这里需要将预热改造成队列形式。对于这种的业务，不需要保证可靠性，也没有性能要求，因此无需使用MQ，直接借助Redis的LIST类型和lpush+rpop可以做一个非常简单的队列。</p>
<ul>
<li>在手动预热请求的logic层：</li>
</ul>
<pre tabindex="0"><code># 要使用集合常量来避免不合法的传参
WARMER_DICT = {
    'sample_method_collection'
}

def submit_warmer(warmer):
    &quot;&quot;&quot;
    :return:
    &quot;&quot;&quot;
    if warmer in WARMER_DICT:
        warmer_key = CACHE_WARMER_KEY
        redis_raw_serv.lpush(warmer_key, warmer)
    return 200, 0, &quot;加入预热队列成功&quot;, {}

</code></pre><ul>
<li>在后台维护一个持续监控队列的进程</li>
</ul>
<pre tabindex="0"><code># 同样使用字典来避免不合法的队列元素
CACHE_FUNC = {
    'sample_method_collection': sample_method_collection
}


def sample_method_collection():
    sample_method1(arg1=1, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method2(arg1=2, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method3(arg1=3, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method4(arg1=4, arg2=2, arg3='hello', arg4='world', force_update=True)

def warmer_server():
    &quot;&quot;&quot;
    缓存更新后台进程
    不断读取redis中的LIST队列，如有则rpop出任务执行
    :return:
    &quot;&quot;&quot;
    while True:
        cache_warmer_key = CACHE_WARMER_KEY
        try:
            func_name = redis_raw_serv.rpop(cache_warmer_key)
            if func_name not in CACHE_FUNC:
                raise KeyError
            print('Found warmer job %s at %s.' % (func_name, datetime.datetime.now().strftime('%m-%d %H:%M:%S')))
            # 执行一个方法来触发对应（或多个）带force_update参数的方法
            CACHE_FUNC[func_name]()
        except KeyError:
            pass
        print('Interval 5 seconds.')
        time.sleep(5)

</code></pre><h2 id="总结">总结</h2>
<p>新完善的这套缓存方案实现了：</p>
<ul>
<li>方法参数粒度的缓存控制</li>
<li>缓存的自动、手动预热</li>
</ul>
<p>基于这些改造：</p>
<ul>
<li>通过缓存的自动预热，避免了缓存雪崩的问题；</li>
<li>通过缓存手动预热（实际上自动预热也同样）使用队列，避免预热过程中给数据库带来过高负载。</li>
</ul>
<p>Python的装饰器可以应用于MVC的各层，实现接口（View）层面的缓存同样可以使用（粗粒度的控制），但是因为Django中view层的参数为request对象，在使用中需要再进行改造，对request进行解析获取具体参数。</p>
<p>对于方法重名问题，实际上也可以将Redis键改造成<code>前缀:模块名:view层方法名:logic层方法名:参数字典</code>的形式，抽象来说只要能在<code>前缀</code>和<code>参数字典</code>之间能够定位到准确的使用装饰器的位置即可。</p>
<h2 id="持续优化">持续优化</h2>
<h4 id="更简便的缓存预热目标生成">更简便的缓存预热目标生成</h4>
<p>目前对于需要预热的目标方法，都是在crontab脚本中显式执行的，这样每当需要添加一个定期预热的目标方法，都要在脚本内添加代码。<br>
优化方案：额外维护一个动态的预热的目标队列，队列是由第一次生成缓存的时候判断这个方法后续是否需要自动预热，若需要，则加入预热队列中并定期执行，执行的时候又加入下一次预热队列中。这样只需要在缓存装饰器的使用中声明<code>redis_cache(ttl=3600, cache_name='示例', auto_update=True, args1=1, args2=20)</code>即可。</p>
<h4 id="预热参数组合">预热参数组合</h4>
<p>在其他业务有使用到，举例如args1可以为1或2或3， args2可以为20或30，这时候对于方法的缓存预热，需要对参数组合（1，20），（2，20），（3，20）和（1，30），（2，30），（3，30）共计6种。<br>
优化方案：这时候可能需要将面向业务层的缓存装饰器和面向预热的缓存装饰器分离开，因为业务层只对特定一次请求负责，也就是说用户只可能传6种请求的1种，服务只需要将这1种的结果，不管是缓存，还是生成缓存，处理好并返回即可； 对面向预热的装饰器，需要实现支持列表传参，生成参数组合，并逐一执行，调用示例：<br>
<code>redis_cache(ttl=3600, cache_name='示例', args1=[1, 2], args2=[20, 30])</code><br>
在其他业务中，也有实现过组合参数的方法，如：</p>
<pre tabindex="0"><code>f param_combination_generator(kwargs):
    &quot;&quot;&quot;
    参数排列组合生成器
    根据dict生成各个key名对应多个可能值的组合情况
    如{'key1':['value1', 'value2'], 'key2':['value3', 'value4']}可以有4种组合
    :param kwargs:
    :return: 返回组合list, 如[((page_num, 1)(sort_type, like_count)), ((page_num, 2)(sort_type, like_count))]
    &quot;&quot;&quot;
    pre_dict = {}
    for k, v in kwargs.iteritems():
        pre_dict[k] = []
        for each_value in v:
            pre_dict[k].append((k, each_value))
    iter_list = []
    for each in pre_dict.values():
        iter_list.append(each)

    param_combination = list(itertools.product(*iter_list))

    return param_combination

</code></pre><p>尽管还需要优化，不过大体思路按照排列组合后的参数对函数逐一放入队列执行应该可以较为友善地实现。当参数排列组合特别多的时候，可能就不太适合缓存的场景，因为cache成本都是非常高昂的，可能需要优化成针对最热点的内容优先缓存的形式。</p>
]]></content>
		</item>
		
		<item>
			<title>学个排序~</title>
			<link>https://jiekun.dev/posts/2019-09-07-%E5%AD%A6%E4%B8%AA%E6%8E%92%E5%BA%8F/</link>
			<pubDate>Sat, 07 Sep 2019 15:49:52 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-07-%E5%AD%A6%E4%B8%AA%E6%8E%92%E5%BA%8F/</guid>
			<description>前言 该补充的算法基础还是要补TuT 快排（Quick Sort） 思路总结: 以某个位置为轴，大于轴的数都移动至右侧，小于轴的数都移动到左侧，轴左右</description>
			<content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>该补充的算法基础还是要补TuT</p>
<h2 id="快排quick-sort">快排（Quick Sort）</h2>
<p>思路总结:</p>
<p>以某个位置为轴，大于轴的数都移动至右侧，小于轴的数都移动到左侧，轴左右侧的新列表递归选取轴和按大小排列</p>
<p><img src="../2019/09/Sorting_quicksort_anim.gif" alt="">
复杂度：</p>
<p>平均：O(nlogn)； 最差：O(n^2)</p>
<p>代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">quick_sort</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">quick_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">quick_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">hi</span><span class="p">):</span>
    <span class="c1"># 递归方法</span>
    <span class="k">if</span> <span class="n">hi</span> <span class="o">&gt;</span> <span class="n">low</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>
        <span class="n">quick_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">quick_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">partition</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">hi</span><span class="p">):</span>
    <span class="c1"># 获取轴</span>
    <span class="c1"># [轴, 小于轴, 小于轴, 小于轴, 大于轴, 大于轴, 大于轴, 大于轴]</span>
    <span class="c1"># [小于轴, 小于轴, 小于轴, 轴, 大于轴, 大于轴, 大于轴, 大于轴]</span>
    <span class="c1"># 返回轴</span>
    <span class="n">privot</span> <span class="o">=</span> <span class="n">get_privot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>
    <span class="n">privot_value</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">privot</span><span class="p">]</span>
    <span class="n">A</span><span class="p">[</span><span class="n">low</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">privot</span><span class="p">]</span> <span class="o">=</span> <span class="n">privot_value</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="n">low</span><span class="p">]</span>
    <span class="n">border</span> <span class="o">=</span> <span class="n">low</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">low</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">hi</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">privot_value</span><span class="p">:</span>
            <span class="n">border</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">border</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">border</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">A</span><span class="p">[</span><span class="n">low</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">border</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">border</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">low</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">border</span>

<span class="k">def</span> <span class="nf">get_privot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">hi</span><span class="p">):</span>
    <span class="c1"># 选取一个位置为轴</span>
    <span class="c1"># 若不选取中间值为轴 最差O(n^2)</span>
    <span class="n">mid</span> <span class="o">=</span> <span class="p">(</span><span class="n">hi</span> <span class="o">+</span> <span class="n">low</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">s</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">A</span><span class="p">[</span><span class="n">hi</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">low</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">mid</span><span class="p">]])</span>
    <span class="k">if</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">A</span><span class="p">[</span><span class="n">hi</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">hi</span>
    <span class="k">elif</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">A</span><span class="p">[</span><span class="n">low</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">low</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mid</span>

</code></pre></div><h2 id="插入排序insertion-sort">插入排序（Insertion Sort）</h2>
<p>思路：</p>
<p>从左往右，拿起一个数，向左侧找它应该插入的位置</p>
<p><img src="../2019/09/Insertion-sort-example-300px.gif" alt="">
复杂度：</p>
<p>O(n^2)</p>
<p>代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">insert_sort</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="c1"># 拿起一个元素</span>
        <span class="n">cur_val</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># 比它大的都往右挪一格</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">k</span> <span class="o">=</span> <span class="n">j</span>
            <span class="k">if</span> <span class="n">cur_val</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="c1"># 挪出来空的一格把该元素放入</span>
        <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">cur_val</span>

</code></pre></div><h2 id="选择排序selection-sort">选择排序（Selection Sort）</h2>
<p>思路：</p>
<p>从左往右，找最小值放到最左边</p>
<p><img src="../2019/09/Selection-Sort-Animation.gif" alt="">
复杂度：</p>
<p>O(n^2)</p>
<p>代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">select_sort</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="c1"># 找出A[i:end]中的最小值</span>
        <span class="n">min_idx</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">A</span><span class="p">[</span><span class="n">min_idx</span><span class="p">]:</span>
                <span class="n">min_idx</span> <span class="o">=</span> <span class="n">j</span>
        <span class="c1"># 将这个最小值交换值A[i]的位置</span>
        <span class="k">if</span> <span class="n">min_idx</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">A</span><span class="p">[</span><span class="n">min_idx</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">min_idx</span><span class="p">]</span>

</code></pre></div><h2 id="冒泡排序bubble-sort">冒泡排序（Bubble Sort）</h2>
<p>思路：</p>
<p>从左往右，左侧比右侧大，则交换；一直交换至最右侧，依次排出：第n位为0至n的最大值，第n-1位为0至n-1的最大值</p>
<p><img src="../2019/09/Bubble-sort-example-300px.gif" alt="">
复杂度：</p>
<p>O(n^2)</p>
<p>代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">bubble_sort</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

</code></pre></div><h2 id="归并排序merge-sort">归并排序（Merge Sort）</h2>
<p>思路：</p>
<p>将列表分为两份，分别对左侧和右侧进行归并排序，排序完之后比较左侧和右侧第一个的大小，小的先放进结果中，再取下一个较小的放入结果，直至取完所有结果</p>
<p><img src="../2019/09/220px-Merge-sort-example-300px.gif" alt="">
复杂度：</p>
<p>O(nlogn)</p>
<p>代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">merge_sort</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">merge_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">merge_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">last</span> <span class="o">&gt;</span> <span class="n">first</span><span class="p">:</span>
        <span class="c1"># 拆分为左右两组 分别归并排序</span>
        <span class="n">mid</span> <span class="o">=</span> <span class="p">(</span><span class="n">first</span><span class="o">+</span><span class="n">last</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">merge_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">first</span><span class="p">,</span> <span class="n">mid</span><span class="p">)</span>
        <span class="n">merge_sort2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">last</span><span class="p">)</span>
        <span class="c1"># 合并左右结果</span>
        <span class="n">merge</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">first</span><span class="p">,</span> <span class="n">mid</span><span class="p">,</span> <span class="n">last</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">first</span><span class="p">,</span> <span class="n">mid</span><span class="p">,</span> <span class="n">last</span><span class="p">):</span>
    <span class="n">left</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">first</span><span class="p">:</span><span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">right</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">last</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">left</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">9999999999</span><span class="p">)</span>
    <span class="n">right</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">9999999999</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># 依次取左右较小的作为第A[k]值，直至拼接成完整的A[first:last+1]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">left</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">=</span> <span class="n">right</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
            <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">left</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">right</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div>]]></content>
		</item>
		
		<item>
			<title>Redis有序集合的实现&amp;跳跃表源码学习</title>
			<link>https://jiekun.dev/posts/2019-08-31-redis%E4%B8%ADzset%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E7%BB%93%E5%90%88%E6%BA%90%E7%A0%81%E7%9A%84%E8%B7%B3%E8%B7%83%E8%A1%A8%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0/</link>
			<pubDate>Sat, 31 Aug 2019 04:49:01 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-08-31-redis%E4%B8%ADzset%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E7%BB%93%E5%90%88%E6%BA%90%E7%A0%81%E7%9A%84%E8%B7%B3%E8%B7%83%E8%A1%A8%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0/</guid>
			<description>O(1)的skiplist成员查找？ 众所周知Redis中每种基本类型都有2种或以上的底层实现，一般谈到ZSET，我们会说它的实现是基于zip</description>
			<content type="html"><![CDATA[<h2 id="o1的skiplist成员查找">O(1)的skiplist成员查找？</h2>
<p>众所周知Redis中每种基本类型都有2种或以上的底层实现，一般谈到ZSET，我们会说它的实现是基于ziplist和skiplist的，这没有问题：</p>
<ul>
<li>当ZSET长度小于设定值（zset-max-ziplist-entries）或成员的长度小于设定值（zset-max-ziplist-value）时会使用ziplist的实现，否则使用skiplist实现</li>
</ul>
<p>但是当ZSET在使用skiplist实现的时候，它对成员的查找也是O(1)复杂度。根据skiplist的结构，要查找某一个成员必须对各个SkiplistNode进行遍历，因此复杂度为O(n)。所以在ZSET-skiplist的实现中查找成员并不是根据skiplist进行的，而是使用字典（dict）。</p>
<p>先来看一下ZSET的结构源码，Redis5.0.5版本中数据结构的定义在redis/src/server.h中：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">zset</span> <span class="p">{</span>
    <span class="n">dict</span> <span class="o">*</span><span class="n">dict</span><span class="p">;</span>
    <span class="n">zskiplist</span> <span class="o">*</span><span class="n">zsl</span><span class="p">;</span>
<span class="p">}</span> <span class="n">zset</span><span class="p">;</span>

</code></pre></div><p>可以看到一个ZSET结构使用了一个dict和一个zskiplist（特殊版本的skiplist），具体代码在SkipList小节中再叙述。ZSET的结构可以由下图来标识：</p>
<p><img src="../2019/09/ZSET-skiplist.jpg" alt=""></p>
<p>通过这样的结构，当ZSET需要进行成员查询的时候，可以根据dict查询，时间复杂度为O(1)；当ZSET需要进行范围查找的时候，根据skiplist结构可以实现平均O(logn)复杂度的查找。</p>
<p>这两种结构单独使用来实现ZSET是可行的，但是dict在范围型操作的时候需要对字典保存的所有元素进行排序因此需要至少O(nlogn)的时间复杂度和额外O(n)的空间复杂度；在单独使用skiplist根据成员查找分值的时候就由O(1)时间复杂度上升到了O(logn)复杂度。因此Redis中选择同时使用dict和skiplist来实现ZSET类型。</p>
<h4 id="skiplist的实现">SkipList的实现</h4>
<p>下面来具体聊一下SkipList数据结构。<br>
在Redis源码中找到跳跃表的相关定义，就在zset的上面几行，补充一些注释：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="cm">/* ZSETs use a specialized version of Skiplists */</span>
<span class="cp"># 跳跃表节点（ZSET版）
</span><span class="cp"></span><span class="k">typedef</span> <span class="k">struct</span> <span class="n">zskiplistNode</span> <span class="p">{</span>
    <span class="cp"># 使用sds来存储成员名字
</span><span class="cp"></span>    <span class="n">sds</span> <span class="n">ele</span><span class="p">;</span>
    <span class="cp"># 浮点型分数
</span><span class="cp"></span>    <span class="kt">double</span> <span class="n">score</span><span class="p">;</span>
    <span class="cp"># 每个zskiplist节点都带有向前的指针
</span><span class="cp"></span>    <span class="k">struct</span> <span class="n">zskiplistNode</span> <span class="o">*</span><span class="n">backward</span><span class="p">;</span>
    <span class="cp"># zskiplist分层，每层中包含指向其他zskiplist节点的指针
</span><span class="cp"></span>    <span class="k">struct</span> <span class="n">zskiplistLevel</span> <span class="p">{</span>
        <span class="cp"># zskiplist节点指针
</span><span class="cp"></span>        <span class="k">struct</span> <span class="n">zskiplistNode</span> <span class="o">*</span><span class="n">forward</span><span class="p">;</span>
        <span class="cp"># 本层指向的下个节点离本节点的跨度
</span><span class="cp"></span>        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">span</span><span class="p">;</span>
    <span class="p">}</span> <span class="n">level</span><span class="p">[];</span>
<span class="p">}</span> <span class="n">zskiplistNode</span><span class="p">;</span>

<span class="cp"># 跳跃表
</span><span class="cp"></span><span class="k">typedef</span> <span class="k">struct</span> <span class="n">zskiplist</span> <span class="p">{</span>
    <span class="cp"># 分别指向头尾的指针
</span><span class="cp"></span>    <span class="k">struct</span> <span class="n">zskiplistNode</span> <span class="o">*</span><span class="n">header</span><span class="p">,</span> <span class="o">*</span><span class="n">tail</span><span class="p">;</span>
    <span class="cp"># 长度 即跳跃表中包含的节点数目（头节点不算）
</span><span class="cp"></span>    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">length</span><span class="p">;</span>
    <span class="cp"># 层数 即跳跃表中各节点层数的最大值（头节点不算）
</span><span class="cp"></span>    <span class="kt">int</span> <span class="n">level</span><span class="p">;</span>
<span class="p">}</span> <span class="n">zskiplist</span><span class="p">;</span>

</code></pre></div><p>t的结构可以由下图来表示：</p>
<p><img src="../2019/09/image-4.png" alt="">
其中：</p>
<ul>
<li>头节点也是zskiplistNode因此也由对应的分数、向前指针、sds，只不过一般不使用，在图中没有表示出来。</li>
<li>skiplist结构中level为5，因为在第三个节点中层数为5。</li>
<li>skiplist结构中length为3，因为一共有头节点（不算在内），o1，o2，o3几个节点。</li>
</ul>
<p>借助ZSET的各种API，来看一下skiplist在实际中是怎么使用的。<br>
下面代码出现在redis/src/t_zset.c中，实现的是zset的插入成员操作：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="cp"># 输入一个zset的skiplist、新成员的得分和名字
</span><span class="cp"></span><span class="n">zskiplistNode</span> <span class="o">*</span><span class="nf">zslInsert</span><span class="p">(</span><span class="n">zskiplist</span> <span class="o">*</span><span class="n">zsl</span><span class="p">,</span> <span class="kt">double</span> <span class="n">score</span><span class="p">,</span> <span class="n">sds</span> <span class="n">ele</span><span class="p">)</span> <span class="p">{</span>    
    <span class="n">zskiplistNode</span> <span class="o">*</span><span class="n">update</span><span class="p">[</span><span class="n">ZSKIPLIST_MAXLEVEL</span><span class="p">],</span> <span class="o">*</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">rank</span><span class="p">[</span><span class="n">ZSKIPLIST_MAXLEVEL</span><span class="p">];</span>
    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">level</span><span class="p">;</span>

    <span class="n">serverAssert</span><span class="p">(</span><span class="o">!</span><span class="n">isnan</span><span class="p">(</span><span class="n">score</span><span class="p">));</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">header</span><span class="p">;</span>

    <span class="cp"># 从头遍历跳跃表来查找当前元素应该插入在哪个节点之后
</span><span class="cp"></span>    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">level</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">--</span><span class="p">)</span> <span class="p">{</span>
        <span class="cm">/* store rank that is crossed to reach the insert position */</span>
        <span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span> <span class="o">==</span> <span class="p">(</span><span class="n">zsl</span><span class="o">-&gt;</span><span class="n">level</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">?</span> <span class="mi">0</span> <span class="o">:</span> <span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span> <span class="o">&amp;&amp;</span>
                <span class="cp"># 排名是由分数和sds名字共同决定的，同分数下按节点名排序
</span><span class="cp"></span>                <span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span><span class="o">-&gt;</span><span class="n">score</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">score</span> <span class="o">||</span>
                    <span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span><span class="o">-&gt;</span><span class="n">score</span> <span class="o">==</span> <span class="n">score</span> <span class="o">&amp;&amp;</span>
                    <span class="n">sdscmp</span><span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span><span class="o">-&gt;</span><span class="n">ele</span><span class="p">,</span><span class="n">ele</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">0</span><span class="p">)))</span>
        <span class="p">{</span>
            <span class="cp"># 注意这一句，说明span是用来便于计算节点排名的
</span><span class="cp"></span>            <span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">span</span><span class="p">;</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="cm">/* we assume the element is not already inside, since we allow duplicated
</span><span class="cm">     * scores, reinserting the same element should never happen since the
</span><span class="cm">     * caller of zslInsert() should test in the hash table if the element is
</span><span class="cm">     * already inside or not. */</span>
    <span class="n">level</span> <span class="o">=</span> <span class="n">zslRandomLevel</span><span class="p">();</span>
    <span class="cp"># 判断是否要重写头节点的level值
</span><span class="cp"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">level</span> <span class="o">&gt;</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">level</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
            <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">header</span><span class="p">;</span>
            <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">span</span> <span class="o">=</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">length</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">level</span> <span class="o">=</span> <span class="n">level</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">zslCreateNode</span><span class="p">(</span><span class="n">level</span><span class="p">,</span><span class="n">score</span><span class="p">,</span><span class="n">ele</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">level</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span> <span class="o">=</span> <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span><span class="p">;</span>
        <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">forward</span> <span class="o">=</span> <span class="n">x</span><span class="p">;</span>

        <span class="cm">/* update span covered by update[i] as x is inserted here */</span>
        <span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">span</span> <span class="o">=</span> <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">span</span> <span class="o">-</span> <span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
        <span class="cp"># span实际就是zset两个成员之间的rank差值
</span><span class="cp"></span>        <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">span</span> <span class="o">=</span> <span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="cm">/* increment span for untouched levels */</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="n">level</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">update</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">span</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">x</span><span class="o">-&gt;</span><span class="n">backward</span> <span class="o">=</span> <span class="p">(</span><span class="n">update</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">header</span><span class="p">)</span> <span class="o">?</span> <span class="nb">NULL</span> <span class="o">:</span> <span class="n">update</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">forward</span><span class="p">)</span>
        <span class="n">x</span><span class="o">-&gt;</span><span class="n">level</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">forward</span><span class="o">-&gt;</span><span class="n">backward</span> <span class="o">=</span> <span class="n">x</span><span class="p">;</span>
    <span class="k">else</span>
        <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">tail</span> <span class="o">=</span> <span class="n">x</span><span class="p">;</span>
    <span class="n">zsl</span><span class="o">-&gt;</span><span class="n">length</span><span class="o">++</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">;</span>
<span class="p">}</span>

</code></pre></div><p>可以观察到：</p>
<ul>
<li>跳跃表的不同节点之间由指针和跨度关联</li>
<li>跨度值实际上为这两个节点之间的排名差距，如上图中o1与o3的排名差正是o1指向o3的第4层的跨度值2，也可以等于o1至o2的跨度值1加上o2至o3的跨度值1</li>
<li>排名取决于分数，同分情况下取决于名字</li>
<li>插入节点的时候判断层数是否大于头节点的层数值，是否需要更新</li>
<li>节点的层数是<code>zslRandomLevel()</code>生成的，根据命名每个节点的层数应该是随机的</li>
<li>注释中提到了在新增元素的时候要在哈希表中判断是否为重复，zset是不允许重复的成员出现的（但是可以有同分成员）</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>RabbitMQ入门学习笔记</title>
			<link>https://jiekun.dev/posts/2019-08-18-rabbitmq%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
			<pubDate>Sun, 18 Aug 2019 04:35:28 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-08-18-rabbitmq%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
			<description>RabbitMQ简介 RabbitMQ是个消息中间件。 Producer：发送消息的程序称为生产者 Queue：消息在RabbitMQ中存储在队列</description>
			<content type="html"><![CDATA[<h2 id="rabbitmq简介">RabbitMQ简介</h2>
<p>RabbitMQ是个消息中间件。</p>
<ul>
<li>Producer：发送消息的程序称为生产者</li>
<li>Queue：消息在RabbitMQ中存储在队列，队列上限由内存和磁盘决定。队列本质上讲就是一个大的消息缓冲区，多个生产者可以发消息到同一个队列，多个消费者可以从同一个队列获取消息。</li>
<li>Consumer：等待接受消息的程序称为消费者</li>
</ul>
<p>本文目标：</p>
<ul>
<li>了解RabbitMQ基础模型</li>
<li>了解RabbitMQ不同的Exchange类型</li>
</ul>
<h2 id="hello-world">Hello World</h2>
<p>官方教程使用<code>Pika</code>作为RabbitMQ的Python客户端。</p>
<p><img src="../2019/09/mq1.jpg" alt="">
send.py:</p>
<pre tabindex="0"><code>import pika

# 连接本地RabbitMQ
connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

# 声明要将消息发送至的队列
channel.queue_declare(queue='hello')

# 指定exchanger, routing_key 发送消息
channel.basic_publish(exchange='', routing_key='hello', body='Hello World!')
print(&quot; [x] Sent 'Hello World!'&quot;)
nnection.close()

</code></pre><p>receive.py</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

# 同样声明队列
channel.queue_declare(queue='hello')

# 接收到消息时执行
def callback(ch, method, properties, body):
    print(&quot; [x] Received %r&quot; % body)


channel.basic_consume(
    queue='hello', on_message_callback=callback, auto_ack=True)

print(' [*] Waiting for messages. To exit press CTRL+C')
hannel.start_consuming()

</code></pre><h2 id="任务队列">任务队列</h2>
<p>借助time.sleep()模拟单个consumer阻塞的情况，让消息分发给多个consumer。</p>
<h4 id="消息分发">消息分发</h4>
<p>RabbitMQ默认采用round-robin的方式对消息进行分发，简而言之，就是消息会平均地分发到各个consumer上。</p>
<h4 id="确认管理">确认管理</h4>
<p>之前的代码consumer对接受到的消息即时进行ACK，因此以但ACK后consumer在处理消息期间出问题，这条消息就永久丢失了。我们可以通过将message acknowledgement在处理完毕后才发送来避免这种情况。但是如果忘记ACK，相关消息就会一直停留在内存中，RabbitMQ不会释放没有ACK的消息。</p>
<h4 id="消息持久化">消息持久化</h4>
<p>为了让服务端的队列消息不丢失，需要声明队列durable=True。但是RabbitMQ不支持对已有的消息队列重新定义。</p>
<h4 id="合理分配">合理分配</h4>
<p>通过声明<code>channel.basic_qos(prefetch_count=1)</code>，使得RabbitMQ知道某个worker一次不能处理多于1条消息，也就是说不要在没有收到前一条ACK的时候发送下一条任务。</p>
<p>task.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.queue_declare(queue='task_queue', durable=True)

message = ' '.join(sys.argv[1:]) or &quot;Hello World!&quot;
channel.basic_publish(
    exchange='',
    routing_key='task_queue',
    body=message,
    properties=pika.BasicProperties(
        delivery_mode=2,  # make message persistent
    ))
print(&quot; [x] Sent %r&quot; % message)
nnection.close()

</code></pre><p>worker.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika
import time

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.queue_declare(queue='task_queue', durable=True)
print(' [*] Waiting for messages. To exit press CTRL+C')


def callback(ch, method, properties, body):
    print(&quot; [x] Received %r&quot; % body)
    time.sleep(body.count(b'.'))
    print(&quot; [x] Done&quot;)
    ch.basic_ack(delivery_tag=method.delivery_tag)


channel.basic_qos(prefetch_count=1)
channel.basic_consume(queue='task_queue', on_message_callback=callback)

hannel.start_consuming()

</code></pre><h2 id="发布订阅模式">发布订阅模式</h2>
<p><code>publish/subscrribe</code>模式：多个consumer获取到同一条消息。<br>
官方实现了一套日志订阅系统，一个consumer负责将日志写至磁盘，另一个consumer负责将日志打印在屏幕上，需要用到发布订阅模式使得这些consumer获取到相同的消息。</p>
<h4 id="exchanges">Exchanges</h4>
<p><img src="../2019/09/image.png" alt=""></p>
<p>前面几节介绍过P-&gt;Q-&gt;C的模型，实际上RabbitMQ中P发送的消息并不是直接到Q中的，而是发送到<code>exchange</code>中。exchange负责接收消息，推送消息至相应的Q，它必须清楚消息要推送到多个Q还是分配到多个Q，这些对应的规则在<code>exchange type</code>定义。</p>
<p>通常有几种exchange type：direct，topic，headers和fanout。</p>
<p>在本节要用上的是fanout类型。fanout顾名思义就是广播所有收到的消息到它所知道的队列中。</p>
<p>生产者在发送消息的时候需要声明发送到的exchange的名字和类型。</p>
<p>如果在声明queue的时候使用空字符串，RabbitMQ会选择一个随机的队列名称，比如<code>amq.gen-JzTY20BRgKO-HjmUJj0wLg</code>。<br>
同时，在consumer中指定<code>exclusive=True</code>可以让consumer断开连接后队列被删除。</p>
<p>通过channel.queue_bind方法让consumer告知exchange对应的queue名字，称为binding（绑定）。</p>
<p>完成声明exchange，声明exchange类型，消费者生成随机的断开即删除的Queue，Queue和exchange绑定之后，exchange就可以把每次收到的消息推送到对应的Q中。</p>
<p><img src="../2019/09/image-1.png" alt="">
emit_log.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='logs', exchange_type='fanout')

message = ' '.join(sys.argv[1:]) or &quot;info: Hello World!&quot;
channel.basic_publish(exchange='logs', routing_key='', body=message)
print(&quot; [x] Sent %r&quot; % message)
nnection.close()

</code></pre><p>receive_logs.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='logs', exchange_type='fanout')

result = channel.queue_declare(queue='', exclusive=True)
queue_name = result.method.queue

channel.queue_bind(exchange='logs', queue=queue_name)

print(' [*] Waiting for logs. To exit press CTRL+C')

def callback(ch, method, properties, body):
    print(&quot; [x] %r&quot; % body)

channel.basic_consume(
    queue=queue_name, on_message_callback=callback, auto_ack=True)

hannel.start_consuming()

</code></pre><h2 id="路由routing">路由（Routing）</h2>
<p>和上一节略有不同，exchange还是会继续广播消息，但是要让consumer只订阅到特定消息，如重要的报错log。</p>
<p>上一节中我们通过binding将Q和E绑定，这次我们加上额外的参数<code>routing_key</code>：</p>
<pre tabindex="0"><code>hannel.queue_bind(exchange=exchange_name,
                   queue=queue_name,
ting_key='black')

</code></pre><p><img src="../2019/09/image-2.png" alt="">
对于<code>fanout</code>来说，这个参数是没有用的因为fanout就是直接将拿到的消息推到各个与exchange绑定了的Q上。<br>
这次改用<code>direct</code>的exchange_type，消息会推到和binding_key和routing_key相同的队列上：</p>
<p>图里可以看到，exchange<code>X</code>有两个queue绑定，其中Q1的rounting_key是orange，Q2是black和green。</p>
<p>P向X推送消息，X按照上一节需要把消息广播到Q1和Q2，但在现在的模型下，P告诉X消息的类型，比如black，X将消息推送至：</p>
<ul>
<li>Q1或者Q2</li>
<li>routing_key是black的<br>
因此Q2收到消息，Q1没有。</li>
</ul>
<p><img src="../2019/09/image-3.png" alt="">
emit_log_direct.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='direct_logs', exchange_type='direct')

severity = sys.argv[1] if len(sys.argv) &gt; 1 else 'info'
message = ' '.join(sys.argv[2:]) or 'Hello World!'
channel.basic_publish(
    exchange='direct_logs', routing_key=severity, body=message)
print(&quot; [x] Sent %r:%r&quot; % (severity, message))
nnection.close()

</code></pre><p>receive_logs_direct.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='direct_logs', exchange_type='direct')

result = channel.queue_declare(queue='', exclusive=True)
queue_name = result.method.queue

severities = sys.argv[1:]
if not severities:
    sys.stderr.write(&quot;Usage: %s [info] [warning] [error]\n&quot; % sys.argv[0])
    sys.exit(1)

for severity in severities:
    channel.queue_bind(
        exchange='direct_logs', queue=queue_name, routing_key=severity)

print(' [*] Waiting for logs. To exit press CTRL+C')


def callback(ch, method, properties, body):
    print(&quot; [x] %r:%r&quot; % (method.routing_key, body))


channel.basic_consume(
    queue=queue_name, on_message_callback=callback, auto_ack=True)

hannel.start_consuming()

</code></pre><h2 id="话题topics">话题（Topics）</h2>
<p>上一节中，<code>direct</code>的exchange_type不能按照不同规则匹配，比如animal.chicken，animal.cow，匹配animal.*。</p>
<h4 id="topic-exchange">Topic exchange</h4>
<p>当exchange的类型为topic时，它的routing_key必须为由<code>.</code>分割的单词组成的列表，如<code>quick.orange.rabbit</code>。</p>
<p><code>topic</code>和<code>direct</code>的逻辑类似，消息推送的routing_key必须符合binding_key，但是允许：</p>
<ul>
<li>
<p><code>*</code>可以匹配一个词</p>
</li>
<li>
<p><code>#</code>可以匹配0或多个词</p>
</li>
<li>
<p>一个带有<code>quick.orange.rabbit</code>routing_key的消息会被推到Q1和Q2</p>
</li>
<li>
<p>一个带有<code>lazy.pink.rabbit</code>的消息只会被推到Q2</p>
</li>
<li>
<p>一个带有<code>quick.brown.fox</code>的消息不会被推到Q1或Q2</p>
</li>
<li>
<p>一个带有<code>quqick.orange.male.rabbit</code>的消息不能匹配上任何bindings所以会被丢弃</p>
</li>
</ul>
<p>通过通配符，<code>topic</code>模式也可以实现<code>fanout</code>和<code>direct</code>。</p>
<p>emit_log_topic.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='topic_logs', exchange_type='topic')

routing_key = sys.argv[1] if len(sys.argv) &gt; 2 else 'anonymous.info'
message = ' '.join(sys.argv[2:]) or 'Hello World!'
channel.basic_publish(
    exchange='topic_logs', routing_key=routing_key, body=message)
print(&quot; [x] Sent %r:%r&quot; % (routing_key, message))
nnection.close()

</code></pre><p>receive_logs_topic.py:</p>
<pre tabindex="0"><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='topic_logs', exchange_type='topic')

result = channel.queue_declare('', exclusive=True)
queue_name = result.method.queue

binding_keys = sys.argv[1:]
if not binding_keys:
    sys.stderr.write(&quot;Usage: %s [binding_key]...\n&quot; % sys.argv[0])
    sys.exit(1)

for binding_key in binding_keys:
    channel.queue_bind(
        exchange='topic_logs', queue=queue_name, routing_key=binding_key)

print(' [*] Waiting for logs. To exit press CTRL+C')


def callback(ch, method, properties, body):
    print(&quot; [x] %r:%r&quot; % (method.routing_key, body))


channel.basic_consume(
    queue=queue_name, on_message_callback=callback, auto_ack=True)

hannel.start_consuming()

</code></pre><h2 id="总结">总结</h2>
<ul>
<li>RabbitMQ模型：Producer-&gt;Exchange-&gt;Queue-&gt;Consumer</li>
<li>通过消息推送后Consumer的ACK来决定消息是否已经被对方处理，没有ACK的消息需要保留重发</li>
<li>默认的Exchange下消息通过Round Robin来推送到不同的队列，Consumer可以声明自己的QOS让消息在没有收到数量符合的ACK下不再分配给当前Consumer</li>
<li>通过不同的Exchange类型，实现将消息：
<ul>
<li>fanout：广播给所有绑定的Queue</li>
<li>direct：附加对应的routing_key，消息只推送给符合routing_key的Queue</li>
<li>topics：允许routing_key匹配不同的binding_key</li>
</ul>
</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>实现Django Models的数据mock</title>
			<link>https://jiekun.dev/posts/2019-08-03-%E5%AE%9E%E7%8E%B0%E4%B8%80%E5%A5%97%E5%AF%B9django-models%E6%95%B0%E6%8D%AEqueryset%E8%BF%9B%E8%A1%8C%E6%A8%A1%E6%8B%9F%E7%9A%84mock%E6%96%B9%E6%A1%88/</link>
			<pubDate>Sat, 03 Aug 2019 02:46:19 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-08-03-%E5%AE%9E%E7%8E%B0%E4%B8%80%E5%A5%97%E5%AF%B9django-models%E6%95%B0%E6%8D%AEqueryset%E8%BF%9B%E8%A1%8C%E6%A8%A1%E6%8B%9F%E7%9A%84mock%E6%96%B9%E6%A1%88/</guid>
			<description>问题 在开发过程中，整个数据流向为： 爬虫抓取数据-&amp;gt;数据中端进行数据清洗-&amp;gt;入库Web端定义的业务表 由于整个流程比较长，而且由于爬</description>
			<content type="html"><![CDATA[<h1 id="问题">问题</h1>
<p>在开发过程中，整个数据流向为：</p>
<pre tabindex="0"><code>爬虫抓取数据-&gt;数据中端进行数据清洗-&gt;入库Web端定义的业务表

</code></pre><p>由于整个流程比较长，而且由于爬虫开发的不稳定性以及数据统计的复杂度，完整的开发往往不能完全异步进行，因为最后面向业务的Web端需要等待清洗入库的数据进行测试。</p>
<p>一般来说，如果Web端需要的业务数据比较简单，开发自测的时候都可以手动生成INSERT等SQL模拟假数据，但是如果业务复杂的时候，往往需要十余个Table联动的数据，手动INSERT比较麻烦，开发效率低。</p>
<h1 id="思考">思考</h1>
<p>模拟数据的难处主要有：</p>
<ul>
<li>涉及地方多，如10多个表逐一写入对应数据</li>
<li>表与表之间的对应关系，如测试的时候需要从表1取10条数据，从表2取这10条数据对应的一周内各日的数据一共10 * 7条</li>
<li>编写测试SQL费事效率低，缺少开箱即用的数据生成器</li>
</ul>
<p>为此需要有一款工具：</p>
<ul>
<li>根据Django的models字段随机生成数据</li>
<li>支持指定数据内容，如指定数据的id，方便联表查询的时候能够正确JOIN出结果</li>
<li>支持filter、get等常用方法，支持聚合查询</li>
<li>无需写入数据库，返回QuerySet</li>
<li>方便开关，Mock与测试真正数据之间任意切换</li>
</ul>
<h1 id="实现">实现</h1>
<p>将以上问题逐一分析：</p>
<h2 id="随机生成对应类型数据">随机生成对应类型数据</h2>
<p>Django的Models常用的数据类型有：<br>
<code>CharField</code>、<code>IntegerField</code>、<code>DateTimeField</code>、<code>TextField</code>、<code>DecimalField</code>、<code>DateField</code><br>
其余类型在开发中不常用，因此先实现这几种类型的随机生成器</p>
<h4 id="charfield">CharField</h4>
<p>CharField对应Varchar和Char类型，目标是在有提供选项的时候随机返回选项中的内容，没提供选项的时候随机出0-max_length范围内的字符串，因此采用英文字母进行随机即可。</p>
<pre tabindex="0"><code>import string
from random import choice, randint

def charfield_generator(min_length=0, max_length=20, choices=[]):
    if not choices:
        return ''.join(choice(string.ascii_letters) for i in range(randint(min_length, max_length)))
    else:
        return choice(choices)

</code></pre><h4 id="integerfield">IntegerField</h4>
<p>IntegerField可以对应各类整数类型，包括SmallInt、TinyInt等均可共用同一个生成器通过限制长度来控制返回值。</p>
<pre tabindex="0"><code>f integerfield_generator(min_value, max_value, choices=[]):
    if not choices:
        return randint(min_value, max_value)
    else:
        return choice(choices)

</code></pre><h4 id="textfield">TextField</h4>
<p>TextField在要求不严格的情况下也可以和CharField共用生成器。业务上一般超长的内容会使用TextField，如文章正文。</p>
<h4 id="datetimefield">DatetimeField</h4>
<p>DatetimeField生成对应的时间对象，考虑生成一个大于起始时间(start_dt)小于结束时间(end_dt)的datetime对象。</p>
<pre tabindex="0"><code>f datetime_generator(start_dt=datetime.now(), end_dt=datetime.now()):
    dt_delta = end_dt - start_dt
    return start_dt + timedelta(seconds=randint(0, 24 * 3600 * dt_delta.days + dt_delta.seconds))

</code></pre><p>简单执行一下看看第一版效果：</p>
<pre tabindex="0"><code>for i in range(10):
    print('-------------- GENERATING SET %s -------------- ' % i)
    print(charfield_generator())
    print(integerfield_generator(0, 1000))
    print(datetime_generator(datetime.strptime('2018-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')))
    print('-------------- GENERATED SET %s -------------- ' % i, '\n')

</code></pre><pre tabindex="0"><code>GENERATING SET 0 -------------- 
I
196
2018-09-30 13:22:31
-------------- GENERATED SET 0 --------------  

-------------- GENERATING SET 1 -------------- 
XBFGGdpVwmlMMbCT
168
2018-11-16 09:02:16
-------------- GENERATED SET 1 --------------  

-------------- GENERATING SET 2 -------------- 
ZgU
293
2018-12-04 08:44:08
-------------- GENERATED SET 2 --------------  

-------------- GENERATING SET 3 -------------- 
TsUkylUiC
791
2018-10-01 03:48:16
-------------- GENERATED SET 3 --------------  

-------------- GENERATING SET 4 -------------- 
IusHQZsKYFtKi
909
2019-04-22 02:02:27
-------------- GENERATED SET 4 --------------  

-------------- GENERATING SET 5 -------------- 
ScRcj
505
2019-02-21 16:16:51
-------------- GENERATED SET 5 --------------  

-------------- GENERATING SET 6 -------------- 
OLmbMrZImnvaF
500
2018-12-24 22:20:47
-------------- GENERATED SET 6 --------------  

-------------- GENERATING SET 7 -------------- 
rNaRvAYSgxVzwLAe
664
2019-08-01 12:43:00
-------------- GENERATED SET 7 --------------  

-------------- GENERATING SET 8 -------------- 
rtLks
532
2019-03-14 07:38:53
-------------- GENERATED SET 8 --------------  

-------------- GENERATING SET 9 -------------- 
oIDFdOUKs
700
2018-09-21 19:59:06
-------------- GENERATED SET 9 --------------  

[Finished in 0.2s]

</code></pre><p>有了模拟数据之后，需要做几件事：</p>
<ul>
<li>将假数据映射到对应的Models上，实例化成QuerySet，由多个QuerySet组成iterative的QuerySet List</li>
<li>需要支持指定QuerySet List长度，因此可以实现计算页数、分页等操作</li>
</ul>
<pre tabindex="0"><code>f model_generator(models, length):
    &quot;&quot;&quot;
    : models Models.model :
    : length int :
    : rtype QuerySet List :
    &quot;&quot;&quot;
    return []

</code></pre><h1 id="最佳实践">最佳实践</h1>
<p>Work in progress!</p>
]]></content>
		</item>
		
		<item>
			<title>Elasticsearch倒排索引原理 数据写入与查询过程</title>
			<link>https://jiekun.dev/posts/2019-07-30-elasticsearch%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86-%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/</link>
			<pubDate>Tue, 30 Jul 2019 09:20:18 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-07-30-elasticsearch%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86-%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/</guid>
			<description>Elasticsearch在生产中充当的角色 业务上，最早启用Elasticsearch（下称ES）是为了解决模糊查询的问题。具体业务场景为大</description>
			<content type="html"><![CDATA[<h1 id="elasticsearch在生产中充当的角色">Elasticsearch在生产中充当的角色</h1>
<p>业务上，最早启用Elasticsearch（下称ES）是为了解决模糊查询的问题。具体业务场景为大量抓取回来的短视频内容、热门微博、公众号文章、小红书笔记、信息流新闻文章等，需要支持用户模糊查找，而随着每日新增的内容越来越多，这些信息已经积累到单个媒体数千万近亿的数量，因此依靠MySQL的模糊查询是无法满足性能上的要求，考虑引入对应的搜索引擎来解决，于是就将数据的特定字段迁移至ES以支持快速高效的模糊查询，并将查询得到的ID取回MySQL匹配再将详细内容返回。</p>
<h1 id="elasticsearch为什么能够支持高效的模糊查询">Elasticsearch为什么能够支持高效的模糊查询</h1>
<h3 id="倒排索引原理">倒排索引原理</h3>
<p>为了支持模糊查询，用户输入关键词之后，需要快速定位到这些词对应的词条，思路与MySQL的LIKE一样，但是MySQL没有实现对应的方案以支持快速定位。ES在这块上略有不同，利用倒排索引（Inverted Index）可以直接获取到文档的ID。下面来简单介绍一下倒排索引的结构。</p>
<p>为了便于理解，介绍的实现与具体实现会有不一致。<br>
现在有以下的数据行：</p>
<table>
<thead>
<tr>
<th style="text-align:center">id</th>
<th style="text-align:center">书名</th>
<th style="text-align:center">出版社</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">高性能MySQL</td>
<td style="text-align:center">电子工业出版社</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">Elasticsearch服务器开发</td>
<td style="text-align:center">人民邮电出版社</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">深入理解Elasticsearch</td>
<td style="text-align:center">机械工业出版社</td>
</tr>
</tbody>
</table>
<p>在写入数据，也就是索引（动词）的过程中：<br>
（1）ES首先会将数据进行分析，如”高性能MySQL”拆分成“高性能”和“MySQL”等词条（tokens），同理，“电子工业出版社”可以被拆分成“电子”、“工业”、“出版社”；<br>
（2) 拆分完毕后添加至对应的倒排索引中：</p>
<table>
<thead>
<tr>
<th style="text-align:center">词条</th>
<th style="text-align:center">对应id</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">高性能</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">MySQL</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">电子</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">工业</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">出版社</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
<p>（3）这样当Client查询“工业”一词的时候，就可以快速定位到id为1的数据行；<br>
（4）同理对id为2和3的数据分析和索引之后，倒排索引变成：</p>
<table>
<thead>
<tr>
<th style="text-align:center">词条</th>
<th style="text-align:center">对应id</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">高性能</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">MySQL</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">电子</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">工业</td>
<td style="text-align:center">1, 3</td>
</tr>
<tr>
<td style="text-align:center">出版社</td>
<td style="text-align:center">1, 2, 3</td>
</tr>
<tr>
<td style="text-align:center">Elasticsearch</td>
<td style="text-align:center">2, 3</td>
</tr>
<tr>
<td style="text-align:center">服务器</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">开发</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">人民</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">邮电</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">深入</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">理解</td>
<td style="text-align:center">3</td>
</tr>
</tbody>
</table>
<p>(5)举例搜索“工业”一词的时候，就应该定位到id为1和2的行</p>
<p>附上官方文档中的倒排索引势力，格式略有不同但是原理是相近的</p>
<pre tabindex="0"><code>Term      Doc_1  Doc_2
-------------------------
Quick   |       |  X
The     |   X   |
brown   |   X   |  X
dog     |   X   |
dogs    |       |  X
fox     |   X   |
foxes   |       |  X
in      |       |  X
jumped  |   X   |
lazy    |   X   |  X
leap    |       |  X
over    |   X   |  X
quick   |   X   |
summer  |       |  X
the     |   X   |
------------------------

</code></pre><h3 id="倒排索引和分析的具体实现">倒排索引和分析的具体实现</h3>
<p>倒排索引具体实现在官网文档中粗略查询了一下没有具体介绍，估计被埋在了厚厚的文档堆中。根据其他资料显示，倒排索引实现方法多种，主要如BSBI和SPIMI等，参考博客<a href="https://blog.csdn.net/androidlushangderen/article/details/44889677">《倒排索引构建算法BSBI和SPIMI》</a>。</p>
<p>在具体的分析过程中，Elasticsearch会使用多种分析器将文本拆分成用于搜索的词条，然后将这些词条统一化以提高“可搜索性”。具体来讲，分析器应该包含如下功能：<br>
（1）字符过滤器：如去除HTML，字符转换如&amp;转为and<br>
（2）分词器：如遇到空格和标点将文本拆分成词条<br>
（3）Token过滤器：如将大小写统一，增加词条（如jump、leap等同义词）<br>
ES内置有多种可选择的分析器，在业务中我们负责写入数据的同事使用的是针对中文分词的分词器以正确处理中文文本。</p>
<p>经过这些处理之后倒排索引生成，就能实现用于模糊查询的功能了。</p>
<h1 id="elasticsearch数据写入的过程">Elasticsearch数据写入的过程</h1>
<h3 id="预备知识">预备知识</h3>
<p>在ES中，数据结构和MySQL相似但也略有不同，类比来看，ES的存储从上至下可以类比成：<br>
索引（Index）：相当于MySQL中的DB<br>
文档类型（Doc Type）：相当于MySQL的Table<br>
文档（Doc）：相当于MySQL中的一行数据</p>
<p>ES的索引并非可以理解为一整块数据块，由不同的doc构成doc type然后聚集在一起就是index。实际上ES的索引是由一个或多个分片组成的，每个分片包含了文档集的一部分。每个分片又可以又对应的副本。<br>
因此，按照默认配置，ES的每个索引会切分出5个分片，而每个分片又有各自对应的副本，所以一共是10个分片。</p>
<p>分片，具体来说就是Lucene索引，因此可以看作ES的索引是由多个Lucene索引（分片）组成的，这些Lucene索引上包含了部分的doc。</p>
<p>继续细分Lucene索引，ES引入了按段搜索的概念，每个Lucene索引都是由多个段组成的，这些段具体而言就是，自身就是一个倒排索引。每个Lucene索引均包含了一个提交点（Commit Point）和多个段。</p>
<p>一下引入多种概念可能有点让人搞不懂，不要紧，下面借助一些官方的图例来理解一下。</p>
<h3 id="数据如何写入">数据如何写入</h3>
<p><img src="https://img-blog.csdnimg.cn/20190826205731562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="Lucene索引和段"> </figure></p>
<p>记住官方这张图，图中一个Lucene索引包含了3个段和一个提交点，当新增数据的时候：<br>
（1）新的doc存放至内存缓冲区（In-memory indexing buffer）中，准备被提交(New documents are collected in an in-memory indexing buffer)；<br>
（2）缓冲区的内容提交(Every so often, the buffer is commited)：</p>
<ul>
<li>
<p>一个新的段被写至磁盘中</p>
</li>
<li>
<p>一个新的、包含新段名称的提交点被写至磁盘中</p>
</li>
<li>
<p>所有在文件系统缓存中的待写入的数据被写入（flush）至磁盘，磁盘同步完成</p>
</li>
<li>
<p>A new segment—a supplementary inverted index—is written to disk.</p>
</li>
<li>
<p>A new commit point is written to disk, which includes the name of the new segment.</p>
</li>
<li>
<p>The disk is fsync’ed—all writes waiting in the filesystem cache are flushed to disk, to ensure that they have been physically written.</p>
<p>由于有按段写入缓冲区、写入磁盘的过程存在，ES的新增数据的搜索并不是实时的——近实时搜索。</p>
</li>
</ul>
<h3 id="近实时搜索">近实时搜索</h3>
<p><img src="https://img-blog.csdnimg.cn/20190826210926484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> </figure></p>
<p>因为需要把对应的段写入之后才能够查询，因此新数据进来的瞬间是无法搜索到的，即使已经按段（意味着倒排索引已经建立好）存在内存中。<br>
提交一个新的段至磁盘需要进行fsync的操作，这是个代价大的操作因此需要在内存缓冲区和磁盘之间增加新的缓冲区，使得在fsync操作之前文档就能够被搜索到。<br>
在Elasticsearch和磁盘之间是文件系统缓存。下图表示段已经从内存缓冲区中同步至文件系统缓存（灰色段），借助缓存，此时文档已经可以被检索到，但是还没有被提交。这个从内存缓冲区至文件系统缓存的过程称为refresh，这是一个写入和打开新段的轻量过程。</p>
<p>我们可以在设置中设置refresh的间隔时间，也可以通过refresh api进行手动refresh使得新增的doc“实时”可见。</p>
<pre tabindex="0"><code># 修改my_logs索引的refresh时间间隔
PUT /my_logs
{
  &quot;settings&quot;: {
    &quot;refresh_interval&quot;: &quot;30s&quot; 
  }
}

</code></pre><pre tabindex="0"><code># 请求接口对blogs进行refresh操作
POST /blogs/_refresh 

</code></pre><h3 id="数据持久化">数据持久化</h3>
<p>既然使用到了内存及文件系统缓存，那么必然有数据丢失的风险。尽管通过refresh实现了近实时搜索，但是还是要时常进行完整commit来确保能从失败中恢复出来。</p>
<p><img src="https://img-blog.csdnimg.cn/20190826211454555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> </figure> <img src="https://img-blog.csdnimg.cn/20190826211610131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure> <img src="https://img-blog.csdnimg.cn/20190826211636889.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure> <img src="https://img-blog.csdnimg.cn/20190826211955835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure></p>
<p>ES中使用了一个translog，在文档被索引（动词）后，就会被添加到内存缓冲区并且追加到translog：</p>
<p>在refresh操作过后，In-memory buffer区域的段转移到文件缓冲区，也就是灰色段：</p>
<p>随着进程的继续，doc会逐渐积累：</p>
<p>经过一定时间或者translog变大之后，这些translog就会通过fsync提交，现在看到所有的段都是绿色，意味着可搜索、持久化完成。文件缓存系统上的段（灰色）在fsync时会被清空（flush），旧的translog会被删除，创建新的空translog：</p>
<p>同样，flush操作也和refresh类似，有对应API可调用：</p>
<pre tabindex="0"><code>POST /blogs/_flush 

</code></pre><p>这里引用官方文档对translog的安全性的描述：</p>
<hr class="wp-block-separator" />
<h4 id="translog-有多安全">Translog 有多安全?</h4>
<p>translog 的目的是保证操作不会丢失。这引出了这个问题： Translog 有多安全 ？</p>
<p>在文件被 fsync 到磁盘前，被写入的文件在重启之后就会丢失。默认 translog 是每 5 秒被 fsync 刷新到硬盘， 或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。最终， 基本上，这意味着在整个请求被 fsync 到主分片和复制分片的translog之前，你的客户端不会得到一个 200 OK 响应。</p>
<p>在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小（特别是bulk导入，它在一次请求中平摊了大量文档的开销）。</p>
<p>但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。</p>
<p>这个行为可以通过设置 durability 参数为 async 来启用：</p>
<pre tabindex="0"><code>PUT /my_index/_settings
{
    &quot;index.translog.durability&quot;: &quot;async&quot;,
    &quot;index.translog.sync_interval&quot;: &quot;5s&quot;
}

</code></pre><p>这个选项可以针对索引单独设置，并且可以动态进行修改。如果你决定使用异步 translog 的话，你需要 保证 在发生crash时，丢失掉 sync_interval 时间段的数据也无所谓。请在决定前知晓这个特性。</p>
<p>如果你不确定这个行为的后果，最好是使用默认的参数（ “index.translog.durability”: “request” ）来避免数据丢失。</p>
<hr class="wp-block-separator" />
<h3 id="段合并">段合并</h3>
<p><img src="https://img-blog.csdnimg.cn/20190826212541329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> </figure> <img src="https://img-blog.csdnimg.cn/20190826212551992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></figure></p>
<p>随着refresh的不断调用，ES中的段会越来越多，太多的段会消耗更多的资源，因为查询是要在各个段中进行检查的，会拖慢查询效率。<br>
ES通过将小段合并至大段来解决这个积累的问题，这个动作是自动的：<br>
（1） 当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。<br>
（2）合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p>
<p>合并之后老的段会被删除，fsync将新的段提交至磁盘</p>
<h1 id="elasticsearch数据查询的过程">Elasticsearch数据查询的过程</h1>
<p>上文已经提过，ES将索引分成不同的分片（Luence索引），再由不同分片中的段（倒排索引）存储具体的数据。为了获取对应的doc，ES需要查询所有分片并且对结果进行合并。</p>
<h3 id="默认的索引过程">默认的索引过程</h3>
<p>ES根据文档的标识符，选择文档应该进入的分片（当然这一步也支持手动指定分片）。默认情况下，通过计算文档的Hash值将文档分配到对应分片上。</p>
<h3 id="取出过程">取出过程</h3>
<p>大多数情况下，为了得到想要的结果，需要查询所有的分片。<br>
我们把请求发送到ES的一个节点，根据请求的搜索类型：<br>
（1）ES首先查询所有节点获得对应符合的文档的标识符+得分（用于排序）<br>
（2）节点根据这些所有的标识符和得分，判断需要取出的对应文档范围（如得分top5的文档），重新构建一个内部请求，再到对应分片上获取这些文档的具体内容。</p>
]]></content>
		</item>
		
		<item>
			<title>Python数据类型——String</title>
			<link>https://jiekun.dev/posts/2019-05-18-python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-string/</link>
			<pubDate>Sat, 18 May 2019 14:23:16 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-05-18-python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-string/</guid>
			<description>又隔了好久好久没有写博客，过完了春节元宵清明五一一大堆节日，今年就没了一半了，所以需要抓紧时间充实一下。立好Flag以后看书一定要随时笔记不</description>
			<content type="html"><![CDATA[<p>又隔了好久好久没有写博客，过完了春节元宵清明五一一大堆节日，今年就没了一半了，所以需要抓紧时间充实一下。立好Flag以后看书一定要随时笔记不然厚厚的书翻起来跟天书一样难找。</p>
<h1 id="前言">前言</h1>
<p>其实这是一篇读书笔记，主要是关于Python的几种基础数据类型，包括顺序结构（List、Tuple等）、哈希结构（Dict、Set等）以及文本和Bytes。这些每天都在打交道的类型其实并不像看上去的简单，简单了解一下背后的理论和一些相关的使用技巧有助于平时编码中提高效率和写出（没）优（人）雅（懂）的代码。<br>
原书里面大概很多文字都没（看）什（不）么（懂）用，所以文章尽可能附上相关代码方便理解。</p>
<h1 id="文本与bytes">文本与Bytes</h1>
<p>Python3将Python2的万能的<code>str</code>分成了<code>text</code>类型（Unicode）和<code>bytes</code>类型，反人类的拆分背后隐藏着怎样的秘密？</p>
<h2 id="什么是字符串">什么是字符串</h2>
<p>字符串就是“字符”的“串”，问题在于什么是“字符”。<br>
两个概念：</p>
<ul>
<li>字符的标识，即<code>码位</code>(code point)，是0-1114111的数字构成的，在Unicode中使用4-6个十六进制的数字标示，前缀U+。例如：A-U+0041，€-U+20AC。</li>
<li>代表字符的byte的表示方式取决于具体编码。例如：A-U+0041在UTF-8中编码成单个字节\x41，在UTF-16LE中编码为两个字节\x41\x00。</li>
</ul>
<p>码位(code points)转字节序(bytes)叫<code>编码</code>，反之叫<code>解码</code></p>
<pre tabindex="0"><code>'你好'
&gt;&gt;&gt; b = s.encode('UTF-8') # 
&gt;&gt;&gt; b  # 这是个bytes对象
b'\xe4\xbd\xa0\xe5\xa5\xbd'
&gt;&gt;&gt; b.decode('UTF-8')
'你好'
&gt;&gt;&gt; b.decode('UTF-16LE')
'뷤\ue5a0붥'
&gt;&gt;&gt; len(s)
2
&gt;&gt;&gt; len(b)
6
</code></pre><h2 id="字节">字节</h2>
<p>震惊，下面这串东西的[0]和[0:1]的结果竟然不一样？</p>
<pre tabindex="0"><code>my_char = bytes('很好玩的代码', encoding='utf_8')
&gt;&gt;&gt; my_char
b'\xe5\xbe\x88\xe5\xa5\xbd\xe7\x8e\xa9\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81'
&gt;&gt;&gt; my_char[0]
229
&gt;&gt;&gt; my_char[0:1]
b'\xe5'
</code></pre><p>好吧本来以为是<code>str</code>类型很好玩，其实Python里面的其他顺序类型也是这么做的，指定某个index的时候返回的是对应的元素，[a:b]切片的时候返回的是同类型的序列，只是<code>str</code>类型看起来像是比较奇怪，只返回了值。</p>
<pre tabindex="0"><code>1 = ['好', '玩', '的', '代', '码']
&gt;&gt;&gt; l1[0]
'好'
&gt;&gt;&gt; l1[0:1]
['好']
</code></pre><p>二进制序列的表示方法有几种，如果不知道什么叫二进制序列的表示方法，请看：</p>
<pre tabindex="0"><code>'cafe咖啡'
&gt;&gt;&gt; s.encode('utf-8')
b'cafe\xe5\x92\x96\xe5\x95\xa1'
&gt;&gt;&gt; s = &quot;&quot;&quot;
... have
... a 
... test
... &quot;&quot;&quot;
&gt;&gt;&gt; s.encode('utf-8')
b'\nhave\na \ntest\n'
</code></pre><p>cafe\xe5\x92\x96\xe5\x95\xa1</p>
<ul>
<li>cafe和原文的cafe完全一致，因此二进制序列可以是ASCII字符本身</li>
<li>换行、回车等和\对应的字节，使用\n、\t等表示</li>
<li>其他字节的值，比如<code>咖啡</code>，使用十六进制转义序列</li>
</ul>
<p>除了少数方法（<code>format</code>、<code>format_map</code>、<code>casefold</code>、<code>isnumeric</code>等）以外，<code>str</code>类型的方法同样支持<code>bytes</code>和<code>bytearray</code>类型。例如<code>endswith</code>、<code>replace</code>等。<code>re</code>模块中的正则表达式也能处理二进制序列。<br>
二进制序列有个类方法是<code>str</code>没有的，<code>fromhex</code>，用于从十六进制数字对构建二进制序列。（大概这东西也没什么用）</p>
<h2 id="struct和memory-views">Struct和Memory Views</h2>
<p><code>struct</code>提供了一些把字节序列(\xe5\x96)转换成不同类型字段组成的元组的方法和逆向方法。<code>struct</code>模块可以处理<code>bytes</code> 、<code>bytearray</code>和<code>memoryview</code>对象。</p>
<pre tabindex="0"><code>import struct
&gt;&gt;&gt; fmt = '&amp;lt;3s3sHH'
&gt;&gt;&gt; with open('filter.gif', 'rb') as fp:
...     img = memoryview(fp.read())  # 使用文件创建memoryview对象
...
&gt;&gt;&gt; header = img[:10]  # memoryview切片再创建一个memoryview对象，但是memoryview的切片是共享内存地址的
&gt;&gt;&gt; bytes(header)
b'GIF89a+\x02\xe6\x00'
&gt;&gt;&gt; struct.unpack(fmt, header)  # 按照fmt规则unpack这个memoryview对象，得到一个元组
(b'GIF', b'89a', 555, 230)
&gt;&gt;&gt; del header
 del img
</code></pre><p>虽然搞不懂有什么用不过看起来很厉害就是了。</p>
<h2 id="编码器解码器">编码器/解码器</h2>
<p>这个小节最核心的点就是<strong>不要依赖系统的编码</strong>。因为不同系统的编码不一致，依赖系统编码会导致你的Python代码在不同系统上运行结果不一致。手动指定每次的编码器/解码器可以避免这个问题。</p>
<p>很显然不同的编码器对同一段字符串的编码得到的字节序列差异很大。开头已经说过，代表字符的byte的表示方式取决于具体编码：</p>
<pre tabindex="0"><code>for codec in ['utf_8', 'utf_16', 'latin_1']:
...     print(codec, 'This is 同样的文字'.encode(codec), sep='\t')
... 
utf_8    b'This is \xe5\x90\x8c\xe6\xa0\xb7\xe7\x9a\x84\xe6\x96\x87\xe5\xad\x97'  # UTF-8编码结果
utf_16    b'\xff\xfeT\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7h\x84v\x87eW['  # UTF-16编码结果
Traceback (most recent call last):
  File &quot;&amp;lt;stdin&gt;&quot;, line 2, in &amp;lt;module&gt;
UnicodeEncodeError: 'latin-1' codec can't encode characters in position 8-12: ordinal not in range(256)  # Lartin-1不支持中文
</code></pre><p>不支持中文肯定不行，所以有一些处理<code>UnicodeEncodeError</code>的方法，包括将不支持的字符转<strong>跳过</strong>、<strong>替换</strong>。</p>
<pre tabindex="0"><code>int(codec, 'This is 同样的文字'.encode('latin_1', errors='ignore'), sep='\t')
latin_1    b'This is '
&gt;&gt;&gt; print(codec, 'This is 同样的文字'.encode('latin_1', errors='replace'), sep='\t')
latin_1    b'This is ?????'
&gt;&gt;&gt; print(codec, 'This is 同样的文字'.encode('latin_1', errors='xmlcharrefreplace'), sep='\t')
latin_1    b'This is &amp;#21516;&amp;#26679;&amp;#30340;&amp;#25991;&amp;#23383;'
</code></pre><p>对应的，如果要将<code>bytes</code>解码，也会有UnicodeDecodeError。</p>
<pre tabindex="0"><code>'\xff\xfeT\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7h\x84v\x87eW['
&gt;&gt;&gt; b.decode('utf-8')
Traceback (most recent call last):
  File &quot;&amp;lt;stdin&gt;&quot;, line 1, in &amp;lt;module&gt;
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte  # 解码不了
&gt;&gt;&gt; b.decode('utf-8', errors='replace')
'��T\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7h�v�eW['  # 代替
&gt;&gt;&gt; b.decode('utf-8', errors='ignore')
'T\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7hveW['  # 忽略
</code></pre><h2 id="使用预期之外的编码抛出syntaxerror">使用预期之外的编码抛出SyntaxError</h2>
<p>文件顶部加上注释</p>
<pre tabindex="0"><code># coding: cp1252
</code></pre><p>Python3默认使用UTF-8，GUN/Linux和OS X默认都是UTF-8，Windows则不是，所以可能会报这种反人类的错误。因此，和前面说的一样，不要依赖系统编码，全部手动指定可以让你的脚本正常运行于不同系统。</p>
<h2 id="怎样才能知道一段字节序列的编码">怎样才能知道一段字节序列的编码</h2>
<p>不可能。<br>
不过可以通过某种编码的特定模式来<strong>猜测</strong>（也就是没有100%准确的方案，a.k.a 不可能）对应编码</p>
<h2 id="bom">BOM</h2>
<pre tabindex="0"><code>u16_en = 'El Niño'.encode('utf_16')
&gt;&gt;&gt; u16_cn = '有鬼'.encode('utf_16')
&gt;&gt;&gt; u16_en
b'\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00'
&gt;&gt;&gt; u16_cn
b'\xff\xfe\tg&amp;lt;\x9b' 
</code></pre><p>奇怪，好像两段没有一个字相同的字符，但经过编码后的字节序列都是以<code>\xff\xfe</code>开头的。没错这就是<code>BOM</code>(byte-order mark)，指明编码时使用小字节序（little-endian byte ordering）。<br>
小字节序中，字母E的位码是U+0045，在字节便宜的第二位和第三位的编码为69和0；而大字节序中是编码顺序是相反的，E的编码为0和69。<br>
因此需要区分开小字节序系统和大字节序系统。因为按照设计,U+FFFE 字符不存在，在小字节序编码中,字节序列 b’\xff\<br>
xfe’ 必定是 ZERO WIDTH NO-BREAK SPACE ,所以编解码器知道该用哪个字节序。</p>
<h2 id="处理文本文件">处理文本文件</h2>
<p>处理文本的原则遵照“Unicode三明治”，就是尽可能早地把输入的字节序列转为字符串，让逻辑层只处理字符串对象。</p>
<pre tabindex="0"><code>n('cafe.txt', 'w', encoding='utf_8').write('café')
4
 open('cafe.txt').read()
</code></pre><p>如果在Windows上，最后的输出可能就不是<code>café</code>了，因为首次打开文件的时候指定了UTF-8编码，而再次打开的时候没有指定编码，则会依照系统的默认编码。Linux上默认均为UTF-8，会给人一种代码没有问题的假象，实际上并不是这样的。<br>
另外，如果在open的参数中声明是在二进制模式中读取文件，将会得到一个<code>BufferedReader</code>对象，而正常情况下会得到一个<code>TextIOWrapper</code>对象。</p>
<pre tabindex="0"><code>f = open('cafe.txt','rb')
&gt;&gt;&gt; f
&amp;lt;_io.BufferedReader name='cafe.txt'&gt;
&gt;&gt;&gt; f = open('cafe.txt','r')
&gt;&gt;&gt; f
&amp;lt;_io.TextIOWrapper name='cafe.txt' mode='r' encoding='UTF-8'&gt;
</code></pre><p>打开文件时没有指定encoding参数，编码会由<code>locale.getpreferredencoding()</code>指定，类似的还有一个用于编解码文件名的方法<code>sys.getfilesystemencoding()</code>。</p>
<h2 id="字符串对比">字符串对比</h2>
<p>先看一段代码：</p>
<pre tabindex="0"><code>1 = 'café'
&gt;&gt;&gt; s2 = 'cafe\u0301'
&gt;&gt;&gt; s1, s2
('café', 'café')
&gt;&gt;&gt; s1 == s2
False
&gt;&gt;&gt; len(s1), len(s2)
(4, 5)
</code></pre><p>看到两种表示的<code>café</code>并不相等，因为Python看到的是不同的码位序列。解决办法是将Unicode规范化，使用<code>unicodedata.normalize</code>。<br>
<code>normalize</code>有4种参数: <code>NFC</code>，<code>NFD</code>，<code>NFKC</code>，<code>NFKD</code>。前两个分别对应“使用最少的bytes构成等价字符串”和“把字符串分解成基本字符和单独的组合字符”，也就是类似于<code>café</code>和<code>cafe\u0301</code>两种形式；后两个分别是前两个的“兼容分解”模式，<code>K</code>表示“compatibility”，这样做格式会有所损失，例如<code>1⁄2</code>（这实际上是一个字符，1在上2在下）经过“兼容分解”后会变成<code>1/2</code>（这是3个字符）。<br>
接上面的代码，经过规范化后对比返回<code>True</code>：</p>
<pre tabindex="0"><code>from unicodedata import normalize
&gt;&gt;&gt; s1 == normalize('NFC', s2)
True
&gt;&gt;&gt; s2 == normalize('NFD', s1)
True
</code></pre><h2 id="大小写折叠case-fold">大小写折叠(Case Fold)</h2>
<p>字符串的<code>casefold</code>方法将文本变为小写，但是对比<code>lower</code>方法更加暴力</p>
<pre tabindex="0"><code>'ß'.casefold()
'ss'  # ß在德语中是“sharp s”
&gt;&gt;&gt; 'ß'.lower()
'ß'
</code></pre><h2 id="规范化总结">规范化总结</h2>
<p>规范化待比较的字符串使用<code>NFC</code>，不区分大小写使用casefold</p>
<h2 id="极端的规范化">极端的“规范化”</h2>
<p>如何将<code>São Paulo</code>规范化成<code>Sao Paulo</code>，尽管这样做会丢失信息？<br>
作者的骚操作，不再展示，可以参考原书4.6.3节。</p>
<h2 id="unicode的文本排序">Unicode的文本排序</h2>
<p>这里有个错误的排序：</p>
<pre tabindex="0"><code>fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
&gt;&gt;&gt; sorted(fruits)
['acerola', 'atemoia', 'açaí', 'caju', 'cajá']
</code></pre><p>期望得到的结果是<code>ç</code>按照<code>c</code>排序，<code>á</code>按照<code>a</code>排序：</p>
<pre tabindex="0"><code>['açaí', 'acerola', 'atemoia', 'cajá', 'caju']
</code></pre><p>非ASCII文本的标准排序方式是使用<code>locale.strxfrm</code>函数，这个函数的结果跟当前所在区域有关，通过使用<code>locale.setlocale()</code>改变所在区域以达到按照特定区域的习惯排序的效果。</p>
<pre tabindex="0"><code>import locale
&gt;&gt;&gt; locale.setlocale(locale.LC_COLLATE, 'zh_CN.UTF-8')
'zh_CN.UTF-8'
&gt;&gt;&gt; fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
&gt;&gt;&gt; sorted(fruits, key=locale.strxfrm)
['açaí', 'acerola', 'atemoia', 'cajá', 'caju']
</code></pre><h2 id="unicode-数据库">Unicode 数据库</h2>
<p>Unicode标准提供了一个完整的数据库，包括码位和字符名称之间的映射、各字符的元数据、字符之间的关系。</p>
]]></content>
		</item>
		
		<item>
			<title>Django单元测试类</title>
			<link>https://jiekun.dev/posts/2019-01-17-django%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%B1%BB/</link>
			<pubDate>Thu, 17 Jan 2019 03:49:11 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-01-17-django%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%B1%BB/</guid>
			<description>TestCase与TransactionTestCase都是继承自SimpleTestCase，两者主要的区别在于： TestCase在测试开</description>
			<content type="html"><![CDATA[<p>TestCase与TransactionTestCase都是继承自SimpleTestCase，两者主要的区别在于：</p>
<ul>
<li>TestCase在测试开始时，判断当前连接的数据库是否支持事务特性，如支持，则开启事务操作；在测试结束时，同样判断是否支持事务特性，如支持，执行事务回滚，然后关闭所有链接。具体setUpClass与tearDownClass方法如下</li>
</ul>
<pre tabindex="0"><code>@classmethod
    def setUpClass(cls):
        super(TestCase, cls).setUpClass()
        if not connections_support_transactions():  # 事务支持判断
            return
        cls.cls_atomics = cls._enter_atomics()  # 开启事务，TestCase中测试代码均处于此事务Block中

        if cls.fixtures:
            for db_name in cls._databases_names(include_mirrors=False):
                    try:
                        call_command('loaddata', *cls.fixtures, **{
                            'verbosity': 0,
                            'commit': False,
                            'database': db_name,
                        })
                    except Exception:
                        cls._rollback_atomics(cls.cls_atomics)
                        raise
        cls.setUpTestData()


@classmethod
def tearDownClass(cls):
    if connections_support_transactions():  # 事务支持判断
        cls._rollback_atomics(cls.cls_atomics)  # 回滚所有操作
        for conn in connections.all():  # 关闭所有链接
            conn.close()
    super(TestCase, cls).tearDownClass()

</code></pre><ul>
<li>TransactionTestCase与TestCase不同，在此测试类中并不开启事务块，测试结束时通过进行Fush操作清空数据。此类没有重写SimpleTestCase的setUp和tearDown方法，只修改了_post_teardown等如下：</li>
</ul>
<pre tabindex="0"><code>f _post_teardown(self):
    &quot;&quot;&quot;
    * 清空数据库的内容
    * 关闭链接
    &quot;&quot;&quot;
    try:
        self._fixture_teardown()
        super(TransactionTestCase, self)._post_teardown()
        if self._should_reload_connections():
            for conn in connections.all():
                conn.close()
    finally:
        if self.available_apps is not None:
            apps.unset_available_apps()
            setting_changed.send(sender=settings._wrapped.__class__,
                                 setting='INSTALLED_APPS',
                                 value=settings.INSTALLED_APPS,
                                 enter=False)


def _fixture_teardown(self):
    for db_name in self._databases_names(include_mirrors=False):
        call_command('flush', verbosity=0, interactive=False,
                     database=db_name, reset_sequences=False,
                     allow_cascade=self.available_apps is not None,
                     inhibit_post_migrate=self.available_apps is not None)

</code></pre><p>在事务方面的区别使得：使用TestCase时，如果被测试代码中出现必须在事务块中执行的代码，则会抛出异常，如官方举例的select_for_update()：</p>
<pre tabindex="0"><code>SampleTestCase(TestCase):
    def setUp(self):
        Sample.objects.create(**{'field1': 'value1, 'field2': 'value2'})

    def test_difference_testcase(self):
        sample = Sample.objects.select_for_update().filter()
        print(sample)


class SampleTransactionTestCase(TransactionTestCase):
    def setUp(self):
        Sample.objects.create(**{'field1': 'value1, 'field2': 'value2'})

    def test_difference_transactiontestcase(self):
        sample = Sample.objects.select_for_update().filter()
        print(sample)

</code></pre><p>第一个TestCase会抛出异常：</p>
<pre tabindex="0"><code>AssertionError: TransactionManagementError not raised

</code></pre><p>第二个TTC会通过测试。</p>
<h2 id="小结">小结</h2>
<ul>
<li>使用TestCase，相当于后续代码都会处于一个外层事务的Block内执行，因此测试者不能测试必须运行在事务Block中的代码 (<em>For instance, you cannot test that a block of code is executing within a transaction, as is required when using select_for_update()</em>)</li>
<li>TestCase中，最终事务需要进行回滚，因此如果在测试代码中进行了conn.close()一类的操作将会引起异常</li>
<li>TransactionTestCase不开启事务，并且通过测试结束时Flush DB的方案来还原干净环境</li>
</ul>
]]></content>
		</item>
		
	</channel>
</rss>
