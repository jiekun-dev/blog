<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Jiekun&#39;s Blog</title>
		<link>https://jiekun.dev/posts/</link>
		<description>Recent content in Posts on Jiekun&#39;s Blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>cn-zh</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Sun, 20 Sep 2020 05:16:52 +0000</lastBuildDate>
		<atom:link href="https://jiekun.dev/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Redis 6.0新Feature实现原理——Threaded I/O</title>
			<link>https://jiekun.dev/posts/2020-09-20-redis-6-0%E6%96%B0feature%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86-threaded-i-o/</link>
			<pubDate>Sun, 20 Sep 2020 05:16:52 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-09-20-redis-6-0%E6%96%B0feature%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86-threaded-i-o/</guid>
			<description>Introduction Redis从6.0版本开始引入了Threaded I/O，目的是为了提升执行命令前后的网络I/O性能。本文会先从Redis的主流程开始分析，讲解网络I/O发生在哪里，以及现有的网络I/O模型，然后介绍Threaded I/O的新模型、实现以及生效场景，最后会进行场景测试，对比Threaded I/O关闭与开启，以及启用Threaded I/O与在单实例上搭建集群的性能差异。如果你已经了解过Redis的循环流程，可以直接跳至Threaded I/O相关的部分；如果你只关心新功能的实际提升，可以跳至性能测试部分查看。
Redis是如何运行的 事件循环 main Redis的入口位于server.c下，main()方法流程如图所示。
在main()方法中Redis首先需要做的是初始化各种库以及服务配置。具体举例：
 crc64_init()会初始化一个crc校验用的Lookup Table getRandomBytes()为hashseed填充随机元素作为初始化值，用作哈希表的seed … initServerConfig()中执行了大量对server对象属性的初始化操作：  初始化server.runid，如16e05f486b8d41e79593a35c8b96edaff101c194 获取当前的时区信息，存放至server.timezone中 初始化server.next_client_id值，使得连接进来的客户端id从1开始自增 …   ACLInit()是对Redis 6.0新增的ACL系统的初始化操作，包括初始化用户列表、ACL日志、默认用户等信息 通过moduleInitModulesSystem()和tlsInit()初始化模块系统和SSL等 …  初始化结束后，开始读取用户的启动参数，和大多数配置加载过程类似，Redis也通过字符串匹配等分析用户输入的argc和argv[]，这个过程中可能会发生：
 获取到配置文件路径，修改server.configfile的值，后续用于加载配置文件 获取到启动选项参数，如loadmodule和对应的Module文件路径，保存至options变量中  解析完参数之后，执行loadServerConfig()，读取配置文件并与命令行参数options的内容进行合并，组成一个config变量，并且逐个将name和value设置进configs列表中。对于每个config，有对应的switch-case的代码，例如对于loadmodule，会执行queueLoadModule()方法，以完成真正的配置加载：
... } else if (!strcasecmp(argv[0],&amp;quot;logfile&amp;quot;) &amp;amp;&amp;amp; argc == 2) { ... } else if (!strcasecmp(argv[0],&amp;quot;loadmodule&amp;quot;) &amp;amp;&amp;amp; argc &amp;gt;= 2) { queueLoadModule(argv[1],&amp;amp;argv[2],argc-2); } else if (!strcasecmp(argv[0],&amp;quot;sentinel&amp;quot;)) { ...&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 回到main方法的流程，Redis会开始打印启动的日志，执行initServer()方法，服务根据配置项，继续为server对象初始化内容，例如：
 创建事件循环结构体aeEventLoop（定义在ae.h），赋值给server.el 根据配置的db数目，分配大小为sizeof(redisDb) * dbnum的内存空间，server.db保存这块空间的地址指针 每个db都是一个redisDb结构，将这个结构中的保存key、保存过期时间等的字典初始化为空dict …  此后就是一些根据不同运行模式的初始化，例如常规模式运行时会记录常规日志、加载磁盘持久化的数据；而在sentinel模式运行时记录哨兵日志，不加载数据等。</description>
			<content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Redis从6.0版本开始引入了Threaded I/O，目的是为了提升执行命令前后的网络I/O性能。本文会先从Redis的主流程开始分析，讲解网络I/O发生在哪里，以及现有的网络I/O模型，然后介绍Threaded I/O的新模型、实现以及生效场景，最后会进行场景测试，对比Threaded I/O关闭与开启，以及启用Threaded I/O与在单实例上搭建集群的性能差异。如果你已经了解过Redis的循环流程，可以直接跳至<strong>Threaded I/O相关</strong>的部分；如果你只关心新功能的实际提升，可以跳至<strong>性能测试</strong>部分查看。</p>
<h1 id="redis是如何运行的">Redis是如何运行的</h1>
<h2 id="事件循环">事件循环</h2>
<h3 id="main">main</h3>
<p>Redis的入口位于server.c下，<code>main()</code>方法流程如图所示。</p>
<p><img src="../2020/09/redis_main-878x1024.png" alt="">
在<code>main()</code>方法中Redis首先需要做的是<strong>初始化各种库以及服务配置</strong>。具体举例：</p>
<ul>
<li><code>crc64_init()</code>会初始化一个crc校验用的Lookup Table</li>
<li><code>getRandomBytes()</code>为<code>hashseed</code>填充随机元素作为初始化值，用作哈希表的seed</li>
<li>…</li>
<li><code>initServerConfig()</code>中执行了大量对<code>server</code>对象属性的初始化操作：
<ul>
<li>初始化<code>server.runid</code>，如<code>16e05f486b8d41e79593a35c8b96edaff101c194</code></li>
<li>获取当前的时区信息，存放至<code>server.timezone</code>中</li>
<li>初始化<code>server.next_client_id</code>值，使得连接进来的客户端id从1开始自增</li>
<li>…</li>
</ul>
</li>
<li><code>ACLInit()</code>是对Redis 6.0新增的ACL系统的初始化操作，包括初始化用户列表、ACL日志、默认用户等信息</li>
<li>通过<code>moduleInitModulesSystem()</code>和<code>tlsInit()</code>初始化模块系统和SSL等</li>
<li>…</li>
</ul>
<p>初始化结束后，开始<strong>读取用户的启动参数</strong>，和大多数配置加载过程类似，Redis也通过字符串匹配等分析用户输入的<code>argc</code>和<code>argv[]</code>，这个过程中可能会发生：</p>
<ul>
<li>获取到配置文件路径，修改<code>server.configfile</code>的值，后续用于加载配置文件</li>
<li>获取到启动选项参数，如<code>loadmodule</code>和对应的Module文件路径，保存至<code>options</code>变量中</li>
</ul>
<p>解析完参数之后，执行<code>loadServerConfig()</code>，<strong>读取配置文件并与命令行参数options的内容进行合并</strong>，组成一个<code>config</code>变量，并且逐个将name和value设置进configs列表中。对于每个config，有对应的switch-case的代码，例如对于<code>loadmodule</code>，会执行<code>queueLoadModule()</code>方法，以完成真正的配置加载：</p>
<pre><code>...
        } else if (!strcasecmp(argv[0],&quot;logfile&quot;) &amp;&amp; argc == 2) {   
            ... 
        } else if (!strcasecmp(argv[0],&quot;loadmodule&quot;) &amp;&amp; argc &gt;= 2) {
            queueLoadModule(argv[1],&amp;argv[2],argc-2);
        } else if (!strcasecmp(argv[0],&quot;sentinel&quot;)) {
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>回到<code>main</code>方法的流程，Redis会开始打印启动的日志，执行<code>initServer()</code>方法，服务根据配置项，继续<strong>为<code>server</code>对象初始化内容</strong>，例如：</p>
<ul>
<li>创建事件循环结构体<code>aeEventLoop</code>（定义在ae.h），赋值给<code>server.el</code></li>
<li>根据配置的db数目，分配大小为<code>sizeof(redisDb) * dbnum</code>的内存空间，<code>server.db</code>保存这块空间的地址指针</li>
<li>每个db都是一个redisDb结构，将这个结构中的保存key、保存过期时间等的字典初始化为空dict</li>
<li>…</li>
</ul>
<p>此后就是一些根据不同运行模式的初始化，例如常规模式运行时会记录常规日志、加载磁盘持久化的数据；而在sentinel模式运行时记录哨兵日志，不加载数据等。</p>
<p>在所有准备操作都完成后，<strong>Redis开始陷入<code>aeMain()</code>的事件循环，在这个循环中会不断执行<code>aeProcessEvents()</code>处理发生的各种事件，直到Redis结束退出</strong>。</p>
<h3 id="两种事件">两种事件</h3>
<p>Redis中存在有两种类型的事件：<strong>时间事件</strong>、<strong>文件事件</strong>。</p>
<p><strong>时间事件也就是到了一定事件会发生的事件</strong>，在Redis中它们被记录成一个链表，每次创建新的事件事件的时候，都会在链表头部插入一个<code>aeTimeEvent</code>节点，其中保存了该事件会在何时发生，需要调用什么样的方法处理。遍历整个链表我们可以知道离最近要发生的时间事件还有多久，因为链表里面的节点按照自增id顺序排列，而在发生时间的维度上时乱序的。</p>
<p><img src="../2020/09/redis_time_event-1024x836.png" alt="">
<strong>文件事件可以看作I/O引起的事件</strong>，客户端发送命令会让服务端产生一个读I/O，对应一个读事件；同样当客户端等待服务端消息的时候需要变得可写，让服务端写入内容，因此会对应一个写事件。<code>AE_READABLE</code>事件会在客户端建立连接、发送命令或其他连接变得可读的时候发生，而<code>AE_WRITABLE</code>事件则会在客户端连接变得可写的时候发生。</p>
<p><img src="../2020/09/redis_file_event_happen-1024x512.png" alt="">
文件事件的结构简单很多，<code>aeFileEvent</code>记录了这是一个可读事件还是可写事件，对应的处理方法，以及用户数据。</p>
<p><img src="../2020/09/redis_file_event-1024x529.png" alt="">
如果同时发生了两种事件，Redis会优先处理<code>AE_READABLE</code>事件。</p>
<h3 id="aeprocessevents">aeProcessEvents</h3>
<p><strong><code>aeProcessEvents()</code>方法处理已经发生和即将发生的各种事件</strong>。</p>
<p><img src="../2020/09/redis_aeProcessEvents-945x1024.png" alt="">
在<code>aeMain()</code>循环进入<code>aeProcessEvents()</code>后，Redis首先检查下一次的时间事件会在什么时候发生，在还没有时间事件发生的这段时间内，可以调用多路复用的API <code>aeApiPoll()</code>阻塞并等待文件事件的发生。如果没有文件事件发生，那么超时后返回0，否则返回已发生的文件事件数量<code>numevents</code>。</p>
<p>在有文件事件可处理的情况下，Redis会调用<code>AE_READABLE</code>事件的<code>rfileProc</code>方法以及<code>AE_WRITABLE</code>事件的<code>wfileProc</code>方法进行处理：</p>
<pre><code>...
            if (!invert &amp;&amp; fe-&gt;mask &amp; mask &amp; AE_READABLE) {
                fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);
                fired++;
                fe = &amp;eventLoop-&gt;events[fd];
            }

            if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) {
                if (!fired || fe-&gt;wfileProc != fe-&gt;rfileProc) {
                    fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);
                    fired++;
                }
            }
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在完成前面的处理后，Redis会继续调用<code>processTimeEvents()</code>处理时间事件。遍历整个时间事件链表，如果此时已经过了一段时间（阻塞等待或处理文件事件耗时），有时间事件发生，那么就调用对应时间事件的<code>timeProc</code>方法，将所有已经过时的时间事件处理掉：</p>
<pre><code>...
        if (te-&gt;when &amp;lt;= now) {
            ...
            retval = te-&gt;timeProc(eventLoop, id, te-&gt;clientData);
            ...
            processed++;
            ...
        }
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>如果执行了文件事件之后还没有到最近的时间事件发生点，那么本次<code>aeMain()</code>循环中将没有时间事件被执行，进入下一次循环。</p>
<h2 id="命令执行前后发生了什么">命令执行前后发生了什么</h2>
<p>在客户端连接上Redis的时候，通过执行<code>connSetReadHandler(conn, readQueryFromClient)</code>，设置了当读事件发生时，使用<code>readQueryFromClient()</code>作为读事件的Handler。</p>
<p>在收到客户端的命令请求时，Redis进行一些检查和统计后，调用<code>read()</code>方法将连接中的数据读取进<code>client.querybuf</code>消息缓冲区中：</p>
<pre><code>void readQueryFromClient(connection *conn) {
    ...
    nread = connRead(c-&gt;conn, c-&gt;querybuf+qblen, readlen);
    ...


static inline int connRead(connection *conn, void *buf, size_t buf_len) {
    return conn-&gt;type-&gt;read(conn, buf, buf_len);
}

static int connSocketRead(connection *conn, void *buf, size_t buf_len) {
    int ret = read(conn-&gt;fd, buf, buf_len);
    ...
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>然后进入<code>processInputBuffer(c)</code>开始读取输入缓冲区中的消息，最后进入<code>processCommand(c)</code>开始处理输入的命令。</p>
<p>在命令执行得到结果后，首先会存放在<code>client.buf</code>中，并且调用调用<code>addReply(client *c, robj *obj)</code>方法，将这个<code>client</code>对象追加到<code>server.clients_pending_write</code>列表中。此时当次的命令，或者说<code>AE_READABLE</code>事件就已经基本处理完毕了，除了一些额外的统计数据、后处理以外，不会再进行发送响应消息的动作。</p>
<p><img src="../2020/09/redis_result_to_reply-904x1024.png" alt="">
在当前<code>aeProcessEvents()</code>方法结束后，进入<strong>下一次的循环</strong>，第二次循环调用I/O多路复用接口等待文件事件发生前，Redis会检查<code>server.clients_pending_write</code>是否有客户端需要进行回复，若有，遍历指向各个待回复客户端的<code>server.clients_pending_write</code>列表，逐个将客户端从中删除，并将待回复的内容通过<code>writeToClient(c,0)</code>回复出去</p>
<pre><code>int writeToClient(client *c, int handler_installed) {
    ...
    nwritten = connWrite(c-&gt;conn,c-&gt;buf+c-&gt;sentlen,c-&gt;bufpos-c-&gt;sentlen);
    ...

static inline int connWrite(connection *conn, const void *data, size_t data_len) {
    return conn-&gt;type-&gt;write(conn, data, data_len);
}

static int connSocketWrite(connection *conn, const void *data, size_t data_len) {
    int ret = write(conn-&gt;fd, data, data_len);
    ...
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><h1 id="threaded-io模型">Threaded I/O模型</h1>
<h2 id="io问题与threaded-io的引入">I/O问题与Threaded I/O的引入</h2>
<p>如果要说Redis会有什么性能问题，那么从I/O角度，由于它没有像其他Database一样使用磁盘，所以不存在磁盘I/O的问题。在数据进入缓冲区前及从缓冲区写至Socket时，存在一定的网络I/O，特别是写I/O对性能影响比较大。以往我们会考虑做管道化来减小网络I/O的开销，或者将Redis部署成Redis集群来提升性能。</p>
<p>在Redis 6.0之后，由于Threaded I/O的引入，Redis开始支持对网络读写的线程化，让更多的线程参与进这部分动作中，同时保持命令的单线程执行。这样的改动从某种程度上说可以既提升性能，但又避免将命令执行线程化而需要引入锁或者其他方式解决并行执行的竞态问题。</p>
<h2 id="threaded-io在做什么">Threaded I/O在做什么</h2>
<p>在老版本的实现中，Redis将不同client的命令执行结果保存在各自的<code>client.buf</code>中，然后把待回复的<code>client</code>存放在一个列表里，最后在事件循环中逐个将<code>buf</code>的内容写至对应Socket。对应在新版本中，Redis使用多个线程完成这部分操作。</p>
<p><img src="../2020/09/redis_prepare_thread_io-1024x1024.png" alt="">
对读操作，Redis同样地为<code>server</code>对象新增了一个<code>clients_pending_read</code>属性，当读事件来临时，判断是否满足线程化读的条件，如果满足，那么执行延迟读操作，将这个<code>client</code>对象添加到<code>server.clients_pending_read</code>列表中。和写操作一样，留到下一次事件循环时使用多个线程完成读操作。</p>
<p><img src="../2020/09/redis_before_sleep-1024x811.png" alt=""></p>
<h1 id="threaded-io的实现与限制">Threaded I/O的实现与限制</h1>
<h2 id="init阶段">Init阶段</h2>
<p>在Redis启动时，如果满足对应参数配置，会进行I/O线程初始化的操作。</p>
<pre><code>void initThreadedIO(void) {
    server.io_threads_active = 0;
    if (server.io_threads_num == 1) return;

    if (server.io_threads_num &gt; IO_THREADS_MAX_NUM) {
        serverLog(LL_WARNING,&quot;Fatal: too many I/O threads configured. &quot;
                             &quot;The maximum number is %d.&quot;, IO_THREADS_MAX_NUM);
        exit(1);
    }
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>Redis会进行一些常规检查，配置数是否符合开启多线程I/O的要求。</p>
<pre><code>...
    for (int i = 0; i &amp;lt; server.io_threads_num; i++) {
        io_threads_list[i] = listCreate();
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>创建一个长度为线程数的<code>io_threads_list</code>列表，列表的每个元素都是另一个列表L，L将会用来存放对应线程待处理的多个<code>client</code>对象。</p>
<pre><code>...
        if (i == 0) continue;
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>对于主线程，初始化操作到这里就结束了。</p>
<pre><code>...
        pthread_t tid;
        pthread_mutex_init(&amp;io_threads_mutex[i],NULL);
        io_threads_pending[i] = 0;
        pthread_mutex_lock(&amp;io_threads_mutex[i]); /* Thread will be stopped. */
        if (pthread_create(&amp;tid,NULL,IOThreadMain,(void*)(long)i) != 0) {
            serverLog(LL_WARNING,&quot;Fatal: Can't initialize IO thread.&quot;);
            exit(1);
        }
        io_threads[i] = tid;
    }
}
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p><code>io_threads_mutex</code>是一个互斥锁列表，<code>io_threads_mutex[i]</code>即第<code>i</code>个线程的锁，用于后续阻塞I/O线程操作，初始化之后将其暂时锁定。然后再对每个线程执行创建操作，<code>tid</code>即其指针，保存至<code>io_threads</code>列表中。新的线程会一直执行<code>IOThreadMain</code>方法，我们将它放到最后讲解。</p>
<h2 id="readswrites">Reads/Writes</h2>
<p>多线程的读写主要在<code>handleClientsWithPendingReadsUsingThreads()</code>和<code>handleClientsWithPendingWritesUsingThreads()</code>中完成，因为两者几乎是对称的，所以这里只对读操作进行讲解，有兴趣的同学可以检查一下写操作有什么不同的地方以及为什么。</p>
<pre><code>int handleClientsWithPendingReadsUsingThreads(void) {
    if (!server.io_threads_active || !server.io_threads_do_reads) return 0;
    int processed = listLength(server.clients_pending_read);
    if (processed == 0) return 0;

    if (tio_debug) printf(&quot;%d TOTAL READ pending clients\n&quot;, processed);
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>同样，Redis会进行常规检查，是否启用线程化读写并且启用线程化读（只开启前者则只有写操作是线程化），以及是否有等待读取的客户端。</p>
<pre><code>...
    listIter li;
    listNode *ln;
    listRewind(server.clients_pending_read,&amp;li);
    int item_id = 0;
    while((ln = listNext(&amp;li))) {
        client *c = listNodeValue(ln);
        int target_id = item_id % server.io_threads_num;
        listAddNodeTail(io_threads_list[target_id],c);
        item_id++;
    }
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这里将<code>server.clients_pending_read</code>的列表转化为方便遍历的链表，然后将列表的每个节点（<code>*client</code>对象）以类似Round-Robin的方式分配个各个线程，线程执行各个client的读写顺序并不需要保证，命令抵达的先后顺序已经由<code>server.clients_pending_read/write</code>列表记录，后续也会按这个顺序执行。</p>
<pre><code>...
    io_threads_op = IO_THREADS_OP_READ;
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>设置状态标记，标识当前处于多线程读的状态。由于标记的存在，Redis的Threaded I/O瞬时只能处于读或写的状态，不能部分线程读，部分写。</p>
<pre><code>...
    for (int j = 1; j &amp;lt; server.io_threads_num; j++) {
        int count = listLength(io_threads_list[j]);
        io_threads_pending[j] = count;
    }
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>为每个线程记录下各自需要处理的客户端数量。当不同线程读取到自己的pending长度不为0时，就会开始进行处理。注意<code>j</code>从1开始，意味着``的主线程的pending长度一直为0，因为主线程马上要在这个方法中同步完成自己的任务，不需要知道等待的任务数。</p>
<p><img src="../2020/09/redis_tio_variables-945x1024.png" alt=""></p>
<pre><code>...
    listRewind(io_threads_list[0],&amp;li);
    while((ln = listNext(&amp;li))) {
        client *c = listNodeValue(ln);
        readQueryFromClient(c-&gt;conn);
    }
    listEmpty(io_threads_list[0]);
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>主线程此时将自己要处理的client处理完。</p>
<pre><code>...
    while(1) {
        unsigned long pending = 0;
        for (int j = 1; j &amp;lt; server.io_threads_num; j++)
            pending += io_threads_pending[j];
        if (pending == 0) break;
    }
    if (tio_debug) printf(&quot;I/O READ All threads finshed\n&quot;);
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>陷入循环等待，<code>pending</code>等于各个线程剩余任务数之和，当所有线程都没有任务的时候，本轮I/O处理结束。</p>
<pre><code>...
    while(listLength(server.clients_pending_read)) {
        ln = listFirst(server.clients_pending_read);
        client *c = listNodeValue(ln);
        c-&gt;flags &amp;= ~CLIENT_PENDING_READ;
        listDelNode(server.clients_pending_read,ln);

        if (c-&gt;flags &amp; CLIENT_PENDING_COMMAND) {
            c-&gt;flags &amp;= ~CLIENT_PENDING_COMMAND;
            if (processCommandAndResetClient(c) == C_ERR) {
                continue;
            }
        }
        processInputBuffer(c);
    }
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>我们已经在各自线程中将<code>conn</code>中的内容读取至对应client的<code>client.querybuf</code>输入缓冲区中，所以可以遍历<code>server.clients_pending_read</code>列表，串行地进行命令执行操作，同时将<code>client</code>从列表中移除。</p>
<pre><code>...
    server.stat_io_reads_processed += processed;

    return processed;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>处理完成，将处理的数量加到统计属性上，然后返回。</p>
<h2 id="iothreadmain">IOThreadMain</h2>
<p>前面还有每个线程具体的工作内容没有解释，它们会一直陷在<code>IOThreadMain</code>的循环中，等待执行读写的时机。</p>
<pre><code>void *IOThreadMain(void *myid) {
    long id = (unsigned long)myid;
    char thdname[16];

    snprintf(thdname, sizeof(thdname), &quot;io_thd_%ld&quot;, id);
    redis_set_thread_title(thdname);
    redisSetCpuAffinity(server.server_cpulist);
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>照常执行一些初始化内容。</p>
<pre><code>...
    while(1) {
        for (int j = 0; j &amp;lt; 1000000; j++) {
            if (io_threads_pending[id] != 0) break;
        }

        if (io_threads_pending[id] == 0) {
            pthread_mutex_lock(&amp;io_threads_mutex[id]);
            pthread_mutex_unlock(&amp;io_threads_mutex[id]);
            continue;
        }


        serverAssert(io_threads_pending[id] != 0);

        if (tio_debug) printf(&quot;[%ld] %d to handle\n&quot;, id, (int)listLength(io_threads_list[id]));
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>线程会检测自己的待处理的client列表长度，当等待队列长度大于0时往下执行，否则会到死循环起点。</p>
<p>这里利用互斥锁，让主线程有机会加锁，使得I/O线程卡在执行<code>pthread_mutex_lock()</code>，达到让I/O线程停止工作的效果。</p>
<pre><code>...
        listIter li;
        listNode *ln;
        listRewind(io_threads_list[id],&amp;li);
        while((ln = listNext(&amp;li))) {
            client *c = listNodeValue(ln);
            if (io_threads_op == IO_THREADS_OP_WRITE) {
                writeToClient(c,0);
            } else if (io_threads_op == IO_THREADS_OP_READ) {
                readQueryFromClient(c-&gt;conn);
            } else {
                serverPanic(&quot;io_threads_op value is unknown&quot;);
            }
        }
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>将<code>io_threads_list[i]</code>的客户端列表转化为方便遍历的链表，逐个遍历，借助<code>io_threads_op</code>标志判断当前是要执行多线程读还是多线程写，完成对自己要处理的客户端的操作。</p>
<pre><code>...
        listEmpty(io_threads_list[id]);
        io_threads_pending[id] = 0;

        if (tio_debug) printf(&quot;[%ld] Done\n&quot;, id);
    }
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>清空自己要处理的客户端列表，并且将自己的待处理数量修改为0，结束本轮操作。</p>
<h2 id="limitation">Limitation</h2>
<p>通过查看代码，使用上Threaded I/O的启用受以下条件影响：</p>
<ul>
<li>配置项<code>io-threads</code>需要大于1，否则会继续使用单线程操作读写I/O</li>
<li>配置项<code>io-threads-do-reads</code>控制读I/O是否使用线程化</li>
<li>对于延迟读取，由<code>postponeClientRead()</code>方法控制。方法中除了配置要求外，还需要当前client不能是主从模型的角色，也不能处于已经等待下次事件循环线程化读取（<code>CLIENT_PENDING_READ</code>）的状态。在这个方法中<code>client</code>对象会被添加到等待队列中，并且将client的状态改为<code>CLIENT_PENDING_READ</code>。</li>
<li>对于多线程写I/O，由<code>handleClientsWithPendingWritesUsingThreads()</code>中的<code>stopThreadedIOIfNeeded()</code>方法加以限制。除了对应配置项要满足要求外，<code>server.clients_pending_write</code>的长度需要大于等于配置线程数的两倍，例如配置使用6线程，当写队列长度小于12时会继续使用单线程I/O。</li>
<li>I/O线程在<code>initThreadedIO()</code>被创建前，互斥锁处于加锁状态，因此线程不能进行实际的任务处理。<code>server</code>对象的<code>io_threads_active</code>属性默认会处于关闭状态，在进行首次多线程写之前才会被开启。这意味着服务启动后的读操作仍然会使用单线程读，产生执行结果到写的pending list中，在第二次循环中，服务判断是否有配置启用TIO，将<code>server.io_threads_active</code>属性打开，然后进行多线程写操作，从下一次循环开始TIO才能被作用于读操作上。上一点说过写I/O会有配置和队列长度判定，在判定不需要TIO写时，会重新把<code>server.io_threads_active</code>关闭，意味着尽管你已经在配置文件里面打开TIO读，但是Redis仍然会根据负载时不时跳过使用它。</li>
</ul>
<h1 id="性能测试">性能测试</h1>
<p>我们编译了unstable版本的Redis进行性能测试，测试工具为Redis自带的redis-benchmark，统计输出的RPS值作为参考。</p>
<pre><code>Server实例: AWS / m5.2xlarge / 8 vCPU / 32 GB
Benchmark Client实例: AWS / m5.2xlarge / 8 vCPU / 32 GB
Command: redis-benchmark -h 172.xx.xx.62 -p 6379 -c 100 -d 256 -t get,set -n 10000000 --threads 8&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="threaded-io-off-vs-threaded-io-on">Threaded I/O off vs. Threaded I/O on</h2>
<p>我们对比了原有的单线程I/O以及开启2线程/4线程的Threaded I/O时的表现，结果如图所示。</p>
<p><img src="../2020/09/redis_tio_performance-945x1024.png" alt="">
在开启<code>io-threads-do-reads</code>选项的情况下，Threaded I/O作用于读操作，也能让性能有进一步提升，但是没有将写I/O线程化提升明显。另外我们还尝试使用了大体积Payload（<code>-d 8192</code>）进行测试，得出结果的提升百分比并没有太大差异。</p>
<h2 id="threaded-io-vs-redis-cluster">Threaded I/O vs. Redis Cluster</h2>
<p>以往开发者会通过在单台实例上部署Redis Cluster来尝试让Redis使用上更多的CPU资源，我们也尝试对比了一下这种情景下的表现。</p>
<p><img src="../2020/09/redis_tio_vs_cluster-1024x683.png" alt="">
在新版本中，redis-benchmark也得到了更新，开始支持对Redis Cluster的测试，通过开启<code>--cluster</code>参数即可检测集群模式和配置。我们在这一组对比测试中看到单实例构建集群的强大性能，在实际测试中，3个进程的CPU使用率均在80%-90%，说明仍有提升的空间。当改用测试参数<code>-c 512</code>时，集群能够跑出超过40万RPS的成绩。尽管测试与实际使用会有所区别，并且我们在构建集群的时候选择了不附带Slave，但是仍然能看出来在几种模型中，构建Cluster能真正使用上多线程进行网络I/O、命令执行，对性能的提升也是最大的。</p>
<h1 id="总结与思考">总结与思考</h1>
<p>Redis 6.0引入的Threaded I/O，将Socket读写延迟和线程化，在网络I/O的方向上给Redis带来了一定的性能提升，并且使用门槛比较低，用户无需做太多的变更，即可在不影响业务的情况下白嫖空闲的线程资源。</p>
<p>另一方面，从测试结果上看，这部分的提升可能还难以让处于Redis 5甚至Redis 3版本的用户有足够的动力进行升级，特别是考虑到很多业务场景中Redis的性能并没有差到成为瓶颈，而且新版本的福利也未经过大规模验证，势必会影响到企业级应用中更多用户关注的服务稳定性。同时，TIO的提升对比集群性能似乎还有一定的差距，这可能更加会让原本就处于集群架构的企业用户忽略这个功能。</p>
<p>但无论如何，用户肯定乐于见到更多的新功能、更多优化提升出现在Redis上。在保持一贯稳定性的前提下，本次的版本可以说是Redis从诞生至今最大的更新，不只有Threaded I/O，包括RESP3、ACLs和SSL，我们期待这些新Feature能够在更多的应用场景下得到推广、验证和使用，也希望未来的版本能够给用户带来更多的惊喜和更好的体验。</p>
<h1 id="further-reading-understanding-redis">Further Reading: Understanding Redis</h1>
<p>作为一位从来没有使用过C/类C语言的开发者，Redis简洁的代码和详尽的注释为我阅读和理解其实现提供了极大的帮助。在文末我想要分享一下自己学习Reids的一些途径、工具和方法。</p>
<p><code>README.md</code>应该是我们了解Redis的入口，而不是全局搜索<code>main()</code>方法。请关注<code>Redis internals</code>小节下的内容，这里介绍了Redis的代码结构，Redis每个文件都是一个“general idea”，其中<code>server.c</code>和<code>network.c</code>的部分逻辑和代码在本文已经介绍过了，持久化相关的<code>aof.c</code>和<code>rdb.c</code>、数据库相关的<code>db.c</code>、Redis对象相关的<code>object.c</code>、复制相关的<code>replication.c</code>等都值得留意。其他包括Redis的命令是以什么样的形式编码的，也能在<code>README.md</code>中找到答案，这样可以方便我们进一步阅读代码时快速定位。</p>
<p><a href="https://redis.io/documentation">Documentation主页</a>和<a href="https://github.com/redis/redis-doc">redis-doc repo</a>是Redis文档的集合处，请注意后者的<code>topics</code>目录下有非常多有趣的主题，我对“有趣”的定义是像这样的文章：</p>
<ul>
<li><a href="https://github.com/redis/redis-doc/blob/master/topics/cluster-spec.md">Redis Cluster Specification</a></li>
<li><a href="https://github.com/redis/redis-doc/blob/master/topics/cluster-spec.md">Redis server-assisted client side caching</a></li>
</ul>
<p>作为开发者，在深入学习的阶段，这些内容能让大家从“使用”变为“了解”，然后发现Redis原来能做更多的事情。所以如果缺乏时间阅读和调试源码，将<code>topics</code>下的60多篇文档看一遍，大概是了解Redis最快的方法。</p>
<p>最后，如果你能看到这里，大概也会对Redis的源码有那么一点兴趣。因为本身并不了解C语言，所以我大概率会选择借助一个IDE，在<code>main()</code>打上断点，然后流程的起点开始看，实际上我也确实是这么做的。另外几个代码的关键点，其实也在本文中出现过：</p>
<ul>
<li><code>main()</code>，起点</li>
<li><code>initServer()</code>，初始化</li>
<li><code>aeMain()</code>，事件循环</li>
<li><code>readQueryFromClient()</code>，读事件的Handler</li>
<li><code>processInputBuffer()</code>，命令处理的入口</li>
</ul>
<p>如果像本文一样想了解Network的内容，可以在<code>aeMain()</code>处打断点，然后关注中<code>network.c</code>中的方法；如果想关注具体命令相关的内容，可以在<code>processInputBuffer()</code>处打断点，然后关注<code>$command.c</code>或者类似文件中的方法，<code>README.md</code>文件里也已经介绍过命令方法的命名格式，定位非常容易。其余经常出现的其他动作，例如持久化、复制等，大概会出现在命令执行的前后，或者时间事件内，也可能在<code>beforeSleep()</code>中。<code>server.h</code>中定义的<code>redisServer</code>和<code>client</code>是Redis中两个非常重要的结构，在业务上很多内容都是转化为对它们的属性的相关操作，要特别留意。</p>
<p>除此以外，Antirez曾经在<a href="https://www.youtube.com/user/antirez">Youtube</a>上发布过一些开发的录播视频，<a href="https://www.youtube.com/c/Redislabs/videos">RedisLab</a>则有一些相对冷门使用场景的实践介绍，这些会比上面的其他学习来得更轻松些，最大的难处可能就是听懂演讲者们的口音，特别是Antirez本人，万幸Youtube的字幕功能非常强大，能解决不少麻烦。</p>
]]></content>
		</item>
		
		<item>
			<title>我的Join查询是如何得出结果的？</title>
			<link>https://jiekun.dev/posts/2020-08-08-%E6%88%91%E7%9A%84join%E6%9F%A5%E8%AF%A2%E6%98%AF%E5%A6%82%E4%BD%95%E5%BE%97%E5%87%BA%E7%BB%93%E6%9E%9C%E7%9A%84/</link>
			<pubDate>Sat, 08 Aug 2020 08:54:53 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-08-08-%E6%88%91%E7%9A%84join%E6%9F%A5%E8%AF%A2%E6%98%AF%E5%A6%82%E4%BD%95%E5%BE%97%E5%87%BA%E7%BB%93%E6%9E%9C%E7%9A%84/</guid>
			<description>Join Algorithms 在需要连接多表数据时，我们通常会使用到JOIN操作。
Nested Loop Join Basic Nested Loop Join 假设现在有两个关系对集合，R和S，我们需要将它连接起来，连接通过一定的条件来指定，这个条件我们称为Join Predicate，即连接谓词:
JP(r, s) := r.x == s.x&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 这个连接谓词表明R与S依靠字段x相等作为条件进行连接，当满足条件时，JP(r, s)返回为True，否则为False。
下面用伪代码表述Nested Loop Join的处理过程：
# R # S # JP(r, s) := r.x == s.x def nested_loop_join(R, S, JP(r, s)): for r in R: for s in S: if JP(r, s): outupt((r, s))&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 可以看出Nested Loop Join的处理过程即是两个关系对集合R与S的求Cross Product过程，因此若R中有n个关系对，S中有m个关系对，他们的处理复杂度即为O(m * n)。
Nested Loop Join的优势在于它不仅可以在等值连接（EquiJoin）中使用，还可以处理其他非等值连接：
 在NLJ中无需关注判定式JP(r, s)的实现 对于非等值连接，只判定式内部实现对应Join Predicate即可，外层循环无感知。如：JP(r, s) := r.x &amp;lt;= s.</description>
			<content type="html"><![CDATA[<h1 id="join-algorithms">Join Algorithms</h1>
<p>在需要连接多表数据时，我们通常会使用到<code>JOIN</code>操作。</p>
<h1 id="nested-loop-join">Nested Loop Join</h1>
<h2 id="basic-nested-loop-join">Basic Nested Loop Join</h2>
<p>假设现在有两个关系对集合，<code>R</code>和<code>S</code>，我们需要将它连接起来，连接通过一定的条件来指定，这个条件我们称为<strong>Join Predicate</strong>，即连接谓词:</p>
<pre><code>JP(r, s) := r.x == s.x&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这个连接谓词表明<code>R</code>与<code>S</code>依靠字段<code>x</code>相等作为条件进行连接，当满足条件时，<code>JP(r, s)</code>返回为<code>True</code>，否则为<code>False</code>。</p>
<p>下面用伪代码表述<strong>Nested Loop Join</strong>的处理过程：</p>
<pre><code># R
# S
# JP(r, s) := r.x == s.x

def nested_loop_join(R, S, JP(r, s)):
    for r in R:
        for s in S:
            if JP(r, s):
                outupt((r, s))&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>可以看出Nested Loop Join的处理过程即是两个关系对集合<code>R</code>与<code>S</code>的求<strong>Cross Product</strong>过程，因此若<code>R</code>中有n个关系对，<code>S</code>中有m个关系对，他们的处理复杂度即为<code>O(m * n)</code>。</p>
<p><strong>Nested Loop Join</strong>的优势在于它不仅可以在等值连接（EquiJoin）中使用，还可以处理其他非等值连接：</p>
<ul>
<li>在NLJ中无需关注判定式<code>JP(r, s)</code>的实现</li>
<li>对于非等值连接，只判定式内部实现对应<strong>Join Predicate</strong>即可，外层循环无感知。如：<code>JP(r, s) := r.x &lt;= s.x</code></li>
</ul>
<h2 id="indexed-nested-loop-join">Indexed Nested Loop Join</h2>
<p>现在输入的情况稍作改变，我们不仅有<code>R</code>、<code>S</code>和连接谓词<code>JP(r, s)</code>，还知道在其中一个关系集合，无论是<code>R</code>还是<code>S</code>，的连接谓词的列<code>x</code>上有对应的索引：</p>
<pre><code>IndexOnRX := catelog.get(indexes, R.x)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p><code>IndexOnRX</code>现在可以视为一个<code>R</code>上<code>x</code>列的索引查询方法，它可以接收查询值，并且返回一个集合，代表集合中的元素存在于<code>R</code>中。</p>
<p>下面用伪代码表述<strong>Indexed Nested Loop Join</strong>的处理过程：</p>
<pre><code># S
# JP(r, s)
# IndexOnRX

def indexed_nested_loop_join(IndexOnRX, S, JP(r, s)):
    for s in S:
        query_result_set = IndexOnRX(s.x)
        if query_result_set != None:
            output({s} * query_result_set)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>与NLJ不同，INLJ通过遍历其中1个关系对集合S，使用对应的索引查询得到另一个查询集合<strong>R的子集</strong>，如果有符合的case，将<code>{s} * query_result_set</code>结果追加到最后输出的集合中。因此在INLJ中，因为只遍历了其中一个关系对集合，查询复杂度可以视为<code>O(n)</code>。</p>
<h1 id="hash-join">Hash Join</h1>
<p>现在我们同样有两个关系对集合<code>R</code>和<code>S</code>，一个连接谓词<code>JP(r, s) := r.x == s.x</code>。<br>
下面用伪代码来表述<strong>Simple Hash Join</strong>的处理过程：</p>
<pre><code># R
# S
# JP(r, s) := r.x == s.x

def simple_hash_join(R, S, JP(r, s)):
    indexOnRX := build_ht(R.x)
    for s in S:
        query_result_set = IndexOnRS(s.x)
        if query_result_set != None:
            output({s} * query_result_set)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>可以看出在循环和判定上，SHJ和INLJ非常相似，最大的区别在于SHJ使用了一个临时生成的Hash内存表作为<code>IndexOnRS</code>依据。由于使用Hash Table，因此SHJ相比之前的NLJ而言缺少了非等值查询的支持。同时在查询复杂度上，SHJ先遍历其中一个关系对集合生成HT，再遍历另一个关系对进行判定，因此为<code>O(m + n)</code></p>
<h1 id="sort-merge-join">Sort-Merge Join</h1>
<p>现在我们有两张表<code>Customer</code>和<code>City</code>，我们需要通过<code>Join</code>操作获取每个customer所在的city。</p>
<!-- raw HTML omitted -->
<pre><code>&lt;th&gt;
  street
&lt;/th&gt;

&lt;th&gt;
  cityID
&lt;/th&gt;

&lt;th&gt;
&lt;/th&gt;

&lt;th&gt;
&lt;/th&gt;

&lt;th&gt;
&lt;/th&gt;

&lt;th&gt;
  cityID
&lt;/th&gt;

&lt;th&gt;
  city
&lt;/th&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s1
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  A
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s2
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  1
&lt;/td&gt;

&lt;td&gt;
  B
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s3
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  3
&lt;/td&gt;

&lt;td&gt;
  C
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s4
&lt;/td&gt;

&lt;td&gt;
  1
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  5
&lt;/td&gt;

&lt;td&gt;
  D
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s5
&lt;/td&gt;

&lt;td&gt;
  1
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  7
&lt;/td&gt;

&lt;td&gt;
  E
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s6
&lt;/td&gt;

&lt;td&gt;
  5
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  9
&lt;/td&gt;

&lt;td&gt;
  F
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s7
&lt;/td&gt;

&lt;td&gt;
  5
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s8
&lt;/td&gt;

&lt;td&gt;
  7
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s9
&lt;/td&gt;

&lt;td&gt;
  9
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s10
&lt;/td&gt;

&lt;td&gt;
  9
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s11
&lt;/td&gt;

&lt;td&gt;
  9
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<p>我们按照以下原则进行<strong>Merge Join</strong>：</p>
<ul>
<li>使用两个指针，分别指向两表的<code>cityID</code>字段</li>
<li>当指针对应的值相等时，output一行结果</li>
<li>指针需要移动至下一行时，优先移动当前指向值较小的指针，若值相等时优先移动指向<code>Customer</code>表的指针</li>
</ul>
<p>输出结果为：</p>
<!-- raw HTML omitted -->
<pre><code>&lt;th&gt;
  street
&lt;/th&gt;

&lt;th&gt;
  cityID
&lt;/th&gt;

&lt;th&gt;
  city
&lt;/th&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s1
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  A
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s2
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  A
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s3
&lt;/td&gt;

&lt;td&gt;
&lt;/td&gt;

&lt;td&gt;
  A
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s4
&lt;/td&gt;

&lt;td&gt;
  1
&lt;/td&gt;

&lt;td&gt;
  B
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s5
&lt;/td&gt;

&lt;td&gt;
  1
&lt;/td&gt;

&lt;td&gt;
  B
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s6
&lt;/td&gt;

&lt;td&gt;
  5
&lt;/td&gt;

&lt;td&gt;
  D
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s7
&lt;/td&gt;

&lt;td&gt;
  5
&lt;/td&gt;

&lt;td&gt;
  D
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s8
&lt;/td&gt;

&lt;td&gt;
  7
&lt;/td&gt;

&lt;td&gt;
  E
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s9
&lt;/td&gt;

&lt;td&gt;
  9
&lt;/td&gt;

&lt;td&gt;
  F
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s10
&lt;/td&gt;

&lt;td&gt;
  9
&lt;/td&gt;

&lt;td&gt;
  F
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  s11
&lt;/td&gt;

&lt;td&gt;
  9
&lt;/td&gt;

&lt;td&gt;
  F
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<p>注意到这种Merge操作的前提是两表的连接谓词所在字段必须是排序的，因此这种连接算法称为<strong>Sort-Merge Join</strong>。</p>
<p>根据以上条件写出伪代码：</p>
<pre><code># R
# S
# JP(r, s)

def sort_merge_join(R, S, JP(r, s)):
    sort(R on R.x)
    sort(S on S.x)
    pointer_r = R[0]
    pointer_s = S[0]

    while pointer_r != R.end and pointer_s != S.end:
        if pointer_r.x == pointer_s.x:
            output((pointer_r, pointer_s))

        if pointer_r.x &amp;lt;= pointer_s.x:
            pointer_r++
        else:
            pointer_s++

    # handle rest row here&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>要注意如果将<code>Customer</code>表与<code>City</code>表位置互换，并且保持优先移动左表(<code>City</code>)表指针，我们输出的结果将会是不正确的。</p>
<p>另外，如果两表的排序字段都不是主键或唯一，输出的结果也会有遗漏的case。</p>
<p>因此，<strong>Sort-Merge Join</strong>算法有必须满足的前提条件：</p>
<ul>
<li>Join字段在其中一个表中必须唯一</li>
<li>保持优先移动ref表（即Join字段非唯一的表）</li>
</ul>
<p>最后估算查询复杂度，需要先进行排序，为<code>O(nlogn)</code>的复杂度，然后双指针遍历两表为<code>O(m+n)</code>的复杂度。</p>
<h1 id="conclusion">Conclusion</h1>
<p>Join操作使用的基础算法：</p>
<ul>
<li>Nested Loop Join，可以视为两表相乘，嵌套循环逐行检查是否满足Join条件</li>
<li>Indexed Nested Loop Join，遍历部分表，并用遍历结果作为索引查询条件，借助索引查询</li>
<li>Hash Join，可以视为INLJ的特殊情况，区别在于Hash Join使用现有或临时生成的Hash值作为索引，此时不支持非等值连接</li>
<li>Sort-Merge Join，限定条件比较多，先根据Join字段排序，再合并两表，同样不支持非等值连接，否则会退化为NLJ</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>InnoDB中的B树与分裂</title>
			<link>https://jiekun.dev/posts/2020-08-05-innodb%E4%B8%AD%E7%9A%84b%E6%A0%91%E4%B8%8E%E5%88%86%E8%A3%82/</link>
			<pubDate>Wed, 05 Aug 2020 12:58:10 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-08-05-innodb%E4%B8%AD%E7%9A%84b%E6%A0%91%E4%B8%8E%E5%88%86%E8%A3%82/</guid>
			<description>Tree Binary Search Tree 在二叉查找树中，左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。
6 / \ 3 7 / \ \ 2 5 8&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 利用这棵二叉树对各个节点进行查找，平均查找次数为(1+2+3+3+2+3) / 6 = 2.3次，比起[2，3，5，6，7，8]顺序查找次数(1+2+3+4+5+6) / 6 = 3.3次要少。
二叉查找树还可以这样构建：
2 \ 3 \ 5 \ 6 \ 7 \ 8&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 这时查找的平均次数退化为顺序查找次数。
因此如果想高性能地构造一棵二叉查找树，需要这棵二叉查找树是平衡的。
Balance Tree 平衡二叉树符合二叉查找树的定义，并且满足任何节点的两个子树高度最大差为1。
6 6 / \ / \ 3 7 3 8 / \ \ / \ / \ 2 5 8 2 5 7 9 \ 9&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 在插入新节点后，平衡二叉树节点7的左右子树高度差为2，需要通过一次左旋操作来让树重新保持平衡。
但是有的情况可能需要旋转多次才能达到平衡。</description>
			<content type="html"><![CDATA[<h1 id="tree">Tree</h1>
<h2 id="binary-search-tree">Binary Search Tree</h2>
<p>在二叉查找树中，左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。</p>
<pre><code>6
       / \
      3   7
     / \   \
    2   5   8&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>利用这棵二叉树对各个节点进行查找，平均查找次数为<code>(1+2+3+3+2+3) / 6 = 2.3</code>次，比起[2，3，5，6，7，8]顺序查找次数<code>(1+2+3+4+5+6) / 6 = 3.3</code>次要少。</p>
<p>二叉查找树还可以这样构建：</p>
<pre><code>2
     \
      3
       \
        5
         \
          6
           \
            7
             \
              8&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这时查找的平均次数退化为顺序查找次数。</p>
<p>因此如果想高性能地构造一棵二叉查找树，需要这棵二叉查找树是<strong>平衡</strong>的。</p>
<h2 id="balance-tree">Balance Tree</h2>
<p>平衡二叉树符合二叉查找树的定义，并且满足任何节点的两个子树高度最大差为1。</p>
<pre><code>6                     6
       / \                  /   \
      3   7                3     8
     / \   \              / \   / \
    2   5   8            2   5 7   9
             \
              9&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在插入新节点后，平衡二叉树节点7的左右子树高度差为2，需要通过一次左旋操作来让树重新保持平衡。</p>
<p>但是有的情况可能需要旋转多次才能达到平衡。</p>
<pre><code>2             2             2               4    
     / \           / \           / \             / \   
    1   5         1   5         1   4           2   5  
       / \           / \           / \         / \   \ 
      4   9         4   9         3   5       1   3   9
                   /                   \                  
                  3                     9                 &lt;/code&gt;&lt;/pre&gt;

</code></pre><p>除了插入操作，还有更新和删除操作都会导致平衡树需要进行旋转。因此维护一棵平衡树是有一定开销的。</p>
<h1 id="b-tree">B+ Tree</h1>
<p>B+树是：</p>
<ul>
<li>一棵n叉树(m-ary)</li>
<li>记录节点按照键值大小顺序存放在同一层叶子节点上，各叶子节点指针进行连接</li>
</ul>
<h2 id="b-tree插入操作">B+ Tree插入操作</h2>
<ul>
<li>Leaf Page未满、Index Page未满时，直接将记录插入到叶子节点</li>
<li>Leaf Page满、Index Page未满时，拆分Leaf Page，将中间的节点（指的是Leaf Page几个节点的中间）放入到Index Page中，小于中间节点的记录放左边，大于中间节点的记录放右边</li>
<li>Leaf Page满、Index Page满时，拆分Leaf Page，小于中间节点的记录放左边，大于中间节点的记录放右边；拆分Index Page，原理同上，此时树的高度+1</li>
</ul>
<h2 id="b-tree删除操作">B+ Tree删除操作</h2>
<ul>
<li>Leaf Page大于填充因子、Index Page大于填充因子，直接删除，如果该节点是Index Page节点，用该节点的右节点代替</li>
<li>Leaf Page小于填充因子、Index Page大于填充因子，合并Leaf Page和它的兄弟节点，同时更新Index Page</li>
<li>Leaf Page小于填充因子、Index Page小于填充因子，合并Leaf Page和它的兄弟节点，更新Index Page，合并Index Page和它的兄弟节点</li>
</ul>
<h2 id="示例">示例</h2>
<p>一棵高度为2，扇出值为5的B+树：</p>
<p><img src="../2020/08/1.jpg" alt="">
插入键值<code>28</code>，Leaf Page和Index Page都没满，直接插入：</p>
<p><img src="../2020/08/2.jpg" alt="">
插入键值<code>70</code>发现Leaf Page已满，这时页的键为<code>[50, 55, 60, 65, 70]</code>，中间值为<code>60</code>，则根据<code>60</code>来<strong>拆分</strong>叶子节点，并且将<code>60</code>放入Index Page中：</p>
<p><img src="../2020/08/3.jpg" alt="">
插入键值<code>95</code>，此时Leaf Page和Index Page都已满，Leaf Page为<code>[75, 80, 85, 90, 95]</code>，按照<code>85</code>拆分，并将<code>85</code>放入Index Page；Index Page为<code>[25, 50, 60, 75, 85]</code>，按照<code>60</code>拆分，并将<code>60</code>放入新的Index Page：</p>
<p><img src="../2020/08/4.jpg" alt="">
Rotation操作，Leaf Page已满但是左右兄弟节点没有满的情况下，不急于做拆分页的操作，将记录移到所在页的兄弟节点上。插入键值<code>70</code>时因为左Leaf Page未满，进行Rotation，<code>50</code>被Rotate到左页，<code>55</code>被Rotate上Index Page：</p>
<p><img src="../2020/08/5.jpg" alt="">
删除键值<code>70</code>，删除后Fill Factor大于50%，直接删除：</p>
<p><img src="../2020/08/6.jpg" alt="">
删除键值<code>25</code>，直接删除，但是<code>25</code>还是Index Page中的值，因此要将右侧键值<code>28</code>更新到Index Page：</p>
<p><img src="../2020/08/7.jpg" alt="">
删除键值<code>60</code>，删除后Fill Factor小于50%，发生<strong>合并</strong>操作，所在Leaf Page与左侧合并，并且更新Index Page，树高度降低：</p>
<p><img src="../2020/08/8.jpg" alt=""></p>
<h1 id="b-tree索引">B+ Tree索引</h1>
<p>B+树索引是B+树中数据库中的实现，具有高扇出性(fanout)，通常扇出值在100以上。</p>
<p>B+树索引的节点在逻辑上是顺序存储的，但是在物理上因为分裂和合并的缘故，并不一定是连续的。从根节点开始向下查找每次都是随机IO。B+树因为高扇出性，高度一般在2-4层，也就是说从根节点开始查找到对应的叶子节点<strong>最多</strong>需要2-4次随机IO。又由于B+树索引的上层是常驻内存的，因此通常只需要更少次的随机IO即可定位到目标的叶子节点。</p>
<p>页是B+树索引磁盘管理的最小单位，在查询某行数据时，需要加载行所在的页到缓冲区再在页内Fetch目标行。</p>
<h2 id="b-tree索引的分裂">B+ Tree索引的分裂</h2>
<p>考虑以下情况，如果页内存储的键值为<code>[1, 2, 3, 4, 5, 6, 7, 8]</code>，如果新增键值<code>9</code>时页满需要发生分裂，按照之前介绍的分裂方法，取<code>5</code>为分裂点，页分裂成<code>[1, 2, 3, 4]</code>和<code>[5, 6, 7, 8, 9]</code>两个页。如果后续的写入操作均为顺序写入，那么页<code>[1, 2, 3, 4]</code>就会永远填充不满，剩余的页同理，因此会导致页空间的浪费。</p>
<p>所以，B+树索引的分裂并不总是从页的中间记录开始。在InnoDB引擎的Page Header中，有以下部分用来保存插入的顺序信息：</p>
<ul>
<li><code>PAGE_LAST_INSERT</code>，记录上一次写入位置的指针</li>
<li><code>PAGE_DIRECTION</code>， 值为<code>PAGE_LEFT</code>、<code>PAGE_RIGHT</code>和<code>PAGE_NO_DIRECTION</code>之一</li>
<li><code>PAGE_N_DIRECTION</code>，表示连续向同一方向插入的数量</li>
</ul>
<p>通过这些信息，InnoDB引擎可以决定要向左还是向右分裂，分裂点记录为哪一个：</p>
<ul>
<li>在随机插入的情况下，取页中间记录作为分裂点的记录</li>
<li>在定位到插入记录的位置后，如果已经向同一方向插入记录数量为5，并且当前位置后还有3条记录，则分裂点的记录定位到当前位置后到第三条记录，否则分裂点就是当前待插入的记录</li>
</ul>
<p>向右分裂的示例：</p>
<p><img src="../2020/08/9.jpg" alt=""></p>
<h2 id="b-tree索引的管理">B+ Tree索引的管理</h2>
<p>通过<code>show index</code>命令可以查看表的索引情况：</p>
<pre><code>mysql&gt; show index from a_real_secret_table_for_testing_000087\G
*************************** 1. row ***************************
        Table: a_real_secret_table_for_testing_000087         -- 索引所在表名
   Non_unique: 0                                              -- 是否唯一
     Key_name: PRIMARY                                        -- 索引名
 Seq_in_index: 1                                              -- 该列在索引中的顺序
  Column_name: id                                             -- 列名
    Collation: A                                              -- 列以什么方式存储在索引中，A：排序的
  Cardinality: 1637220                                        -- 索引中唯一值的数目的估计值
     Sub_part: NULL                                           -- 是否是列的部分被索引，如100即该列前100字符被索引
       Packed: NULL                                           -- 关键字如何被压缩
         Null:                                                -- 是否索引列含有NULL值
   Index_type: BTREE                                          -- 索引类型，InnoDB均为BTREE
      Comment:
Index_comment:&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="cardinality值">Cardinality值</h2>
<p>Cardinality值与表的行数比应该尽可能接近1，否则说明这个索引列选择性小，可能需要考虑是否删除此索引，例如在用户表中的性别等。</p>
<p>Cardinality值非常关键，优化器会根据这个值来判断是否使用这个索引。它代表索引中唯一值的数目的估计值，因此真实值在每次<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>操作时都会改变，InnoDB不可能在每次写操作时都更新该值，因为这样做代价太大了，所以Cardinality是一个估计值，如果需要更新Cardinality信息，可以使用<code>ANALYZE TABLE</code>命令。</p>
<p>在InnoDB中，更新Cardinality值的策略为：</p>
<ul>
<li>表中1/16的数据已经发生过变化</li>
<li>stat_modified_counter &gt; 2,000,000,000</li>
</ul>
<p>在满足更新条件的情况下，InnoDB通过采样的方法统计Cardinality值：</p>
<ul>
<li>取得B+树索引中叶子节点的数量，记为P</li>
<li>随机取所有叶子节点中的8（默认，<code>innodb_stats_sample_pages</code>配置）个叶子节点，统计每个页不同值的个数，记为N0, N1, … ,N7</li>
<li>Cardinality预估值 = (N0 + N1 + … + N7) / 8 * P</li>
</ul>
<p>因此，Cardinality不是一个精确值，同时，即使没有数据改动，每次统计得到的值也可能会不同。</p>
<h2 id="online-schema-change">Online Schema Change</h2>
<p>在MySQL 5.5版本前，对索引的增删改这类DDL操作，MySQL的操作过程为：</p>
<ul>
<li>创建一张新的临时表，表结构为<code>ALTER</code>命令定义的新结构</li>
<li>将原表数据导入临时表</li>
<li>删除原表</li>
<li>临时表重命名为原表</li>
</ul>
<p>这意味着在对大表的索引进行添加删除操作时会需要很长时间，并且服务会对其他事务不可用。</p>
<p>Facebook用PHP脚本实现OSC：</p>
<ul>
<li>init，验证表的主键、触发器、外键等是否满足</li>
<li>createCopyTable，创建和原始表结构一样的新表</li>
<li>alterCopyTable，对新表进行<code>ALTER</code>操作，如添加索引或列</li>
<li>createDeltasTable，创建<code>deltas</code>表</li>
<li>createTriggers，对原表创建<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>操作对触发器，触发操作产生的记录会被写到<code>deltas</code>表</li>
<li>startSnpshotXact，开始OSC操作的事务</li>
<li>seletTableIntoOutfile，将原表中的数据写入外部文件</li>
<li>dropNCIndexs，导入数据到新表前，删除新表中的所有辅助索引</li>
<li>loadCopyTable，将导出的文件导入到新表</li>
<li>replayChanges，将OSC过程中原表的DML操作（保存在<code>deltas</code>表）的记录应用到新表中</li>
<li>recreateNCIndexes，重新创建辅助索引</li>
<li>replayChanges，再次进行DML日志的回放操作，这些操作是在重建辅助索引时产生的</li>
<li>swapTables，原子的<code>RENAME</code>操作互换新旧表名</li>
</ul>
<h1 id="与页和b-tree相关的查询case">与页和B+ Tree相关的查询Case</h1>
<p>示例的查询会使用索引吗 / 会使用哪个索引 / 为什么？</p>
<pre><code>Table Schema
create table t (
  id int not null auto_increment comment &quot;unique id&quot;,
  a int not null default 0 comment &quot;column a&quot;,
  b varchar(255) not null default &quot;&quot; comment &quot;column b&quot;,
  c int not null default 0 comment &quot;column c&quot;,
  primary key (id),
  key idx_a(a),
  key idx_a_b(a, b)
) comment &quot;test table for index decision&quot;;

-- Table record count
mysql&gt; select count(*) from t;
+----------+
| count(*) |
+----------+
|   500000 |
+----------+
1 row in set (0.02 sec)

-- Table data sample
mysql&gt; select * from t limit 10;
+----+----------+--------------------------------------------------------------+----------+
| id | a        | b                                                            | c        |
+----+----------+--------------------------------------------------------------+----------+
|  1 | 74050441 |                                                              | 83633927 |
|  2 | 74330977 | JayiceJayiceJayiceJayiceJayiceJayiceJayiceJayiceJayiceJayice |  1986453 |
|  3 | 90869050 | JayiceJayiceJayice                                           | 13026881 |
|  4 |  6235189 | JayiceJayiceJayiceJayiceJayiceJayiceJayice                   |  6147585 |
|  5 | 29282553 | JayiceJayiceJayiceJayice                                     | 51497909 |
|  6 | 30223437 | JayiceJayiceJayice                                           | 28159699 |
|  7 | 37207514 |                                                              | 71102047 |
|  8 | 76961456 | JayiceJayiceJayiceJayiceJayiceJayice                         | 17116481 |
|  9 | 87737033 |                                                              | 70935248 |
| 10 | 67230439 | Jayice                                                       | 99513787 |
+----+----------+--------------------------------------------------------------+----------+
10 rows in set (0.01 sec)

-- Query
explain select * from t where a &gt; ???;
xplain select a from t where b &gt; ???;&lt;/code&gt;&lt;/pre&gt;
</code></pre>]]></content>
		</item>
		
		<item>
			<title>2019再见，Hello 2020</title>
			<link>https://jiekun.dev/posts/2020-04-12-2019%E5%86%8D%E8%A7%81hello-2020/</link>
			<pubDate>Sat, 11 Apr 2020 16:23:14 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-04-12-2019%E5%86%8D%E8%A7%81hello-2020/</guid>
			<description>“2019” 时间过得飞快，还有几个月就毕业满两年了，毫无疑问经历了非常充实的一段时间，现在回过头来看甚至觉得这段经历不属于自己。
时间回到2019年中，不知道处于什么原因，突然觉得要将落下的知识补一补，毕竟受限于学历和专业，不被看好是再正常不过的了。
虽然不确定未来会怎么样，但是还是尝试了一下，至少也要缩小一点差距。于是大概也是那时开始，周末坚持早起和中考高考考研的同学一起呆在图书馆，坚持借书买书看书。我本来以为自己很快就会偷懒，不过幸运的是所学所接触的内容似乎并没有让自己感到疲倦。一年时间很快就过了，现在我的书架长这个样子：
虽然有没有完整看完的书，不过也有经典的著作读了好几遍还意犹未尽，每次都有新的收获。将自己包的报纸书皮一个一个拆开有点舍不得，但是看到书还保护得这么新还是很开心的。
奇怪的书 所谓“奇怪”大概就是，为什么用不上的东西我一定要去看，当然这是以前的想法，现在我知道这些东西是真的非常宝贵。
脑筋急转弯 好吧其实这个东西比前面“奇怪的书”更加不明白什么时候才能用得上，但是搞起来之后反倒觉得非常、非常有意思。《算法导论》还在快递手里，只能下次再合影咯。
“2020” 再过半个月，就要离开广州，到深圳开始新的一段adventure了。在老东家加上实习足足有两年时间，收获特别多，一时间也不知道怎么描述。不过聊到技术以外的经历，印象特别深刻的大概是去年年末跟同事赌了1000块钱减重10斤，同事后来说转手就拿去花了，没想到还真的要还回来。
总之还是特别感谢老东家的支持和帮助，从来没有在这么好的团队呆过（好吧其实我也没有在别的团队呆过这么长的时间）。到4月末，我的2019年才算结束了，准备好迎接自己的2020，一定要继续加油。</description>
			<content type="html"><![CDATA[<h2 id="2019">“2019”</h2>
<p>时间过得飞快，还有几个月就毕业满两年了，毫无疑问经历了非常充实的一段时间，现在回过头来看甚至觉得这段经历不属于自己。</p>
<p>时间回到2019年中，不知道处于什么原因，突然觉得要将落下的知识补一补，毕竟受限于学历和专业，不被看好是再正常不过的了。</p>
<p>虽然不确定未来会怎么样，但是还是尝试了一下，至少也要缩小一点差距。于是大概也是那时开始，周末坚持早起和中考高考考研的同学一起呆在图书馆，坚持借书买书看书。我本来以为自己很快就会偷懒，不过幸运的是所学所接触的内容似乎并没有让自己感到疲倦。一年时间很快就过了，现在我的书架长这个样子：</p>
<p><img src="../2020/04/small-1024x657.jpg" alt="">
虽然有没有完整看完的书，不过也有经典的著作读了好几遍还意犹未尽，每次都有新的收获。将自己包的报纸书皮一个一个拆开有点舍不得，但是看到书还保护得这么新还是很开心的。</p>
<h2 id="奇怪的书">奇怪的书</h2>
<p>所谓“奇怪”大概就是，为什么用不上的东西我一定要去看，当然这是以前的想法，现在我知道这些东西是真的非常宝贵。</p>
<p><img src="../2020/04/system_s-1024x768.jpg" alt=""></p>
<h2 id="脑筋急转弯">脑筋急转弯</h2>
<p>好吧其实这个东西比前面“奇怪的书”更加不明白什么时候才能用得上，但是搞起来之后反倒觉得非常、非常有意思。《算法导论》还在快递手里，只能下次再合影咯。</p>
<p><img src="../2020/04/algorithm_s-1024x768.jpg" alt=""></p>
<h2 id="2020">“2020”</h2>
<p>再过半个月，就要离开广州，到深圳开始新的一段adventure了。在老东家加上实习足足有两年时间，收获特别多，一时间也不知道怎么描述。不过聊到技术以外的经历，印象特别深刻的大概是去年年末跟同事赌了1000块钱减重10斤，同事后来说转手就拿去花了，没想到还真的要还回来。</p>
<p>总之还是特别感谢老东家的支持和帮助，从来没有在这么好的团队呆过（好吧其实我也没有在别的团队呆过这么长的时间）。到4月末，我的2019年才算结束了，准备好迎接自己的2020，一定要继续加油。</p>
]]></content>
		</item>
		
		<item>
			<title>Shopee面试复盘</title>
			<link>https://jiekun.dev/posts/2020-03-28-shopee%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/</link>
			<pubDate>Sat, 28 Mar 2020 09:14:35 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-03-28-shopee%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/</guid>
			<description>背景 了解到Shopee最初是在其他dalao的面经、V2EX上。因为2月份字节跳动的面试失利，而且结合2020年年初整体环境的情况，所以打算做个100 Day Countdown复习再尝试的，不过综合考虑觉得金三银四的机会错过可能就没有了，最后在三月初的时候找dalao内推了Shopee的岗位。同期在考虑的还有网易和360的一些岗位，网易在广州的主要是游戏岗，技术栈上Match的程度会相对低一些，而且了解到部分目标岗位入职之后貌似是以Python为主，而我目前做的也是Python开发，但是更倾向于接触Go和Go的生态（云原生），这个也是优先考虑Shopee机会的原因之一。
面试 因为赶上春招，所以大概面试官们都比较忙，投递之后大约过了2周HR电话联系，约了一面时间。
一面（1小时17分钟） 一面我要求在了一个比较晚的时间，因为Shopee晚上是不面试的，所以定在了下午大概下班前一点的时候，然而没有想到一聊就聊了接近80分钟，结束的时候已经接近7点了。
 自我介绍 介绍基本的项目架构，问了Elasticsearch在项目中的用途 每日新增数据量*00w，不算少了，用MySQL怎么样做的？  看具体业务，例如新增这块是某些业务数据的快照，用作趋势图 新增数据多，分策略处理，按业务分区，定时归档到oss   除去归档之后数据还有多大？以什么样的方式检索？  除去归档之后的量级在千万级 虽然有千万，但是根据业务查询做Partition，每个tablespace不大，使用xx作为主键，查询也按照主键，速度可以接受   对Percona和它MySQL的分支了解多少？它改表的工具有看过吗？原理能说一下吗，改表过程中一致性如何保证？  Percona的工具一般都是运维在用，自己RSS了他们的博客，阅读和翻译感兴趣的文章 pt-osc，改表通过创建新表，复制旧表数据最后原子操作RENAME替换完成。（答得不在点子上，最重要的通过Trigger保障过程中的一致性没有提出来）   有做过分享过BloomFilter，分享的原理还是应用？  Both 概率型过滤器，业务上用做去重判定，有在团队里面推广，目前在新业务上准备尝试 Redis中使用Bitmap实现，对判断内容Hash置位，如果对应位置都已经置位过说明元素可能存在，反之必然不存在   用过Redis的哪些数据结构？redis-cell是什么？  除了基础的5种结构以外，还尝试过HyperLogLog，布隆过滤器，redis-cell，stream redis-cell是一个外挂模块，漏斗模型限流   有用过Redis的Cluster吗？了解原理吗？如果有节点挂了会怎么样？  业务使用Redis的部分数据量比较少所以用不上，自己有尝试过 基于槽分配，将集群划分成16384个槽，分配给不同节点，当所有槽分配完毕的时候集群上线 如果用官方工具创建类似典型的三主三从集群，主节点挂掉之后会自动有从节点顶上   用Redis不同的数据结构都实现过什么业务？  HyperLogLog，和BloomFilter相似，场景为概率型的计数，例如超大量的每日访问IP数（PV），代替set类型 ZSET，做过排行榜 String，做日常缓存   了解Redis HASH结构的实现吗？怎么保证查找的复杂度是O(1)？  底层是一个字典 Emmm…（场面一度尴尬，觉得很基础又一时说不上来，最后猜测是Hash之后通过内存地址查找所以是O(1)）不太了解    然后聊到这里附近的时候远程聊天网络原因断开了一下orz，多给了一点点思考的时间，虽然重连之后还是答得不太满意。
 有用过短域名服务吗，能说一下吗？  （简历上写了一个TinyURL系统架构设计的博客，不知道面试官是看到了所以对这方面感兴趣，还是这么凑巧他想问一个我设计过的架构） 方案：自增ID + Base62 细节：自增ID肯定是唯一的，问题在于如何保证在分布式系统中不同节点的自增ID没有重复，使用ZooKeeper提前对号段进行划分，应用节点自行获取和内部维护 比较：MD5、UUID、自增Base62，各有优势，使用HASH的方案需要考虑冲突问题，UUID太长   大访问量的情况下这个业务怎么设计？  短链有失效时间吗？（一天内访问非常频繁，后面急剧下降） 那将生成的数据放到Cache中设置1天TTL，Cache不存在回MySQL查（这里有遗漏的点没有答好，场景下会产生大量的短链长链对应关系，数据量级也需要考虑和处理，不可能无限增长下去，面试官提问的时候有强调到，但是回答之后貌似刚好也和我一样漏掉了XD）   如果要求长域名一样的时候对应短域名也一样怎么设计？  每次回表查关系，但是这样不理想 思路是判定的时候需要查询，那么就想办法降低查询次数，没出现过的URL肯定会对应新短链，那么结合BloomFilter判定是否曾经出现过，如果出现过再回表确认真的出现还是BloomFilter的误判   有试过BloomFilter数据量比较大的时候占用Redis空间有多少吗？  很低，但是不知道具体数字（这里是个超级大坑，一面没有深究，二面的时候被追问细节，然而当初是想一二面一起复盘所以orz）   业务已经很久，数据量大，需要做分表或者归档，会怎么做？  归档貌似不行，旧数据还是要可用 分表按照业务场景，查询是围绕短链ID，根据短链ID做hash分表而不是自增ID，这里视情况可能需要设计上用短链ID作为主键   用Python里面的数据结构实现一个有序集合，思路  （答得不是很好，问到了讲的几个思路的复杂度的计算，自己打个50分不及格） List + Dict（期望小于O(n)可以吗？） …（求求自己回去多看看数据结构） SkipList（真的不会，于是开始胡扯…）   写SQL：找出A表存在，B表不存在的id  写了一个NOT IN，强调性能不佳 补充一个LEFT JOIN WHERE IS NULL的方案 小表驱动大表   MySQL事务隔离级别？你们用的级别？可重复读是什么意思？  4个 可重复读 解释了一下Read Commited里面不可重复读的场景，可重复读解决了这种问题，但是会存在幻读问题;强调InnoDB中使用Next-Key Locking，在Repeatable Read中就已经解决了幻读问题，解释了一下Gap Lock和Record Lock   了解乐观锁与悲观锁吗？  描述了一下以及讲一下怎么使用乐观锁   了解InnoDB的索引实现？B+树和B树有什么区别？  B+树 高扇出性，层数少、叶子节点带指针、B+树数据全部在叶子节点，B树索引节点也存数据   SQL题：哪个SQL能用上全部索引 都是在用Python是吗？还会其他语言吗？  读书的时候写PHP，现在在学Go   对Python装饰器的理解？  （写了3行代码表达装饰器是对方法进行前置处理和后处理的夹心饼结构） -（更好的表达应该是强调将被装饰对象作为参数传递，因为它是First Class Object，同时执行前后进行额外的逻辑，最后返回）   写了一小段代码，问如何调用装饰器内部的定义的方法 写了一小段闭包的代码，问执行结果  答了一个错误的执行结果和正确的闭包概念 （我确认我是清晰理解了闭包的概念，但是思考的时候多操了一份心，又考虑了一些mutable object和immutable object的事情，结果就答错了结果，气坏了）   Python的functools和itertools有用过什么吗？Collections用到什么？  有用过，但是一时想不起来里面的方法/对象了，经常用Collections 用到defaultdict、OrderedDict、Counter等等   进程与线程 Python的多线程可以用到多核，一般多线程用来做什么，多线程多进程用的什么库？ 了解HTTPS加密过程吗？讲一下握手的过程 浏览器的缓存了解多少？自己建站静态文件会加缓存吗？ 编程题：Word Break和翻转二叉树 有什么问题想问吗？  对我的建议 技术分享 开源文化    一面结束之后过了几天接到HR电话，约了第二面的时间。</description>
			<content type="html"><![CDATA[<h1 id="背景">背景</h1>
<p>了解到Shopee最初是在其他dalao的面经、V2EX上。因为2月份字节跳动的面试失利，而且结合2020年年初整体环境的情况，所以打算做个100 Day Countdown复习再尝试的，不过综合考虑觉得金三银四的机会错过可能就没有了，最后在三月初的时候找dalao内推了Shopee的岗位。同期在考虑的还有网易和360的一些岗位，网易在广州的主要是游戏岗，技术栈上Match的程度会相对低一些，而且了解到部分目标岗位入职之后貌似是以Python为主，而我目前做的也是Python开发，但是更倾向于接触Go和Go的生态（云原生），这个也是优先考虑Shopee机会的原因之一。</p>
<h1 id="面试">面试</h1>
<p>因为赶上春招，所以大概面试官们都比较忙，投递之后大约过了2周HR电话联系，约了一面时间。</p>
<h2 id="一面1小时17分钟">一面（1小时17分钟）</h2>
<p>一面我要求在了一个比较晚的时间，因为Shopee晚上是不面试的，所以定在了下午大概下班前一点的时候，然而没有想到一聊就聊了接近80分钟，结束的时候已经接近7点了。</p>
<ul>
<li>自我介绍</li>
<li>介绍基本的项目架构，问了Elasticsearch在项目中的用途</li>
<li>每日新增数据量*00w，不算少了，用MySQL怎么样做的？
<ul>
<li>看具体业务，例如新增这块是某些业务数据的快照，用作趋势图</li>
<li>新增数据多，分策略处理，按业务分区，定时归档到oss</li>
</ul>
</li>
<li>除去归档之后数据还有多大？以什么样的方式检索？
<ul>
<li>除去归档之后的量级在千万级</li>
<li>虽然有千万，但是根据业务查询做Partition，每个tablespace不大，使用xx作为主键，查询也按照主键，速度可以接受</li>
</ul>
</li>
<li>对Percona和它MySQL的分支了解多少？它改表的工具有看过吗？原理能说一下吗，改表过程中一致性如何保证？
<ul>
<li>Percona的工具一般都是运维在用，自己RSS了他们的博客，阅读和翻译感兴趣的文章</li>
<li>pt-osc，改表通过创建新表，复制旧表数据最后原子操作<code>RENAME</code>替换完成。（答得不在点子上，最重要的通过Trigger保障过程中的一致性没有提出来）</li>
</ul>
</li>
<li>有做过分享过BloomFilter，分享的原理还是应用？
<ul>
<li>Both</li>
<li>概率型过滤器，业务上用做去重判定，有在团队里面推广，目前在新业务上准备尝试</li>
<li>Redis中使用Bitmap实现，对判断内容Hash置位，如果对应位置都已经置位过说明元素可能存在，反之必然不存在</li>
</ul>
</li>
<li>用过Redis的哪些数据结构？redis-cell是什么？
<ul>
<li>除了基础的5种结构以外，还尝试过HyperLogLog，布隆过滤器，redis-cell，stream</li>
<li>redis-cell是一个外挂模块，漏斗模型限流</li>
</ul>
</li>
<li>有用过Redis的Cluster吗？了解原理吗？如果有节点挂了会怎么样？
<ul>
<li>业务使用Redis的部分数据量比较少所以用不上，自己有尝试过</li>
<li>基于槽分配，将集群划分成16384个槽，分配给不同节点，当所有槽分配完毕的时候集群上线</li>
<li>如果用官方工具创建类似典型的三主三从集群，主节点挂掉之后会自动有从节点顶上</li>
</ul>
</li>
<li>用Redis不同的数据结构都实现过什么业务？
<ul>
<li>HyperLogLog，和BloomFilter相似，场景为概率型的计数，例如超大量的每日访问IP数（PV），代替set类型</li>
<li>ZSET，做过排行榜</li>
<li>String，做日常缓存</li>
</ul>
</li>
<li>了解Redis HASH结构的实现吗？怎么保证查找的复杂度是O(1)？
<ul>
<li>底层是一个字典</li>
<li>Emmm…（场面一度尴尬，觉得很基础又一时说不上来，最后猜测是Hash之后通过内存地址查找所以是O(1)）不太了解</li>
</ul>
</li>
</ul>
<p>然后聊到这里附近的时候远程聊天网络原因断开了一下orz，多给了一点点思考的时间，虽然重连之后还是答得不太满意。</p>
<ul>
<li>有用过短域名服务吗，能说一下吗？
<ul>
<li>（简历上写了一个TinyURL系统架构设计的博客，不知道面试官是看到了所以对这方面感兴趣，还是这么凑巧他想问一个我设计过的架构）</li>
<li>方案：自增ID + Base62</li>
<li>细节：自增ID肯定是唯一的，问题在于如何保证在分布式系统中不同节点的自增ID没有重复，使用ZooKeeper提前对号段进行划分，应用节点自行获取和内部维护</li>
<li>比较：MD5、UUID、自增Base62，各有优势，使用HASH的方案需要考虑冲突问题，UUID太长</li>
</ul>
</li>
<li>大访问量的情况下这个业务怎么设计？
<ul>
<li>短链有失效时间吗？（一天内访问非常频繁，后面急剧下降）</li>
<li>那将生成的数据放到Cache中设置1天TTL，Cache不存在回MySQL查（这里有遗漏的点没有答好，场景下会产生大量的短链长链对应关系，数据量级也需要考虑和处理，不可能无限增长下去，面试官提问的时候有强调到，但是回答之后貌似刚好也和我一样漏掉了XD）</li>
</ul>
</li>
<li>如果要求长域名一样的时候对应短域名也一样怎么设计？
<ul>
<li>每次回表查关系，但是这样不理想</li>
<li>思路是判定的时候需要查询，那么就想办法降低查询次数，没出现过的URL肯定会对应新短链，那么结合BloomFilter判定是否曾经出现过，如果出现过再回表确认真的出现还是BloomFilter的误判</li>
</ul>
</li>
<li>有试过BloomFilter数据量比较大的时候占用Redis空间有多少吗？
<ul>
<li>很低，但是不知道具体数字（这里是个超级大坑，一面没有深究，二面的时候被追问细节，然而当初是想一二面一起复盘所以orz）</li>
</ul>
</li>
<li>业务已经很久，数据量大，需要做分表或者归档，会怎么做？
<ul>
<li>归档貌似不行，旧数据还是要可用</li>
<li>分表按照业务场景，查询是围绕短链ID，根据短链ID做hash分表而不是自增ID，这里视情况可能需要设计上用短链ID作为主键</li>
</ul>
</li>
<li>用Python里面的数据结构实现一个有序集合，思路
<ul>
<li>（答得不是很好，问到了讲的几个思路的复杂度的计算，自己打个50分不及格）</li>
<li>List + Dict（期望小于O(n)可以吗？）</li>
<li>…（求求自己回去多看看数据结构）</li>
<li>SkipList（真的不会，于是开始胡扯…）</li>
</ul>
</li>
<li>写SQL：找出A表存在，B表不存在的id
<ul>
<li>写了一个<code>NOT IN</code>，强调性能不佳</li>
<li>补充一个<code>LEFT JOIN WHERE IS NULL</code>的方案</li>
<li>小表驱动大表</li>
</ul>
</li>
<li>MySQL事务隔离级别？你们用的级别？可重复读是什么意思？
<ul>
<li>4个</li>
<li>可重复读</li>
<li>解释了一下Read Commited里面不可重复读的场景，可重复读解决了这种问题，但是会存在幻读问题;强调InnoDB中使用Next-Key Locking，在Repeatable Read中就已经解决了幻读问题，解释了一下Gap Lock和Record Lock</li>
</ul>
</li>
<li>了解乐观锁与悲观锁吗？
<ul>
<li>描述了一下以及讲一下怎么使用乐观锁</li>
</ul>
</li>
<li>了解InnoDB的索引实现？B+树和B树有什么区别？
<ul>
<li>B+树</li>
<li>高扇出性，层数少、叶子节点带指针、B+树数据全部在叶子节点，B树索引节点也存数据</li>
</ul>
</li>
<li>SQL题：哪个SQL能用上全部索引</li>
<li>都是在用Python是吗？还会其他语言吗？
<ul>
<li>读书的时候写PHP，现在在学Go</li>
</ul>
</li>
<li>对Python装饰器的理解？
<ul>
<li>（写了3行代码表达装饰器是对方法进行前置处理和后处理的夹心饼结构）</li>
<li>-（更好的表达应该是强调将被装饰对象作为参数传递，因为它是First Class Object，同时执行前后进行额外的逻辑，最后返回）</li>
</ul>
</li>
<li>写了一小段代码，问如何调用装饰器内部的定义的方法</li>
<li>写了一小段闭包的代码，问执行结果
<ul>
<li>答了一个错误的执行结果和正确的闭包概念</li>
<li>（我确认我是清晰理解了闭包的概念，但是思考的时候多操了一份心，又考虑了一些mutable object和immutable object的事情，结果就答错了结果，气坏了）</li>
</ul>
</li>
<li>Python的functools和itertools有用过什么吗？Collections用到什么？
<ul>
<li>有用过，但是一时想不起来里面的方法/对象了，经常用Collections</li>
<li>用到defaultdict、OrderedDict、Counter等等</li>
</ul>
</li>
<li>进程与线程</li>
<li>Python的多线程可以用到多核，一般多线程用来做什么，多线程多进程用的什么库？</li>
<li>了解HTTPS加密过程吗？讲一下握手的过程</li>
<li>浏览器的缓存了解多少？自己建站静态文件会加缓存吗？</li>
<li>编程题：Word Break和翻转二叉树</li>
<li>有什么问题想问吗？
<ul>
<li>对我的建议</li>
<li>技术分享</li>
<li>开源文化</li>
</ul>
</li>
</ul>
<p>一面结束之后过了几天接到HR电话，约了第二面的时间。</p>
<h2 id="二面45分钟">二面（45分钟）</h2>
<p>二面是部门负责人面，问的问题相对少一些，但是抓的细节比较多，因为自己准备的方向（有一些知识点没有太细致的见解，因为不是科班背景，所以花了很多时间拓宽知识储备的广度，相对而言深度就只针对特定方向做了准备）没有在对应的点上，所以答得稀烂。</p>
<ul>
<li>自我介绍</li>
<li>介绍基本的业务</li>
<li>数据存储用的是什么？</li>
<li>项目主要的难点是什么？快照是怎么做的，增量还是全量？全部数据（指的是动态和静态数据）都做快照吗？</li>
<li>这些表都有多大？</li>
<li>讲解一些表的设计的结构，字段类型</li>
</ul>
<p>这里面试官对我描述的表的数据行数和体积有一些疑问，于是花了一点时间探讨，按照要求对描述的表进行了数据量的计算，最后得出来的结果和我提出的体积有比较大的差异。主要体现出来平时对业务数据量的预估和设计经验不够丰富，缺乏细致和准确性。面试的时候如果这些内容和对方经验值出入比较大被质疑，不可避免会拉低面试官的评价结果。然后引起了面试官一连串的疑问，包括像如果数据量没有描述的这么大，为什么要做分区？惭愧orz</p>
<ul>
<li>为了优化性能的话，是要控制表的大小还是控制表的行数？</li>
<li>Redis能够讲一下吗？</li>
<li>大概讲一下BloomFilter？</li>
<li>BloomFilter的错误率有多少？（从这里开始后面就一直爆炸了）
<ul>
<li>可以自己配置，受Bitmap长度和Hash函数影响</li>
</ul>
</li>
<li>具体会有多大？比如要让错误率在1/10000以下？</li>
<li>具体和长度什么关系？和Hash函数个个数关系？</li>
<li>Hash函数一般选择用多少个？
<ul>
<li>（Orz这里我的理解和面试官的理解有所出入，我理解的模型是通过一个Hash函数计算出3个Bitmap需要置位的位置，而面试官认为的应该是通过3个不同的Hash函数计算出3个需要置位的位置，实际上都一样是需要计算3个置位的位置）</li>
</ul>
</li>
<li>一段递归代码，讲输出的结果
<ul>
<li>写了正确的递归表达式，但是计算复杂度没有出结果</li>
</ul>
</li>
<li>递推式是正确的，时间复杂度？我们学算法的时候时间复杂度是怎么算的？
<ul>
<li>（非常惭愧没有掌握计算过程，噗甩锅跨专业，一定好好补充这块的知识）</li>
</ul>
</li>
</ul>
<p>二面技术问题基本就到这里结束了，大约30分钟，毫无疑问时间太短是个Bad Smell，可能意味着面试官已经认为不符合要求，打算结束。</p>
<p>面试全程都在“答不上来”和“不了解”之间切换，然后就到了跟面试官聊人生聊理想的环节，主要关注出来看工作机会的目的和考虑之类的问题。最后也解答了一下我的问题，问到面试官对我的建议，那么当然就是反复强调的细节了，技术细节需要更深入了解，惭愧。</p>
<p>挂掉二面通话之后感觉非常糟糕，很多问题看似简单（orz实际上真的不难）没有答得对甚至就没有能答出来，需要继续加油。</p>
<p>二面结束几个小时之后接到了HR的电话，约了聊人生的时间。</p>
<h2 id="hr面30分钟">HR面（30分钟）</h2>
<p>二面和HR面都是在同一天的，有点意外因为二面的表现实在是太糟糕了，不过也可能是因为需要综合评定，所以还有后续的流程要走完。HR面也是常规的一些问题提出来要了解，以及解答疑问，就不再详细描述了。</p>
<h1 id="总结">总结</h1>
<p>整体来说考核的难度都比较正常，不过二面里面业务的掌握程度还是有所欠缺，一面里面的一些场景设计大概也不是特别理想。所以遵从面试官的建议，需要细抠技术细节，希望能够保持学习和成长。</p>
<p>面试感受：Pending有点久，大概是因为赶上毕业的同学们春招。<br>
面试难度：正常，基础和业务结合。</p>
<p>最后许愿结果满意XD</p>
]]></content>
		</item>
		
		<item>
			<title>Redis 6.0 ACL基于Bitmap实现</title>
			<link>https://jiekun.dev/posts/2020-03-14-redis-6-0-acl%E5%9F%BA%E4%BA%8Ebitmap%E5%AE%9E%E7%8E%B0/</link>
			<pubDate>Sat, 14 Mar 2020 14:00:46 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-03-14-redis-6-0-acl%E5%9F%BA%E4%BA%8Ebitmap%E5%AE%9E%E7%8E%B0/</guid>
			<description>Redis 6.0在4月30日就要和大家正式见面了，现在redis.io上已经提供了RC版本。在之前的博客中，已经介绍过权限控制新功能的一些用法，主要来源于作者Antirez在Redis Day上的一些演示。Antirez在最后提到，ACL的主要实现是基于Bitmap，因此对性能影响是可以忽略不计的。当时大致猜想了一下实现的思路，那么现在离发布已经很近了，作者也对ACL Logging进行了一些补充，不妨一起来看一下。
user结构 server.h中定义了对应的user结构保存用户的ACL信息，包括：
 用户名 flag，主要是一些特殊状态，例如用户的启用与禁用、整体控制（所有命令可用与否、所有键可访问与否）、免密码等 可用命令（allowed_commands），一个长整型数。每一位代表命令，如果用户允许使用这个命令则置位1 可用子命令（allowed_subcommands），一个指针数组，值也为指针，数组与可用命令一一对应，值为一个SDS数组，SDS数组中存放的是这个命令可用的子命令 用户密码 可用的key patterns。如果这个字段为NULL，用户将不能使用任何Key，除非flag中指明特殊状态如ALLKEYS  typedef struct user { sds name; uint64_t flags; uint64_t allowed_commands[USER_COMMAND_BITS_COUNT/64]; sds **allowed_subcommands; list *passwords; list *patterns; } user;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 补充一下一些新鲜的字段描述，allowed_commands实际上是一个（默认）长度为1024的位图，它的index对应各个命令的ID，在历史版本中命令结构redisCommand是通过名字（name）来查找的，id为这个版本中新增的属性，专门用于ACL功能。
truct redisCommand { ... int id; };&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; user这个结构对应的是client结构的”user”字段，熟悉Redis的同学应该对client也有所了解，就不再赘述了。
ACL操作选读 ACL的命令很多，总体而言都是围绕着user对象展开的，因此从中挑选了几个函数来看一下具体是如何操作user对象。
一个需要铺垫的通用方法就是ACLGetUserCommandBit，ACL操作中都会涉及到获取用户的命令位图，ACLGetUserCommandBit()接收一个user结构和命令ID，根据ID定位出命令在allowed_commands中的位置，通过位运算返回用户是否有该命令权限。
int ACLGetUserCommandBit(user *u, unsigned long id) { uint64_t word, bit; if (ACLGetCommandBitCoordinates(id,&amp;amp;word,&amp;amp;bit) == C_ERR) return 0; return (u-&amp;gt;allowed_commands[word] &amp;amp; bit) != 0; }&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 当用户进行Redis操作时，例如set操作，操作的命令会保存在client结构的*cmd字段中，*cmd字段就是一个redisCommand结构的指针，redisCommand结构包含了命令的id，因此在使用时通过ACLGetUserCommandBit(u, cmd-&amp;gt;id)传入。</description>
			<content type="html"><![CDATA[<p>Redis 6.0在4月30日就要和大家正式见面了，现在<a href="https://redis.io">redis.io</a>上已经提供了RC版本。在<a href="https://bytedance-hire.me/archives/235">之前的博客</a>中，已经介绍过权限控制新功能的一些用法，主要来源于作者Antirez在Redis Day上的一些演示。Antirez在最后提到，ACL的主要实现是基于Bitmap，因此对性能影响是可以忽略不计的。当时大致猜想了一下实现的思路，那么现在离发布已经很近了，作者也对ACL Logging进行了一些补充，不妨一起来看一下。</p>
<h1 id="user结构">user结构</h1>
<p>server.h中定义了对应的<code>user</code>结构保存用户的ACL信息，包括：</p>
<ul>
<li>用户名</li>
<li>flag，主要是一些特殊状态，例如用户的启用与禁用、整体控制（所有命令可用与否、所有键可访问与否）、免密码等</li>
<li>可用命令（allowed_commands），一个长整型数。每一位代表命令，如果用户允许使用这个命令则置位1</li>
<li>可用子命令（allowed_subcommands），一个指针数组，值也为指针，数组与可用命令一一对应，值为一个SDS数组，SDS数组中存放的是这个命令可用的子命令</li>
<li>用户密码</li>
<li>可用的key patterns。如果这个字段为<code>NULL</code>，用户将不能使用任何Key，除非flag中指明特殊状态如<code>ALLKEYS</code></li>
</ul>
<pre><code>typedef struct user {
    sds name;
    uint64_t flags;
    uint64_t allowed_commands[USER_COMMAND_BITS_COUNT/64];
    sds **allowed_subcommands;
    list *passwords;
    list *patterns;
} user;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>补充一下一些新鲜的字段描述，<code>allowed_commands</code>实际上是一个（默认）长度为1024的位图，它的index对应各个命令的ID，在历史版本中命令结构<code>redisCommand</code>是通过名字（<code>name</code>）来查找的，<code>id</code>为这个版本中新增的属性，专门用于ACL功能。</p>
<pre><code>truct redisCommand {
    ...
    int id;
};&lt;/code&gt;&lt;/pre&gt;

</code></pre><p><code>user</code>这个结构对应的是<code>client</code>结构的”user”字段，熟悉Redis的同学应该对<code>client</code>也有所了解，就不再赘述了。</p>
<h1 id="acl操作选读">ACL操作选读</h1>
<p>ACL的命令很多，总体而言都是围绕着<code>user</code>对象展开的，因此从中挑选了几个函数来看一下具体是如何操作<code>user</code>对象。</p>
<p>一个需要铺垫的通用方法就是<code>ACLGetUserCommandBit</code>，ACL操作中都会涉及到获取用户的命令位图，<code>ACLGetUserCommandBit()</code>接收一个<code>user</code>结构和命令ID，根据ID定位出命令在<code>allowed_commands</code>中的位置，通过位运算返回<strong>用户是否有该命令权限</strong>。</p>
<pre><code>int ACLGetUserCommandBit(user *u, unsigned long id) {
    uint64_t word, bit;
    if (ACLGetCommandBitCoordinates(id,&amp;word,&amp;bit) == C_ERR) return 0;
    return (u-&gt;allowed_commands[word] &amp; bit) != 0;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>当用户进行Redis操作时，例如<code>set</code>操作，操作的命令会保存在<code>client</code>结构的<code>*cmd</code>字段中，<code>*cmd</code>字段就是一个<code>redisCommand</code>结构的指针，<code>redisCommand</code>结构包含了命令的<code>id</code>，因此在使用时通过<code>ACLGetUserCommandBit(u, cmd-&gt;id)</code>传入。</p>
<h2 id="创建用户">创建用户</h2>
<p>创建用户分为两步，首先需要创建一个<code>user</code>，通过调用<code>ACLCreateUser(const char *name, size_t namelen)</code>实现，返回的是一个<code>user</code>对象的指针。在创建时，会在<code>server.h</code>定义的<code>Users</code>中查找是否有同名用户，也是本次功能新增的，因为旧版本中只有”default”用户。此时这个用户拥有名称，flag被初始化为禁用用户，其余的属性均为Null或空list等。</p>
<p>然后，通过调用<code>ACLSetUser(user *u, const char *op, ssize_t oplen)</code>，调整传入用户<code>u</code>的对应属性，调整内容放在名为<code>op</code>操作的参数中。这个函数非常长，主要是针对各种不同的“操作” switch case处理，节选部分如下：</p>
<pre><code>int ACLSetUser(user *u, const char *op, ssize_t oplen) {
    if (oplen == -1) oplen = strlen(op);
    /* Part1 - 处理用户状态(flag)操作 */
    // 控制用户启用状态
    if (!strcasecmp(op,&quot;on&quot;)) {
        u-&gt;flags |= USER_FLAG_ENABLED;
        u-&gt;flags &amp;= ~USER_FLAG_DISABLED;
    } else if (!strcasecmp(op,&quot;off&quot;)) {
        u-&gt;flags |= USER_FLAG_DISABLED;
        u-&gt;flags &amp;= ~USER_FLAG_ENABLED;
    // 控制全局键、命令等可用与否
    } else if (!strcasecmp(op,&quot;allkeys&quot;) ||
               !strcasecmp(op,&quot;~*&quot;))
    {
        u-&gt;flags |= USER_FLAG_ALLKEYS;
        listEmpty(u-&gt;patterns);
    }
    ...


    /* Part2 - 操作用户密码增删改查 */
    // &gt; 和 &amp;lt; 等控制密码的改动删除等
    else if (op[0] == '&gt;' || op[0] == '#') {
        sds newpass;
        if (op[0] == '&gt;') {
            newpass = ACLHashPassword((unsigned char*)op+1,oplen-1);
        }


    /* Part3 - 操作用户可用命令的范围 */
    else if (op[0] == '+' &amp;&amp; op[1] != '@') {
        if (strchr(op,'|') == NULL) {
            if (ACLLookupCommand(op+1) == NULL) {
                errno = ENOENT;
                return C_ERR;
            }
            unsigned long id = ACLGetCommandID(op+1);
            // 根据传入的id参数设置对应allowed_commands位图的值
            ACLSetUserCommandBit(u,id,1);
            // 新调整的命令的子命令数组会被重置
            ACLResetSubcommandsForCommand(u,id);
        }
    }&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>补充一下具体调用例子，其实Redis的默认用户就是按照这套流程创建的：初始化名为“default”的空白无权限用户，然后为这个用户设置上所有权限：</p>
<pre><code>DefaultUser = ACLCreateUser(&quot;default&quot;,7);
ACLSetUser(DefaultUser,&quot;+@all&quot;,-1);
ACLSetUser(DefaultUser,&quot;~*&quot;,-1);
ACLSetUser(DefaultUser,&quot;on&quot;,-1);
ACLSetUser(DefaultUser,&quot;nopass&quot;,-1);&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="拦截不可用命令键">拦截不可用命令/键</h2>
<p>命令/键拦截操作非常简单：</p>
<ul>
<li>判断命令/键是否可用
<ul>
<li>如果不可用，ACL Log处理以及返回错误</li>
</ul>
</li>
</ul>
<h3 id="acl判断">ACL判断</h3>
<p>我们先看一下“不可用”的判断逻辑，然后再回到命令执行流程中看判断方法的调用。</p>
<p>判断函数同样非常长，展示完后会进行总结：</p>
<pre><code>int ACLCheckCommandPerm(client *c, int *keyidxptr) {
    user *u = c-&gt;user;
    uint64_t id = c-&gt;cmd-&gt;id;
    // 命令相关的全局flag的检查，若满足则跳过后续部分
    if (!(u-&gt;flags &amp; USER_FLAG_ALLCOMMANDS) &amp;&amp;
        c-&gt;cmd-&gt;proc != authCommand)
    {
        // 即使当前命令没有在allowed_commands中，还要检查子命令是否可用
        // 以免出现仅开放了部分子命令权限的情况
        if (ACLGetUserCommandBit(u,id) == 0) {
            ...
            // 遍历子命令
            long subid = 0;
            while (1) {
                if (u-&gt;allowed_subcommands[id][subid] == NULL)
                    return ACL_DENIED_CMD;
                if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,
                                u-&gt;allowed_subcommands[id][subid]))
                    break; // 子命令可用，跳出循环
                subid++;
            }
        }
    }

    // 键相关的全局flag检查，若满足则跳过后续部分
    if (!(c-&gt;user-&gt;flags &amp; USER_FLAG_ALLKEYS) &amp;&amp;
        (c-&gt;cmd-&gt;getkeys_proc || c-&gt;cmd-&gt;firstkey))
    {
        int numkeys;
        // 先拿到当前要进行操作的Key
        int *keyidx = getKeysFromCommand(c-&gt;cmd,c-&gt;argv,c-&gt;argc,&amp;numkeys);
        for (int j = 0; j &amp;lt; numkeys; j++) {
            listIter li;
            listNode *ln;
            listRewind(u-&gt;patterns,&amp;li);

            // 检查当前user所有的关于Key的匹配Pattern
            // 如果有任意命中则跳出，否则判定不可用
            int match = 0;
            while((ln = listNext(&amp;li))) {
                sds pattern = listNodeValue(ln);
                size_t plen = sdslen(pattern);
                int idx = keyidx[j];
                if (stringmatchlen(pattern,plen,c-&gt;argv[idx]-&gt;ptr,
                                   sdslen(c-&gt;argv[idx]-&gt;ptr),0))
                {
                    match = 1;
                    break;
                }
            }
            if (!match) {
                if (keyidxptr) *keyidxptr = keyidx[j];
                getKeysFreeResult(keyidx);
                return ACL_DENIED_KEY;
            }
        }
        getKeysFreeResult(keyidx);
    }
    return ACL_OK;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>那么为了方便喜欢跳过代码的同学看结论：</p>
<ul>
<li>ACL限制围绕<code>user</code>的各个字段进行</li>
<li>全局的flag优先级最高，例如设置为所有键可用，所有命令可用，会跳过后续的可用命令遍历和可用键Pattern匹配</li>
<li>即使在allowed_commands位图中没有被置位，命令也可能可用，因为它是个子命令，而且命令只开放了部分子命令的使用权限</li>
<li>键通过遍历所有定义了的Pattern检查，如果有匹配上说明可用</li>
<li>先判断操作是否可用，再判断键（包括全局flag也在操作之后）是否可用，两种判断分别对应不同返回整数值：<code>ACL_DENIED_CMD</code>、<code>ACL_DENIED_KEY</code></li>
</ul>
<h3 id="命令执行流程中的调用">命令执行流程中的调用</h3>
<p>判断逻辑之后到何时调用这套判断。我们先来复习一下Redis如何执行命令：</p>
<ul>
<li>用户操作</li>
<li>客户端RESP协议（Redis 6.0中有RESP3新协议记得关注）压缩发送给服务端</li>
<li>服务端解读消息，存放至<code>client</code>对象的对应字段中，例如<code>argc</code>、<code>argv</code>等存放命令和参数等内容</li>
<li><strong>执行前检查（各种执行条件）</strong></li>
<li>执行命令</li>
<li><strong>执行后处理（慢查询日志、AOF等）</strong></li>
</ul>
<p>目前执行命令的方法是在<code>server.c</code>中的<code>processCommand(client *c)</code>，传入<code>client</code>对象，执行，返回执行成功与否。我们节选其中关于ACL的部分如下：</p>
<pre><code>int processCommand(client *c) {
    ...
    int acl_keypos;
    int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
    if (acl_retval != ACL_OK) {
        addACLLogEntry(c,acl_retval,acl_keypos,NULL);
        flagTransaction(c);
        if (acl_retval == ACL_DENIED_CMD)
            addReplyErrorFormat(c,
                &quot;-NOPERM this user has no permissions to run &quot;
                &quot;the '%s' command or its subcommand&quot;, c-&gt;cmd-&gt;name);
        else
            addReplyErrorFormat(c,
                &quot;-NOPERM this user has no permissions to access &quot;
                &quot;one of the keys used as arguments&quot;);
        return C_OK;
    }
    ...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在命令解析之后，真正执行之前，通过调用<code>ACLCheckCommandPerm</code>获取判断结果，如果判定不通过，进行以下操作：</p>
<ul>
<li>记录ACL不通过的日志，这个是作者在RC1之后新增的功能，还在Twitch上进行了直播开发，有兴趣的同学可以在Youtube上看到录播</li>
<li>如果当前处于事务（MULTI）过程中，将client的<code>flag</code>置为<code>CLIENT_DIRTY_EXEC</code></li>
<li>根据命令还是键不可用，返回给客户端不同的信息</li>
</ul>
<p>因此这次ACL功能影响的是执行命令前后的操作。</p>
<h3 id="其他功能对acl的调用">其他功能对ACL的调用</h3>
<p>通过搜索可以发现一共有3处调用了<code>ACLCheckCommandPerm</code>方法：</p>
<pre><code>/home/duck/study/redis/src/multi.c:
  179  
  180          int acl_keypos;
  181:         int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
  182          if (acl_retval != ACL_OK) {
  183              addACLLogEntry(c,acl_retval,acl_keypos,NULL);

/home/duck/study/redis/src/scripting.c:
  608      /* Check the ACLs. */
  609      int acl_keypos;
  610:     int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
  611      if (acl_retval != ACL_OK) {
  612          addACLLogEntry(c,acl_retval,acl_keypos,NULL);

/home/duck/study/redis/src/server.c:
 3394       * ACLs. */
 3395      int acl_keypos;
 3396:     int acl_retval = ACLCheckCommandPerm(c,&amp;acl_keypos);
 3397      if (acl_retval != ACL_OK) {
 3398          addACLLogEntry(c,acl_retval,acl_keypos,NULL);&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>形式都是大同小异，了解一下即可。总结一下需要判定ACL的位置：</p>
<ul>
<li>正常命令执行流程中</li>
<li>MULTI事务执行过程中</li>
<li>Lua脚本</li>
</ul>
<h1 id="总结">总结</h1>
<p>补充一张图来描述新增的ACL功能相关的结构（点击放大查看）：</p>
<p><img src="%22./2020/03/Redis_ACL_user-1024x535.png" alt=""></p>
<p>图中部分的表达可能与实际的数据结构有所差异，主要原因是代码理解和C语言的语法掌握不到位所致。</p>
<p>阅读代码的过程中留意到，对命令的限制是通过Bitmap来实现的，而对Key的限制是通过特定Pattern来实现的。当对Key的限制Pattern数量特别多时，是否会因为匹配Pattern而对性能造成影响，例如超多次的<code>stringmatchlen()</code>执行。当然这一块内容似乎确实没有想到什么提升非常大的判断方式，后续也会继续关注ACL的相关改进。</p>
]]></content>
		</item>
		
		<item>
			<title>Elasticsearch节点选举、分片及Recovery</title>
			<link>https://jiekun.dev/posts/2020-03-14-elasticsearch%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE%E5%88%86%E7%89%87%E5%8F%8Arecovery/</link>
			<pubDate>Sat, 14 Mar 2020 07:58:10 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-03-14-elasticsearch%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE%E5%88%86%E7%89%87%E5%8F%8Arecovery/</guid>
			<description>隔了挺长一段时间没有更新，主要是因为近段时间忙于业务和刷题，想来刷题除了Po题解和Explanation也是没有什么特别之处，除非钻研得特别深入，所以（@#$%^&amp;amp;找理由）。
关于Elasticsearch Elasticsearch其实官网的文档特别齐全，所以关于用法没有什么特别好写的，看博客不如RTFM。但是文档特别全的情况下，很多时候又缺少对一些具体细节的描述，一句话说就是不知其所以然。所以今天写的博客内容理应是无关使用的，不涉及命令与操作，大概会更有意义一些吧。
概述 以Elasticsearch（下称ES）集群启动过程作为索引来展开，ES想要从Red转为Green，需要经历以下过程：
 主节点选举。集群启动需要从已知的活跃机器中选取主节点，因为这是PacificA算法的思想——主从模式，使用Master节点管理元信息，数据则去中心化。这块使用类似Bully的算法。 元信息选举。主节点确认后，需要从各节点的元信息中获取最新版本的元信息。由Gateway模块负责。 主副分片选举。由Allocation模块负责，各分片的多个副本中选出主分片和副分片，记录他们所属的节点，重构内容路由表。 恢复分片数据。因为启动可能包含之前没有来得及刷盘的数据，副分片也可能落后于新选出的主分片。  Bully算法与主节点选举 Bully算法 特地查了一下Bully的意思——“仗势欺人者，横行霸道者”，所以这个霸道选举算法如其名，简单暴力地通过选出ID最大的候选者来完成。在Bully算法中有几点假设：
 系统是处于同步状态的 进程任何时间都可能失效，包括在算法执行过程中 进程失败则停止，并通过重新启动来恢复 有能够进行失败检测的机制 进程间的消息传递是可靠的 每个进程知道自己的ID和地址，以及其他所有的进程ID和地址  它的选举通过以下几类消息：
 选举消息：用来声明一次选举 响应消息：响应选举消息 协调消息：胜利者向参与者发送胜利声明  设想以下场景，集群中存在ID为1、2、3的节点，通过Bully算法选举出了3为主节点，此时之前因为网络分区无法联系上的4节点加入，通过Bully算法成了新的主节点，后续失联的5节点加入，同样成为新主节点。这种不稳定的状态在ES中通过优化选举发起的条件来解决，当主节点确定后，在失效前不进行新一轮的选举。另外其他分布式应用一样，ES通过Quorum来解决脑裂的问题。
Elasticsearch主节点选举 ES的选举与Bully算法有所出入，它选举的是ID最小的节点，当然这并没有太大影响。另外目前版本中ES的排序影响因素还有集群状态，对应一个状态版本号，排序中会优先将版本号高的节点放在最前。
在选举过程中有几个概念：
 临时Master节点：某个节点认可的Master节点 activeMasters列表：不同节点了解到的其他节点范围可能不一样，因此他们可能各自认可不同的Master节点，这些临时Master节点的集合称为activeMasters列表 masterCanditates列表：所有满足Master资格（一般不满足例原因如配置了某些节点不能作为主节点）的节点列表 正式Master节点：票数足够时临时Master节点确立为真正Master节点  某个节点ping所有节点，获取一份节点列表，并将自己加入其中。通过这份列表查看当前活跃的Master列表，也就是每个节点认为当前的Master节点，加入activeMasters列表中。同样，通过过滤原始列表中不符合Master资格的节点，形成masterCandidates列表。
如果activeMasters列表不为空，按照ES的（近似）Bully算法选举自己认为的Master节点；如果activeMasters列表空，从masterCandidates列表中选举，但是此时需要判断当前候选人数是否达到Quorum。ES使用具体的比较Master的逻辑如下：
/** * compares two candidates to indicate which the a better master. * A higher cluster state version is better * 比较两个候选节点以得出更适合作为Master的节点。 * 优先以集群状态版本作为排序 * * @return -1 if c1 is a batter candidate, 1 if c2.</description>
			<content type="html"><![CDATA[<p>隔了挺长一段时间没有更新，主要是因为近段时间忙于业务和刷题，想来刷题除了Po题解和Explanation也是没有什么特别之处，除非钻研得特别深入，所以（@#$%^&amp;找理由）。</p>
<h1 id="关于elasticsearch">关于Elasticsearch</h1>
<p>Elasticsearch其实官网的文档特别齐全，所以关于用法没有什么特别好写的，看博客不如RTFM。但是文档特别全的情况下，很多时候又缺少对一些具体细节的描述，一句话说就是不知其所以然。所以今天写的博客内容理应是无关使用的，不涉及命令与操作，大概会更有意义一些吧。</p>
<h1 id="概述">概述</h1>
<p>以Elasticsearch（下称ES）集群启动过程作为索引来展开，ES想要从Red转为Green，需要经历以下过程：</p>
<ul>
<li>主节点选举。集群启动需要从已知的活跃机器中选取主节点，因为这是PacificA算法的思想——主从模式，使用Master节点管理元信息，数据则去中心化。这块使用类似Bully的算法。</li>
<li>元信息选举。主节点确认后，需要从各节点的元信息中获取最新版本的元信息。由Gateway模块负责。</li>
<li>主副分片选举。由Allocation模块负责，各分片的多个副本中选出主分片和副分片，记录他们所属的节点，重构内容路由表。</li>
<li>恢复分片数据。因为启动可能包含之前没有来得及刷盘的数据，副分片也可能落后于新选出的主分片。</li>
</ul>
<h1 id="bully算法与主节点选举">Bully算法与主节点选举</h1>
<h2 id="bully算法">Bully算法</h2>
<p>特地查了一下Bully的意思——“仗势欺人者，横行霸道者”，所以这个霸道选举算法如其名，简单暴力地通过<strong>选出ID最大的候选者</strong>来完成。在Bully算法中有几点假设：</p>
<ul>
<li>系统是处于同步状态的</li>
<li>进程任何时间都可能失效，包括在算法执行过程中</li>
<li>进程失败则停止，并通过重新启动来恢复</li>
<li>有能够进行失败检测的机制</li>
<li>进程间的消息传递是可靠的</li>
<li>每个进程知道自己的ID和地址，以及其他所有的进程ID和地址</li>
</ul>
<p>它的选举通过以下几类消息：</p>
<ul>
<li>选举消息：用来声明一次选举</li>
<li>响应消息：响应选举消息</li>
<li>协调消息：胜利者向参与者发送胜利声明</li>
</ul>
<p>设想以下场景，集群中存在ID为1、2、3的节点，通过Bully算法选举出了3为主节点，此时之前因为网络分区无法联系上的4节点加入，通过Bully算法成了新的主节点，后续失联的5节点加入，同样成为新主节点。这种不稳定的状态在ES中通过优化选举发起的条件来解决，当主节点确定后，在失效前不进行新一轮的选举。另外其他分布式应用一样，ES通过Quorum来解决脑裂的问题。</p>
<h2 id="elasticsearch主节点选举">Elasticsearch主节点选举</h2>
<p>ES的选举与Bully算法有所出入，它选举的是<strong>ID最小</strong>的节点，当然这并没有太大影响。另外目前版本中ES的排序影响因素还有集群状态，对应一个状态版本号，排序中会优先将版本号高的节点放在最前。</p>
<p>在选举过程中有几个概念：</p>
<ul>
<li>临时Master节点：某个节点认可的Master节点</li>
<li>activeMasters列表：不同节点了解到的其他节点范围可能不一样，因此他们可能各自认可不同的Master节点，这些临时Master节点的集合称为activeMasters列表</li>
<li>masterCanditates列表：所有满足Master资格（一般不满足例原因如配置了某些节点不能作为主节点）的节点列表</li>
<li>正式Master节点：票数足够时临时Master节点确立为真正Master节点</li>
</ul>
<p>某个节点ping所有节点，获取一份节点列表，并将自己加入其中。通过这份列表查看当前活跃的Master列表，也就是每个节点认为当前的Master节点，加入<strong>activeMasters列表</strong>中。同样，通过过滤原始列表中不符合Master资格的节点，形成<strong>masterCandidates列表</strong>。</p>
<p>如果activeMasters列表不为空，按照ES的（近似）Bully算法选举自己认为的Master节点；如果activeMasters列表空，从masterCandidates列表中选举，但是此时需要判断当前候选人数是否达到Quorum。ES使用具体的比较Master的逻辑如下：</p>
<pre><code>/**
 * compares two candidates to indicate which the a better master.
 * A higher cluster state version is better
 * 比较两个候选节点以得出更适合作为Master的节点。
 * 优先以集群状态版本作为排序
 *
 * @return -1 if c1 is a batter candidate, 1 if c2.
 * @c1更合适则返回-1，c2更合适则返回1
 */
public static int compare(MasterCandidate c1, MasterCandidate c2) {
    // we explicitly swap c1 and c2 here. the code expects &quot;better&quot; is lower in a sorted
    // list, so if c2 has a higher cluster state version, it needs to come first.
    // 先比较版本
    int ret = Long.compare(c2.clusterStateVersion, c1.clusterStateVersion);
    if (ret == 0) {
        // 比较节点
        ret = compareNodes(c1.getNode(), c2.getNode());
    }
    return ret;
}

/** master nodes go before other nodes, with a secondary sort by id **/
 private static int compareNodes(DiscoveryNode o1, DiscoveryNode o2) {
    if (o1.isMasterNode() &amp;&amp; !o2.isMasterNode()) {
        // 如果o1是主节点
        return -1;
    }
    if (!o1.isMasterNode() &amp;&amp; o2.isMasterNode()) {
        // 如果o2是主节点
        return 1;
    }
    // ID比较
    return o1.getId().compareTo(o2.getId());
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>确定之后进行投票，ES的投票是通过发送Join请求进行的，票数即为当前连接数。</p>
<p>如果临时Master为当前节点，则当前节点等待Quorum连接数，若配置时间内不满足，则选举失败，进行新一轮选举；若满足，发布新的clusterState。</p>
<p>如果临时Master节点不是本节点，则向Master发送Join请求，等待回复。Master如果得到足够票数，会先发布状态再确认请求。</p>
<h1 id="主副分片选举与allocation模块">主副分片选举与Allocation模块</h1>
<p>分片的决策由Master节点完成，需要确认的内容包括：</p>
<ul>
<li>哪些分片应该分配到哪个节点上（平衡）</li>
<li>分片的多个副本中哪个应该成为主分片（数据完整）</li>
</ul>
<h2 id="allocators">allocators</h2>
<p>Allocation模块中，allocators负责对分片作出优先选择，例如：</p>
<ul>
<li>平衡分片，节点列表按照它们的分片数排序，分片少的靠前，优先将新分片分配至靠前节点</li>
<li>主副分片，按照：节点上如果有完整的分片副本，主分片才能够指定到这个节点；节点上如果有（不一定需要完整）分片副本，副分片可以优先分配在这个节点（然后从主分片恢复数据）。</li>
<li>具体包括：
<ul>
<li>primaryShardAllocator：找到拥有分配最新数据的节点</li>
<li>replicaShardAllocator：找到拥有这个分片数据的节点</li>
<li>BalancedShardsAllocator：找到拥有最少分片个数的节点</li>
</ul>
</li>
</ul>
<h2 id="deciders">deciders</h2>
<p>作出选择后，需要通过deciders判断分片是否真的可以指定在这个节点，例如：</p>
<ul>
<li>磁盘空间限制</li>
<li>配置限制</li>
<li>避免主副分片落在同一节点</li>
<li>具体包括：
<ul>
<li>SameShardAllocationDecider：避免同节点</li>
<li>AwarenessAllocationDecider：分散存储shard</li>
<li>ShardsLimitAllocationDecider：同一节点允许同index的shard数目</li>
<li>ThrottlingAllocationDecider：recovery阶段的限速配置影响</li>
<li>ConcurrentRebalanceAllocationDecider：重新分片的并发控制</li>
<li>DiskThresholdDecider：磁盘空间</li>
<li>RebalanceOnlyWhenActiveAllocationDecider：是否所有shard都处于active状态</li>
<li>FilterAllocationDecider：接口动态设置的限定参数</li>
<li>ReplicaAfterPrimaryActiveAllocationDecider：主分片分配完毕才开始分配副分片</li>
<li>ClusterRebalanceAllocationDecider：集群中active的shard的状态</li>
</ul>
</li>
</ul>
<h2 id="主分片选举">主分片选举</h2>
<p>分片经过指定节点后有allocation id，并且有inSyncAllocationIds列表记录哪些分片是处于“in-sync”状态的。主分片的选举通过是否处于in-sync列表来进行。</p>
<p>在历史版本中，分片有对应的版本号，但是如果使用版本号进行选举，如果拥有最新数据版本的分片还未启动，那么就会有历史版本的分片被选为主分片，例如只有一个活跃分片时它必定会被选为主分片。</p>
<p>通过将in-sync列表的分片遍历各个decider，如果有任一deny发生，则拒绝本次分配。决策结束之后可能会有多个节点，取第一个节点上的分片作为主分片。</p>
<h2 id="分片模型">分片模型</h2>
<p>ES中使用Sequence ID标记写操作，以得到索引操作的顺序。现在考虑这种情况：由于网络原因，主分片产生的SID=145的操作转发到副分片上，但是没有传达成功，此时主分片被另一个副分片取代，也产生了一个SID=145（因为这个副分片最新的SID是144）的操作，转发给其他副分片。转发过程中，原来网络分区的主分片恢复，它的旧SID=145操作继续发送给其他副分片，那么分片副本中就有部分收到了旧主发的145操作，部分收到了新主发的145操作。</p>
<p>因此，除了Sequence ID以外，ES使用Primary Terms来标记主分片，每次新主分片产生时，Primary Terms加1，副分片会拒绝旧的Primary Terms发来的操作。</p>
<p>主节点为分片分配Primary Terms、Allocation ID，其中各个满足in-sync状态的分片的Allocation ID构成inSyncAllocationIds列表；Sequence ID由主分片为写操作分配，副分片拒绝Primary Terms+Sequence ID落后的操作。</p>
<h1 id="分片数据recovery">分片数据Recovery</h1>
<p>ES（大致的）存储模型在官网上有描述有图，所以就不多费时间描述了。</p>
<h2 id="主分片recovery">主分片Recovery</h2>
<p>主分片因为处于in-sync list中，需要恢复的数据只有未进行fsync刷盘的部分，也就是refresh之后，变得可被索引，但是没有进行flush生成新的commit point持久化到磁盘的部分。这部分数据在translog中，因此需要将数据从translog进行恢复。</p>
<p>经过一系列的校验（是否主分片、分片状态是否异常等）工作后，从分片读取最后一次提交（commit）的段（segment）信息，获取其中版本号，更新当前索引版本。然后验证元信息中的checksum和实际值是否匹配，避免分片受损。</p>
<p>根据最后一次commit的信息，确认translog中哪些数据需要进行reply，执行具体的写操作，结束后进行refresh，和正常写操作一样，让数据转移到文件系统缓存中，变得可被索引到，但是没有fsync。</p>
<p>最后进行一次refresh更新分片状态，恢复完毕。</p>
<h2 id="副分片recovery">副分片Recovery</h2>
<p>副分片恢复需要根据当前数据状态（进度）决定，如果Sequence ID满足，可以直接从主分片的Translog中恢复缺失部分；如果不满足，需要拉取主分片的Lucene索引和Translog进行恢复。</p>
<p>主分片一般先Recovery，结束后接受新业务的操作，如何保证副分片需要的Translog不清理？在最初的1.x版本中，ES阻止refresh操作保留translog，但是这样会产生很大的translog；在2.0-5.x版本中，引入了translog.view的概念，translog被分为多个文件，维护一个引用文件的列表，同时recovery通过translog.view获取这些文件的引用，因为文件引用的存在translog不能被清理，直到view关闭（没有引用）。6.0版本中引入了TranslogDeletingPolicy概念，维护活跃的translog文件，通过将translog做快照来保持translog不被清理。</p>
<p>副分片的恢复由两个阶段构成：</p>
<ul>
<li>phase1：在主分片上获取translog保留锁，此时translog不会被清理；将Lucene索引做快照，数据复制到副本节点。完成后，副分片可以启动Engine开始接受请求。</li>
<li>phase2：对translog做快照，这部分包含了从phase1开始到执行translog快照期间的新增数据，发送到副分片进行reply。</li>
</ul>
<p>前面提过，如果可以基于SID进行恢复，跳过phase1；如果主副分片有同样的syncid且doc数相同，跳过phase1。</p>
<p>什么是syncid？当分片5分钟（可配置）没有写入操作就会被标记为inactive，执行synced flush，生成一个syncid，相同syncid意味着分片是相同的Lucene索引。</p>
<h2 id="恢复过程中的主副分片一致性">恢复过程中的主副分片一致性</h2>
<p>恢复时，因为主副分片恢复时间不一致，主分片先进行Recovery，然后副分片才能基于主分片进行Recovery，所以主分片可以工作之后，副分片可能还在恢复中，此时主分片会向副分片发送写请求，因此恢复reply与主分片可能会同时（或者不按发生顺序）对同一个doc进行操作。ES中通过doc的版本号解决这个问题，当收到一个版本号低于doc当前版本号的操作时，会放弃本次操作。对于特定的doc，只有最新一次操作生效。</p>
<h1 id="总结">总结</h1>
<p>Elasticsearch是个易用又复杂的分布式项目，其中很多分布式相关的设计和思想都值得学习和借鉴。在拉取代码时发现项目体积接近1GB：</p>
<pre><code>uck@duck-MS-7A34:~/study/tmp$ du -sh elasticsearch/
949M    elasticsearch/&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>因此其中很多模块都没有了解清楚，希望以后可以保持学习的新鲜感，继续摸索更多的内容。</p>
]]></content>
		</item>
		
		<item>
			<title>字节跳动一面复盘 &amp; Redis多线程IO模型源码学习</title>
			<link>https://jiekun.dev/posts/2020-02-22-%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E4%B8%80%E9%9D%A2%E5%A4%8D%E7%9B%98-redis%E5%A4%9A%E7%BA%BF%E7%A8%8Bio%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</link>
			<pubDate>Sat, 22 Feb 2020 12:42:24 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-02-22-%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E4%B8%80%E9%9D%A2%E5%A4%8D%E7%9B%98-redis%E5%A4%9A%E7%BA%BF%E7%A8%8Bio%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</guid>
			<description>面试 上周参加了字节跳动的面试，也是18年毕业后的首次面试，整场下来一共70分钟，面试官非常Nice，无奈自己太过紧张，很多准备好的知识点都没有能够准确传达意思。
面试中因为在简历上有提到Redis相关的内容，那么毫无疑问就会被问到了。先从经典的问题开始：Reids为什么这么快？那自然会回答诸如单线程、IO多路复用等固定套路，然后这里因为一直有关注Redis的相关新闻，知道Redis 6.0年末发布了RC1版本，其中新特性包括多线程IO，那么自然想在面试中提及一下。面试官应该对这点比较感兴趣，于是就继续探讨了这个多线程IO的模型。
 Q：Redis 6多线程是指什么？ A：Redis这边将部分处理流程改为多线程，具体来说是.. Q：是指查询是多线程吗？ A：应该说是处理请求的最后部分改为了多线程，因为这些部分涉及到数据的IO，是整个（Redis）模型中最耗时的部分，所以改成了多线程；这部分之前的比如用户请求进来、将请求放入一个队列中，还是单线程的。（注意这部分回答是错误的，实际上Redis是将网络IO的部分做成了多线程，后文继续分析） Q：如果我有一个SET操作的话，是单线程还是多线程？ A：多线程。（回答也是错的） Q：那如果是，因为Redis都是内存操作，如果多线程操作一个数据结构的话会有问题吗？ A：Emm，目前我理解的模型上看确实会有问题，比如并发改同一个Key，那可能Redis有对应处理这些问题比如进行加锁处理。（确实不了解，回答也自然是错的） Q：好，下一个问题..  这里先总结一下：
 因为Antirez在Redis Day介绍过，所以就了解到了有这么个新Feature，但是具体的实现因为没有看过源码，所以实际上对这个多线程模型的理解是有偏差的。 如果对这些点没有十足的把握的话，面试中尝试自己思考和解决这样的问题实际上还是会比较扣分，首先如果猜错了的话肯定不行，其次即使是猜对了也很难有足够的知识储备去复述出完整的模型出来，也会让自己一边思考一边表达起来很费劲。  于是坑坑洼哇地坚持完了70分钟的面试，再总结一下做得不足的地方，因为是1.5Year经验，面试官主要考察：
 现有的业务的一些设计细节的问题：要提前准备好你想介绍给面试官的业务系统，个人认为应该从业务中选出一两个难度比较大的点会比较合适。这次面试没有能够拿出对应的业务来介绍，是准备不到位。 数据库的基础知识：这块觉得回答得还可以，不过有的时候因为准备的东西比较多，会经常想充分地展现和描述，有的时候可能会比较冗长，也是表达不够精确的问题。 计算机网络的基础知识：不是科班毕业，没有能够答完美，实际上问题并不难。 计算机系统的基础知识：同上。 一道算法题：字节跳动给的算法题还是偏简单和经典的，建议多刷题和看Discussion总结。  所以就这样结束了第一次的社招面试，整体来说几个方向的基础知识需要回去再多写多看就可以了，然后表达上尽量控制时间和范围，深入的内容如果面试官希望和你继续探讨，自然会发问，如果没问，可以提及但是不应该直接展开讲。
Redis的Threaded IO 面试结束后马上知道这块的回答有问题，检查果然如此。所以也就借这个机会将Threaded IO对应的源码看了一遍，后续如果有机会的话，希望能跟下一位面试官再来探讨这个模型。
综述 本次新增的代码位于networking.c中，很显然多线程生效的位置就能猜出来是在网络请求上。作者希望改进读写缓冲区的性能，而不是命令执行的性能主要原因是：
 读写缓冲区的在命令执行的生命周期中是占了比较大的比重 Redis更倾向于保持简单的设计，如果在命令执行部分改用多线程会不得不处理各种问题，例如并发写入、加锁等  那么将读写缓冲区改为多线程后整个模型大致如下：
具体模型 线程初始化(initThreadedIO) 首先，如果用户没有开启多线程IO，也就是io_threads_num == 1时直接按照单线程模型处理；如果超过线程数IO_THREADS_MAX_NUM上限则异常退出。
紧接着Redis使用listCreate()创建io_threads_num个线程，并且对主线程（id=0）以外的线程进行处理：
 初始化线程的等待任务数为0 获取锁，使得线程不能进行操作 将线程tid与Redis中的线程id（for循环生成）进行映射  /* Initialize the data structures needed for threaded I/O. */ void initThreadedIO(void) { io_threads_active = 0; /* We start with threads not active.</description>
			<content type="html"><![CDATA[<h1 id="面试">面试</h1>
<p>上周参加了字节跳动的面试，也是18年毕业后的首次面试，整场下来一共70分钟，面试官非常Nice，无奈自己太过紧张，很多准备好的知识点都没有能够准确传达意思。</p>
<p>面试中因为在简历上有提到Redis相关的内容，那么毫无疑问就会被问到了。先从经典的问题开始：Reids为什么这么快？那自然会回答诸如单线程、IO多路复用等固定套路，然后这里因为一直有关注Redis的相关新闻，知道Redis 6.0年末发布了RC1版本，其中新特性包括多线程IO，那么自然想在面试中提及一下。面试官应该对这点比较感兴趣，于是就继续探讨了这个多线程IO的模型。</p>
<ul>
<li>Q：Redis 6多线程是指什么？</li>
<li>A：Redis这边将部分处理流程改为多线程，具体来说是..</li>
<li>Q：是指查询是多线程吗？</li>
<li>A：应该说是处理请求的最后部分改为了多线程，因为这些部分涉及到数据的IO，是整个（Redis）模型中最耗时的部分，所以改成了多线程；这部分之前的比如用户请求进来、将请求放入一个队列中，还是单线程的。（注意这部分回答是错误的，实际上Redis是将网络IO的部分做成了多线程，后文继续分析）</li>
<li>Q：如果我有一个SET操作的话，是单线程还是多线程？</li>
<li>A：多线程。（回答也是错的）</li>
<li>Q：那如果是，因为Redis都是内存操作，如果多线程操作一个数据结构的话会有问题吗？</li>
<li>A：Emm，目前我理解的模型上看确实会有问题，比如并发改同一个Key，那可能Redis有对应处理这些问题比如进行加锁处理。（确实不了解，回答也自然是错的）</li>
<li>Q：好，下一个问题..</li>
</ul>
<p>这里先总结一下：</p>
<ul>
<li>因为Antirez在Redis Day介绍过，所以就了解到了有这么个新Feature，但是具体的实现因为没有看过源码，所以实际上对这个多线程模型的理解是有偏差的。</li>
<li>如果对这些点没有十足的把握的话，面试中尝试自己思考和解决这样的问题实际上还是会比较扣分，首先如果猜错了的话肯定不行，其次即使是猜对了也很难有足够的知识储备去复述出完整的模型出来，也会让自己一边思考一边表达起来很费劲。</li>
</ul>
<p>于是坑坑洼哇地坚持完了70分钟的面试，再总结一下做得不足的地方，因为是1.5Year经验，面试官主要考察：</p>
<ul>
<li>现有的业务的一些设计细节的问题：要提前准备好你想介绍给面试官的业务系统，个人认为应该从业务中选出一两个难度比较大的点会比较合适。这次面试没有能够拿出对应的业务来介绍，是准备不到位。</li>
<li>数据库的基础知识：这块觉得回答得还可以，不过有的时候因为准备的东西比较多，会经常想充分地展现和描述，有的时候可能会比较冗长，也是表达不够精确的问题。</li>
<li>计算机网络的基础知识：不是科班毕业，没有能够答完美，实际上问题并不难。</li>
<li>计算机系统的基础知识：同上。</li>
<li>一道算法题：字节跳动给的算法题还是偏简单和经典的，建议多刷题和看Discussion总结。</li>
</ul>
<p>所以就这样结束了第一次的社招面试，整体来说几个方向的基础知识需要回去再多写多看就可以了，然后表达上尽量控制时间和范围，深入的内容如果面试官希望和你继续探讨，自然会发问，如果没问，可以提及但是不应该直接展开讲。</p>
<h1 id="redis的threaded-io">Redis的Threaded IO</h1>
<p>面试结束后马上知道这块的回答有问题，检查果然如此。所以也就借这个机会将Threaded IO对应的源码看了一遍，后续如果有机会的话，希望能跟下一位面试官再来探讨这个模型。</p>
<h2 id="综述">综述</h2>
<p>本次新增的代码位于<code>networking.c</code>中，很显然多线程生效的位置就能猜出来是在网络请求上。作者希望改进读写缓冲区的性能，而不是命令执行的性能主要原因是：</p>
<ul>
<li>读写缓冲区的在命令执行的生命周期中是占了比较大的比重</li>
<li>Redis更倾向于保持简单的设计，如果在命令执行部分改用多线程会不得不处理各种问题，例如并发写入、加锁等</li>
</ul>
<p>那么将读写缓冲区改为多线程后整个模型大致如下：</p>
<p><img src="../2020/02/Threaded-IO-1-1024x1016.png" alt=""></p>
<h2 id="具体模型">具体模型</h2>
<h3 id="线程初始化initthreadedio">线程初始化(initThreadedIO)</h3>
<p>首先，如果用户没有开启多线程IO，也就是<code>io_threads_num == 1</code>时直接按照单线程模型处理；如果超过线程数<code>IO_THREADS_MAX_NUM</code>上限则异常退出。</p>
<p>紧接着Redis使用listCreate()创建io_threads_num个线程，并且对主线程（id=0）以外的线程进行处理：</p>
<ul>
<li>初始化线程的等待任务数为0</li>
<li>获取锁，使得线程不能进行操作</li>
<li>将线程tid与Redis中的线程id（for循环生成）进行映射</li>
</ul>
<pre><code>/* Initialize the data structures needed for threaded I/O. */
void initThreadedIO(void) {
    io_threads_active = 0; /* We start with threads not active. */

    /* Don't spawn any thread if the user selected a single thread:
     * we'll handle I/O directly from the main thread. */
    // 如果用户没有开启多线程IO直接返回 使用主线程处理
    if (server.io_threads_num == 1) return;
    // 线程数设置超过上限
    if (server.io_threads_num &gt; IO_THREADS_MAX_NUM) {
        serverLog(LL_WARNING,&quot;Fatal: too many I/O threads configured. &quot;
                             &quot;The maximum number is %d.&quot;, IO_THREADS_MAX_NUM);
        exit(1);
    }

    /* Spawn and initialize the I/O threads. */
    // 初始化io_threads_num个对应线程
    for (int i = 0; i &amp;lt; server.io_threads_num; i++) {
        /* Things we do for all the threads including the main thread. */
        io_threads_list[i] = listCreate();
        if (i == 0) continue; // Index 0为主线程

        /* Things we do only for the additional threads. */
        // 非主线程则需要以下处理
        pthread_t tid;
        // 为线程初始化对应的锁
        pthread_mutex_init(&amp;io_threads_mutex[i],NULL);
        // 线程等待状态初始化为0
        io_threads_pending[i] = 0;
        // 初始化后将线程暂时锁住
        pthread_mutex_lock(&amp;io_threads_mutex[i]);
        if (pthread_create(&amp;tid,NULL,IOThreadMain,(void*)(long)i) != 0) {
            serverLog(LL_WARNING,&quot;Fatal: Can't initialize IO thread.&quot;);
            exit(1);
        }
        // 将index和对应线程ID加以映射
        io_threads[i] = tid;
    }
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="读事件到来readqueryfromclient">读事件到来（readQueryFromClient）</h3>
<p>Redis需要判断是否满足Threaded IO条件，执行<code>if (postponeClientRead(c)) return;</code>，执行后会将Client放到等待读取的队列中，并将Client的等待读取Flag置位：</p>
<pre><code>int postponeClientRead(client *c) {
    if (io_threads_active &amp;&amp; // 线程是否在不断(spining)等待IO
        server.io_threads_do_reads &amp;&amp; // 是否多线程IO读取
        !(c-&gt;flags &amp; (CLIENT_MASTER|CLIENT_SLAVE|CLIENT_PENDING_READ)))
    {//client不能是主从，且未处于等待读取的状态
        c-&gt;flags |= CLIENT_PENDING_READ; // 将Client设置为等待读取的状态Flag
        listAddNodeHead(server.clients_pending_read,c); // 将这个Client加入到等待读取队列
        return 1;
    } else {
        return 0;
    }
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这时server维护了一个<code>clients_pending_read</code>，包含所有处于读事件pending的客户端列表。</p>
<h3 id="如何分配client给threadhandleclientswithpendingreadsusingthreads">如何分配client给thread（handleClientsWithPendingReadsUsingThreads）</h3>
<p>首先，Redis检查有多少等待读的client：</p>
<pre><code>istLength(server.clients_pending_read)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>如果长度不为0，进行While循环，将每个等待的client分配给线程，当等待长度超过线程数时，每个线程分配到的client可能会超过1个：</p>
<pre><code>int item_id = 0;
while((ln = listNext(&amp;li))) {
    client *c = listNodeValue(ln);
    int target_id = item_id % server.io_threads_num;
    listAddNodeTail(io_threads_list[target_id],c);
    item_id++;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>并且修改每个线程需要完成的数量（初始化时为0）：</p>
<pre><code>for (int j = 1; j &amp;lt; server.io_threads_num; j++) {
    int count = listLength(io_threads_list[j]);
    io_threads_pending[j] = count;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>等待处理直到没有剩余任务：</p>
<pre><code>hile(1) {
    unsigned long pending = 0;
    for (int j = 1; j &amp;lt; server.io_threads_num; j++)
        pending += io_threads_pending[j];
    if (pending == 0) break;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>最后清空client_pending_read：</p>
<pre><code>istRewind(server.clients_pending_read,&amp;li);
while((ln = listNext(&amp;li))) {
    client *c = listNodeValue(ln);
    c-&gt;flags &amp;= ~CLIENT_PENDING_READ;
    if (c-&gt;flags &amp; CLIENT_PENDING_COMMAND) {
        c-&gt;flags &amp;= ~ CLIENT_PENDING_COMMAND;
        processCommandAndResetClient(c);
    }
    processInputBufferAndReplicate(c);
}
listEmpty(server.clients_pending_read);&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="如何处理读请求">如何处理读请求</h3>
<p>在上面的过程中，当任务分发完毕后，每个线程按照正常流程将自己负责的Client的读取缓冲区的内容进行处理，和原来的单线程没有太大差异。</p>
<p>每轮处理中，需要将各个线程的锁开启，并且将相关标志置位：</p>
<pre><code>void startThreadedIO(void) {
    if (tio_debug) { printf(&quot;S&quot;); fflush(stdout); }
    if (tio_debug) printf(&quot;--- STARTING THREADED IO ---\n&quot;);
    serverAssert(io_threads_active == 0);
    for (int j = 1; j &amp;lt; server.io_threads_num; j++)
        // 解开线程的锁定状态
        pthread_mutex_unlock(&amp;io_threads_mutex[j]);
    // 现在可以开始多线程IO执行对应读/写任务
    io_threads_active = 1;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>同样结束时，首先需要检查是否有剩余待读的IO，如果没有，将线程锁定，标志关闭：</p>
<pre><code>void stopThreadedIO(void) {
    // 需要停止的时候可能还有等待读的Client 在停止前进行处理
    handleClientsWithPendingReadsUsingThreads();
    if (tio_debug) { printf(&quot;E&quot;); fflush(stdout); }
    if (tio_debug) printf(&quot;--- STOPPING THREADED IO [R%d] [W%d] ---\n&quot;,
        (int) listLength(server.clients_pending_read),
        (int) listLength(server.clients_pending_write));
    serverAssert(io_threads_active == 1);
    for (int j = 1; j &amp;lt; server.io_threads_num; j++)
        // 本轮IO结束 将所有线程上锁
        pthread_mutex_lock(&amp;io_threads_mutex[j]);
    // IO状态设置为关闭
    io_threads_active = 0;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="其他补充">其他补充</h3>
<p>Redis的Threaded IO模型中，每次所有的线程都只能进行读或者写操作，通过<code>io_threads_op</code>控制，同时每个线程中负责的client依次执行：</p>
<pre><code>// 每个thread有可能需要负责多个client
listRewind(io_threads_list[id],&amp;li);
while((ln = listNext(&amp;li))) {
    client *c = listNodeValue(ln);
    if (io_threads_op == IO_THREADS_OP_WRITE) {
        // 当前全局处于写事件时，向输出缓冲区写入响应内容
        writeToClient(c,0);
    } else if (io_threads_op == IO_THREADS_OP_READ) {
        // 当前全局处于读事件时，从输入缓冲区读取请求内容
        readQueryFromClient(c-&gt;conn);
    } else {
        serverPanic(&quot;io_threads_op value is unknown&quot;);
    }
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>每个线程执行<code>readQueryFromClient</code>，将对应的请求放入一个队列中，单线程执行，最后类似地由多线程将结果写入客户端的buffer中。</p>
<h2 id="总结">总结</h2>
<p>Threaded IO将服务读Client的输入缓冲区和将执行结果写入输出缓冲区的过程改为了多线程的模型，同时保持同一时间全部线程均处于读或者写的状态。但是命令的具体执行仍是以单线程（队列）的形式，因为Redis希望保持简单的结构避免处理锁和竞争的问题，并且读写缓冲区的时间占命令执行生命周期的比重较大，处理这部分的IO模型会给性能带来显著的提升。</p>
]]></content>
		</item>
		
		<item>
			<title>短链生成系统设计——Counter&#43;ZooKeeper&#43;Base62</title>
			<link>https://jiekun.dev/posts/2020-02-15-%E7%9F%AD%E9%93%BE%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-counterzookeeperbase62/</link>
			<pubDate>Sat, 15 Feb 2020 05:02:40 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-02-15-%E7%9F%AD%E9%93%BE%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-counterzookeeperbase62/</guid>
			<description>我们最后设计出的系统架构如图所示，如果想了解最后的结论可以跳到最后一小节。这个系统理论上可以支持大流量的生成请求，分布式部署便于扩展。当然在使用的存储方案性能上没有过多的讨论，因为这次的重点是解决“唯一”、“分布式”的ID问题。
准备设计 设计一个系统之前，我们应该对系统的需求有所了解。对于短链系统，首先应该有以下思考：
 我们需要什么样的短链接，具体是多短？ 短链系统的请求量有多大？ 这是个单实例还是分布式系统？  首先我们可以做一些假设，例如参考Twitter有3亿访问/月，我们假设有它的10%，也就是3千万/月，平均每日100万。
然后再来假设生成的短链，一般格式为domain/unique_id，例如s-url.com/D28CZ63，我们假设Unique ID的长度最多为7位。
下面我们根据这些假设条件来完成这个系统的设计。
数据量计算 根据上面的假设，首先每个原始URL可以按照2KB估算（2048字符），而短URL可以按照17Byte估算；我们可能还需要记录创建时间和过期时间，分别是7Byte。因此可以大致估算每行记录的大小应该为2.031KB。
我们一共有30M月访问，30M * 2.031KB = 60.7GB，每月约60GB数据，因此一年内估算为0.7TB，5年3.6TB数据量。
唯一ID算法 我们需要的是一个短的（7位）唯一ID生成方案。考虑Base62和MD5，Base62即使用0-9A-Za-z一共62个字符，MD5使用0-9a-z，一般输出长度为32的字符串。
使用MD5的话，因为输出长度固定，我们可能需要截取其前7位来作为唯一ID，这种情况下，首先不同的输入可能会输出相同的MD5，其次，不同的MD5的前7位也可能是相同的。这样的话会产生不少的Collision，需要业务上进行保障。而使用MD5的好处，也恰恰是如果不同用户提交相同输入，那么可以得到相同的ID而不需要重复生成新的短链ID，但是同样需要业务进行处理和保证。
对于Base62，每一位有62个可能字符串，7位则是62^7=3521614606208种组合，每秒产生1000个ID的话也足够使用110年。同时在短URL的要求上，Base62接受输入，产生的输出长度会根据输入变化，因此不需要进行截取，而只需要想办法将7位ID的所有情况消耗完毕就可以满足大部分场景的要求。Base62伪代码如下：
f base62_encode(deci): s = &#39;0-9A-Za-z&#39; hash_str = &#39;&#39; while deci &amp;gt; 0: hash_str = s[deci % 62] + hash_str deci /= 62 return hash_str&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 存储选择 一般我们会考虑使用RDBMS比如MySQl，或者NoSQL比如Redis。在关系型数据库中，横向扩展会比较麻烦，例如MySQL进行分表和分库，我们可能需要多个实例，而扩展需要一开始就设想好，但是这一点在NoSQL中会相对比较容易，例如使用一个Redis的Cluster，或许向里面添加节点会相对容易一点。而使用NoSQL我们可能需要考虑数据的最终一致性，还有数据的持久化等问题。
同时根据业务场景，从性能上考虑如果在高峰期有大量短链生成请求需要写入到MySQL或许表现会比Redis差一些。
对于将“长URL-短URL”的映射关系写入数据库的步骤，重点是确保这个短URL没有被其他长URL使用过。如果使用过，那么你需要想办法使用新的字符串生成这个短URL。
先来想一下，这是一个两步操作，首先查询是否存在，然后写入。如果这是个串行，那么是可行的。如果这是一个并行操作，很显然，你可能查询的时候发现没有存在这个短URL，而其他Session也查到了同样的结果，最后大家都认为可以写入，然后写入过程中晚写的一方就会出问题。
在RDBMS中我们可能可以通过一些提供的方法来解决这个问题，例如INSERT_IF_NOT_EXISTS，但是在NoSQL中是没有这些方法的，因为它的设计是要实现最终一致性，所以不会提供这种支持。
基于以上分析和假设的方案 我们需要确定的内容主要是：
 生成算法 存储选择  目前罗列出来的方案主要包括：MD5，Base62，以及MySQL和Redis。
如果使用MD5的话，需要使用能够解决哈希冲突的RDBMS，因为这个步骤在NoSQL上处理比较麻烦，所以会有MD5+MySQL的组合。这套组合实际上性能并不太满足需求，并且在扩展上会相对另外一组组合难度大些。
那么另外一种就是我们打算使用的方案：Base62+Redis。如何将7位Base62的所有情况都用尽，我们可以采用一个计数器，从0-62^7的数字转为Base62，作为短链ID使用。这个方案在单实例上是很容易的，并且可以保证冲突问题。那么如何实现它的可扩展性呢？
在接入大流量的情况下，我们必然需要部署多点的ID生成服务，那么根据思路，我们需要对应的计数来转换成Base62的唯一ID，如果不同的服务拿到了同样的计数，那么就会生成相同的ID，造成冲突，且因为分布式的部署，仍然能够正常写入。
因此现在问题转化为如何让不同的服务拿到正确的计数。因为总的数字段是已知的（0-62^7），一个很简单的方法就是我们提前将这些数字进行分段，每个ID生成服务都拿到不同段的数字本地使用。例如：
0-100000 100001-200000 200001-300000 300001-400000 400001-500000 500001-600000 .</description>
			<content type="html"><![CDATA[<p>我们最后设计出的系统架构如图所示，如果想了解最后的结论可以跳到最后一小节。这个系统理论上可以支持大流量的生成请求，分布式部署便于扩展。当然在使用的存储方案性能上没有过多的讨论，因为这次的重点是解决“唯一”、“分布式”的ID问题。</p>
<h2 id="准备设计">准备设计</h2>
<p>设计一个系统之前，我们应该对系统的需求有所了解。对于短链系统，首先应该有以下思考：</p>
<ul>
<li>我们需要什么样的短链接，具体是多短？</li>
<li>短链系统的请求量有多大？</li>
<li>这是个单实例还是分布式系统？</li>
</ul>
<p>首先我们可以做一些假设，例如参考Twitter有3亿访问/月，我们假设有它的10%，也就是3千万/月，平均每日100万。</p>
<p>然后再来假设生成的短链，一般格式为<code>domain/unique_id</code>，例如<code>s-url.com/D28CZ63</code>，我们假设Unique ID的长度最多为7位。</p>
<p>下面我们根据这些假设条件来完成这个系统的设计。</p>
<h2 id="数据量计算">数据量计算</h2>
<p>根据上面的假设，首先每个原始URL可以按照2KB估算（2048字符），而短URL可以按照17Byte估算；我们可能还需要记录创建时间和过期时间，分别是7Byte。因此可以大致估算每行记录的大小应该为2.031KB。</p>
<p>我们一共有30M月访问，<code>30M * 2.031KB = 60.7GB</code>，<strong>每月约60GB数据</strong>，因此一年内估算为<strong>0.7TB</strong>，<strong>5年3.6TB</strong>数据量。</p>
<h2 id="唯一id算法">唯一ID算法</h2>
<p>我们需要的是一个短的（7位）唯一ID生成方案。考虑Base62和MD5，Base62即使用0-9A-Za-z一共62个字符，MD5使用0-9a-z，一般输出长度为32的字符串。</p>
<p>使用MD5的话，因为输出长度固定，我们可能需要截取其前7位来作为唯一ID，这种情况下，首先不同的输入可能会输出相同的MD5，其次，不同的MD5的前7位也可能是相同的。这样的话会产生不少的Collision，需要业务上进行保障。而使用MD5的好处，也恰恰是如果不同用户提交相同输入，那么可以得到相同的ID而不需要重复生成新的短链ID，但是同样需要业务进行处理和保证。</p>
<p>对于Base62，每一位有62个可能字符串，7位则是<code>62^7=3521614606208</code>种组合，每秒产生1000个ID的话也足够使用110年。同时在短URL的要求上，Base62接受输入，产生的输出长度会根据输入变化，因此不需要进行截取，而只需要想办法将7位ID的所有情况消耗完毕就可以满足大部分场景的要求。Base62伪代码如下：</p>
<pre><code>f base62_encode(deci):
    s = '0-9A-Za-z'
    hash_str = ''
    while deci &gt; 0:
        hash_str = s[deci % 62] + hash_str
        deci /= 62
    return hash_str&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="存储选择">存储选择</h2>
<p>一般我们会考虑使用RDBMS比如MySQl，或者NoSQL比如Redis。在关系型数据库中，横向扩展会比较麻烦，例如MySQL进行分表和分库，我们可能需要多个实例，而扩展需要一开始就设想好，但是这一点在NoSQL中会相对比较容易，例如使用一个Redis的Cluster，或许向里面添加节点会相对容易一点。而使用NoSQL我们可能需要考虑数据的最终一致性，还有数据的持久化等问题。</p>
<p>同时根据业务场景，从性能上考虑如果在高峰期有大量短链生成请求需要写入到MySQL或许表现会比Redis差一些。</p>
<p>对于将“长URL-短URL”的映射关系写入数据库的步骤，重点是确保这个短URL没有被其他长URL使用过。如果使用过，那么你需要想办法使用新的字符串生成这个短URL。</p>
<p>先来想一下，这是一个两步操作，首先查询是否存在，然后写入。如果这是个串行，那么是可行的。如果这是一个并行操作，很显然，你可能查询的时候发现没有存在这个短URL，而其他Session也查到了同样的结果，最后大家都认为可以写入，然后写入过程中晚写的一方就会出问题。</p>
<p>在RDBMS中我们可能可以通过一些提供的方法来解决这个问题，例如<code>INSERT_IF_NOT_EXISTS</code>，但是在NoSQL中是没有这些方法的，因为它的设计是要实现最终一致性，所以不会提供这种支持。</p>
<h2 id="基于以上分析和假设的方案">基于以上分析和假设的方案</h2>
<p>我们需要确定的内容主要是：</p>
<ul>
<li>生成算法</li>
<li>存储选择</li>
</ul>
<p>目前罗列出来的方案主要包括：MD5，Base62，以及MySQL和Redis。</p>
<p>如果使用MD5的话，需要使用能够解决哈希冲突的RDBMS，因为这个步骤在NoSQL上处理比较麻烦，所以会有MD5+MySQL的组合。这套组合实际上性能并不太满足需求，并且在扩展上会相对另外一组组合难度大些。</p>
<p>那么另外一种就是我们打算使用的方案：Base62+Redis。如何将7位Base62的所有情况都用尽，我们可以采用一个计数器，从0-62^7的数字转为Base62，作为短链ID使用。这个方案在单实例上是很容易的，并且可以保证冲突问题。那么如何实现它的可扩展性呢？</p>
<p>在接入大流量的情况下，我们必然需要部署多点的ID生成服务，那么根据思路，我们需要对应的计数来转换成Base62的唯一ID，如果不同的服务拿到了同样的计数，那么就会生成相同的ID，造成冲突，且因为分布式的部署，仍然能够正常写入。</p>
<p>因此现在问题转化为如何让不同的服务拿到正确的计数。因为总的数字段是已知的（0-62^7），一个很简单的方法就是我们提前将这些数字进行分段，每个ID生成服务都拿到不同段的数字本地使用。例如：</p>
<pre><code>0-100000
100001-200000
200001-300000
300001-400000
400001-500000
500001-600000
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>当服务的计数消耗完毕后，继续向计数分配的服务请求下一段可用的数字。例如目前有3个ID生成服务A、B、C，在最初的分配中A拿到了0-100000号码段，B拿到了100001-200000，C拿到了200001-300000。当A使用完之后，询问分配服务，拿到下一段300001-400000。如此即可解决计数器分布式部署的问题。</p>
<p>在数字段分配的业务场景，很容易想到使用ZooKeeper实现，因为ZooKeeper是分布式架构，保障单点故障时仍然可以正确地分配计数号码，这样我们不用重复造轮子实现自己的高可用的分发服务。</p>
<h2 id="2020-03-03号段生成与获取">2020-03-03：号段生成与获取</h2>
<p>补充这一段主要因为很想尝试一下，ZK对于自己来说还是太过陌生，于是就花了点时间测试。</p>
<h3 id="初始化">初始化</h3>
<pre><code>import json
from kazoo.client import KazooClient

zk = KazooClient(hosts='127.0.0.1:2181')
zk.start()
exist = zk.exists(&quot;/url-shortener&quot;)
if exist:
    quit()

# Node not exist. Initializing with counter range
zk.create(&quot;/url-shortener&quot;)

uid_length = 7
start = 62 ** uid_length
end = start + 100000
data = json.dumps({
    &quot;start&quot;: start,
    &quot;end&quot;: end
}).encode(&quot;utf-8&quot;)
zk.create(&quot;/url-shortener/range-&quot;, value=data, sequence=True)

children = zk.get_children(&quot;/url-shortener&quot;)
int(children)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>连接上本地的ZK，如果目录已经存在，说明已经完成过初始化了，直接结束。</p>
<p>初始化过程也就是根据配置参数初始化对应的起始数值，因为我需要一个7位长度的ID，对应base62的数值起始位置是<code>62 ** 7</code>。号段长度可以分配，号段太长的话，如果有应用的节点挂掉，则有可能浪费掉一段；号段太短，则应用节点需要频繁向ZK询问取号。这里设置为100000。</p>
<p>拿到号段始末后，初始化一个顺序的znode，顺序是因为我可以提前生成一堆znode保存数据，Client直接取即可。不过这里测试过62^7-62^8的范围实在是太大了，按照区间长度为100000来分配的话需要预先初始化<code>(62^8 - 62^7) / 100000 = 2148184909</code>个节点，完全没有必要。先初始化1个节点，然后让Client取的时候自动生成下一段即可。</p>
<h3 id="取号">取号</h3>
<pre><code>import json
import os
import time
import random

from kazoo.client import KazooClient
zk = KazooClient(hosts='127.0.0.1:2181')
zk.start()
lock = zk.Lock(&quot;/url-shortener-lock&quot;, &quot;get_range&quot;)

def get_range():
    with lock:
        exist = zk.exists(&quot;/url-shortener&quot;)
        if not exist:
            print(&quot;ZK path not exist!&quot;)

        children = zk.get_children(&quot;/url-shortener/&quot;)
        if children and len(children) == 1:
            node_path = &quot;/url-shortener/%s&quot; % children[0]
            data, stat = zk.get(node_path)
            seq_range = json.loads(data.decode(&quot;utf-8&quot;))
            start = seq_range[&quot;start&quot;]
            end = seq_range[&quot;end&quot;]
            print(&quot;Process %d gets range: %d-%d&quot; % (os.getpid(), start, end))
            # generating next range
            start = end + 1
            end = start + 100000
            data = json.dumps({
                &quot;start&quot;: start,
                &quot;end&quot;: end
            }).encode(&quot;utf-8&quot;)
            zk.create(&quot;/url-shortener/range-&quot;, value=data, sequence=True)
            zk.delete(node_path)
            children = zk.get_children(&quot;/url-shortener&quot;)
        else:
            print(&quot;Running out of range!&quot;)
    return

if __name__ == '__main__':
    get_range()&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>取号逻辑也很简单，暂时还没有完善异常处理。检查指定的Path下是否有znode可用，如果没有的话可能是异常或号段用完，对应处理一下即可。然后获取znode的值，作为自己目前的号段范围。</p>
<p>生成下一个号段，那么就用上一段的末尾加上固定长度就行，同样创建一个znode，删除旧的节点。</p>
<p>原来确实是这么考虑的，不过发现，如果有多个Client同时尝试获取range，因为读znode和写znode和删除znode并不是原子操作，多个节点读到znode信息后，用作自己的range（已重复），创建新znode（创建了多个顺序的，内容相同的znode），删除znode（只有1个会操作成功，其余出错），所以数据都是错的。</p>
<p>既然用到了ZK，那么顺便来用一下ZK的分布式锁，原理就是创建对应的用作锁的顺序znode，序号靠后的client需要注册对应的watcher等待前一把锁释放（删除），当前面的锁释放（或挂掉，临时znode自动删除）触发watcher后，后面的client获得锁。kazoo已经为我们实现好了对应的逻辑，在执行过程中，可以看到<code>/url-shortener-lock</code>路径下的znode：</p>
<pre><code>[zk: localhost:2181(CONNECTED) 121] ls /url-shortener-lock
[1f5cda205022418c8b7db432a667dfd5__lock__0000000342, 9dffb44d40a74bbc969c4c64616b77d2__lock__0000000344, a829fbf9835c46bbaa4af4dda02aa9c1__lock__0000000343]&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>我们运行了3个并行的进程，因此有3个znode被创建，只有其中1个能执行临界区的代码。执行结果就是各自获取到了不同的range，符合期望：</p>
<pre><code>(zk) duck@duck-MS-7A34:~/src/apache-zookeeper-3.5.7-bin/script$ ./run_consume.sh 
Process 14188 gets range: 3521648606548-3521648706548
Process 14186 gets range: 3521648706549-3521648806549
Process 14187 gets range: 3521648806550-3521648906550
All done&lt;/code&gt;&lt;/pre&gt;
</code></pre>]]></content>
		</item>
		
		<item>
			<title>Redis哨兵故障转移</title>
			<link>https://jiekun.dev/posts/2020-01-31-redis%E5%93%A8%E5%85%B5%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB/</link>
			<pubDate>Fri, 31 Jan 2020 13:26:45 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-01-31-redis%E5%93%A8%E5%85%B5%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB/</guid>
			<description>下线标记 Sentinel定期向Master节点发送PING命令，若在限定时间内没有收到有效回复，则会将该节点状态中的flags字段设为SRI_S_DOWN，即标记为主观下线状态，同时尝试向其他Sentinel询问节点状态。
Sentinel使用：
SENTINEL is-master-down-by-addr &amp;amp;lt;ip&amp;gt; &amp;amp;lt;port&amp;gt; &amp;amp;lt;current_epoch&amp;gt; &amp;amp;lt;runid&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 来询问其他Sentinel是否同意主服务器已下线，其他Sentinel按照以下格式回复:
1) &amp;amp;lt;down_state&amp;gt; 2) &amp;amp;lt;leader_runid&amp;gt; 3) &amp;amp;lt;leader_epoch&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 若down_state为1，则说明同意下线状态。
当有足够的Sentinel同意下线数量，Sentinel会将该Master节点状态中的flags字段设为SRI_O_DOWN，表示进入客观下线状态。
选举领头Sentinel 当有Master节点被标记为客观下线，监视这个下线Master节点的各个Sentienl会进行协商，选举领头Sentinel进行故障转移操作。
所有的该Master节点的Sentinel都有被选为领头节点的资格。每次选举中不管是否成功，Sentinel配置中的纪元epoch都要加1。
在每个epoch内，各个Sentinel都可能成为领头，局部领头一旦设置，在当前epoch内就不能改变。
每个发现Master节点进入客观下线的Sentinel都会要求其他Sentinel将自己设置为局部领头Sentinel。当一个Sentinel向对方发送is-master-down-by-addr命令且ip参数为*时，即表示希望对方将自己设置为领头。设置规则为先到先得，后续的申请都会被拒绝。对方收到申请后会响应命令回复，回复中的leader_runid和leader_epoch分别记录了局部领头的运行id和配置纪元。源Sentinel会判断对方响应的runid和epoch是否与自己对应，如果对应则说明对方将自己设置为局部领头。当某个Sentinel被半数以上的Sentinel设置为局部领头，那么这个Sentinel成为领头Sentinel。
如果在时限内没有Sentinel拿到半数以上投票，则开始一个新的纪元重新进行选举。
故障转移 领头Sentinel确定后，领头Sentinel对下线的Master节点进行故障转移：
 从下线Master节点的从服务器中挑选一个转为主服务器 让已经下线的节点的从服务器改为复制新的主服务器 将已经下线的节点设置为新的Master的从服务器  选择新Master服务器按照如下规则逐步过滤：
 删除已经下线的从服务器 删除最近5秒内没有回复过领头Sentinel的INFO命令的从服务器 删除与已下线主服务器断开连接超过down-after-milliseconds * 10毫秒的从服务器，以保证从服务器没有过早与主服务器断开连接 根据从服务器的优先级进行排序，优先级相同则按照复制偏移量排序，最后按照runid进行排序  Sentinel向新选出的主服务器发送slaveof no one命令，并且持续发送INFO命令观察服务器的角色是否从role变为master。
当新Master的角色改变后，Sentinel向其他从服务器发送slaveof命令使他们复制新的主服务器。
当旧的Master上线后，Sentinel也会向它发送slaveof命令，让他成为从服务器。</description>
			<content type="html"><![CDATA[<h2 id="下线标记">下线标记</h2>
<p>Sentinel定期向Master节点发送<code>PING</code>命令，若在限定时间内没有收到有效回复，则会将该节点状态中的flags字段设为<code>SRI_S_DOWN</code>，即标记为主观下线状态，同时尝试向其他Sentinel询问节点状态。</p>
<p>Sentinel使用：</p>
<pre><code>SENTINEL is-master-down-by-addr &amp;lt;ip&gt; &amp;lt;port&gt; &amp;lt;current_epoch&gt; &amp;lt;runid&gt;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>来询问其他Sentinel是否同意主服务器已下线，其他Sentinel按照以下格式回复:</p>
<pre><code>1) &amp;lt;down_state&gt;
2) &amp;lt;leader_runid&gt;
3) &amp;lt;leader_epoch&gt;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>若down_state为1，则说明同意下线状态。</p>
<p>当有足够的Sentinel同意下线数量，Sentinel会将该Master节点状态中的flags字段设为<code>SRI_O_DOWN</code>，表示进入客观下线状态。</p>
<h2 id="选举领头sentinel">选举领头Sentinel</h2>
<p>当有Master节点被标记为客观下线，监视这个下线Master节点的各个Sentienl会进行协商，选举领头Sentinel进行故障转移操作。</p>
<p>所有的该Master节点的Sentinel都有被选为领头节点的资格。每次选举中不管是否成功，Sentinel配置中的纪元epoch都要加1。</p>
<p>在每个epoch内，各个Sentinel都可能成为领头，局部领头一旦设置，在当前epoch内就不能改变。</p>
<p>每个发现Master节点进入客观下线的Sentinel都会要求其他Sentinel将自己设置为局部领头Sentinel。当一个Sentinel向对方发送<code>is-master-down-by-addr</code>命令且ip参数为<code>*</code>时，即表示希望对方将自己设置为领头。设置规则为先到先得，后续的申请都会被拒绝。对方收到申请后会响应命令回复，回复中的leader_runid和leader_epoch分别记录了局部领头的运行id和配置纪元。源Sentinel会判断对方响应的runid和epoch是否与自己对应，如果对应则说明对方将自己设置为局部领头。当某个Sentinel被半数以上的Sentinel设置为局部领头，那么这个Sentinel成为领头Sentinel。</p>
<p>如果在时限内没有Sentinel拿到半数以上投票，则开始一个新的纪元重新进行选举。</p>
<h2 id="故障转移">故障转移</h2>
<p>领头Sentinel确定后，领头Sentinel对下线的Master节点进行故障转移：</p>
<ul>
<li>从下线Master节点的从服务器中挑选一个转为主服务器</li>
<li>让已经下线的节点的从服务器改为复制新的主服务器</li>
<li>将已经下线的节点设置为新的Master的从服务器</li>
</ul>
<p>选择新Master服务器按照如下规则逐步过滤：</p>
<ul>
<li>删除已经下线的从服务器</li>
<li>删除最近5秒内没有回复过领头Sentinel的INFO命令的从服务器</li>
<li>删除与已下线主服务器断开连接超过<code>down-after-milliseconds</code> * 10毫秒的从服务器，以保证从服务器没有过早与主服务器断开连接</li>
<li>根据从服务器的优先级进行排序，优先级相同则按照复制偏移量排序，最后按照runid进行排序</li>
</ul>
<p>Sentinel向新选出的主服务器发送<code>slaveof no one</code>命令，并且持续发送<code>INFO</code>命令观察服务器的角色是否从role变为master。</p>
<p>当新Master的角色改变后，Sentinel向其他从服务器发送<code>slaveof</code>命令使他们复制新的主服务器。</p>
<p>当旧的Master上线后，Sentinel也会向它发送<code>slaveof</code>命令，让他成为从服务器。</p>
]]></content>
		</item>
		
		<item>
			<title>TCP补充笔记</title>
			<link>https://jiekun.dev/posts/2020-01-21-tcp%E8%A1%A5%E5%85%85%E7%AC%94%E8%AE%B0/</link>
			<pubDate>Tue, 21 Jan 2020 05:50:32 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2020-01-21-tcp%E8%A1%A5%E5%85%85%E7%AC%94%E8%AE%B0/</guid>
			<description>春节假期期间补充学习的内容，查缺补漏，先从TCP开始。
选择确认的重传（SACK） TCP头部包含一个可选的选项变量，如图所示：
其中可以用来填充以下内容：
在数据传输过程中，因为TCP抵达的顺序是不予保证的，因此接收方必然会有收到乱序数据的情况。
在没有SACK的情况下，接收方在缺失数据时，会一直进行ACK并附带期望的SEQ，发送方在重复（duptrash常量，默认3次）收到同一个序列号时会断定有包在传输过程中丢失，然后进行重传。
如果TCP发送方能够了解接收方当前的空洞，它就能在报文段丢失或者接收方遗漏的时候更好地进行重传工作，且减少不必要的重传。在丢包严重的情况下，SACK可以在一个RTT内填补多个空缺。
ACK号与接收端缓存中的其他数据之间的间隔称为“空缺”，序列号高于“空缺”的数据称为“失序数据”。一个ACK可以包含三四个告知失序数据的SACK信息，每个SACK信息包含32位序列号，代表接收端存储的失序数据的起始至最后一个序列号。
SACK接收端 第一个SACK块内包含的时最近接收到的报文段的序列号范围，其余SACK块包含的内容也按照接收的先后顺序依次排列。也就是说，最新一个块中包含的内容除了包含最近接收的序列号信息，还需要重复之前SACK块。这样可以为防止SACK丢失提供一些备份，若SACK不会丢失，每个SACK中包含一个SACK块即可实现SACK全部功能。
SACK发送端 合理利用接收到的SACK块进行丢失重传，称为选择性重传。一种方法是当接收到相应序列号范围的ACK时，则在其重传缓存中标记该报文段的选择重传成功。
当发送端收到SACK时，可以选择发送新数据或重传旧数据。通过SACK提供的序列号范围可以推断需要重传的空缺数据。最常用、最简单的方法是使发送端首先填补接收端的空缺，然后继续发送新数据。
SACK发送端不能在收到一个SACK后立即清空其重传缓存中的数据，因为接收端告诉发送端一段SACK范围，其后可能会“食言”。只有当ACK号大于缓存序列号时才能将缓存清除。
普通的重传（Timer-based和Fast Retransmit） 基于计时器的重传 基于计时器的重传需要RTT的测量值，而这个测量值的确定算法较为复杂，后文再详细描述。
当TCP发送端拿到RTT测量值，就可以设置RTO。
发送单记录需要被计时的报文段序列号，如果收到了报文的ACK，那么计时器取消；若在设定的RTO内没有收到ACK，将会触发超时重传。发送端会降低当前数据的发送率来对此快速响应：
 基于拥塞控制机制，减小发送窗口（cwnd）大小 每一个重传报文被再次重传时，增大RTO的退避因子：RTO=γRTO，其中γ初始为1，随着重传加倍增长：2、4、8等。一旦接收到ACK则重置为1。  下面再来说一下RTT的测量，RTT即round-trip time，TCP接收端在收到数据后会返回确认信息，因此可以在这个信息中携带一个字节的数据来测量传输该确认信息所需的时间。每个测量结果称为RTT样本。TCP需要根据一段时间内的样本建立好估计值，再根据估计值设置RTO。
经典方法采用如下公式计算得到平滑的RTT估计值（SRTT）：
SRTT ← α(SRTT) + (1 − α) RTTs&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 基于现存值和新的RTTs得到更新结果，常量α为平滑因子。
标准方法采用如下算式，其中M代表RTT测量值（前面称RTTs）：
tt ← (1 - g)(srtt) + (g)M rttvar ← (1 - h)(rttvar) + (h)(|M - srtt|) RTO = srtt + 4(rttvar)&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 快速重传 快速重传机制基于接收端的反馈信息来引发重传，更加及时有效修复丢包情况。当接收到失序报文段时，TCP需要立即生成确认信息（重复ACK）。重复ACK到达发送端表明先前发送的某个分组已经丢失，当然也可能仅是失序到达。通常我们无法区分，TCP等待一定数目（duptresh）的重复ACK后，就决定数据是否丢失并触发快速重传。
Nagle算法与延时ACK Nagle 假设有如下场景：每次TCP的数据部分非常小，TCP头部和IP头部体积固定为40字节，那么这些小包因为有效的应用数据占比甚微，就会造成很高的网络传输代价。
John Nagle提出了一种算法，当一个TCP连接中有在传数据，则长度小于SMSS的报文段都不能发送，直到所有在传数据收到ACK。并且，在ACK后，TCP需要收集这些小的数据，将其整合到一个报文段中发送。
在Nagle开启下，传输的包数量更少，但是长度更大，同时传输时延也更长。
延时确认 TCP并不是对每个到来的数据包都返回ACK，通常会积累一段时间发送TCP，减少ACK传输数目。对于批量数据传输通常为2:1的比例。
结合 如果直接将Nagle和延时ACK结合，接收端会尝试等待，看是否有更多的ACK可以捎带进行应答，而发送端因为Nagle的存在，在没有接收到ACK前不能进行发送，就会产生死锁。死锁在延时ACK计时器超时后就会解除，但是在死锁期间传输连接处于空闲状态，性能会变差。</description>
			<content type="html"><![CDATA[<p>春节假期期间补充学习的内容，查缺补漏，先从TCP开始。</p>
<h2 id="选择确认的重传sack">选择确认的重传（SACK）</h2>
<p>TCP头部包含一个可选的选项变量，如图所示：</p>
<p><img src="../2020/01/tcp_option.jpg" alt="">
其中可以用来填充以下内容：</p>
<p><img src="../2020/01/tcp_option_list.jpg" alt="">
在数据传输过程中，因为TCP抵达的顺序是不予保证的，因此接收方必然会有收到乱序数据的情况。</p>
<p>在没有SACK的情况下，接收方在缺失数据时，会一直进行ACK并附带期望的SEQ，发送方在重复（duptrash常量，默认3次）收到同一个序列号时会断定有包在传输过程中丢失，然后进行重传。</p>
<p>如果TCP发送方能够了解接收方当前的空洞，它就能在报文段丢失或者接收方遗漏的时候更好地进行重传工作，且减少不必要的重传。在丢包严重的情况下，SACK可以在一个RTT内填补多个空缺。</p>
<p>ACK号与接收端缓存中的其他数据之间的间隔称为“空缺”，序列号高于“空缺”的数据称为“失序数据”。一个ACK可以包含三四个告知失序数据的SACK信息，每个SACK信息包含32位序列号，代表接收端存储的失序数据的<strong>起始至最后一个序列号</strong>。</p>
<h3 id="sack接收端">SACK接收端</h3>
<p>第一个SACK块内包含的时最近接收到的报文段的序列号范围，其余SACK块包含的内容也按照接收的先后顺序依次排列。也就是说，最新一个块中包含的内容除了包含最近接收的序列号信息，还需要重复之前SACK块。这样可以为防止SACK丢失提供一些备份，若SACK不会丢失，每个SACK中包含一个SACK块即可实现SACK全部功能。</p>
<h3 id="sack发送端">SACK发送端</h3>
<p>合理利用接收到的SACK块进行丢失重传，称为选择性重传。一种方法是当接收到相应序列号范围的ACK时，则在其重传缓存中标记该报文段的选择重传成功。</p>
<p>当发送端收到SACK时，可以选择发送新数据或重传旧数据。通过SACK提供的序列号范围可以推断需要重传的空缺数据。最常用、最简单的方法是使发送端首先填补接收端的空缺，然后继续发送新数据。</p>
<p>SACK发送端不能在收到一个SACK后立即清空其重传缓存中的数据，因为接收端告诉发送端一段SACK范围，其后可能会“食言”。只有当ACK号大于缓存序列号时才能将缓存清除。</p>
<h2 id="普通的重传timer-based和fast-retransmit">普通的重传（Timer-based和Fast Retransmit）</h2>
<h3 id="基于计时器的重传">基于计时器的重传</h3>
<p>基于计时器的重传需要RTT的测量值，而这个测量值的确定算法较为复杂，后文再详细描述。</p>
<p>当TCP发送端拿到RTT测量值，就可以设置RTO。</p>
<p>发送单记录需要被计时的报文段序列号，如果收到了报文的ACK，那么计时器取消；若在设定的RTO内没有收到ACK，将会触发超时重传。发送端会降低当前数据的发送率来对此快速响应：</p>
<ul>
<li>基于拥塞控制机制，减小发送窗口（cwnd）大小</li>
<li>每一个重传报文被再次重传时，增大RTO的退避因子：RTO=γRTO，其中γ初始为1，随着重传加倍增长：2、4、8等。一旦接收到ACK则重置为1。</li>
</ul>
<p>下面再来说一下RTT的测量，RTT即round-trip time，TCP接收端在收到数据后会返回确认信息，因此可以在这个信息中携带一个字节的数据来测量传输该确认信息所需的时间。每个测量结果称为RTT样本。TCP需要根据一段时间内的样本建立好估计值，再根据估计值设置RTO。</p>
<p>经典方法采用如下公式计算得到平滑的RTT估计值（SRTT）：</p>
<pre><code>SRTT ← α(SRTT) + (1 − α) RTTs&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>基于现存值和新的RTTs得到更新结果，常量α为平滑因子。</p>
<p>标准方法采用如下算式，其中M代表RTT测量值（前面称RTTs）：</p>
<pre><code>tt ← (1 - g)(srtt) + (g)M
rttvar ← (1 - h)(rttvar) + (h)(|M - srtt|)
RTO = srtt + 4(rttvar)&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="快速重传">快速重传</h3>
<p>快速重传机制基于接收端的反馈信息来引发重传，更加及时有效修复丢包情况。当接收到失序报文段时，TCP需要立即生成确认信息（重复ACK）。重复ACK到达发送端表明先前发送的某个分组已经丢失，当然也可能仅是失序到达。通常我们无法区分，TCP等待一定数目（duptresh）的重复ACK后，就决定数据是否丢失并触发快速重传。</p>
<h2 id="nagle算法与延时ack">Nagle算法与延时ACK</h2>
<h3 id="nagle">Nagle</h3>
<p>假设有如下场景：每次TCP的数据部分非常小，TCP头部和IP头部体积固定为40字节，那么这些小包因为有效的应用数据占比甚微，就会造成很高的网络传输代价。</p>
<p>John Nagle提出了一种算法，当一个TCP连接中有在传数据，则长度小于SMSS的报文段都不能发送，直到所有在传数据收到ACK。并且，在ACK后，TCP需要收集这些小的数据，将其整合到一个报文段中发送。</p>
<p><img src="../2020/01/tcp_nagle.jpg" alt="">
在Nagle开启下，传输的包数量更少，但是长度更大，同时传输时延也更长。</p>
<h3 id="延时确认">延时确认</h3>
<p>TCP并不是对每个到来的数据包都返回ACK，通常会积累一段时间发送TCP，减少ACK传输数目。对于批量数据传输通常为2:1的比例。</p>
<h3 id="结合">结合</h3>
<p>如果直接将Nagle和延时ACK结合，接收端会尝试等待，看是否有更多的ACK可以捎带进行应答，而发送端因为Nagle的存在，在没有接收到ACK前不能进行发送，就会产生死锁。死锁在延时ACK计时器超时后就会解除，但是在死锁期间传输连接处于空闲状态，性能会变差。</p>
<p>某些情况下，例如ssh传输，就可以禁用Nagle算法。</p>
<h2 id="拥塞控制">拥塞控制</h2>
<p>反映网络传输能力的变量称为拥塞窗口（congestion window），记作cwnd，通告窗口（advertisement window）记为awnd，实际发送端可用的窗口为：</p>
<pre><code>W = min(cwnd, awnd)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>因此还没有收到ACK回复的数据量（称为在外数据值）不能多于W。</p>
<p>然而cwnd、awnd等值需要动态调节，因此并不能准确获取。W值不能过大或过小，我们希望有一个最佳窗口大小。</p>
<h3 id="获得cwnd">获得cwnd</h3>
<p>获得最佳值的方法是以越来越快的速度发送数据，直到出现数据丢失或网络阻塞。一般可以以awnd启动或者慢速启动，因为直接以awnd启动会影响其他连接性能，所以通常避免过快启动。</p>
<h3 id="慢启动">慢启动</h3>
<p>一个新的TCP连接建立或者检测到重传超时导致的丢包时，需要执行慢启动。慢启动的目的是让TCP使用拥塞避免探寻更多带宽前得到cwnd值，以及帮助TCP建立ACK时钟。</p>
<p>TCP在SYN后开始慢启动，称为初始窗口（Initial Window，IW）。初始值设为一个SMSS值或稍大。假设没有出现丢包，第一个数据段的ACK到达，慢启动算法会以min(N, SMSS)来增加cwnd值。N是指在传输数据中通过这一ACK确认的字节数（不包括ACK号小于之前收到ACK号的数据）。</p>
<p>那么在接收到1个数据段的ACK后，cwnd就会变为2，发送2个数据段。在接收到对应的新ACK后，cwnd就会变为4，以此类推。</p>
<p><img src="../2020/01/tcp_slow_start.jpg" alt="">
然而因为ACK并不是每一次都会累积发送端一次发送的包进行ACK，例如，发送端在cwnd变为4后，发送了4个包，而接收端在接收前两个包后进行ACK（长度为2），接收到后两个包后进行ACK（长度也为2），那么此时min(N, SMSS)因为N为2个MSS，并非发出去的4个MSS，所以cwnd = cwnd + 2，而不是 cwnd = cwnd * 2的指数增长。具体见下图的两种增长曲线：</p>
<h3 id="拥塞避免">拥塞避免</h3>
<p>通过慢启动，cwnd会快速增长，帮助建立一个慢启动阈值。一旦确定慢启动阈值，TCP会进入拥塞避免阶段，cwnd每次增长值近似于成功传输的数据段大小。更准确说，每接收一个新的ACK，cwnd会做一下更新：</p>
<pre><code>nd(t+1) = cwnd(t) + SMSS * SMSS/cwnd(t)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>通常认为，拥塞避免阶段窗口随时间线性增长，慢启动阶段呈指数增长。</p>
<p>当cwnd &lt; ssthresh，使用慢启动算法；反之使用拥塞避免。</p>
<p>慢启动阈值在重传时按照下式改变：</p>
<pre><code>thresh = max(flight size/2, 2*SMSS)&lt;/code&gt;&lt;/pre&gt;
</code></pre>]]></content>
		</item>
		
		<item>
			<title>[翻译] UUID方案很受欢迎，但是于性能不利</title>
			<link>https://jiekun.dev/posts/2019-12-28-%E7%BF%BB%E8%AF%91-uuid%E6%96%B9%E6%A1%88%E5%BE%88%E5%8F%97%E6%AC%A2%E8%BF%8E%E4%BD%86%E6%98%AF%E4%BA%8E%E6%80%A7%E8%83%BD%E4%B8%8D%E5%88%A9/</link>
			<pubDate>Sat, 28 Dec 2019 10:23:47 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-28-%E7%BF%BB%E8%AF%91-uuid%E6%96%B9%E6%A1%88%E5%BE%88%E5%8F%97%E6%AC%A2%E8%BF%8E%E4%BD%86%E6%98%AF%E4%BA%8E%E6%80%A7%E8%83%BD%E4%B8%8D%E5%88%A9/</guid>
			<description>在网上搜索UUID方案和MySQL，你能查到一大堆结果，比如：
 存储UUID和Generated Columns 在MySQL中存储UUID值 InnoDB中的主键模型及它们对磁盘使用的影响 MySQL UUID Smackdown: UUID与整型的主键对比 GUID/UUID性能突破 用还是不用UUID？  所以对于资料如此完善的话题还需要更多讨论吗？很明显是要的。尽管很多文章都是提醒人们少用UUID方案，但它们还是很受欢迎。受欢迎的原因是UUID值可以很方便地由远程设备生成，并且冲突概率非常低。这篇文章里我的目标是总结其他人写的内容，并且尽可能提出一些新的观点。
什么是UUID方案？ UUID即全局唯一标识符（Universally Unique IDentifier），在RFC 4122定义。它的格式是128位，16进制，由“-”分割成5部分。典型的UUID值如下：
yves@laptop:~$ uuidgen 83fda883-86d9-4913-9729-91f20973fa52&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 官方来说，一共有5类UUID值，版本1-5,但最常见的是：基于时间的版本（版本1或版本2）和纯随机的版本（版本3）。基于时间的UUID方案将1970年1月1日以来的10ns数量编码成7.5字节（60位），分割为“time-low”-“time-mid”-“time-hi”的样式。空缺的4位是用在time-hi段作为prefix。这样前三段的64位就定下来了。后两段是时间序列即一个随时间改动而增加的值，和宿主唯一标识符（host unique identifier）。大多数时候，当前宿主网络的MAC地址都会被用来当作唯一标识符。
在使用基于时间的UUID时，有几个重要的点需要考虑：
 在前三段的值生成后，就可以用来确认大致的时间 在连续的UUID值中会有大量重复的段 第一段“time-low”每过429秒就会耗尽重置 MySQL UUID函数产生的是版本1的值  以下是使用“uuidgen”Unix工具产生的基于时间的UUID值：
yves@laptop:~$ for i in $(seq 1 500); do echo &amp;quot;$(date +%s): $(uuidgen -t)&amp;quot;; sleep 1; done 1573656803: 572e4122-0625-11ea-9f44-8c16456798f1 1573656804: 57c8019a-0625-11ea-9f44-8c16456798f1 1573656805: 586202b8-0625-11ea-9f44-8c16456798f1 ... 1573657085: ff86e090-0625-11ea-9f44-8c16456798f1 1573657086: 0020a216-0626-11ea-9f44-8c16456798f1 ... 1573657232: 56b943b2-0626-11ea-9f44-8c16456798f1 1573657233: 57534782-0626-11ea-9f44-8c16456798f1 1573657234: 57ed593a-0626-11ea-9f44-8c16456798f1 ...&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 第一段的值（在t=1573657086）重置，第二段值会增加。每过大约429秒就会在第一段看到类似的值。第三段值每年变1次。最后一段值在同一台的宿主机上是固定的，就是我的笔记本上的MAC地址：</description>
			<content type="html"><![CDATA[<p>在网上搜索UUID方案和MySQL，你能查到一大堆结果，比如：</p>
<ul>
<li><a href="https://www.percona.com/blog/2017/05/03/uuid-generated-columns/">存储UUID和Generated Columns</a></li>
<li><a href="https://www.percona.com/blog/2014/12/19/store-uuid-optimized-way/">在MySQL中存储UUID值</a></li>
<li><a href="https://www.percona.com/blog/2015/04/03/illustrating-primary-key-models-in-innodb-and-their-impact-on-disk-usage/">InnoDB中的主键模型及它们对磁盘使用的影响</a></li>
<li><a href="http://www.mysqltutorial.org/mysql-uuid/">MySQL UUID Smackdown: UUID与整型的主键对比</a></li>
<li><a href="http://mysql.rjweb.org/doc.php/uuid">GUID/UUID性能突破</a></li>
<li><a href="https://www.percona.com/blog/2007/03/13/to-uuid-or-not-to-uuid/">用还是不用UUID？</a></li>
</ul>
<p>所以对于资料如此完善的话题还需要更多讨论吗？很明显是要的。尽管很多文章都是提醒人们少用UUID方案，但它们还是很受欢迎。受欢迎的原因是UUID值可以很方便地由远程设备生成，并且冲突概率非常低。这篇文章里我的目标是总结其他人写的内容，并且尽可能提出一些新的观点。</p>
<h2 id="什么是uuid方案">什么是UUID方案？</h2>
<p>UUID即全局唯一标识符（Universally Unique IDentifier），在<a href="https://tools.ietf.org/html/rfc4122">RFC 4122</a>定义。它的格式是128位，16进制，由“-”分割成5部分。典型的UUID值如下：</p>
<pre><code>yves@laptop:~$ uuidgen 
83fda883-86d9-4913-9729-91f20973fa52&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>官方来说，一共有5类UUID值，版本1-5,但最常见的是：基于时间的版本（版本1或版本2）和纯随机的版本（版本3）。基于时间的UUID方案将1970年1月1日以来的10ns数量编码成7.5字节（60位），分割为“time-low”-“time-mid”-“time-hi”的样式。空缺的4位是用在time-hi段作为prefix。这样前三段的64位就定下来了。后两段是时间序列即一个随时间改动而增加的值，和宿主唯一标识符（host unique identifier）。大多数时候，当前宿主网络的MAC地址都会被用来当作唯一标识符。</p>
<p>在使用基于时间的UUID时，有几个重要的点需要考虑：</p>
<ul>
<li>在前三段的值生成后，就可以用来确认大致的时间</li>
<li>在连续的UUID值中会有大量重复的段</li>
<li>第一段“time-low”每过429秒就会耗尽重置</li>
<li>MySQL UUID函数产生的是版本1的值</li>
</ul>
<p>以下是使用“uuidgen”Unix工具产生的基于时间的UUID值：</p>
<pre><code>yves@laptop:~$ for i in $(seq 1 500); do echo &quot;$(date +%s): $(uuidgen -t)&quot;; sleep 1; done
1573656803: 572e4122-0625-11ea-9f44-8c16456798f1
1573656804: 57c8019a-0625-11ea-9f44-8c16456798f1
1573656805: 586202b8-0625-11ea-9f44-8c16456798f1
...
1573657085: ff86e090-0625-11ea-9f44-8c16456798f1
1573657086: 0020a216-0626-11ea-9f44-8c16456798f1
...
1573657232: 56b943b2-0626-11ea-9f44-8c16456798f1
1573657233: 57534782-0626-11ea-9f44-8c16456798f1
1573657234: 57ed593a-0626-11ea-9f44-8c16456798f1
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>第一段的值（在t=1573657086）重置，第二段值会增加。每过大约429秒就会在第一段看到类似的值。第三段值每年变1次。最后一段值在同一台的宿主机上是固定的，就是我的笔记本上的MAC地址：</p>
<pre><code>yves@laptop:~$ ifconfig | grep ether | grep 8c
      ether 8c:16:45:67:98:f1  txqueuelen 1000  (Ethernet)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>另一种常见的UUID版本是版本4，纯随机。默认情况下，Unix“uuidgen”工具生成的是版本4的UUID值：</p>
<pre><code>yves@laptop:~$ for i in $(seq 1 3); do uuidgen; done
6102ef39-c3f4-4977-80d4-742d15eefe66
14d6e343-028d-48a3-9ec6-77f1b703dc8f
ac9c7139-34a1-48cf-86cf-a2c823689a91&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>唯一重复的值是版本“4”，在第三段的开头。其余的124位都是随机的。</p>
<h2 id="uuid值有什么问题">UUID值有什么问题？</h2>
<p>为了理解UUID用作主键的影响，首先要复习一下InnoDB是如何组织数据的。InnoDB将表中的行存储在主键的B树中，在数据库中我们称之为聚簇索引。聚簇索引自动将数据行按主键顺序排列。</p>
<p>当你插入一行随机主键值的数据，InnoDB需要找到这行应该属于哪一页，如果页没在缓冲池中则将其加载进缓冲池，插入数据行，最后将脏页刷回磁盘。纯随机值加上大表使得B树上的每个叶子节点都有机会插入行，而没有热点数据页。数据行不按照主键顺序（译注：主键顺序指主键顺序的末端）插入会导致页的分裂，进一步导致页的填充因子降低。在缓冲池中，有新数据插入的页称为脏页。而缓冲池中的页在被刷回磁盘前再次有新数据需要写入的概率很低。所以大部分时间中，每次插入操作会导致两次IO过程——一次读取和一次写入。所以首先UUID会对IO操作的比例造成影响，而这个又是伸缩性的主要限制因素。</p>
<p>获得高性能的唯一方法就是使用低延迟和高耐久的存储介质。然而这又是一个对性能造成影响的因素。因为聚簇索引的存在，辅助索引需要使用主键值作为指针。主键B树的叶子节点存储数据行，而辅助索引的叶子节点存储主键值。</p>
<p>我们假定有一个UUID作主键的表，并且有5个辅助索引，一共10亿行数据。如果你读了前面的段落，你会知道每行主键值被存了6次。也就是说一共6亿的36字节字符串值，216GB。这只是冰山一角而已，因为表通常还会有外键，显式或者隐式地指向其他表。当表是基于UUID设计的时候，列或者索引需要以<code>char(36)</code>来容纳数据。最近我分析了一个基于UUID的表，发现70%的存储空间都用来存放UUID值。</p>
<p>不止这些，UUID还有第三点影响。整型在CPU中一次性可以比较8字节，而UUID是逐字节比较的。数据库很少会受限于CPU性能，但是不管怎么样这都会提高查询的延迟。如果你不信，来看看整型和字符串的性能对比：</p>
<pre><code>mysql&gt; select benchmark(100000000,2=3);
+--------------------------+
| benchmark(100000000,2=3) |
+--------------------------+
|                        0 |
+--------------------------+
1 row in set (0.96 sec)

mysql&gt; select benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='df878007-80da-11e9-93dd-00163e000003');
+----------------------------------------------------------------------------------------------------+
| benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='df878007-80da-11e9-93dd-00163e000003') |
+----------------------------------------------------------------------------------------------------+
|                                                                                                  0 |
+----------------------------------------------------------------------------------------------------+
1 row in set (27.67 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>当然，上面的例子是最坏的情况，但也体现出两者的差距。整型的比对能比字符串型快28倍。而且就算字符串从第一位就开始不同，测试仍比整型慢2.5倍：</p>
<pre><code>mysql&gt; select benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='ef878007-80da-11e9-93dd-00163e000003');
+----------------------------------------------------------------------------------------------------+
| benchmark(100000000,'df878007-80da-11e9-93dd-00163e000002'='ef878007-80da-11e9-93dd-00163e000003') |
+----------------------------------------------------------------------------------------------------+
|                                                                                                  0 |
+----------------------------------------------------------------------------------------------------+
1 row in set (2.45 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>下面我们来看下这些问题的几种解决方案。</p>
<h2 id="值的长度">值的长度</h2>
<p>UUID、哈希、token值一般都是十六进制的形式。因此每一字节的可能情况有16种，这远算不上高效。如果用其他形式会怎么样呢，比如base64或者直接用二进制？节约了多少空间？性能影响怎么样？</p>
<p>首先我们来尝试改用base64。每一字节有64种情况，所以base64需要用3个字节来表示真实值的2个字节。UUID值包含16字节的数据，除以3余数是1，所以base64编码后末尾加了“=”。</p>
<pre><code>mysql&gt; select to_base64(unhex(replace(uuid(),'-','')));
+------------------------------------------+
| to_base64(unhex(replace(uuid(),'-',''))) |
+------------------------------------------+
| clJ4xvczEeml1FJUAJ7+Fg==                 |
+------------------------------------------+
1 row in set (0.00 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>如果被编码的内容长度已知，像UUID，也可以直接把无用的“==”移除。UUID编码成base64之后长度为22。</p>
<p>下一个尝试是将数据存储为二进制。这是最优方案但是对于用户来说值的可读性较差。</p>
<p>所以，长度对性能的影响如何？为了战士说明，我向如下表中插入随机的，未转成其他编码的UUID值：</p>
<pre><code>CREATE TABLE `data_uuid` (
  `id` char(36) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>而对base64，id列定义为<code>char(22)</code>，二进制的id列定义为<code>binary(16)</code>。数据库服务器的缓冲池大小为128M，IOPs限制至500。插入均以单线程操作。</p>
<p><img src="../2019/12/001-zhujiekun-rates_vs_sizes.png" alt="">
此场景下，写入速率开始时受CPU性能限制，随着表的增大超过缓冲池大小，写入速率变为受IO限制。这和预期的一样。使用更小长度的值代替UUID使得更多的行可以放入缓冲池中，但长远来看，因为随机插入顺序的原因，对性能的帮助很小。如果你在使用随机UUID作为主键，那么性能将受限于内存大小。</p>
<h2 id="方案1使用伪随机顺序节省iops">方案1：使用伪随机顺序节省IOPs</h2>
<p>如我们所见，最大的问题是值的随机性。任何一个叶子节点都有可能插入新数据行。所以除非整个表都加载到缓冲池，不然每次插入都会等同于一次读IO和一次写IO。我的同事David Ducos给出了一个<a href="https://www.percona.com/blog/2017/05/03/uuid-generated-columns/">好的解决方案</a>，但是一些客户不希望看到UUID值有被反解的可能性，比如说通过值获取到一个时间戳。</p>
<p>那按照固定时间间隔内在几个字节上使用同样的prefix来减少随机性又如何？在这段时间内，表中只有某一部分可以对应得上这个prefix，这部分会被放入内存以减少读IO。这样可以提高某个页在刷回磁盘前收到第二次写请求的可能性，降低写入负载。考虑下面的UUID生成方案：</p>
<pre><code>function if exists f_new_uuid; 
delimiter ;;
CREATE DEFINER=`root`@`%` FUNCTION `f_new_uuid`() RETURNS char(36)
    NOT DETERMINISTIC
BEGIN
    DECLARE cNewUUID char(36);
    DECLARE cMd5Val char(32);


    set cMd5Val = md5(concat(rand(),now(6)));
    set cNewUUID = concat(left(md5(concat(year(now()),week(now()))),4),left(cMd5Val,4),'-',
        mid(cMd5Val,5,4),'-4',mid(cMd5Val,9,3),'-',mid(cMd5Val,13,4),'-',mid(cMd5Val,17,12));

    RETURN cNewUUID;
END;;
limiter ;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>UUID的前四个字符由当前年和周的值MD5得到。这个值会在一周内都保持不变。剩余的UUID值通过MD5一个随机值和1us精度的当前时间生成。第三段以“4”开头，意味着这是版本4的UUID。一共有65536种可能的前缀，所以一周内只有表的1/65536行会被读取到内存，避免插入时的读IO压力。这让管理更加容易，1TB的表只需要16MB存放在缓冲池中就能支撑起插入操作。</p>
<h2 id="方案2">方案2：</h2>
<p>即使使用伪随机的UUID值，以<code>binary(16)</code>存储，这还是个很大的数据类型，会让数据的体积暴涨。要记得InnoDB中主键值是辅助索引的指针。那如果用一张映射表来存储UUID值会怎么样？映射表定义如下：</p>
<pre><code>CREATE TABLE `uuid_to_id` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `uuid` char(36) NOT NULL,
  `uuid_hash` int(10) unsigned GENERATED ALWAYS AS (crc32(`uuid`)) STORED NOT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_hash` (`uuid_hash`)
) ENGINE=InnoDB AUTO_INCREMENT=2590857 DEFAULT CHARSET=latin1;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>要注意<code>uuid_to_id</code>表并没有要求uuid列值唯一。<code>idx_hash</code>索引更像是作为一个布隆过滤器使用。如果没有匹配中，我们可以知道UUID值不存在表上。但如果有匹配中的话，我们还需要去检验是否真的有匹配的UUID。为了完成这点，我们写一个SQL函数：</p>
<pre><code>DELIMITER ;;
CREATE DEFINER=`root`@`%` FUNCTION `f_uuid_to_id`(pUUID char(36)) RETURNS int(10) unsigned
    DETERMINISTIC
BEGIN
        DECLARE iID int unsigned;
        DECLARE iOUT int unsigned;

        select get_lock('uuid_lock',10) INTO iOUT;

        SELECT id INTO iID
        FROM uuid_to_id WHERE uuid_hash = crc32(pUUID) and uuid = pUUID;

        IF iID IS NOT NULL THEN
            select release_lock('uuid_lock') INTO iOUT;
            SIGNAL SQLSTATE '23000'
                SET MESSAGE_TEXT = 'Duplicate entry', MYSQL_ERRNO = 1062;
        ELSE
            insert into uuid_to_id (uuid) values (pUUID);
            select release_lock('uuid_lock') INTO iOUT;
            set iID = last_insert_id();
        END IF;

        RETURN iID;
END ;;
DELIMITER ;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>函数检查UUID值是否曾经存在在<code>uuid_to_id</code>表中，如果存在则返回对应的id至，否则插入UUID，返回<code>last_insert_id</code>。为了避免并发插入同一个UUID值，我加了一个数据库锁。数据库锁限制了方案的伸缩性。如果你的业务不允许段时间内重复提交多次，那可以把锁去掉。我也有另一个无锁版本的函数，并且使用了一个数据行仅会保存数秒的用于去重的小表。如果有兴趣可以查看我的<a href="https://github.com/y-trudeau/blog_data/tree/master/YetAnotherPostAboutUUIDs">github</a></p>
<h2 id="替代方案的测试结果">替代方案的测试结果</h2>
<p>现在让我们来看一下几种替代方案的插入速率。</p>
<p><img src="../2019/12/001-zhujiekun-alternate_solutions.png" alt="">
伪顺序的表现不错。我修改了UUID前缀的算法让它在1分钟内保持不变，而不是一周，这样更符合测试场景。但是要记住即使伪顺序的方案性能过得去，它仍会让表变得很大，性能收益也没有那么理想。</p>
<p>使用整型映射的方案，尽管插入速率更低，毕竟需要额外的DMLs，但将表从冗长的UUID值中解放了出来。表使用整型作为主键，映射关系可以将所有UUID伸缩性的担忧抛开。而且，即使是在CPU性能和IOPS受限的小型虚拟机中，UUID映射方案也达到了4000插入/秒。这意味着每小时可以写入140万行的数据，每日3450行，一年1260亿行。这样的速率应该能满足大部分需求。唯一的增长限制因素是hash索引的体积，当hash索引太大而放不进缓冲池中的时候，性能就会开始下降。</p>
<h2 id="其他非uuid的方案">其他非UUID的方案？</h2>
<p>当然，还有其他方案生成唯一ID。MySQL的<code>UUID_SHORT()</code>函数的方法就很有意思。远程设备，比如手机，可以使用UTC时间来代替服务器运行时间。例如：</p>
<pre><code>(Seconds since January 1st 1970) &amp;lt;&amp;lt; 32
+ (lower 2 bytes of the wifi MAC address) &amp;lt;&amp;lt; 16
+ 16_bits_unsigned_int++;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>16位计数器需要初始化一个随机值，并且允许耗尽后循环。两台设备生成同一ID的可能性很小，这需要发生在几乎同一时间，两个设备有着同样的低位MAC地址并且16位计数器值的也一致才行。</p>
<h2 id="备注">备注</h2>
<p>文章的所有相关数据都可以在我的<a href="https://github.com/y-trudeau/blog_data/tree/master/YetAnotherPostAboutUUIDs">github</a>找到。</p>
<h2 id="more">More</h2>
<p><a href="https://kalasearch.cn/community/tutorials/mysql-use-uuid-or-int-as-primary-key/">MySQL主键应该用UUID还是INT类型</a></p>
]]></content>
		</item>
		
		<item>
			<title>SYN Flood Attack</title>
			<link>https://jiekun.dev/posts/2019-12-26-syn-flood-attack/</link>
			<pubDate>Thu, 26 Dec 2019 14:03:53 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-26-syn-flood-attack/</guid>
			<description>什么是SYN Flood SYN Flood，又称TCP Flood，是利用TCP协议三次握手消耗目标服务器资源的DDoS攻击。客户端通过伪造SYN包，使用伪造的源IP地址，因为服务端收到请求后会对SYN进行响应——发送SYN和ACK包，但是对方的地址是伪造的因此不会响应，服务端会重试几次后丢弃这个连接。这样会导致服务端对多个伪造的SYN包在重试响应，无暇理睬正常的连接请求。
实践 初步尝试 根据定义，需要向特定服务发送大量的TCP SYN包，因此需要利用一些发包工具。通过搜索找到hping工具，作者是antirez（Redis作者）。以下是安装及文档中部分实践使用到的参数：
uck@duck-MS-7A34:~$ sudo apt install hping3 duck@duck-MS-7A34:~$ sudo hping --help usage: hping3 host [options] -i --interval wait (uX for X microseconds, for example -i u1000) --fast alias for -i u10000 (10 packets for second) --faster alias for -i u1000 (100 packets for second) --flood sent packets as fast as possible. Don&#39;t show replies. IP -a --spoof spoof source address --rand-dest random destionation address mode.</description>
			<content type="html"><![CDATA[<h2 id="什么是syn-flood">什么是SYN Flood</h2>
<p>SYN Flood，又称TCP Flood，是利用TCP协议三次握手消耗目标服务器资源的DDoS攻击。客户端通过伪造SYN包，使用伪造的源IP地址，因为服务端收到请求后会对SYN进行响应——发送SYN和ACK包，但是对方的地址是伪造的因此不会响应，服务端会重试几次后丢弃这个连接。这样会导致服务端对多个伪造的SYN包在重试响应，无暇理睬正常的连接请求。</p>
<h2 id="实践">实践</h2>
<h3 id="初步尝试">初步尝试</h3>
<p>根据定义，需要向特定服务发送大量的TCP SYN包，因此需要利用一些发包工具。通过搜索找到<a href="https://github.com/antirez/hping">hping工具</a>，作者是antirez（Redis作者）。以下是安装及文档中部分实践使用到的参数：</p>
<pre><code>uck@duck-MS-7A34:~$ sudo apt install hping3
duck@duck-MS-7A34:~$ sudo hping --help
usage: hping3 host [options]
  -i  --interval  wait (uX for X microseconds, for example -i u1000)
      --fast      alias for -i u10000 (10 packets for second)
      --faster    alias for -i u1000 (100 packets for second)
      --flood      sent packets as fast as possible. Don't show replies.
IP
  -a  --spoof      spoof source address
  --rand-dest      random destionation address mode. see the man.
  --rand-source    random source address mode. see the man.
UDP/TCP
  -s  --baseport   base source port             (default random)
  -p  --destport   [+][+]&amp;lt;port&gt; destination port(default 0) ctrl+z inc/dec
  -S  --syn        set SYN flag&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>尝试攻击部署在阿里云的个人博客：</p>
<pre><code>uck@duck-MS-7A34:~$ sudo hping3 -i u1000 -S -p 443 120.25.247.125
HPING 120.25.247.125 (enp33s0 120.25.247.125): S set, 40 headers + 0 data bytes
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=0 win=29200 rtt=15.8 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=1 win=29200 rtt=14.7 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=2 win=29200 rtt=13.6 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=3 win=29200 rtt=12.6 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=4 win=29200 rtt=11.5 ms
len=46 ip=120.25.247.125 ttl=49 DF id=0 sport=443 flags=SA seq=5 win=29200 rtt=10.5 ms
...&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>此时可以在ECS上看到网络情况，通过netstat命令查看到处于SYN_RECV的大量TCP连接，如图所示：</p>
<p><img src="../2019/12/001-zhujiekun-SYN_RECV.png" alt=""></p>
<h3 id="暴力发包">暴力发包</h3>
<p>尝试将攻击频率调快：<code>sudo hping3 -i u1 -S -p 443 120.25.247.125</code>，然后在ECS上查看当前的SYN包个数：</p>
<pre><code>uck@iZwz92ujq5zpxvm1vtq0gtZ:~$ netstat -n | grep SYN | wc -l
128&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>只有128个TCP半连接，与发包数量相差很大。猜测是系统配置限制了总TCP连接数上限或者半连接状态连接数上限。</p>
<p>通过查询相关文档，找到系统配置：</p>
<pre><code>uck@iZwz92ujq5zpxvm1vtq0gtZ:~$ vim /etc/sysctl.conf
vm.swappiness = 0
net.ipv4.neigh.default.gc_stale_time = 120

# see details in https://help.aliyun.com/knowledge_detail/39428.html
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.lo.arp_announce = 2
net.ipv4.conf.all.arp_announce = 2

# see details in https://help.aliyun.com/knowledge_detail/41334.html
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 128
net.ipv4.tcp_synack_retries = 2

net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
net.ipv6.conf.eth0.disable_ipv6 =1

kernel.sysrq = 1&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>其中一项<code>net.ipv4.tcp_max_syn_backlog = 128</code>可能是有关项，并且通过查阅文件中提供的阿里云文档，得到参数和它相关参数的具体描述：</p>
<ul>
<li><code>net.ipv4.tcp_max_syn_backlog</code>：该参数决定了系统中处于SYN_RECV状态的TCP连接数量。SYN_RECV状态指的是当系统收到SYN后，作为SYN+ACK响应后等待对方回复三次握手阶段中的最后一个ACK的阶段。对于还未获得对方确认的连接请求，可保存在队列中的最大数目。如果服务器经常出现过载，可以尝试增加这个数字。默认为1024。</li>
<li><code>net.core.somaxconn</code>：该参数定义了系统中每一个端口最大的监听队列的长度，是个全局参数。该参数和net.ipv4.tcp_max_syn_backlog有关联，后者指的是还在三次握手的半连接的上限，该参数指的是处于ESTABLISHED的数量上限。当backlog大于net.core.somaxconn时，以net.core.somaxconn参数为准。</li>
</ul>
<p>那么将他们都改成一个特别大的数值然后保存，再尝试SYN Flood，结果如下：</p>
<ul>
<li>因为发包占用了很多的流量所以本机无法SSH上ECS查看</li>
<li>通过阿里云的管理面板查看到TCP包一共64000个，其中NON_ESTABLISHED状态的包占了几乎全部数量</li>
<li>访问https的博客地址无法响应</li>
</ul>
<p><img src="../2019/12/001-zhujiekun-TCP_connection_count.png" alt=""></p>
<h3 id="持续监控">持续监控</h3>
<p>在持续发包一段时间后，发现TCP连接数下降至约500个，并且博客站点重新可以访问。因为时间原因没有尝试其他的手段，主要推测可能是现有的系统（也可能是协议层、云服务商等）对暴力SYN Flood攻击有判断和校验，丢弃特定特征的包（相同IP、端口或者其他指纹）。</p>
<p>因为ECS地理位置离测试地点较近，所以通常延迟非常低。在SYN状态TCP连接数量从64k下降到500时，站点可以进行访问但是观察到速度比原来明显缓慢，通过这点猜测DoS攻击有生效但是受限于使用的发起攻击的设备流量条件不足以拖跨服务。</p>
<h2 id="延伸思考">延伸思考</h2>
<p>因为设备条件问题，虽然可以观察到大量半连接的TCP状态，但是离DoS（Denial of Service）还是有很大的差距，消耗不完目标的网络带宽或系统资源。那是否有方案通过小流量产生大流量（放大）的攻击呢？</p>
<h3 id="memcached-ddos">Memcached DDoS</h3>
<p>当Memcached服务器接收到GET请求，它从内存获取相关信息组织起一个RESPONSE，然后通过连续的UDP包进行返回。通常来说GET请求的体积和RESPONSE的体积大小可以相差很多倍。</p>
<p>攻击者可以利用这点，先向Memcached服务器插入随机的大体积数据，然后向服务器请求。根据CloudFlare的报告，这样会导致一个巨大的流量放大倍数，例如15 byte的请求可以引起134KB的响应。当Memcached响应的对象指向攻击目标机器的时候，目标机器就会收到海量的UDP包，从而可能导致拒绝服务。</p>
]]></content>
		</item>
		
		<item>
			<title>[翻译] 理解MySQL 8中的HASH JOIN</title>
			<link>https://jiekun.dev/posts/2019-12-23-%E7%BF%BB%E8%AF%91-%E7%90%86%E8%A7%A3mysql-8%E4%B8%AD%E7%9A%84hash-join/</link>
			<pubDate>Mon, 23 Dec 2019 12:18:11 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-23-%E7%BF%BB%E8%AF%91-%E7%90%86%E8%A7%A3mysql-8%E4%B8%AD%E7%9A%84hash-join/</guid>
			<description>在MySQL 8.0.18中有个新功能叫Hash Joins。我打算研究一下它是如何运作的和在什么场景下它能够帮到我们。你可以在这里了解它的底层原理。
更上层的解释：如果使用join查询，它会基于其中一个表在内存构建一个哈希表，然后一行一行读另一个表，计算其哈希值到内存哈希表中进行查找。
很好，但性能上带给我们什么好处呢？ 首先，它只会在没有索引的字段上生效，所以它是个实时的表扫描。通常我们不推荐在没有索引的列上join查询，因为这很慢。这种情况下Hash Joins就有它的优势，因为它用的是内存哈希表而不是嵌套循环（Nested Loop）。
让我们来做些测试。首先创建如下表：
CREATE TABLE `t1` ( `id` int(11) NOT NULL AUTO_INCREMENT , `c1` int(11) NOT NULL DEFAULT &#39;0&#39;, `c2` int(11) NOT NULL DEFAULT &#39;0&#39;, PRIMARY KEY (`id`), KEY `idx_c1` (`c1`) ) ENGINE=InnoDB; CREATE TABLE `t2` ( `id` int(11) NOT NULL AUTO_INCREMENT , `c1` int(11) NOT NULL DEFAULT &#39;0&#39;, `c2` int(11) NOT NULL DEFAULT &#39;0&#39;, PRIMARY KEY (`id`), KEY `idx_c1` (`c1`) ) ENGINE=InnoDB;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 我向两个表都插入了131072行随机数据。</description>
			<content type="html"><![CDATA[<!-- raw HTML omitted -->
<p>在MySQL 8.0.18中有个新功能叫Hash Joins。我打算研究一下它是如何运作的和在什么场景下它能够帮到我们。你可以在<a href="https://dev.mysql.com/worklog/task/?id=2241">这里</a>了解它的底层原理。</p>
<p>更上层的解释：如果使用join查询，它会基于其中一个表在内存构建一个哈希表，然后一行一行读另一个表，计算其哈希值到内存哈希表中进行查找。</p>
<h2 id="很好但性能上带给我们什么好处呢">很好，但性能上带给我们什么好处呢？</h2>
<p>首先，它只会在没有索引的字段上生效，所以它是个实时的表扫描。通常我们不推荐在没有索引的列上join查询，因为这很慢。这种情况下Hash Joins就有它的优势，因为它用的是内存哈希表而不是嵌套循环（Nested Loop）。</p>
<p>让我们来做些测试。首先创建如下表：</p>
<pre><code>CREATE TABLE `t1` (
`id` int(11) NOT NULL AUTO_INCREMENT ,
`c1` int(11) NOT NULL DEFAULT '0',
`c2` int(11) NOT NULL DEFAULT '0',
PRIMARY KEY (`id`),
KEY `idx_c1` (`c1`)
) ENGINE=InnoDB;

CREATE TABLE `t2` (
`id` int(11) NOT NULL AUTO_INCREMENT ,
`c1` int(11) NOT NULL DEFAULT '0',
`c2` int(11) NOT NULL DEFAULT '0',
PRIMARY KEY (`id`),
KEY `idx_c1` (`c1`)
) ENGINE=InnoDB;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>我向两个表都插入了131072行随机数据。</p>
<pre><code>mysql&gt; select count(*) from t1;
+----------+
| count(*) |
+----------+
| 131072   |
+----------+&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="测试1-8211-hash-joins">测试1 – Hash Joins</h2>
<p>基于没有索引的表c2执行Join查询。</p>
<pre><code>mysql&gt; explain format=tree select count(*) from t1 join t2 on t1.c2 = t2.c2\G
*************************** 1. row ***************************
EXPLAIN: -&gt; Aggregate: count(0)
-&gt; Inner hash join (t2.c2 = t1.c2) (cost=1728502115.04 rows=1728488704)
-&gt; Table scan on t2 (cost=0.01 rows=131472)
-&gt; Hash
-&gt; Table scan on t1 (cost=13219.45 rows=131472)

1 row in set (0.00 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>我们使用<code>explain format=tree</code>来查看Hash Join是否生效，默认情况下(explain)会误导说这会是个嵌套循环。我已经提了<a href="https://bugs.mysql.com/bug.php?id=97299">bug report</a>，在工单中你可以看到开发者回复：</p>
<!-- raw HTML omitted -->
<p>因此在旧的explain中这不会被修复，我们要使用新的查询方式。</p>
<p>回到语句上，我们可以看到它使用Hash Join了，但性能有多快？</p>
<pre><code>mysql&gt; select count(*) from t1 join t2 on t1.c2 = t2.c2;
+----------+
| count(*) |
+----------+
| 17172231 |
+----------+
1 row in set (0.73 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>17000000多行数据，0.73秒。看起来很不错。</p>
<h2 id="测试2-8211-非hash-joins">测试2 – 非Hash Joins</h2>
<p>我们现在用优化器的开关或hint关掉Hash Join。</p>
<pre><code>mysql&gt; select /*+ NO_HASH_JOIN (t1,t2) */ count(*) from t1 join t2 on t1.c2 = t2.c2;
+----------+
| count(*) |
+----------+
| 17172231 |
+----------+
1 row in set (13 min 36.36 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>同样的查询使用了超过13分钟。非常大的差距，可以看到Hash Join性能提升明显。</p>
<h2 id="测试3-8211-索引join">测试3 – 索引Join</h2>
<p>让我们来创建索引，看看基于索引的join速度如何。</p>
<pre><code>te index idx_c2 on t1(c2);
create index idx_c2 on t2(c2);

mysql&gt; select count(*) from t1 join t2 on t1.c2 = t2.c2;
+----------+
| count(*) |
+----------+
| 17172231 |
+----------+
1 row in set (2.63 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>2.6秒。在这个测试用例中Hash Join比基于索引的Join还要快。</p>
<p>然而，我可以在索引可用的情况下，通过<code>ignore index</code>强制优化器使用Hash Join：</p>
<pre><code>mysql&gt; explain format=tree select count(*) from t1 ignore index (idx_c2) join t2 ignore index (idx_c2) on t1.c2 = t2.c2 where t1.c2=t2.c2\G
*************************** 1. row ***************************
EXPLAIN: -&gt; Aggregate: count(0)
-&gt; Inner hash join (t2.c2 = t1.c2) (cost=1728502115.04 rows=17336898)
-&gt; Table scan on t2 (cost=0.00 rows=131472)
-&gt; Hash
-&gt; Table scan on t1 (cost=13219.45 rows=131472)

1 row in set (0.00 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>我在想即使索引存在的情况下，优化器也能够根据提示使用Hash Join，这样我们就不需要在各种表上<code>ignore index</code>了。我已经提了<a href="https://bugs.mysql.com/bug.php?id=97302">feature request</a>。</p>
<p>然而，如果你有认真阅读我提的<a href="https://bugs.mysql.com/bug.php?id=97299">bug report</a>，你会看到MySQL的开发者有表明这可能是不必要的：</p>
<!-- raw HTML omitted -->
<p>这意味着他们在未来可能打算移除块钱套循环Join，使用Hash Join代替。</p>
<h2 id="限制">限制</h2>
<p>我们可以看到Hash Join很强大，但也有些限制：</p>
<ul>
<li>我提到过它只在没有索引的列上其作用（或者需要手动忽略索引）</li>
<li>只有Join条件是“=”的情况才会生效</li>
<li><code>LEFT JOIN</code>和<code>RIGHT JOIN</code>不生效</li>
</ul>
<p>我还期望看到Hash Join使用次数的统计，所以我又提了<a href="https://bugs.mysql.com/bug.php?id=97301">另一个feature request</a></p>
<h2 id="总结">总结</h2>
<p>Hash Join是个很强大的join查询方式，我们应该重点关注它，未来如果有更多Feature我也不会感到惊讶。理论上，它应该也能用来做<code>LEFT JOIN</code>和<code>RIGHT JOIN</code>，我们在bug report的评论里面也能看到Oracle在未来也打算使用Hash Join。</p>
]]></content>
		</item>
		
		<item>
			<title>[翻译] InnoDB中的页合并与分裂</title>
			<link>https://jiekun.dev/posts/2019-12-22-%E7%BF%BB%E8%AF%91-innodb%E4%B8%AD%E7%9A%84%E9%A1%B5%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E8%A3%82/</link>
			<pubDate>Sun, 22 Dec 2019 14:53:53 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-22-%E7%BF%BB%E8%AF%91-innodb%E4%B8%AD%E7%9A%84%E9%A1%B5%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E8%A3%82/</guid>
			<description>如果你找过任何一位MySQL顾问，问他对你的语句和/或数据库设计的建议，我保证他会跟你讲主键设计的重要性。特别是在使用InnoDB引擎的情景，他们肯定会给你解释索引合并和页分裂这些。这两个方面与性能息息相关，你应该在任何设计索引（不止是主键索引）的时候都将他们考虑在内。
你可能觉得这些听起来挺莫名其妙，没准你也没错。这不是容易的事，特别是讲到关于内部实现的时候。通常你都不会需要处理这些事情，并且你也不想去着手他们。
但是有时候这些问题又是必须搞清楚的。如果有这种情况，那这篇文章正适合你。
我尝试用这篇文章将一些最不清晰、InnoDB内部的操作解释清楚：索引页的创建、页合并和页分裂。
在InnoDB中，数据即索引（译注：索引组织数据）。你可能听过这种说法，但它具体是什么样的？
文件表（File-Table）结构 假设你已经装好了MySQL最新的5.7版本（译注：文章发布于17年4月），并且你创建了一个windmills库（schema）和wmills表。在文件目录（通常是/var/lib/mysql/）你会看到以下内容：
ta/ windmills/ wmills.ibd wmills.frm&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 这是因为从MySQL 5.6版本开始innodb_file_per_table参数默认设置为1。该配置下你的每一个表都会单独作为一个文件存储（如果有分区也可能有多个文件）。
目录下要注意的是这个叫wmills.ibd的文件。这个文件由多个段（segments）组成，每个段和一个索引相关。
文件的结构是不会随着数据行的删除而变化的，但段则会跟着构成它的更小一级单位——区的变化而变化。区仅存在于段内，并且每个区都是固定的1MB大小（页体积默认的情况下）。页则是区的下一级构成单位，默认体积为16KB。
按这样算，一个区可以容纳最多64个页，一个页可以容纳2-N个行。行的数量取决于它的大小，由你的表结构定义。InnoDB要求页至少要有两个行，因此可以算出行的大小最多为8000 bytes。
听起来就像俄罗斯娃娃（Matryoshka dolls）一样是么，没错！下面这张图能帮助你理解：
根，分支与叶子 每个页（逻辑上讲即叶子节点）是包含了2-N行数据，根据主键排列。树有着特殊的页区管理不同的分支，即内部节点（INodes）。
上图仅为示例，后文才是真实的结构描述。
具体来看一下：
ROOT NODE #3: 4 records, 68 bytes NODE POINTER RECORD ≥ (id=2) → #197 INTERNAL NODE #197: 464 records, 7888 bytes NODE POINTER RECORD ≥ (id=2) → #5 LEAF NODE #5: 57 records, 7524 bytes RECORD: (id=2) → (uuid=&amp;quot;884e471c-0e82-11e7-8bf6-08002734ed50&amp;quot;, millid=139, kwatts_s=1956, date=&amp;quot;2017-05-01&amp;quot;, location=&amp;quot;For beauty&#39;s pattern to succeeding men.</description>
			<content type="html"><![CDATA[<!-- raw HTML omitted -->
<p>如果你找过任何一位MySQL顾问，问他对你的语句和/或数据库设计的建议，我保证他会跟你讲主键设计的重要性。特别是在使用InnoDB引擎的情景，他们肯定会给你解释索引合并和页分裂这些。这两个方面与性能息息相关，你应该在任何设计索引（不止是主键索引）的时候都将他们考虑在内。</p>
<p>你可能觉得这些听起来挺莫名其妙，没准你也没错。这不是容易的事，特别是讲到关于内部实现的时候。通常你都不会需要处理这些事情，并且你也不想去着手他们。</p>
<p>但是有时候这些问题又是必须搞清楚的。如果有这种情况，那这篇文章正适合你。</p>
<p>我尝试用这篇文章将一些最不清晰、InnoDB内部的操作解释清楚：索引页的创建、页合并和页分裂。</p>
<p>在InnoDB中，数据即索引（译注：索引组织数据）。你可能听过这种说法，但它具体是什么样的？</p>
<h2 id="文件表file-table结构">文件表（File-Table）结构</h2>
<p>假设你已经装好了MySQL最新的5.7版本（译注：文章发布于17年4月），并且你创建了一个<code>windmills</code>库（schema）和<code>wmills</code>表。在文件目录（通常是<code>/var/lib/mysql/</code>）你会看到以下内容：</p>
<pre><code>ta/
  windmills/
      wmills.ibd
      wmills.frm&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这是因为从MySQL 5.6版本开始<code>innodb_file_per_table</code>参数默认设置为1。该配置下你的每一个表都会单独作为一个文件存储（如果有分区也可能有多个文件）。</p>
<p>目录下要注意的是这个叫<code>wmills.ibd</code>的文件。这个文件由多个段（segments）组成，每个段和一个索引相关。</p>
<p>文件的结构是不会随着数据行的删除而变化的，但段则会跟着构成它的更小一级单位——区的变化而变化。区仅存在于段内，并且每个区都是固定的1MB大小（页体积默认的情况下）。页则是区的下一级构成单位，默认体积为16KB。</p>
<p>按这样算，一个区可以容纳最多64个页，一个页可以容纳2-N个行。行的数量取决于它的大小，由你的表结构定义。InnoDB要求页至少要有两个行，因此可以算出行的大小最多为8000 bytes。</p>
<p>听起来就像俄罗斯娃娃（Matryoshka dolls）一样是么，没错！下面这张图能帮助你理解：</p>
<p><img src="../2019/12/001-zhujiekun-segment_extent-722x1024.jpg" alt=""></p>
<h2 id="根分支与叶子">根，分支与叶子</h2>
<p>每个页（逻辑上讲即叶子节点）是包含了2-N行数据，根据主键排列。树有着特殊的页区管理不同的分支，即内部节点（INodes）。</p>
<p><img src="../2019/12/001-zhujiekun-bplustree-1024x471.jpg" alt="">
上图仅为示例，后文才是真实的结构描述。</p>
<p>具体来看一下：</p>
<pre><code>ROOT NODE #3: 4 records, 68 bytes
 NODE POINTER RECORD ≥ (id=2) → #197
 INTERNAL NODE #197: 464 records, 7888 bytes
 NODE POINTER RECORD ≥ (id=2) → #5
 LEAF NODE #5: 57 records, 7524 bytes
 RECORD: (id=2) → (uuid=&quot;884e471c-0e82-11e7-8bf6-08002734ed50&quot;, millid=139, kwatts_s=1956, date=&quot;2017-05-01&quot;, location=&quot;For beauty's pattern to succeeding men.Yet do thy&quot;, active=1, time=&quot;2017-03-21 22:05:45&quot;, strrecordtype=&quot;Wit&quot;)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>下面是表结构：</p>
<pre><code>CREATE TABLE `wmills` (
  `id` bigint(11) NOT NULL AUTO_INCREMENT,
  `uuid` char(36) COLLATE utf8_bin NOT NULL,
  `millid` smallint(6) NOT NULL,
  `kwatts_s` int(11) NOT NULL,
  `date` date NOT NULL,
  `location` varchar(50) COLLATE utf8_bin DEFAULT NULL,
  `active` tinyint(2) NOT NULL DEFAULT '1',
  `time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `strrecordtype` char(3) COLLATE utf8_bin NOT NULL,
  PRIMARY KEY (`id`),
  KEY `IDX_millid` (`millid`)
) ENGINE=InnoDB;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>所有的B树都有着一个入口，也就是根节点，在上图中#3就是根节点。根节点（页）包含了如索引ID、INodes数量等信息。INode页包含了关于页本身的信息、值的范围等。最后还有叶子节点，也就是我们数据实际所在的位置。在示例中，我们可以看到叶子节点#5有57行记录，共7524 bytes。在这行信息后是具体的记录，可以看到数据行内容。</p>
<p>这里想引出的概念是当你使用InnoDB管理表和行，InnoDB会将他们会以分支、页和记录的形式组织起来。InnoDB不是按行的来操作的，它可操作的最小粒度是页，页加载进内存后才会通过扫描页来获取行/记录。</p>
<p>现在页的结构清楚了吗？好，我们继续。</p>
<h2 id="页的内部原理">页的内部原理</h2>
<p>页可以空或者填充满（100%），行记录会按照主键顺序来排列。例如在使用<code>AUTO_INCREMENT</code>时，你会有顺序的ID 1、2、3、4等。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_1.jpg" alt="">
页还有另一个重要的属性：<code>MERGE_THRESHOLD</code>。该参数的默认值是50%页的大小，它在InnoDB的合并操作中扮演了很重要的角色。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_2.jpg" alt="">
当你插入数据时，如果数据（大小）能够放的进页中的话，那他们是按顺序将页填满的。</p>
<p>若当前页满，则下一行记录会被插入下一页（NEXT）中。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_4.jpg" alt="">
根据B树的特性，它可以自顶向下遍历，但也可以在各叶子节点水平遍历。因为每个叶子节点都有着一个指向包含下一条（顺序）记录的页的指针。</p>
<p>例如，页#5有指向页#6的指针，页#6有指向前一页（#5）的指针和后一页（#7）的指针。</p>
<p>这种机制下可以做到快速的顺序扫描（如范围扫描）。之前提到过，这就是当你基于自增主键进行插入的情况。但如果你不仅插入还进行删除呢？</p>
<h2 id="页合并">页合并</h2>
<p>当你删了一行记录时，实际上记录并没有被物理删除，记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_3.jpg" alt="">
当页中删除的记录达到<code>MERGE_THRESHOLD</code>（默认页体积的50%），InnoDB会开始寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_4.jpg" alt="">
在示例中，页#6使用了不到一半的空间，页#5又有足够的删除数量，现在同样处于50%使用以下。从InnoDB的角度来看，它们能够进行合并。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_5.jpg" alt="">
合并操作使得页#5保留它之前的数据，并且容纳来自页#6的数据。页#6变成一个空页，可以接纳新数据。</p>
<p><img src="../2019/12/001-zhujiekun-Locality_6.jpg" alt="">
如果我们在UPDATE操作中让页中数据体积达到类似的阈值点，InnoDB也会进行一样的操作。</p>
<p>规则就是：页合并发生在删除或更新操作中，关联到当前页的相邻页。如果页合并成功，在<code>INFOMATION_SCHEMA.INNODB_METRICS</code>中的<code>index_page_merge_successful</code>将会增加。</p>
<h2 id="页分裂">页分裂</h2>
<p>前面提到，页可能填充至100%，在页填满了之后，下一页会继续接管新的记录。但如果有下面这种情况呢？</p>
<p><img src="../2019/12/001-zhujiekun-Locality_7.jpg" alt="">
页#10没有足够空间去容纳新（或更新）的记录。根据“下一页”的逻辑，记录应该由页#11负责。然而：</p>
<p><img src="../2019/12/001-zhujiekun-Locality_9.jpg" alt="">
页#11也同样满了，数据也不可能不按顺序地插入。怎么办？</p>
<p>还记得之前说的链表吗（译注：指B+树的每一层都是双向链表）？页#10有指向页#9和页#11的指针。</p>
<p>InnoDB的做法是（简化版）：</p>
<ol>
<li>创建新页</li>
<li>判断当前页（页#10）可以从哪里进行分裂（记录行层面）</li>
<li>移动记录行</li>
<li>重新定义页之间的关系</li>
</ol>
<p><img src="../2019/12/001-zhujiekun-Locality_8.jpg" alt="">
新的页#12被创建：</p>
<p><img src="../2019/12/001-zhujiekun-Locality_10.jpg" alt="">
页#11保持原样，只有页之间的关系发生了改变：</p>
<ul>
<li>页#10相邻的前一页为页#9，后一页为页#12</li>
<li>页#12相邻的前一页为页#10，后一页为页#11</li>
<li>页#11相邻的前一页为页#10，后一页为页#13</li>
</ul>
<p>（译注：页#13可能本来就有，这里意思为页#10与页#11之间插入了页#12）</p>
<p>这样B树水平方向的一致性仍然满足，因为满足原定的顺序排列逻辑。然而从物理存储上讲页是乱序的，而且大概率会落到不同的区。</p>
<p>规律总结：页分裂会发生在插入或更新，并且造成页的错位（dislocation，落入不同的区）</p>
<p>InnoDB用<code>INFORMATION_SCHEMA.INNODB_METRICS</code>表来跟踪页的分裂数。可以查看其中的<code>index_page_splits</code>和<code>index_page_reorg_attempts/successful</code>统计。</p>
<p>一旦创建分裂的页，唯一（译注：实则仍有其他方法，见下文）将原先顺序恢复的办法就是新分裂出来的页因为低于合并阈值（merge threshold）被删掉。这时候InnoDB用页合并将数据合并回来。</p>
<p>另一种方式就是用<code>OPTIMIZE</code>重新整理表。这可能是个很重量级和耗时的过程，但可能是唯一将大量分布在不同区的页理顺的方法。</p>
<p>另一方面，要记住在合并和分裂的过程，InnoDB会在索引树上加写锁（x-latch）。在操作频繁的系统中这可能会是个隐患。它可能会导致索引的锁争用（index latch contention）。如果表中没有合并和分裂（也就是写操作）的操作，称为“乐观”更新，只需要使用读锁（S）。带有合并也分裂操作则称为“悲观”更新，使用写锁（X）。</p>
<h2 id="我的主键">我的主键</h2>
<p>好的主键不仅对于数据查找很重要，而且也影响写操作时数据在区上的分布（也就是与页分裂和页合并操作相关）。</p>
<p>在第一个测试中我使用的是是自增主键，第二个测试主键是基于一个1-200的ID与自增值的，第三个测试也是1-200的ID不过与UUID联合。</p>
<p>插入操作时，InnoDB需要增加页，视为“分裂”操作：</p>
<p><img src="../2019/12/001-zhujiekun-split_1.jpg" alt="">
表现因不同主键而异。</p>
<p>在头两种情况中数据的分布更为紧凑，也就是说他们拥有更好的空间利用率。对比半随机（semi-random）特性的UUID会导致明显的页稀疏分布（页数量更多，相关分裂操作更多）。</p>
<p>在页合并的情况中，尝试合并的次数因主键类型的不同而表现得更加不一致。</p>
<p><img src="../2019/12/001-zhujiekun-merges_1-1024x542.jpg" alt="">
在插入-更新-删除操作中，自增主键有更少的合并尝试次数，成功比例比其他两种类型低9.45%。UUID型主键（图表的右一侧）有更多的合并尝试，但是合并成功率明显更高，达22.34%，因为数据稀疏分布让很多页都有部分空闲空间。</p>
<p>在辅助索引与上面主键索引相似的情况下，测试的表现也是类似的。</p>
<h2 id="总结">总结</h2>
<p>MySQL/InnoDB不断地进行这些操作，你可能只能了解到很少的信息。但他们可能给你造成伤害，特别是比起用SSD，你还在用传统的机械存储（spindle storage）的时候（顺便提一下SSD会有另外的问题）。</p>
<p>坏消息就是我们用什么参数或者魔法去改变服务端。但好消息是我们可以在设计的时候做很多（有帮助）的事。</p>
<p>恰当地使用主键和设计辅助索引，并且记住不要滥用（索引）。如果你已经预计到会有很多插入/删除/更新操作，规划一个合适的时间窗来管理（整理）表。</p>
<p>有个很重要的点，InnoDB中你不会有断断续续的行记录，但是你会在页-区的维度上遇到这些问题。忽略表的管理工作会导致需要在IO层面、内存层面和InnoDB缓冲池层面做更多工作。</p>
<p>你必须不时（at regular intervals）重建一些表。可以采用一些技巧，比如分区和外部的工具（pt-osc）。不要让表变得过大和过于碎片化（fragmented）。</p>
<p>磁盘空间浪费？需要读多个表去获取需要的数据而不是一次搞定？每次搜索导致明显更多的读操作？那是你的锅，不要找借口！</p>
<p>Happy MySQL to everyone!</p>
<h2 id="感谢">感谢</h2>
<p>Laurynas Biveinis: 感谢花时间向我解释一些内部实现。</p>
<p>Jeremy Cole: 感谢他的项目<a href="https://github.com/jeremycole/innodb_ruby">InnoDB_ruby</a> (我经常用上）。</p>
]]></content>
		</item>
		
		<item>
			<title>InnoDB——锁、事务和复制</title>
			<link>https://jiekun.dev/posts/2019-12-16-innodb-%E9%94%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%A4%8D%E5%88%B6/</link>
			<pubDate>Mon, 16 Dec 2019 13:17:56 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-16-innodb-%E9%94%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%A4%8D%E5%88%B6/</guid>
			<description>锁 数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。
InnoDB存储引擎中的锁  共享锁（S Lock），允许事务读一行数据 排他锁（X Lock），允许事务删除或更新一行数据  兼容性：
 S与S可以兼容 X不与任何锁兼容  InnoDB支持多粒度锁定，也就是允许行级和表级的锁同时存在。实现方式为通过意向锁（Intention Lock）：如果需要对最细粒度进行加锁，需要在上层粒度加意向锁。
具体举例，如果需要对行加X锁，需要对表、页依次加IX锁。当意向锁遇到等待时，必须等待结束后才能继续对下级加锁。如准备加对一行有S锁的行加S锁，行记录因为原来就有S锁，所以表和页都已经存在了IS锁，首先新的IS锁加在表上，因为IS、IS锁兼容，可以加上；然后再看页锁，同样IS、IS兼容，可以加上；最后看行锁IS与S兼容，那么行记录可以加上S锁。对同样这行有S锁的行加X锁，先加表IX锁，IX与IS兼容，可以加上，页同样，最后IX锁与行记录上的S锁不兼容，因此要等待S锁释放后才能加上X锁。
一致性非锁定读 一致性非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi version）的方式来读取当前执行时间数据库中行的数据。在行记录正在执行DELETE或UPDATE时执行读操作，不会等待锁释放，而是会去读undo段中的行的快照数据。
在不同的事务隔离级别下，读取方式不同，不是每个事务隔离级别都采用非锁定的一致性读，即使使用CNR，对快照数据的定义也不一样。快照数据就是undo段中的历史版本，一行记录可能有多个版本，一般称为行多版本技术，由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control，MVCC）。
在事务隔离级别READ COMMITTED下，非一致性读总是读取被锁定行的最新一份快照数据，而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。
表中所示的事务执行过程，在READ COMMITED中会话A可以SELECT到0个id=1的结果，因为已经被会话B所更新；而在REPEATABLE READ中因为读取的是事务开始前的快照，因此结果不会发生变化（可重复读）。
一致性锁定读 REPEATABLE READ隔离级别下，InnoDB的SELECT操作使用一致性非锁定读，但支持两种一致性锁定读操作：
 SELECT…FOR UPDATE (X Lock) SELECT…LOCK IN SHARE MODE (S Lock)  锁的算法 InnoDB存储引擎有3种行锁的算法：
 Record Lock：单个行记录上的锁 Gap Lock：间隙锁，锁定一个范围，但不包括记录本身 Next-Key Lock：Gap Lock+Record Lock，锁定一个范围和记录本身  InnoDB对于行的查询都是采用Next-Key Lock，例如索引有10，11，13，和20，那么可锁定的区间有：
 (-∞, 10] (10, 11] (11, 13] (13, 20] (20, +∞)  Next-Key Lock的设计是为了解决Phantom Problem。除了Next-Key Lock还有Previous-Key Lock，区别在于区间的开闭。</description>
			<content type="html"><![CDATA[<h1 id="锁">锁</h1>
<p>数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。</p>
<h2 id="innodb存储引擎中的锁">InnoDB存储引擎中的锁</h2>
<ul>
<li>共享锁（S Lock），允许事务读一行数据</li>
<li>排他锁（X Lock），允许事务删除或更新一行数据</li>
</ul>
<p>兼容性：</p>
<ul>
<li>S与S可以兼容</li>
<li>X不与任何锁兼容</li>
</ul>
<p>InnoDB支持多粒度锁定，也就是允许行级和表级的锁同时存在。实现方式为通过意向锁（Intention Lock）：如果需要对最细粒度进行加锁，需要在上层粒度加意向锁。</p>
<p>具体举例，如果需要对行加X锁，需要对表、页依次加IX锁。当意向锁遇到等待时，必须等待结束后才能继续对下级加锁。如准备加对一行有S锁的行加S锁，行记录因为原来就有S锁，所以表和页都已经存在了IS锁，首先新的IS锁加在表上，因为IS、IS锁兼容，可以加上；然后再看页锁，同样IS、IS兼容，可以加上；最后看行锁IS与S兼容，那么行记录可以加上S锁。对同样这行有S锁的行加X锁，先加表IX锁，IX与IS兼容，可以加上，页同样，最后IX锁与行记录上的S锁不兼容，因此要等待S锁释放后才能加上X锁。</p>
<h3 id="一致性非锁定读">一致性非锁定读</h3>
<p>一致性非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi version）的方式来读取当前执行时间数据库中行的数据。在行记录正在执行DELETE或UPDATE时执行读操作，不会等待锁释放，而是会去读undo段中的行的快照数据。</p>
<p>在不同的事务隔离级别下，读取方式不同，不是每个事务隔离级别都采用非锁定的一致性读，即使使用CNR，对快照数据的定义也不一样。快照数据就是undo段中的历史版本，一行记录可能有多个版本，一般称为行多版本技术，由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control，MVCC）。</p>
<p>在事务隔离级别READ COMMITTED下，非一致性读总是读取被锁定行的最新一份快照数据，而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-16-19-28-11.png" alt="">
表中所示的事务执行过程，在READ COMMITED中会话A可以SELECT到0个id=1的结果，因为已经被会话B所更新；而在REPEATABLE READ中因为读取的是事务开始前的快照，因此结果不会发生变化（可重复读）。</p>
<h3 id="一致性锁定读">一致性锁定读</h3>
<p>REPEATABLE READ隔离级别下，InnoDB的SELECT操作使用一致性非锁定读，但支持两种一致性锁定读操作：</p>
<ul>
<li>SELECT…FOR UPDATE (X Lock)</li>
<li>SELECT…LOCK IN SHARE MODE (S Lock)</li>
</ul>
<h2 id="锁的算法">锁的算法</h2>
<p>InnoDB存储引擎有3种行锁的算法：</p>
<ul>
<li>Record Lock：单个行记录上的锁</li>
<li>Gap Lock：间隙锁，锁定一个范围，但不包括记录本身</li>
<li>Next-Key Lock：Gap Lock+Record Lock，锁定一个范围和记录本身</li>
</ul>
<p>InnoDB对于行的查询都是采用Next-Key Lock，例如索引有10，11，13，和20，那么可锁定的区间有：</p>
<ul>
<li>(-∞, 10]</li>
<li>(10, 11]</li>
<li>(11, 13]</li>
<li>(13, 20]</li>
<li>(20, +∞)</li>
</ul>
<p>Next-Key Lock的设计是为了解决Phantom Problem。除了Next-Key Lock还有Previous-Key Lock，区别在于区间的开闭。</p>
<pre><code>CREATE TABLE z(a INT,b INT,PRIMARY KEY(a),KEY(b));
INSERT INTO z SELECT 1,1;
INSERT INTO z SELECT 3,1;
INSERT INTO z SELECT 5,3;
INSERT INTO z SELECT 7,6;
INSERT INTO z SELECT 10,8;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>现在z表中有如下数据：</p>
<pre><code>mysql&gt; SELECT * FROM z;
+----+------+
| a  | b    |
+----+------+
|  1 |    1 |
|  3 |    1 |
|  5 |    3 |
|  7 |    6 |
| 10 |    8 |
+----+------+&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>开启一个事务，锁定b=3行：</p>
<pre><code>mysql&gt; SELECT * FROM z WHERE b=3 FOR UPDATE;
+---+------+
| a | b    |
+---+------+
| 5 |    3 |
+---+------+
1 row in set (0.00 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>由于Next-Key Lock的存在，现在在辅助索引上3所处的区间被上锁，也就是(1,3]。需要注意的是InnoDB还会对3的下一个区间加上gap lock，也就是(3,6)。那么此时如果往这些区间内做其他操作会被阻塞：</p>
<pre><code>mysql&gt; INSERT INTO z SELECT 6,5;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在列a上由于是唯一索引列，Next-Key Lock会降级为Record Lock，因此在索引a上的锁定只针对a=5这一行。</p>
<p>Gap Lock的作用是为了阻止多个事务将记录插入到同一范围内，这会导致Phantom Problem的产生。</p>
<p>InnoDB只在能够定位到唯一行的情况下将Next-Key Lock降级为Record Lock，也就是特别需要强调唯一索引由多个列组成的情况，查询其中部分列仍会使用Next-Key Lock。</p>
<p>Phantom Problem是指在同一事务下，连续执行两次SQL会导致不同的结果，第二次的SQL语句会返回之前不存在的行。</p>
<pre><code>+---+
| a |
+---+
| 1 |
+---+
| 2 |
+---+
| 5 |
+---+
SELECT * FROM t WHERE a&gt;2 FOR UPDATE;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>Next-Key Locking这里锁住的不仅仅是a=5这个行，而是锁定(2,+∞)这个范围，因此此时如果使用的是REPEATABLE READ的话是无法向这个范围内INSERT数据的，不会存在Phantom Problem。而如果是COMMITTED READ则允许写入，例如下次执行的时候可能就会新增了一条a=4的记录。</p>
<h2 id="锁问题">锁问题</h2>
<ul>
<li>脏读，就是在读到另一个事务中未提交的数据，违反数据库的隔离性</li>
<li>不可重复读，事务内读取同一数据集合，由于另一个事务的修改，事务两次读到的数据可能是不一样的，违反了数据库事务一致性的要求</li>
<li>丢失更新，在事务中不使用SELECT…FOR UPDATE的查询，在SELECT和UPDATE之间由其他事务进行了SELECT，在UPDATE COMMIT之后，其他事务也进行UPDATE（基于它自己的SELECT结果）和COMMIT，那么就相当与地一个事务的UPDATE没有其作用，需要操作串行化或者FOR UPDATE加锁解决</li>
</ul>
<h2 id="死锁">死锁</h2>
<p>死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。</p>
<p>死锁举例：</p>
<ul>
<li>A SELECT a=1 FOR UPDATE</li>
<li>B SELECT a=2 FOR UPDATE</li>
<li>A SELECT a=2 FOR UPDATE（阻塞，等待B释放）</li>
<li>B SELECT a=1 FOR UPDATE（阻塞，等待A释放）</li>
</ul>
<p>在InnoDB中会话A会得到记录为2的这个资源，因为B会被因死锁而回滚。</p>
<h2 id="锁升级">锁升级</h2>
<p>Lock Escalation是指将当前锁的粒度降低，如将1000个行锁升级为一个页锁。InnoDB不存在锁升级问题。</p>
<h1 id="事务">事务</h1>
<p>InnoDB中的事务完全符合ACID特性：</p>
<ul>
<li>原子性（atomicity）</li>
<li>一致性（consistency）</li>
<li>隔离性（isolation）</li>
<li>持久性（durability）</li>
</ul>
<p>通过在事务中使用<code>SAVE WORK</code>函数可以建立保存点。保存点可以通过<code>ROLLBACK WORK: n</code>来回滚。</p>
<h2 id="事务的实现">事务的实现</h2>
<p>事务的隔离性由上一章讲的锁来实现。原子性、一致性、持久性通过数据库的redo log和undo log来完成。redo log称为重做日志，用来保证事务的原子性和持久性；undo log用来保证事务的一致性。</p>
<p>redo log和undo log不是相互的逆过程，redo log是物理日志，而undo log是操作的逆向操作，是逻辑日志。</p>
<h3 id="redo">redo</h3>
<p>redo log是用来实现事务的持久性，即ACID中的D，由内存中的redo log buffer和磁盘的redo log file组成。</p>
<p>当事务提交时，必须将所有日志写入重做日志文件进行持久化，待事务的COMMIT操作完成才算完成。重做日志指的是redo log和undo log，redo log是用来保证事务的吃就行，undo log用来帮助事务回滚及MVCC的功能。redo log基本顺序写，而undo log是需要进行随机读写的。</p>
<p>在每次将重做日志缓冲写入重做日志文件后，InnoDB都调用一次fsync操作，确保日志写入重做日志文件。磁盘性能决定了事务提交的性能。</p>
<p>在数据库中还有一种二进制日志（binlog），用来进行POINT-IN-TIME的恢复和主从复制环境的建立。redo log是在InnoDB存储引擎层产生，bin log是在MySQL数据库的上层产生，并且不只是对InnoDB引擎的；同时bin log是逻辑日志，记录的是对应的SQL语句，redo log是物理格式的日志，记录的是每个页的修改；binlog只在事务提交完成后一次写入，redo log在事务进行中不断地被写入，因此redo log不是随事务提交的顺序进行写入的。</p>
<p>redo log是物理日志，因此它是幂等的，而bin log由于是逻辑日志，如INSERT等操作不是幂等的，所以它不能被重复执行。</p>
<h3 id="undo">undo</h3>
<p>在对数据库进行修改时，InnoDB存储引擎不但会产生redo，还会产生一定量的undo。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。</p>
<p>与redo log放在文件不同，undo放在数据库内部的一个特殊段中，称为undo段，位于共享表空间中。</p>
<p>undo是逻辑日志，回滚时修改会被逻辑地取消，数据结构和页本身在回滚之后可能不太相同，因为这个过程中可能有其他并发的事务，因此不能将一个页回滚到事务开始的样子。InnoDB回滚时实际上是做与之前相反的工作，例如对于INSERT会回滚一个DELETE操作。</p>
<p>undo除了回滚以外的另一个作用是MVCC，若记录被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读。</p>
<p>undo log会产生redo log，因为undo log也需要持久性的保护。</p>
<p>事务提交后不能马上删除undo log及undo log所在的页，因为可能还有其他事务需要通过undo log得到行记录之前的版本。事务提交时会将undo log放入一个链表，是否可删除由purge线程来判断。</p>
<h3 id="purge">purge</h3>
<pre><code>DELETE FROM t WHERE a=1;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>DELETE操作仅是将主键列中等于1的记录delete flag设为1,记录还存在在B+树上。purge用于最终完成delete和update操作，因为MVCC所以记录不能立即处理。若该行记录已经不被其他任何事务引用，那么就可以进行真正的DELETE操作。</p>
<h3 id="group-commit">group commit</h3>
<p>事务非只读的话，需要在提交时执行fsync操作，保证重做日志都写入磁盘。但是fsync性能是有限的，为了提高效率，数据库提供了group commit功能，一次fsync可以刷新确保多个事务日志写入文件。</p>
<p>BLGC是指：</p>
<ul>
<li>Flush阶段，将每个事务的bin log写入内存</li>
<li>Sync阶段，将内存的bin log刷到磁盘，若有多个事务，通过一次fsync完成bin log的写入（BLGC）</li>
<li>Commit阶段，leader根据顺序调用存储引擎层事务的提交</li>
</ul>
<h1 id="复制">复制</h1>
<p>复制是MySQL数据库提供的一种高可用高性能的解决方案。因为不是InnoDB实现，所以使用来传递数据的文件不是redo log而是bin log：</p>
<ul>
<li>主服务器将数据更改记录到bin log中</li>
<li>从服务器将bin log复制到自己的中继日志（relay log）中</li>
<li>从服务器重做中继日志中的日志，把更改应用到自己的数据库上，达到数据的最终一致性</li>
</ul>
<p>从服务器有两个线程，一个是I/O线程，负责读取主服务器的二进制日志，并将其保存为relay log，一个是SQL线程，负责执行relay log。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-16-21-12-53.png" alt=""></p>
]]></content>
		</item>
		
		<item>
			<title>InnoDB——架构、日志、表和索引</title>
			<link>https://jiekun.dev/posts/2019-12-15-innodb-%E6%9E%B6%E6%9E%84%E6%97%A5%E5%BF%97%E8%A1%A8%E5%92%8C%E7%B4%A2%E5%BC%95/</link>
			<pubDate>Sun, 15 Dec 2019 13:40:15 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-12-15-innodb-%E6%9E%B6%E6%9E%84%E6%97%A5%E5%BF%97%E8%A1%A8%E5%92%8C%E7%B4%A2%E5%BC%95/</guid>
			<description>前言 写这篇博文是为了将自己学习完InnoDB的内容梳理一遍。InnoDB是个很复杂很庞大的存储引擎，其中的细节显然是不可能通过一篇文章或者笔记完整地描述出来的，所以这里主要目的是“补漏”，也就是将以前学习MySQL没有了解到的InnoDB“专属”的内容进行梳理和记录。
学习的主要来源是姜承尧老师的《MySQL技术内幕——InnoDB存储引擎》一书，国内除了这本书以外，也鲜有对InnoDB进行详细介绍的书籍。应用固然重要，但是正确理解技术本身才能够从根本上解决问题。最近这段时间看的技术向的书不少，其中不乏一些夸夸其谈，滥竽充数的书，尤其在架构设计书中最为明显，部分作者直接使用官方文档的图文翻译来填充内容，如果没有个人观点和核心的代码剖析，这些书就是IT书架上的混子。当然，从姜老师这本书可以读得出来，代码、配图和很多细节的描述都是出自一个有多年技术积累的专家之手，在现在大量浑水摸鱼的IT图书市场上就显得特别的宝贵。
有几句话姜老师在前言中提及到，我认为特别重要：
 不要相信任何的“神话”，学会自己思考 不要墨守成规，大部分人都知道的事情可能是错误的 不要相信网上的传言，去测试，根据自己的实践做出决定 花时间充分地思考，敢于提出质疑  这些都是作为开发者特别需要做到的，所以花时间充分地思考，是我在这篇博客最想做到的事情，希望能够通过思考真正掌握书中的内容。
InnoDB架构模型 内存池：
 维护所有进程/线程需要访问的多个内部数据结构 缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里缓存 redo log缓冲  后台线程：
 负责刷新内存池中的数据，保证缓冲池中的内存缓存是最近的数据 将修改的数据文件刷到磁盘文件 保证发生异常的情况下InnoDB能够恢复到正常运行状态  内存 缓冲池 设置原因：CPU与磁盘速度之间的鸿沟。
在数据库中读取页的操作，先从磁盘读取到缓冲池中，读取相同页的时候判断是否在缓冲池中直接命中。
缓冲池中缓存的数据页类型有：
 索引页 数据页 undo页 insert buffer 自适应哈希索引 引擎的锁信息 数据字典信息  缓冲池允许有多个，通过参数配置，默认为1。
LRU List、Free List、Flush List 最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。
InnoDB中设置了midpoint位置，读取到新的页，虽然是“Recently Used”，但是先插入到midpoint位置而不是前端，默认配置下处于LRU列表长度的5/8处，midpoint前的列表称为new列表，midpoint后的列表称为old列表。使用midpoint优化的原因是在读取页的时候，因为会导致尾端的页被刷出LRU列表，如果直接在前端插入大量的页（一般为索引或扫描操作）会将LRU列表大量页刷出，而这部分插入的操作可能仅是一次性的，因此需要先将这些页放在midpoint位置，然后后续如果确实频繁使用再加入LRU列表的热端。
Free列表表示可用的页，如果Free列表有可用的空闲页，就会将页从Free列表中删除、加入LRU列表中；如果没有，则要从LRU列表尾端淘汰，将内存分配给新的页。可以理解成LRU长度增加，Free长度就减少，Free没有的时候还需要插页面就需要从LRU淘汰。
在LRU列表中的页被修改后，称为dirty page，缓冲区与磁盘中的数据不一致，这时候通过CHECKPOINT机制刷回磁盘，Flush列表中的页即为脏页列表，脏页既存在于LRU列表中也存在与Flush列表中，前者保证页的可用性，后者管理页刷回磁盘。
Checkpoint Checkpoint是为了解决：
 缩短数据库的恢复时间，宕机后不需要重做所有日志，而是从Checkpoint开始 缓冲池不够用时，溢出尾端页，若为脏页，将脏页刷新回磁盘 redo log不需要时，会被覆盖重用；需要使用就会强制产生Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置  InnoDB使用LSN（Log Sequence Number）来标记版本，Checkpoint也有LSN。
Checkpint有两种：
 Sharp Checkpoint，发生在数据库关闭时将所有脏页数据刷新回磁盘 Fuzzy Checkpoint，刷新部分脏页回磁盘  Fuzzy Checkpoint发生在：</description>
			<content type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>写这篇博文是为了将自己学习完InnoDB的内容梳理一遍。InnoDB是个很复杂很庞大的存储引擎，其中的细节显然是不可能通过一篇文章或者笔记完整地描述出来的，所以这里主要目的是“补漏”，也就是将以前学习MySQL没有了解到的InnoDB“专属”的内容进行梳理和记录。</p>
<p>学习的主要来源是姜承尧老师的《MySQL技术内幕——InnoDB存储引擎》一书，国内除了这本书以外，也鲜有对InnoDB进行详细介绍的书籍。应用固然重要，但是正确理解技术本身才能够从根本上解决问题。最近这段时间看的技术向的书不少，其中不乏一些夸夸其谈，滥竽充数的书，尤其在架构设计书中最为明显，部分作者直接使用官方文档的图文翻译来填充内容，如果没有个人观点和核心的代码剖析，这些书就是IT书架上的混子。当然，从姜老师这本书可以读得出来，代码、配图和很多细节的描述都是出自一个有多年技术积累的专家之手，在现在大量浑水摸鱼的IT图书市场上就显得特别的宝贵。</p>
<p>有几句话姜老师在前言中提及到，我认为特别重要：</p>
<ul>
<li>不要相信任何的“神话”，学会自己思考</li>
<li>不要墨守成规，大部分人都知道的事情可能是错误的</li>
<li>不要相信网上的传言，去测试，根据自己的实践做出决定</li>
<li>花时间充分地思考，敢于提出质疑</li>
</ul>
<p>这些都是作为开发者特别需要做到的，所以花时间充分地思考，是我在这篇博客最想做到的事情，希望能够通过思考真正掌握书中的内容。</p>
<h1 id="innodb架构模型">InnoDB架构模型</h1>
<p><img src="../2019/12/Screenshot-from-2019-12-15-13-59-54.png" alt="">
内存池：</p>
<ul>
<li>维护所有进程/线程需要访问的多个内部数据结构</li>
<li>缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里缓存</li>
<li>redo log缓冲</li>
</ul>
<p>后台线程：</p>
<ul>
<li>负责刷新内存池中的数据，保证缓冲池中的内存缓存是最近的数据</li>
<li>将修改的数据文件刷到磁盘文件</li>
<li>保证发生异常的情况下InnoDB能够恢复到正常运行状态</li>
</ul>
<h2 id="内存">内存</h2>
<p><img src="../2019/12/Screenshot-from-2019-12-15-14-10-04.png" alt=""></p>
<h3 id="缓冲池">缓冲池</h3>
<p>设置原因：CPU与磁盘速度之间的鸿沟。</p>
<p>在数据库中读取页的操作，先从磁盘读取到缓冲池中，读取相同页的时候判断是否在缓冲池中直接命中。</p>
<p>缓冲池中缓存的数据页类型有：</p>
<ul>
<li>索引页</li>
<li>数据页</li>
<li>undo页</li>
<li>insert buffer</li>
<li>自适应哈希索引</li>
<li>引擎的锁信息</li>
<li>数据字典信息</li>
</ul>
<p>缓冲池允许有多个，通过参数配置，默认为1。</p>
<h3 id="lru-listfree-listflush-list">LRU List、Free List、Flush List</h3>
<p>最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。</p>
<p>InnoDB中设置了<code>midpoint</code>位置，读取到新的页，虽然是“Recently Used”，但是先插入到midpoint位置而不是前端，默认配置下处于LRU列表长度的5/8处，midpoint前的列表称为new列表，midpoint后的列表称为old列表。使用midpoint优化的原因是在读取页的时候，因为会导致尾端的页被刷出LRU列表，如果直接在前端插入大量的页（一般为索引或扫描操作）会将LRU列表大量页刷出，而这部分插入的操作可能仅是一次性的，因此需要先将这些页放在midpoint位置，然后后续如果确实频繁使用再加入LRU列表的热端。</p>
<p>Free列表表示可用的页，如果Free列表有可用的空闲页，就会将页从Free列表中删除、加入LRU列表中；如果没有，则要从LRU列表尾端淘汰，将内存分配给新的页。可以理解成LRU长度增加，Free长度就减少，Free没有的时候还需要插页面就需要从LRU淘汰。</p>
<p>在LRU列表中的页被修改后，称为dirty page，缓冲区与磁盘中的数据不一致，这时候通过<code>CHECKPOINT</code>机制刷回磁盘，Flush列表中的页即为脏页列表，脏页既存在于LRU列表中也存在与Flush列表中，前者保证页的可用性，后者管理页刷回磁盘。</p>
<h2 id="checkpoint">Checkpoint</h2>
<p>Checkpoint是为了解决：</p>
<ul>
<li>缩短数据库的恢复时间，宕机后不需要重做所有日志，而是从Checkpoint开始</li>
<li>缓冲池不够用时，溢出尾端页，若为脏页，将脏页刷新回磁盘</li>
<li>redo log不需要时，会被覆盖重用；需要使用就会强制产生Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置</li>
</ul>
<p>InnoDB使用LSN（Log Sequence Number）来标记版本，Checkpoint也有LSN。</p>
<p>Checkpint有两种：</p>
<ul>
<li>Sharp Checkpoint，发生在数据库关闭时将所有脏页数据刷新回磁盘</li>
<li>Fuzzy Checkpoint，刷新部分脏页回磁盘</li>
</ul>
<p>Fuzzy Checkpoint发生在：</p>
<ul>
<li>Master Thread Checkpoint，以每秒或者每10秒的速度刷新一定比例的脏页回磁盘</li>
<li>FLUSH_LRU_LIST Checkpoint，为了保证LRU列表有空闲页（数量可配置）可供使用</li>
<li>Async/Sync Flush Checkpoint，定义：</li>
</ul>
<pre><code>ync_water_mark = 75% * total_redo_log_file_size
sync_water_mark = 90% * total_redo_log_file_size&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在checkpoint age（redo_lsn – checkpoint_lsn）大于async水位的时候触发Async Flush，大于sync水位的时候触发Sync Flush，保证刷完后age小于async水位</p>
<h2 id="master-thread">Master Thread</h2>
<p>InnoDB主要工作都是在Master Thread中完成的，内部由多个循环组成：</p>
<ul>
<li>主循环（loop）</li>
<li>后台循环（background loop）</li>
<li>刷新循环（flush loop）</li>
<li>暂停循环（suspend loop）</li>
</ul>
<p>主循环执行每秒操作和每10秒操作。每秒操作包括：</p>
<ul>
<li>日志缓冲刷新到磁盘，即使事务还没提交（总是，因此再大的事务提交时间也很短）</li>
<li>合并插入缓冲（可能，IO小于5% innodb_io_capacity的时候执行）</li>
<li>至多刷新innodb_io_capacity个InnoDB的缓冲池中的脏页到磁盘（可能，判断阈值）</li>
<li>如果上一步没有超过阈值，又开启了自适应刷新，通过函数判断合适的数量脏页刷新到磁盘</li>
<li>如果用户没有活动，切到后台循环（可能）</li>
</ul>
<p>每10秒操作包括：</p>
<ul>
<li>刷新100个脏页到磁盘（可能，IO小于200次的时候执行）</li>
<li>合并至多5% innodb_io_capacity插入缓冲（总是）</li>
<li>将日志缓冲刷新到磁盘（总是）</li>
<li>删除无用的undo页（总是，因为undo页需要保留给MVCC，如果确认无用会在这里删除掉）</li>
<li>刷新innodb_io_capacity个或10% innodb_io_capacity个脏页到磁盘（总是，判断脏页比例，如果超过70%刷innodb_io_capacity个，小于70%刷10% innodb_io_capacity个）</li>
</ul>
<p>后台循环操作包括：</p>
<ul>
<li>删除无用的undo页（总是）</li>
<li>合并innodb_io_capacity个插入缓冲（总是）</li>
<li>跳回到主循环（总是）</li>
<li>不断刷新innodb_io_capacity个页直到符合条件（可能，在flush loop完成）</li>
</ul>
<p>如果flush loop也没有事情可以做，切换到suspend loop，挂起Master Thread，等待事件发生。</p>
<p>伪代码：</p>
<pre><code>void master_thread() {
  goto loop;
  loop：
  for (int i = 0; i &amp;lt; 10; i++) {
    thread_sleep(1) //sleep 1 second
    do log buffer flush to disk
    if (last_one_second_ios &amp;lt; 5 % innodb_io_capacity)
      do merge 5 % innodb_io_capacity insert buffer
      if (buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct)
        do buffer pool flush 100 % innodb_io_capacity dirty page
    else if enable adaptive flush
    do buffer pool flush desired amount dirty page
    if (no user activity)
      goto backgroud loop
  }
  if (last_ten_second_ios &amp;lt; innodb_io_capacity)
    do buffer pool flush 100 % innodb_io_capacity dirty page
    do merge 5 % innodb_io_capacity insert buffer
    do log buffer flush to disk
    do full purge
    if (buf_get_modified_ratio_pct &gt; 70 % )
      do buffer pool flush 100 % innodb_io_capacity dirty page
  else
    dobuffer pool flush 10 % innodb_io_capacity dirty page
  goto loop
  background loop:
    do full purge
    do merge 100 % innodb_io_capacity insert buffer
    if not idle:
    goto loop:
    else :
      goto flush loop
  flush loop:
    do buffer pool flush 100 % innodb_io_capacity dirty page
    if (buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct)
      go to flush loop
  goto suspend loop
  suspend loop:
    suspend_thread()
  waiting event
  goto loop;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="innodb关键特性">InnoDB关键特性</h2>
<h3 id="insert-buffer">Insert Buffer</h3>
<p>插入缓冲和数据页一样，也是物理页的一个组成部分。</p>
<p>在B+树上数据是按照聚集索引的值顺序存放的，在非聚集索引中插入数据则是离散的，因此随机读取导致插入性能下降。InnoDB在非聚集索引的插入或者更新操作时，不是一次直接插入索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在则直接插入，若不在则放到一个Insert Buffer对象中，再通过一定频率进行Insert Buffer和辅助索引页子节点的merge操作，这样通常能够将多个插入合并到一个操作中（因为在同一个索引页中），提高非聚集索引的插入性能。</p>
<p>Insert Buffer的使用需要同时满足两个条件：</p>
<ul>
<li>索引是辅助索引</li>
<li>索引不是唯一的</li>
</ul>
<p>Insert Buffer在发生宕机的时候因为没有合并到非聚集索引中去，恢复可能需要很长时间。同时索引不是唯一的目的是为了避免去非聚集索引中判断唯一性，如果需要判断那么就需要离散读取，Insert Buffer就失去了意义。</p>
<p>InnoDB从1.0.x版本引入Change Buffer作为升级，对INSERT、DELETE、UPDATE操作都进行缓冲，对应Insert Buffer、Delete Buffer、Purge Buffer。对记录的Update操作分为两个过程：标记删除、真正删除，Delete Buffer对应第一个过程，Purge Buffer对应第二个过程。</p>
<p>Merge Insert Buffer可能发生在以下几种情况：</p>
<ul>
<li>辅助索引页被读取到缓冲池时，如执行SELECT操作时，检查Insert Buffer Bitmap页确认该辅助索引页是否有记录存放在Insert Buffer B+树中</li>
<li>Insert Buffer Bitmap页追查到该辅助索引页已经没有可用空间（小于1/32页）时，强制一个读取辅助索引页进行合并</li>
<li>Master Thread</li>
</ul>
<h3 id="两次写">两次写</h3>
<p>在写某个页到表中时发生宕机，页只写了部分，称为部分写失效。redo log是物理操作的记录，如偏移量800,写’aaaa’，因为页本身发生损坏，所以重做没有意义，因此需要一个页的副本，通过页的副本还原页，再进行重做，这就是doublewrite。</p>
<p>在对缓冲池的脏页进行刷新时，并不直接写磁盘，通过memcpy将脏页先复制到doublewrite buffer，之后通过doublewrite buffer分两次，每次1MB顺序地写入共享表空间的物理磁盘上，然后调用fsync函数同步磁盘，避免缓冲写带来的问题。</p>
<h3 id="自适应哈希索引">自适应哈希索引</h3>
<p>构造AHI（Adaptive Hash Index）的要求是对页的连续访问模式必须是一样的，并且以该模式访问了100次，页通过该模式访问了N次，N=页中记录/16。</p>
<h3 id="异步io">异步IO</h3>
<p>用户请求可能需要扫描多个索引页，进行多次IO操作。在扫描完一个页后进行下一次扫描是没有必要的，用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后等待所有IO操作完成，这就是AIO。</p>
<p>AIO的优势是可以进行IO Merge操作，将连续的IO操作合并为1个IO请求。</p>
<h3 id="刷新邻接页">刷新邻接页</h3>
<p>当刷新一个脏页时，InnoDB会检测该页所在的区（extent）的所有页，如果是脏页，则一起进行刷新，通过AIO可以合并成一个IO操作。</p>
<h1 id="文件">文件</h1>
<p>组成MySQL和InnoDB的文件有很多类：</p>
<ul>
<li>参数文件</li>
<li>日志文件</li>
<li>socket文件</li>
<li>pid文件</li>
<li>MySQL表结构文件</li>
<li>存储引擎文件</li>
</ul>
<h2 id="二进制日志">二进制日志</h2>
<p>binary log记录了对MySQL数据库执行更改的所有操作，但是不包括SELECT和SHOW这类操作，但是操作没有导致数据库发生变化也可能会被写入bin log中，如UPDATE结果为<code>0 row affected</code>的语句。</p>
<p>bin log主要有以下作用：</p>
<ul>
<li>恢复</li>
<li>复制</li>
<li>审计</li>
</ul>
<p>当使用事务的表存储引擎时，所有未提交的bin log会被记录到一个缓存中去，等待事务提交时将缓存中的日志写入bin log文件，缓存默认大小为32k，并且是基于session的，也就是说MySQL会给不同session分配不同的缓存，因此缓存不能设置太大；当bin log超过缓存大小时，会被写入临时文件中去，因此该值也不能设置得太小。</p>
<p>如果当前数据库是slave角色，它不会将从master取得并执行的bin log写入自己的bin log中去，通过配置也可以开启写入以实现master-&gt;slave-&gt;slave的架构。</p>
<p>binlog_format控制bin log的格式，可以为STATMENT、ROW和MIXED：</p>
<ul>
<li>STATMENT格式记录的是SQL语句</li>
<li>ROW记录表的行更改情况</li>
<li>MIXED默认使用STATMENT格式，一些情况下使用ROW格式</li>
</ul>
<h2 id="innodb表空间文件">InnoDB表空间文件</h2>
<p>InnoDB将存储的数据按照tablespace存放，默认10MB、名为ibdata1的文件，设置innodb_data_file_path后所有基于InnoDB的表的数据都会记录到该tablespace中，若设置了innodb_file_per_table，每个InnoDB的表都会产生一个独立的表空间：表名.ibd。</p>
<h2 id="innodb重做日志文件">InnoDB重做日志文件</h2>
<p>默认情况下ib_logfile0和ib_logfile1是redo log file，他们记录了InnoDB存储引擎的事务日志，实例失败时可以使用重做日志回复到掉电前的时刻来保证数据的完整性。</p>
<p>redo log和bin log的区别在于：</p>
<ul>
<li>bin log是MySQL层面的日志，记录的是所有（包括不同引擎）的日志；而redo log只记录InnoDB引擎本身的日志</li>
<li>bin log记录的是一个事物的具体操作内容，是逻辑日志；redo log记录的是关于每个页的更改的物理情况</li>
<li>bin log仅在事务提交前进行提交，只写磁盘一次；redo log在事务进行的过程中不断有redo entry被写入redo log中</li>
</ul>
<h1 id="表">表</h1>
<h2 id="索引组织表">索引组织表</h2>
<p>InnoDB中一个很重要的概念就是表都是根据主键顺序组织存放的，成为索引组织表（index organized table）。没有显式定义主键的时候会按照如下方式选择或创建主键：</p>
<ul>
<li>非空唯一索引，如有多个，按照定义索引的顺序取第一个</li>
<li>无符合条件，自动创建6字节大小的主键</li>
</ul>
<h2 id="innodb逻辑存储结构">InnoDB逻辑存储结构</h2>
<p>InnoDB中数据被放在tablespace中，由段（segment）、区（extent）、页（page）组成。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-15-16-17-01.png" alt="">
默认情况下InnoDB有一个tablespace ibdata1，通过设置innodb_file_per_table也可以改为每个表内的数据（数据、索引和插入缓冲Bitmap）放到单独的tablespace，这种情况下其他类型的数据（如回滚信息、插入缓冲索引页、系统事务信息、double write buffer等）仍在共享表空间中，因此共享表空间仍会一直增大。</p>
<p>表空间是由各个段组成的，因为InnoDB是索引组织表，索引段就是B+树的非叶子节点，数据段是B+树的叶子节点。</p>
<p>区是连续的页组成的空间，每个区的大小为1MB，为了保证区中页的连续性，InnoDB会一次从磁盘申请4-5个区，默认情况下一个页16KB，一个区中有64个连续的页。</p>
<p>页是InnoDB磁盘管理的最小单位。常见页类型有：</p>
<ul>
<li>数据页（B-tree Node）</li>
<li>undo页（Undo Log Page）</li>
<li>系统页（System Page）</li>
<li>事务数据页（Transaction System Page）</li>
<li>插入缓冲位图页（Insert Buffer Bitmap）</li>
<li>插入缓冲空闲列表页（Insert Buffer Free List）</li>
<li>未压缩的二进制大对象页（Uncompressed BLOB Page）</li>
<li>压缩的二进制大对象页（Compressed BLOB Page）</li>
</ul>
<p>InnoDB是row-oriented，每个页最多允许存放16KB/2-200行记录。</p>
<h2 id="innodb行记录格式">InnoDB行记录格式</h2>
<p>InnoDB提供了Compact和Redundant两种格式来存放行记录数据，默认为Compact。一个页中存放的行数据越多，其性能就越高。</p>
<p>Compact行记录的存储方式为：</p>
<!-- raw HTML omitted -->
<pre><code>&lt;th&gt;
  NULL标记位
&lt;/th&gt;

&lt;th&gt;
  记录头信息
&lt;/th&gt;

&lt;th&gt;
  列1数据
&lt;/th&gt;

&lt;th&gt;
  列2数据
&lt;/th&gt;

&lt;th&gt;
  …
&lt;/th&gt;
</code></pre>
<!-- raw HTML omitted -->
<ul>
<li>变长字段长度列表，顺序按照列的顺序逆序放置，若列长度小于255字节则用1字节表示，否则用2字节表示</li>
<li>NULL标志位，指示该行中是否有NULL值，有则用1表示</li>
<li>record header，固定占用5字节</li>
<li>每个列的数据，NULL不占该部分任何空间，事务ID列和回滚指针列也包含在内，若没有主键还会增加一个6字节的rowid列</li>
</ul>
<p>InnoDB可以将某些数据存储在真正的数据页之外，如BLOB这类大对象列。要注意的是BLOB可以不将数据放在溢出页面，VARCHAR类型也有可能被存放为溢出数据。</p>
<p>首先VARCHAR类型上限是65535字节，但是因为有别的开销，所以实际测试发现最大长度为65532：</p>
<pre><code>mysql &gt; CREATE TABLE test(
-&gt; a VARCHAR(65535)
-&gt; )CHARSET=latin1 ENGINE=InnoDB;
ERROR 1118(42000):Row size too large.The maximum row size for the used table type,not counting BLOBs,is 65535.You have to change some columns to TEXT or BLOBs&lt;/code&gt;&lt;/pre&gt;

</code></pre><pre><code>mysql &gt; CREATE TABLE test(
-&gt; a VARCHAR(65532)
-&gt; )CHARSET=latin1 ENGINE=InnoDB;
Query OK,0 rows affected(0.15 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>如果没有将SQL_MODE设为严格模式，会抛出warning并转换为TEXT类型。</p>
<p>上述创建的65532的表字符类型为latin1,如果转换为UTF-8：</p>
<pre><code>mysql&gt; CREATE TABLE test(
-&gt; a VARCHAR(65532)
-&gt; )CHARSET=UTF8 ENGINE=InnoDB;
ERROR 1074(42000):Column length too big for column'a'(max=21845);use BLOB or TEXT instead&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>因此VARCHAR(N)中的N指的是字符的长度，而限制的65535是字节长度。</p>
<p>要注意的是，65535长度是指所有VARCHAR列的长度总和，如果列的长度超过这个长度，依然无法创建。</p>
<p>InnoDB的页为16KB，即16384字节，实际上是不能存放65532字节长度的数据的，此时插入长度为65532的记录，会观察到tablespace中有一个数据页节点B-tree Node，另外有Uncompressed BLOB Page，而实际上数据页中只保存了VARCHAR(65532)的前768字节的前缀数据，之后是偏移量，指向行溢出页。</p>
<p>InnoDB中每页至少要有两条行数据，如果页中只放得下一条记录，那么InnoDB就会自动将行数据存到溢出页中。同样如果TEXT或BLOB类型的数据能够保证一个页能存放两条记录，那么他们也是可以放在数据页中的。</p>
<p>对于多字节的字符编码，CHAR类型不再代表固定长度的字符串，如UTF-8下的CHAR(10)列，最小可以存储10字节的字符，最大可以存储30字节的字符，因此对于多字节编码的CHAR数据类型，InnoDB在内部将其视为变长字符类型。</p>
<h2 id="分区表">分区表</h2>
<p>分区的过程是将一个表或索引分解为多个更小、更可管理的部分。逻辑上的一个表或索引由数十个物理分区组成。</p>
<p>MySQL不支持垂直分区，并且是局部分区索引，即一个分区中既存放了数据又存放了索引，而全局分区，数据存放在各个分区中，索引放在一个对象中，目前并不支持。</p>
<p>分区主要应该用于数据库高可用性的管理，如果使用不当会对性能产生负面的影响。</p>
<p>目前MySQL支持以下几种类型的分区：</p>
<ul>
<li>RANGE：基于一个给定的连续区间的列值被放入分区</li>
<li>LIST：和RANGE类似，但是面向的是离散的值</li>
<li>HASH：根据用户自定义的表达式的返回值来进行分区，不能为负数</li>
<li>KEY：根据MySQL提供的哈希函数来进分区</li>
</ul>
<p>如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分。</p>
<h3 id="range">RANGE</h3>
<pre><code>CREATE TABLE t(
id INT
)ENGINE=INNDB
PARTITION BY RANGE(id)(
PARTITION p0 VALUES LESS THAN(10),
PARTITION p1 VALUES LESS THAN(20));&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>分区后表不再由一个ibd文件组成：</p>
<pre><code>mysql&gt; system ls-lh/usr/local/mysql/data/test2/t*
-rw-rw----1 mysql mysql 8.4K 7月31 14:11/usr/local/mysql/data/test2/t.frm
-rw-rw----1 mysql mysql 28 7月31 14:11/usr/local/mysql/data/test2/t.par
-rw-rw----1 mysql mysql 96K 7月31 14:12/usr/local/mysql/data/test2/t#P#p0.ibd
-rw-rw----1 mysql mysql 96K 7月31 14:12/usr/local/mysql/data/test2/t#P#p1.ibd&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>对于插入不在分区中定义的值时MySQL会抛出一个异常，也可以通过对分区添加一个MAXVALUE值的分区来解决。</p>
<p>通过分区，可以在管理上直接删除某些数据的分区，而不需要<code>DELETE...WHERE...</code>：</p>
<pre><code>mysql&gt; alter table sales drop partition p2008;
Query OK,0 rows affected(0.18 sec)
Records:0 Duplicates:0 Warnings:0&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在查询特定条件时，如果可以只搜索部分分区，SQL优化器不搜索所有分区称为Partition Pruning。启用分区后，应该根据分区的特性来编写最优的SQL语句。</p>
<h3 id="list">LIST</h3>
<p>LIST分区和RANGE分区很相似，只是分区列的值是离散而非连续的：</p>
<pre><code>mysql&gt; CREATE TABLE t(
-&gt; a INT,
-&gt; b INT)ENGINE=INNODB
-&gt; PARTITION BY LIST(b)(
-&gt; PARTITION p0 VALUES IN(1,3,5,7,9),
-&gt; PARTITION p1 VALUES IN(0,2,4,6,8)
-&gt; );
Query OK,0 rows affected(0.26 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在插入多个数据行时遇到分区未定义的值，MyISAM会将之前的行数据都插入，之后的数据不插入；但InnoDB则会视为一个事物，因此没有任何数据插入。</p>
<h3 id="hash分区">HASH分区</h3>
<pre><code>CREATE TABLE t_hash(
a INT,
b DATETIME
)ENGINE=InnoDB
PARTITION BY HASH(YEAR(b))
PARTITIONS 4;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>表示将表t按照日期列b分为4个区，因为：</p>
<pre><code>MOD(YEAR('2010-04-01'), 4)
=MOD(2010,4)
=2&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>因此’2010-04-01’这条数据将会被放入分区p2中。</p>
<p>如果PARTITIONS没有声明，那分区数量将默认为1。</p>
<h3 id="key分区">KEY分区</h3>
<p>KEY分区和HASH分区类似，不过HASH分区使用用户定义的函数进行分区，KEY分区使用MySQL数据库提供的函数进行分区，这些函数基于和<code>PASSWORD()</code>一样的运算法则：</p>
<pre><code>mysql&gt; CREATE TABLE t_key(
-&gt; a INT,
-&gt; b DATETIME)ENGINE=InnoDB
-&gt; PARTITION BY KEY(b)
-&gt; PARTITIONS 4;
Query OK,0 rows affected(0.43 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="columns分区">COLUMNS分区</h3>
<p>MySQL5.5开始支持COLUMNS分区，可以直接使用非整型数进行分区，而其他几种必须为整型或转化为整型：</p>
<pre><code>CREATE TABLE t_columns_range(
a INT,
b DATETIME
)ENGINE=INNODB
PARTITION BY RANGE COLUMNS(B)(
PARTITION p0 VALUES LESS THAN('2009-01-01'),
PARTITION p1 VALUES LESS THAN('2010-01-01')
);&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="子分区">子分区</h3>
<p>MySQL允许在RANGE和LIST的分区上再进行HASH或KEY的子分区：</p>
<pre><code>mysql&gt; CREATE TABLE ts(a INT,b DATE)engine=innodb
-&gt; PARTITION BY RANGE(YEAR(b))
-&gt; SUBPARTITION BY HASH(TO_DAYS(b))
-&gt; SUBPARTITIONS 2(
-&gt; PARTITION p0 VALUES LESS THAN(1990),
-&gt; PARTITION p1 VALUES LESS THAN(2000),
-&gt; PARTITION p2 VALUES LESS THAN MAXVALUE
-&gt; );
Query OK,0 rows affected(0.01 sec)&lt;/code&gt;&lt;/pre&gt;

</code></pre><pre><code>mysql&gt; system ls-lh/usr/local/mysql/data/test2/ts*
-rw-rw----1 mysql mysql 8.4K Aug 1 15:50/usr/local/mysql/data/test2/ts.frm
-rw-rw----1 mysql mysql 96 Aug 1 15:50/usr/local/mysql/data/test2/ts.par
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p0#SP#p0sp0.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p0#SP#p0sp1.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p1#SP#p1sp0.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/
ts#P#p1#SP#p1sp1.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p2#SP#p2sp0.ibd
-rw-rw----1 mysql mysql 96K Aug 1 15:50/usr/local/mysql/data/test2/ts#P#p2#SP#p2sp1.ibd&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="分区问题">分区问题</h3>
<p>分区中总是视NULL值是小于任何一个非NULL值。对于RANGE分区，NULL值会落在最左边的分区；对于HASH和KEY，任何分区函数都会将含有NULL值的记录返回为0。</p>
<p>对于不满足Partition Pruning的分区，对于一张大表，一般B+树需要2-3次磁盘IO，而如果需要扫描多个分区，如10个分区，每个分区查询开销为2-3次IO，则一共需要20-30次IO，有可能会带来严重的性能问题。</p>
<h1 id="索引与算法">索引与算法</h1>
<p>InnoDB支持以下几种常见的索引：</p>
<ul>
<li>B+树索引</li>
<li>全文索引</li>
<li>哈希索引</li>
</ul>
<p>B+树索引并不能找到一个给定键值的具体行，它只能找到被查找数据行所在的页，然后数据库通过把页读入到内存，再在内存中进行查找，最后得到想要的数据。</p>
<h2 id="b树">B+树</h2>
<p>B+树是为磁盘或者其他直接存取辅助设备设计的一种平衡查找树，所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接。</p>
<h3 id="b树的插入操作">B+树的插入操作</h3>
<p>B+树的插入必须保证插入后的叶子节点中的记录依然排序：</p>
<ul>
<li>Leaf Page未满、Index Page未满时，直接将记录插入到叶子节点</li>
<li>Leaf Page满、Index Page未满时，拆分Leaf Page，将中间的节点（指的是Leaf Page几个节点的中间）放入到Index Page中，小于中间节点的记录放左边，大于中间节点的记录放右边</li>
<li>Leaf Page满、Index Page满时，拆分Leaf Page，小于中间节点的记录放左边，大于中间节点的记录放右边；拆分Index Page，原理同上，此时树的高度+1</li>
</ul>
<p>因为拆分页操作意味着磁盘的操作，所以应该尽量减少。因此，B+树同样提供了类似平衡二叉树的旋转（Rotation）功能。当Leaf Page已满，而左右兄弟节点没满时，B+树不会急于去做拆分页的操作，而是将记录移到所在页的兄弟节点上，通常左兄弟会被首先检查用来做旋转操作。</p>
<h3 id="b树的删除操作">B+树的删除操作</h3>
<p>与插入通过“满”来控制不同，删除通过使用填充因子来控制树的变化。50%是填充因子可设的最小值。B+树的删除同样要保证删除后叶子节点中的记录依然排序：</p>
<ul>
<li>Leaf Page大于填充因子、Index Page大于填充因子，直接删除，如果该节点是Index Page节点，用该节点的右节点代替</li>
<li>Leaf Page小于填充因子、Index Page大于填充因子，合并Leaf Page和它的兄弟节点，同时更新Index Page</li>
<li>Leaf Page小于填充因子、Index Page小于填充因子，合并Leaf Page和它的兄弟节点，更新Index Page，合并Index Page和它的兄弟节点</li>
</ul>
<h3 id="b树索引">B+树索引</h3>
<p>B+树索引具有高扇出性，高度一般都在2-4层，说明查找某一键值的行记录最多只需要2-4次IO。</p>
<p>B+树索引可以分为聚集索引和辅助索引，区别在于叶子节点存放的是否是一整行的信息。</p>
<h4 id="聚集索引">聚集索引</h4>
<p>聚集索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-15-20-40-05.png" alt="">
数据只能按照一颗B+树来排序，因此每张表只能拥有一个聚集索引，由于定义了数据的逻辑顺序，按照聚集索引能够特别快地针对范围值查找。数据页上存放的是完整的每行的记录，而非数据页的索引页中存放的是键值和指向数据页的偏移量，而不是一个完整的行记录。</p>
<h4 id="辅助索引">辅助索引</h4>
<p>辅助索引的叶子节点除了包含键值意外，每个叶子节点中的索引行还包含了一个书签，用来告诉InnoDB存储引擎哪里可以找到与索引对应的行数据。由于InnoDB存储引擎是索引组织表，因此辅助索引的数千就是相应行数据的聚集索引键。</p>
<p>如果在一棵高度为3的辅助索引树中查找数据，那需要对这棵辅助索引树便利3次找到制定的主键，如果聚集索引树的高度同样为3，那还需要对聚集索引进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问以得到最终的一个数据页。</p>
<h4 id="b树索引的分裂">B+树索引的分裂</h4>
<p>在前面讲到的B+树的插入删除，和数据库中B+树索引的情况可能有所不同，因为B+树索引页的分裂并不总是从页的中间记录开始的，这样会导致页空间的浪费，例如自增ID列上：</p>
<pre><code>1、2、3、4、5、6、7、8、9&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>现在需要插入10，按照之前的理论应该是将记录5作为分裂点记录，得到P1、P2：</p>
<pre><code>P1：1、2、3、4
P2：5、6、7、8、9、10&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>由于是自增ID，现在P1永远不会有新数据，浪费了空间；P2又会再次进行分裂。</p>
<p>InnoDB的Page Header中有以下几个部分用来保存插入的顺序信息：</p>
<ul>
<li>PAGE_LAST_INSERT</li>
<li>PAGE_DIRECTION</li>
<li>PAGE_N_DIRECTION</li>
</ul>
<p>通过这些信息，InnoDB决定向左还是向右分裂，同时决定分裂点记录是哪一个。若插入是随机的则取中间记录，若往一个方向插入的记录数量为5,并且目前已经定位到的记录之后还有3条记录，则分裂点记录为定位到的记录后的第三条记录，否则分裂点记录就是待插入的记录。在自增时页的分裂通常都会在记录自身，避免前面的浪费空间的情况。</p>
<p><img src="../2019/12/Screenshot-from-2019-12-15-20-51-31.png" alt=""></p>
<h4 id="fast-index-creation">Fast Index Creation</h4>
<p>在对辅助索引的创建，InnoDB会对创建索引的表加上一个S锁，这样创建过程中只能对该表进行读操作，这改变了以前创建索引时，MySQL通过创建新临时表再导入数据的方式（会导致服务不可用）的情况。</p>
<h3 id="cardinality">Cardinality</h3>
<p>Cardinality是一个预估值，代表索引中不重复记录数量的预估值，Cardinality/n_rows_in_table应该尽可能接近1（高选择性），太小的时候用户应该考虑是否还需要创建这个索引。</p>
<p>Cardinality在不同引擎都有，因此对Cardinality的统计是放在存储引擎层进行的。数据库对于Cardinality的统计是通过采样进行的。</p>
<p>Cardinality的更新发生在INSERT和UPDATE操作中，因为不可能每次操作都要更新Cardinality信息，InnoDB内部对Cardinality信息的更新策略为：</p>
<ul>
<li>表中1/16的数据已发生过变化</li>
<li>stat_modified_counter &gt; 2000000000</li>
</ul>
<p>具体采样的方法是默认对8个叶子节点进行采样：</p>
<ul>
<li>取得B+树索引中叶子节点的数量A</li>
<li>随机取B+树中8个叶子节点，统计每个页不同的个数P1、P2、…、P8</li>
<li>Cardinality = (P1 + … + P8) * A / 8</li>
</ul>
<p>因为采样8个叶子节点是随机的，因此Cardinality每次取得的值可能不同。在目前的InnoDB版本中欧给你采样数量是可以配置的，同时对于采样结果中的NULL值也可以配置为忽略（不统计）、多个NULL统计为1个不重复值、多个NULL记为多个不重复值。</p>
<h3 id="b树索引的应用">B+树索引的应用</h3>
<h4 id="联合索引">联合索引</h4>
<p>联合索引与单个索引创建方法一样，其实和之前讨论的单个键值的B+树并没有什么不同，键值都是排序的，按照索引指定列的顺序进行存放。</p>
<p>要注意的是，在优化器选择索引的时候，例如在某个表(a,b)上有索引a和索引(a,b)，当查询where a=xx的时候，优化器会选择使用索引a而不用索引(a,b)，因为该索引只包含了单个键值，理论上一个页能够存放的数据应该更多，通过扫描更少的页就能拿到对应的记录。</p>
<h4 id="覆盖索引">覆盖索引</h4>
<p>通过在辅助索引中就能直接查到记录，而不用查询聚集索引中的记录，叫做覆盖索引。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，其大小要远小于聚集索引，因此可以减少大量的IO操作。</p>
<h4 id="优化器选择不用索引的情况">优化器选择不用索引的情况</h4>
<pre><code>SELECT * FROM orderdetails WHERE orderid&gt;10000 AND orderid&amp;lt;102000;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>假设这个表上有(orderid, productid)联合主键，orderid辅助索引，最后在EXPLAIN中看到优化器选择了主键的聚集索引，也就是表扫描（table scan），而非orderid辅助索引扫描（index scan），因为用户需要查整行信息，而orderid不能覆盖到我们要查询的信息，还需要根据书签进行查找，从顺序的scan操作变成了离散读操作。如果数量较少的情况下优化器会选择辅助索引，如果占比较大（一般20%左右）的时候，优化器因为顺序读离散读的问题，还是会选择用聚集索引来查找数据。</p>
<h4 id="multi-range-read优化">Multi-Range Read优化</h4>
<p>MRR优化目的是为了减少磁盘的随机访问：</p>
<ul>
<li>在使用辅助索引时，首先根据得到的查询结果，按照主键进行排序，并且按照主键顺序进行书签查找，</li>
<li>减少缓冲池中页被替换的次数</li>
<li>批量处理对键值的查询操作</li>
</ul>
<h4 id="index-condition-pushdown优化">Index Condition Pushdown优化</h4>
<p>在根据查询取出索引数据时，尽管索引对某些查询可能没有帮助（例如LIKE），但是可以在取出时就进行过滤数据，而不需要等全部取出后再进行过滤。Extra列Using index condition提示优化器选择了ICP优化。</p>
]]></content>
		</item>
		
		<item>
			<title>[听译]Redis 6.0新特性——ACLs</title>
			<link>https://jiekun.dev/posts/2019-11-24-redis-6-0%E6%96%B0%E7%89%B9%E6%80%A7-acls/</link>
			<pubDate>Sun, 24 Nov 2019 11:58:26 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-11-24-redis-6-0%E6%96%B0%E7%89%B9%E6%80%A7-acls/</guid>
			<description>在2019年纽约的Redis Day上，Salvatore Sanfilippo（AKA Antirez）介绍了即将发布的Redis 6.0的新特性。
ACLs简介 在过去的十年中，Redis都会有这样的问题：
用户执行FLUSHALL，OK现在整个数据库就空了，或者执行DEBUG SEGFAULT，然后Redis的进程就crash退出了。
在以前解决这个问题的办法可能是在Redis配置中将危险命令进行rename：
name-command FLUSHALL &amp;quot;&amp;quot;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 这样将命令更名为随机字符串或者直接屏蔽掉，以满足需要。
缺少危险命令管理就会导致很多问题，比如当你使用网络上的一些库的时候，你压根就不知道别人会不会在里面加些FLUSHALL这样的命令，或者你也可以每次用外部代码都进行一轮Code Review。
当有了ACLs之后，你就可以控制比如：
这个连接只允许使用RPOP，LPUSH这些命令，其他命令都无法调用。
是不是很方便？来看看ACLs是怎么工作的。
最佳实践 首先你要做的是定义用户。
当登录的时候，旧版本中默认用户（defaule user）是可以做任何事的，在Redis 6.0中你可以定义默认用户：
127.0.0.1:6379&amp;gt; ACL setuser antirez on &amp;gt;password1 &amp;gt;password2 &amp;gt;foobar +@all ~*&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; setuser…on表示启用此用户，off则是只定义一个不可用（unaccessable）的用户。
&amp;gt;password1 &amp;gt;password2 &amp;gt;foobar表示设置了3个密码，可以用来做密码轮换策略。
+@all表示用户可以使用所有权限，+后面跟命令权限如+get，或者+@后面跟某一类权限。
~*表示可用（accessable）的键名，这里是*也就是所有键都可被访问。
127.0.0.1:6379&amp;gt; ACL WHOAMI &amp;quot;default&amp;quot;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 现在是处于默认用户下的，切换用户：
127.0.0.1:6379&amp;gt; AUTH antirez foobar OK&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 在以前AUTH后面是直接跟密码的，现在是用户名和密码。
127.0.0.1:6379&amp;gt; ACL WHOAMI &amp;quot;antirez&amp;quot;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 因为之前给这个用户设置的是所有命令可用+所有键可见，所以现在跟default用户没有什么区别：
127.0.0.1:6379&amp;gt; GET foo (nil) 127.0.0.1:6379&amp;gt; SET foo bar OK&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 现在去掉一些权限：
127.0.0.1:6379&amp;gt; ACL setuser antirez -SET&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 把这个用户的SET权限去掉后，就不能进行这个操作了：</description>
			<content type="html"><![CDATA[<p>在2019年纽约的Redis Day上，Salvatore Sanfilippo（AKA Antirez）介绍了即将发布的Redis 6.0的新特性。</p>
<h2 id="acls简介">ACLs简介</h2>
<p>在过去的十年中，Redis都会有这样的问题：</p>
<p>用户执行<code>FLUSHALL</code>，OK现在整个数据库就空了，或者执行<code>DEBUG SEGFAULT</code>，然后Redis的进程就crash退出了。</p>
<p>在以前解决这个问题的办法可能是在Redis配置中将危险命令进行rename：</p>
<pre><code>name-command FLUSHALL &quot;&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这样将命令更名为随机字符串或者直接屏蔽掉，以满足需要。</p>
<p>缺少危险命令管理就会导致很多问题，比如当你使用网络上的一些库的时候，你压根就不知道别人会不会在里面加些<code>FLUSHALL</code>这样的命令，或者你也可以每次用外部代码都进行一轮Code Review。</p>
<p>当有了ACLs之后，你就可以控制比如：</p>
<p>这个连接只允许使用<code>RPOP</code>，<code>LPUSH</code>这些命令，其他命令都无法调用。</p>
<p>是不是很方便？来看看ACLs是怎么工作的。</p>
<h2 id="最佳实践">最佳实践</h2>
<p>首先你要做的是定义用户。</p>
<p>当登录的时候，旧版本中默认用户（defaule user）是可以做任何事的，在Redis 6.0中你可以定义默认用户：</p>
<pre><code>127.0.0.1:6379&gt; ACL setuser antirez on &gt;password1 &gt;password2 &gt;foobar +@all ~*&lt;/code&gt;&lt;/pre&gt;

</code></pre><p><code>setuser</code>…<code>on</code>表示启用此用户，off则是只定义一个不可用（unaccessable）的用户。</p>
<p><code>&gt;password1 &gt;password2 &gt;foobar</code>表示设置了3个密码，可以用来做密码轮换策略。</p>
<p><code>+@all</code>表示用户可以使用所有权限，<code>+</code>后面跟命令权限如<code>+get</code>，或者<code>+@</code>后面跟某一类权限。</p>
<p><code>~*</code>表示可用（accessable）的键名，这里是<code>*</code>也就是所有键都可被访问。</p>
<pre><code>127.0.0.1:6379&gt; ACL WHOAMI
&quot;default&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>现在是处于默认用户下的，切换用户：</p>
<pre><code>127.0.0.1:6379&gt; AUTH antirez foobar
OK&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在以前AUTH后面是直接跟密码的，现在是用户名和密码。</p>
<pre><code>127.0.0.1:6379&gt; ACL WHOAMI
&quot;antirez&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>因为之前给这个用户设置的是所有命令可用+所有键可见，所以现在跟default用户没有什么区别：</p>
<pre><code>127.0.0.1:6379&gt; GET foo
(nil)
127.0.0.1:6379&gt; SET foo bar
OK&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>现在去掉一些权限：</p>
<pre><code>127.0.0.1:6379&gt; ACL setuser antirez -SET&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>把这个用户的<code>SET</code>权限去掉后，就不能进行这个操作了：</p>
<pre><code>127.0.0.1:6379&gt; GET foo
&quot;bar&quot;
127.0.0.1:6379&gt; SET foo 123
(error) NOPERM this user has no permissions to run the 'set' command or its subcommand&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>再来查看一下现在的ACL list：</p>
<pre><code>127.0.0.1:6379&gt; ACL list
1) &quot;user antirez on &gt;password1 &gt;password2 &gt;foobar ~* +@all -set&quot;
2) &quot;user default on nopass ~* +@all&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>类似的，你也可以限制用户可以用任何命令但是却只能看部分键，如<code>object*</code>。</p>
<h2 id="备注">备注</h2>
<p>ACLs的实现使用了一些小技巧，像用上了命令的位图（commands’ bitmaps），以便让它不会在速度上有所下降。<br>
不使用ACLs的话就和原来的Redis 5一样，使用ACLs当然会有一些额外的开销，但是它们非常小，你在benchmarks中不会察觉到新旧版本的区别。</p>
]]></content>
		</item>
		
		<item>
			<title>(WIP)Docker原理</title>
			<link>https://jiekun.dev/posts/2019-11-17-wipdocker%E5%8E%9F%E7%90%86/</link>
			<pubDate>Sun, 17 Nov 2019 04:57:23 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-11-17-wipdocker%E5%8E%9F%E7%90%86/</guid>
			<description>Docker原理 主题一：Docker容器的资源隔离和限制管理 概述 Docker是基于Go实现的，它使用了namespaces来为不同容器提供独立环境。简单来说，当创建一个容器时，Docker创建了容器的一系列namespaces，不同容器只能在它所在的namespaces内操作相关资源，而察觉不到其他namespaces内存在的资源。
同时，Docker还使用了control groups(cgroups)来实现对资源使用的限制。
namespaces 从内核版本4.10开始，Linux有7种namespace:
 Mount Process ID Network Interprocess Communication UTS User ID Control group  在/proc/$PID/ns下可以看到对应的namespaces链接:
# root@duck-MS-7A34:/proc/1172/ns# ll total 0 dr-x--x--x 2 root root 0 11月 13 17:42 ./ dr-xr-xr-x 9 gdm gdm 0 11月 13 17:41 ../ lrwxrwxrwx 1 root root 0 11月 13 17:42 cgroup -&amp;gt; &#39;cgroup:[4026531835]&#39; lrwxrwxrwx 1 root root 0 11月 13 17:42 ipc -&amp;gt; &#39;ipc:[4026531839]&#39; lrwxrwxrwx 1 root root 0 11月 13 17:42 mnt -&amp;gt; &#39;mnt:[4026531840]&#39; lrwxrwxrwx 1 root root 0 11月 13 17:42 net -&amp;gt; &#39;net:[4026531992]&#39; lrwxrwxrwx 1 root root 0 11月 13 17:42 pid -&amp;gt; &#39;pid:[4026531836]&#39; lrwxrwxrwx 1 root root 0 11月 13 17:42 pid_for_children -&amp;gt; &#39;pid:[4026531836]&#39; lrwxrwxrwx 1 root root 0 11月 13 17:42 user -&amp;gt; &#39;user:[4026531837]&#39; lrwxrwxrwx 1 root root 0 11月 13 17:42 uts -&amp;gt; &#39;uts:[4026531838]&#39;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 如果两个进程指向的namespace编号相同，就说明它们在同一个namespace下。查看宿主机的其他进程的ns发现是指向同样编号的ns。</description>
			<content type="html"><![CDATA[<h2 id="docker原理">Docker原理</h2>
<h3 id="主题一docker容器的资源隔离和限制管理">主题一：Docker容器的资源隔离和限制管理</h3>
<h4 id="概述">概述</h4>
<p>Docker是基于Go实现的，它使用了<code>namespaces</code>来为不同容器提供独立环境。简单来说，当创建一个容器时，Docker创建了容器的一系列<code>namespaces</code>，不同容器只能在它所在的<code>namespaces</code>内操作相关资源，而察觉不到其他<code>namespaces</code>内存在的资源。<br>
同时，Docker还使用了<code>control groups</code>(<code>cgroups</code>)来实现对资源使用的限制。</p>
<h4 id="namespaces">namespaces</h4>
<p>从内核版本4.10开始，Linux有7种<code>namespace</code>:</p>
<ul>
<li>Mount</li>
<li>Process ID</li>
<li>Network</li>
<li>Interprocess Communication</li>
<li>UTS</li>
<li>User ID</li>
<li>Control group</li>
</ul>
<p>在<code>/proc/$PID/ns</code>下可以看到对应的<code>namespaces</code>链接:</p>
<pre><code># root@duck-MS-7A34:/proc/1172/ns# ll
total 0
dr-x--x--x 2 root root 0 11月 13 17:42 ./
dr-xr-xr-x 9 gdm  gdm  0 11月 13 17:41 ../
lrwxrwxrwx 1 root root 0 11月 13 17:42 cgroup -&gt; 'cgroup:[4026531835]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 ipc -&gt; 'ipc:[4026531839]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 mnt -&gt; 'mnt:[4026531840]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 net -&gt; 'net:[4026531992]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 pid -&gt; 'pid:[4026531836]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 pid_for_children -&gt; 'pid:[4026531836]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 user -&gt; 'user:[4026531837]'
lrwxrwxrwx 1 root root 0 11月 13 17:42 uts -&gt; 'uts:[4026531838]'&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>如果两个进程指向的<code>namespace</code>编号相同，就说明它们在同一个<code>namespace</code>下。查看宿主机的其他进程的ns发现是指向同样编号的ns。</p>
<p>在容器内查看：</p>
<pre><code># root@duck-MS-7A34:/proc/1172# docker run -it ubuntu /bin/bash
# root@a21f7e39c31c:/proc/1/ns# ls -l
total 0
lrwxrwxrwx 1 root root 0 Nov 13 09:44 cgroup -&gt; 'cgroup:[4026531835]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 ipc -&gt; 'ipc:[4026532665]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 mnt -&gt; 'mnt:[4026532663]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 net -&gt; 'net:[4026532669]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 pid -&gt; 'pid:[4026532667]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 pid_for_children -&gt; 'pid:[4026532667]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 user -&gt; 'user:[4026531837]'
lrwxrwxrwx 1 root root 0 Nov 13 09:44 uts -&gt; 'uts:[4026532664]'&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>可见容器内的进程是指向不同的namespaces的，他们之间的资源互不可见。</p>
<h4 id="cgroups">cgroups</h4>
<p>cgroups是设计来为不同用户层面的资源管理提供一个统一化的接口，主要功能有：</p>
<ul>
<li>资源限制</li>
<li>优先级分配</li>
<li>资源统计</li>
<li>任务控制</li>
</ul>
<p>cgroups的实现本质就是给任务挂上钩子，当任务运行的过程中涉及某种资源时，会触发钩子上所附带的子系统进行检测。</p>
<p>以Memory相关控制为例，cgroup有对应的配置文件：</p>
<pre><code># root@duck-MS-7A34:/sys/fs/cgroup/memory# ls
cgroup.clone_children  init.scope                  memory.kmem.max_usage_in_bytes      memory.kmem.tcp.usage_in_bytes   memory.numa_stat            memory.swappiness      system.slice
cgroup.event_control   memory.failcnt              memory.kmem.slabinfo                memory.kmem.usage_in_bytes       memory.oom_control          memory.usage_in_bytes  tasks
cgroup.procs           memory.force_empty          memory.kmem.tcp.failcnt             memory.limit_in_bytes            memory.pressure_level       memory.use_hierarchy   user.slice
cgroup.sane_behavior   memory.kmem.failcnt         memory.kmem.tcp.limit_in_bytes      memory.max_usage_in_bytes        memory.soft_limit_in_bytes  notify_on_release
ker                 memory.kmem.limit_in_bytes  memory.kmem.tcp.max_usage_in_bytes  memory.move_charge_at_immigrate  memory.stat                 release_agent&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这些以资源开头（比如memory.limit_in_bytes）的文件就是相关的配置文件。</p>
<p>当进程需要申请更多内存时，就会触发cgroup的用量检测，超过cgroup规定的限额就会拒绝用户的内存申请。如果进程需要的内存超过了它所属cgroup最大限额后，如果设置了OOM Control，那么进程就会收到OOM信号并结束，否则会被挂起，直到cgroup中其他进程释放了足够多的内存资源为止。</p>
<p>再如memory.limit_in_bytes和memory.soft_limit_in_bytes控制，当进程超过了软限制之后，如果有其他进程需要申请资源，系统会优先回收超额的进程占用的内存资源。</p>
]]></content>
		</item>
		
		<item>
			<title>Dockerの初体験</title>
			<link>https://jiekun.dev/posts/2019-11-17-docker%E3%81%AE%E5%88%9D%E4%BD%93%E9%A8%93/</link>
			<pubDate>Sun, 17 Nov 2019 04:54:19 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-11-17-docker%E3%81%AE%E5%88%9D%E4%BD%93%E9%A8%93/</guid>
			<description>Docker实践 学习背景  没有接触过容器 不太了解微服务 偶尔使用Linux  概述 什么是Docker？不妨先来看一下为什么需要Docker：
微服务 微服务是模块化的，每个不同的服务独立运行，因此需要满足能够独立部署和一定的可伸缩性。在部署过程中每一处的人为操作都伴随着出错的风险，所以必须有方法来消除这种服务部署的风险。
Docker为这种使用场景提供了解决方案，使用容器（Container）来部署微服务可以做到：
 将部署过程标准化和自动化 环境隔离，满足微服务的独立运行要求  CI/CD CI是不断提交代码并且打包编译，然后自动使用测试用例验证来保障改动内容对功能的影响的一种实践；CD是CI的延伸，它将通过CI验证的内容自动地发布和部署到指定环境。构建CI/CD时一般会需要做到：
 环境可控 快速高效部署，流程化执行 可并行运行测试  使用Docker可以满足以上的需求，使开发者专注于开发而运维专注于项目部署。
Get started with Docker docker-katas项目中有一些Docker的基本知识讲解和实践，主要包括Docker的各种常用概念及命令，如：
 Docker的镜像（Images）、容器（Containers）、守护进程（Docker daemon）、客户端（Docker client）、公共仓库（Docker Hub）等概念 镜像的拉取（pull）、容器的创建与运行（run）等命令  在完成docker-katas练习后，基于这些内容以及参考相关书籍，本次实践的目标是实现一套简单的服务，需要包括：
 使用Docker的数据卷（Volume）来进行数据的共享 使用Docker的网络来使几个容器间可以进行数据交互 使用Docker的端口转发  Volume Docker通过数据卷来实现不同容器间、容器与宿主机间数据的共享。最容易想到的场景就是在宿主机上修改服务的配置文件然后运行在不同的容器间，这里配置一套Redis服务使得容器的redis-server使用本地的配置文件运行。
以Redis镜像创建容器，将本地的配置文件/data/redis-master/redis.conf挂载到容器的/data/redis.conf中，并且执行redis-server /data/redis.conf命令启动redis-server。
# duck@duck-MS-7A34:~$ sudo docker run -d --name redis-master -v /data/redis-master/redis.conf:/data/redis.conf redis redis-server /data/redis.conf&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 因为redis-master使用-d后台运行，因此redis.conf中的后台运行需要改为关闭：
# duck@duck-MS-7A34:~$ sudo vim /data/redis-master.conf aemonize no&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 现在可以看到容器服务的运行状态：
# duck@duck-MS-7A34:~$ sudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f45e340eb1ba redis &amp;quot;docker-entrypoint.</description>
			<content type="html"><![CDATA[<h2 id="docker实践">Docker实践</h2>
<h3 id="学习背景">学习背景</h3>
<ul>
<li>没有接触过容器</li>
<li>不太了解微服务</li>
<li>偶尔使用Linux</li>
</ul>
<h3 id="概述">概述</h3>
<p>什么是Docker？不妨先来看一下为什么需要Docker：</p>
<h4 id="微服务">微服务</h4>
<p>微服务是模块化的，每个不同的服务独立运行，因此需要满足能够独立部署和一定的可伸缩性。在部署过程中每一处的人为操作都伴随着出错的风险，所以必须有方法来消除这种服务部署的风险。</p>
<p>Docker为这种使用场景提供了解决方案，使用容器（Container）来部署微服务可以做到：</p>
<ul>
<li>将部署过程标准化和自动化</li>
<li>环境隔离，满足微服务的独立运行要求</li>
</ul>
<h4 id="cicd">CI/CD</h4>
<p>CI是不断提交代码并且打包编译，然后自动使用测试用例验证来保障改动内容对功能的影响的一种实践；CD是CI的延伸，它将通过CI验证的内容自动地发布和部署到指定环境。构建CI/CD时一般会需要做到：</p>
<ul>
<li>环境可控</li>
<li>快速高效部署，流程化执行</li>
<li>可并行运行测试</li>
</ul>
<p>使用Docker可以满足以上的需求，使开发者专注于开发而运维专注于项目部署。</p>
<h3 id="get-started-with-docker">Get started with Docker</h3>
<p><a href="https://github.com/praqma-training/docker-katas">docker-katas</a>项目中有一些Docker的基本知识讲解和实践，主要包括Docker的各种常用概念及命令，如：</p>
<ul>
<li>Docker的镜像（Images）、容器（Containers）、守护进程（Docker daemon）、客户端（Docker client）、公共仓库（Docker Hub）等概念</li>
<li>镜像的拉取（<code>pull</code>）、容器的创建与运行（<code>run</code>）等命令</li>
</ul>
<p>在完成docker-katas练习后，基于这些内容以及参考相关书籍，本次实践的目标是实现一套简单的服务，需要包括：</p>
<ul>
<li>使用Docker的数据卷（Volume）来进行数据的共享</li>
<li>使用Docker的网络来使几个容器间可以进行数据交互</li>
<li>使用Docker的端口转发</li>
</ul>
<h4 id="volume">Volume</h4>
<p>Docker通过数据卷来实现不同容器间、容器与宿主机间数据的共享。最容易想到的场景就是在宿主机上修改服务的配置文件然后运行在不同的容器间，这里配置一套Redis服务使得容器的redis-server使用本地的配置文件运行。</p>
<p>以Redis镜像创建容器，将本地的配置文件<code>/data/redis-master/redis.conf</code>挂载到容器的<code>/data/redis.conf</code>中，并且执行<code>redis-server /data/redis.conf</code>命令启动redis-server。</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker run -d --name redis-master -v /data/redis-master/redis.conf:/data/redis.conf redis redis-server /data/redis.conf&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>因为redis-master使用<code>-d</code>后台运行，因此redis.conf中的后台运行需要改为关闭：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo vim /data/redis-master.conf
aemonize no&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>现在可以看到容器服务的运行状态：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
f45e340eb1ba        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up 56 minutes       6379/tcp                 redis-master&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="容器间连接">容器间连接</h4>
<p>Docker容器可以通过<code>--link</code>连接其他的容器，具体示例如下。<br>
因为之前已经创建过一个名为redis-master的容器了，现在再创建一台基于ubuntu镜像的容器，并且与redis-master连接：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker run -it --name ubuntu1 --link redis-master:redis-master ubuntu /bin/bash&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>创建完毕后在这个ubuntu1容器上查看<code>/etc/hosts</code>发现：</p>
<pre><code># root@5e0ca7fa39ef:/# cat /etc/hosts
172.17.0.2  redis-master f45e340eb1ba&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>因此在ubuntu1中可以通过redis-master访问另一台容器。</p>
<p>现在为之前创建的redis-master容器配置上两个slave节点。</p>
<p>和之前类似，需要让新的redis容器使用本地的配置，因此需要<code>-v</code>参数；并且需要让slave节点连接上master节点，因此需要<code>--link redis-master:redis-master</code>参数；slave配置与master类似，但是要加上<code>slaveof redis-master</code>的配置项：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker run -d --name redis-slave1 -v /data/redis-slave/redis.conf:/data/redis.conf --link redis-master:master redis redis-server /data/redis.conf
# duck@duck-MS-7A34:~$ sudo docker run -d --name redis-slave2 -v /data/redis-slave/redis.conf:/data/redis.conf --link redis-master:master redis redis-server /data/redis.conf&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>现在docker管理中可以看到3个容器在运行中：</p>
<pre><code>uck@duck-MS-7A34:~$ sudo docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS                    NAMES
bf991586e7c3        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up About an hour           6379/tcp                 redis-slave2
2831c5a828da        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up About an hour           6379/tcp                 redis-slave1
f45e340eb1ba        redis               &quot;docker-entrypoint.s…&quot;   42 hours ago        Up About an hour           6379/tcp                 redis-master&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>进入redis-master中查看Redis状态：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker exec -it f45e340eb1ba /bin/bash
# root@f45e340eb1ba:/data# redis-cli
## 127.0.0.1:6379&gt; info&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在返回的内容中可以看到</p>
<pre><code># Replication
role:master
connected_slaves:2
slave0:ip=172.17.0.3,port=6379,state=online,offset=6682,lag=1
slave1:ip=172.17.0.4,port=6379,state=online,offset=6682,lag=1
master_replid:d7713802a61c75bd794c282accda8add66631804
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:6682
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
l_backlog_histlen:6682&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>创建一个键检查是主从同步是否正常：</p>
<pre><code># 127.0.0.1:6379&gt; set 1 1&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>进入redis-slave1中查看Redis状态：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker exec -it 2831c5a828da /bin/bash
# root@2831c5a828da:/data# redis-cli
# 127.0.0.1:6379&gt; info&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>其中主从Replication部分显示当前节点工作在slave模式：</p>
<pre><code># Replication
role:slave
master_host:master
master_port:6379
master_link_status:up
master_last_io_seconds_ago:2
master_sync_in_progress:0
slave_repl_offset:6556
slave_priority:100
slave_read_only:1
connected_slaves:0
master_replid:d7713802a61c75bd794c282accda8add66631804
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:6556
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:15
l_backlog_histlen:6542&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>查看数据同步是否正常：</p>
<pre><code># 127.0.0.1:6379&gt; keys *
1) &quot;1&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="app与haproxy">App与HAProxy</h4>
<p>最后再来加上两个App服务以及使用HAProxy进行Round-Robin的负载均衡。</p>
<p>创建两个Django容器，我们需要在本地修改代码，因此需要使用<code>-v</code>将代码目录与本地目录连通；App需要连接Redis数据库，因此需要<code>--link</code>连接Redis主节点：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker run -it -d --name app1 --link redis-master:db -v /data/App1:/usr/src/app django /bin/bash
# duck@duck-MS-7A34:~$ sudo docker run -it -d --name app2 --link redis-master:db -v /data/App2:/usr/src/app django /bin/bash&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>之后进入容器中，安装对应包及根据Django的命令创建一系列的内容，主要包括：</p>
<ul>
<li>pip安装redis</li>
<li>Django创建项目redisweb</li>
<li>Django生成应用helloworld</li>
</ul>
<p>完成之后可以在我们宿主机挂在的目录看到有对应的文件：</p>
<pre><code># duck@duck-MS-7A34:/data/app1$ tree
.
└── dockerweb
    └── redisweb
        ├── db.sqlite3
        ├── helloworld
        │   ├── admin.py
        │   ├── apps.py
        │   ├── __init__.py
        │   ├── migrations
        │   │   └── __init__.py
        │   ├── models.py
        │   ├── tests.py
        │   └── views.py
        ├── manage.py
        └── redisweb
            ├── __init__.py
            ├── settings.py
            ├── urls.py
            └── wsgi.py&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>其中我们在redisweb/helloworld/views.py中添加对应的逻辑并且配置好路由urls.py和项目设置settings.py，最后通过<code>python manage.py runserver 0.0.0.0:8001</code>命令启动，就可以进行访问。</p>
<p>接下来创建HAProxy容器，HAProxy需要和App1和App2连接，因此加上<code>--link</code>参数；并且为了让容器的端口和宿主机的映射起来，添加<code>-p</code>参数；HAProxy的配置为了方便编辑，同样加上<code>-v</code>与本地配置目录互联：</p>
<pre><code># duck@duck-MS-7A34:~$ sudo docker run -it -d --name HAProxy --link app1:app1 --link app2:app2 -p 6301:6301 -v /data/haproxy:/tmp haproxy /bin/bash&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>HAProxy配置修改好后，在容器中使用配置启动HAProxy：</p>
<pre><code># root@8ef76bd496c3:/usr/local/sbin# haproxy -f haproxy.cfg&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="访问测试">访问测试</h3>
<p>因为之前已经将HAProxy容器的6301端口与本地6301端口映射，现在可以访问本地的6301端口查看HAProxy工作状态：</p>
<p><img src="../2019/11/001-zhujiekun-haproxy.png" alt="">
然后再来访问Apps查看负载均衡是否生效：</p>
<p><img src="../2019/11/001-zhujiekun-app-lb-1024x610.png" alt=""></p>
<h3 id="容器应用搭建总结">容器应用搭建总结</h3>
<p>假如这套应用改用传统的云服务（虚拟机）进行搭建，则会在部署上浪费额外的时间，例如：</p>
<ul>
<li>云服务启动时间</li>
<li>各种软件包的安装时间，如Redis，HAProxy，Django环境配置</li>
<li>不同实例间的配置时间，如在实例上配置Host文件连接其他内网机器</li>
</ul>
<p>通过改用Docker拉取镜像创建容器的方式实现，使得整个流程大为精简，免除了许多冗余的重复配置操作，特别适合独立的微服务构建。</p>
<h3 id="docker-katas1练习"><a href="https://github.com/praqma-training/docker-katas">docker-katas</a>练习</h3>
<p>因为练习与Django App实践有部分内容重复，因此只选取了部分练习展示。</p>
<h4 id="07-building-an-image">07-building-an-image</h4>
<p>了解使用Dockerfile创建镜像和镜像的分层。</p>
<pre><code># duck@duck-MS-7A34:~/script$ cat Dockerfile
# The base image
FROM ubuntu:latest

# Install python and pip
RUN apt-get update &amp;&amp; apt-get install -y \
 python-pip \
 python-dev \
 build-essential

# Install Python modules needed by the Python app
COPY requirements.txt /usr/src/app/
RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt

# Copy files required for the app to run
COPY app.py /usr/src/app/

# Declare the port number the container should expose
EXPOSE 5000

# Run the application
WORKDIR /usr/src/app
CMD [&quot;env&quot;, &quot;FLASK_APP=app.py&quot;, &quot;&amp;&amp;&quot;, &quot;flask&quot;, &quot;run&quot;, &quot;--host=0.0.0.0&quot;]&lt;/code&gt;&lt;/pre&gt;

</code></pre><pre><code># duck@duck-MS-7A34:~/script$ sudo docker container run -p 8888:5000 --name myfirstapp myfirstapp
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
172.17.0.1 - - [13/Nov/2019 02:58:50] &quot;GET / HTTP/1.1&quot; 200 -
172.17.0.1 - - [13/Nov/2019 02:58:50] &quot;GET /favicon.ico HTTP/1.1&quot; 404 -&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="09-multi-container">09-multi-container</h4>
<p>在多个容器构成的应用中，每次都手动管理各个容器非常麻烦，依靠Docker compose将这些逻辑汇聚在一起方便定义和运行。</p>
<p>使用Docker composer运行WP应用</p>
<pre><code># duck@duck-MS-7A34:~/script$ cat docker-compose.yaml 
version: '3.1'

networks:
  if_wordpress:

services:
  wordpress_container:
    image: wordpress
    networks: 
      - if_wordpress
    ports: 
      - 8080:80
    environment:
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_HOST: mysql_container

  mysql_container:
    image: mysql:5.7
    networks: 
      - if_wordpress
    ports:
      - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD: wordpress&lt;/code&gt;&lt;/pre&gt;

</code></pre><pre><code># duck@duck-MS-7A34:~/script$ sudo docker-compose up -d
Creating network &quot;script_if_wordpress&quot; with the default driver
Creating script_wordpress_container_1 ... done
Creating script_mysql_container_1     ... done
# duck@duck-MS-7A34:~/script$ curl 127.0.0.1:8080/wp-admin/install.php?step=1
&amp;lt;!DOCTYPE html&gt;
&amp;lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;en-US&quot; xml:lang=&quot;en-US&quot;&gt;
&amp;lt;head&gt;
    &amp;lt;meta name=&quot;viewport&quot; content=&quot;width=device-width&quot; /&gt;
    &amp;lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;
    &amp;lt;meta name=&quot;robots&quot; content=&quot;noindex,nofollow&quot; /&gt;
    &amp;lt;title&gt;WordPress › Installation&amp;lt;/title&gt;
    &amp;lt;link rel='stylesheet' id='dashicons-css'  href='http://127.0.0.1:8080/wp-includes/css/dashicons.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='buttons-css'  href='http://127.0.0.1:8080/wp-includes/css/buttons.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='forms-css'  href='http://127.0.0.1:8080/wp-admin/css/forms.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='l10n-css'  href='http://127.0.0.1:8080/wp-admin/css/l10n.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;link rel='stylesheet' id='install-css'  href='http://127.0.0.1:8080/wp-admin/css/install.min.css?ver=5.2.4' type='text/css' media='all' /&gt;
&amp;lt;/head&gt;&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="10-multi-stage-builds">10-multi-stage-builds</h4>
<p>分Stage build镜像可以减少镜像体积</p>
<pre><code># duck@duck-MS-7A34:~/script/goapp$ sudo docker image ls
REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE
goapp               2.0                 fa4ad66bd1d1        2 seconds ago        7.56MB
&amp;lt;none&gt;              &amp;lt;none&gt;              1d51fc13798f        5 seconds ago        361MB&lt;/code&gt;&lt;/pre&gt;

</code></pre>]]></content>
		</item>
		
		<item>
			<title>理解Chrome请求流程</title>
			<link>https://jiekun.dev/posts/2019-10-27-%E7%90%86%E8%A7%A3chrome%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B/</link>
			<pubDate>Sun, 27 Oct 2019 09:17:37 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-10-27-%E7%90%86%E8%A7%A3chrome%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B/</guid>
			<description>Timing Tab Chrome的DevTools中提供了对请求的时间分析，如配图所示。
对每个请求，Chrome统计了它们不同阶段的通信时间，包括：
 Queueing Stalled DNS Lookup Proxy negotiation Initial Connection /Connecting SSL Request sent ServiceWorker Preparation Request to ServiceWorker Waiting(TTFB) Content Download Receiving Push Reading Push  Queueing Queueing意味着请求没有马上发生，加入队列排队等候。导致这种情况一般可能的原因有：
 有更高优先级的请求 请求等待即将被释放的TCP socket 与当前域名的TCP连接数已满上限6个（仅对HTTP/1.0和HTTP/1.1生效） 浏览器正在分配磁盘缓存（一般非常短暂）  要注意的是第三点中的6个TCP连接数上限在不同浏览器中也不相同，根据HTTP协议的规定限制数量应为2个，但是各浏览器有不同的标准：
 | Browser | Maximum connections | |---------|---------------------| | IE7 | 2 | | IE8/IE9 | 6 | | IE10 | 8 | | IE11 | 13 | | FireFox | 6 | | Chrome | 6 | | Safari | 6 | | Opera | 6 | | iOS | 6 | | Android | 6 | ---------------------------------&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; Stalled 当请求被放入队列后，就会有阻塞的时长。Stalled描述的是请求被发送之前等待的时长，一般就是Queueing中的原因导致的。除此之外，Stalled还包含了代理协商的时长。</description>
			<content type="html"><![CDATA[<h1 id="timing-tab">Timing Tab</h1>
<p>Chrome的DevTools中提供了对请求的时间分析，如配图所示。</p>
<p>对每个请求，Chrome统计了它们不同阶段的通信时间，包括：</p>
<ul>
<li>Queueing</li>
<li>Stalled</li>
<li>DNS Lookup</li>
<li>Proxy negotiation</li>
<li>Initial Connection /Connecting</li>
<li>SSL</li>
<li>Request sent</li>
<li>ServiceWorker Preparation</li>
<li>Request to ServiceWorker</li>
<li>Waiting(TTFB)</li>
<li>Content Download</li>
<li>Receiving Push</li>
<li>Reading Push</li>
</ul>
<h3 id="queueing">Queueing</h3>
<p>Queueing意味着请求没有马上发生，加入队列排队等候。导致这种情况一般可能的原因有：</p>
<ul>
<li>有更高优先级的请求</li>
<li>请求等待即将被释放的TCP socket</li>
<li>与当前域名的TCP连接数已满上限6个（仅对HTTP/1.0和HTTP/1.1生效）</li>
<li>浏览器正在分配磁盘缓存（一般非常短暂）</li>
</ul>
<p>要注意的是第三点中的6个TCP连接数上限在不同浏览器中也不相同，根据<a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.1.4">HTTP协议</a>的规定限制数量应为2个，但是各浏览器有不同的标准：</p>
<pre><code>
| Browser | Maximum connections |
|---------|---------------------|
| IE7     | 2                   |
| IE8/IE9 | 6                   |
| IE10    | 8                   |
| IE11    | 13                  |
| FireFox | 6                   |
| Chrome  | 6                   |
| Safari  | 6                   |
| Opera   | 6                   |
| iOS     | 6                   |
| Android | 6                   |
---------------------------------&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="stalled">Stalled</h3>
<p>当请求被放入队列后，就会有阻塞的时长。Stalled描述的是请求被发送之前等待的时长，一般就是Queueing中的原因导致的。除此之外，Stalled还包含了代理协商的时长。</p>
<h3 id="dns-lookup">DNS Lookup</h3>
<p>进行DNS查找（域名解析）的时长。每次请求一个新的域名的时候，需要进行一次完整的域名解析过程。</p>
<h3 id="proxy-negotiation">Proxy negotiation</h3>
<p>浏览器与代理服务器进行协商的过程。</p>
<h3 id="initial-connection-connecting">Initial Connection /Connecting</h3>
<p>建立连接的时长，包括TCP握手/重试的时长和SSL协商的时长。</p>
<h3 id="ssl">SSL</h3>
<p>完成SSL握手的时长。</p>
<h3 id="request-sendingsent">Request sending/sent</h3>
<p>发布请求的过程时间，一般非常快。</p>
<h3 id="serviceworker-preparation">ServiceWorker Preparation</h3>
<p>浏览器启动Service Worker的时长。</p>
<h3 id="request-to-serviceworker">Request to ServiceWorker</h3>
<p>请求被发送至Service Worker的时长。</p>
<h3 id="waitingttfb">Waiting(TTFB)</h3>
<p>等待最初相应的时长，A.K.A Time To First Byte。这个时长等于请求发送至服务器的延迟、响应返回至客户端的延迟、服务器处理请求的时间之和。</p>
<h3 id="content-download">Content Download</h3>
<p>浏览器接收完整相应的时长。</p>
<h3 id="receiving-push">Receiving Push</h3>
<p>浏览器接收服务器（HTTP/2）推送数据的时长。</p>
<h3 id="reading-push">Reading Push</h3>
<p>浏览器读取接收到数据的时长。</p>
<p>结合上图为例，可以看到请求图中接口的时间消耗：</p>
<ul>
<li>请求放入队列花费1.94ms</li>
<li>请求在队列中被阻塞了2.25ms直至开始发送请求</li>
<li>域名解析花费0.41ms</li>
<li>与服务器建立连接，花费72.11ms，其中，完成SSL协商，花费的38.24ms是包含在72.11ms内的</li>
<li>发送请求，花费0.17ms</li>
<li>发送后到接收第一个响应数据间隔了36.07ms</li>
<li>完成响应报文的下载花费了2.00ms</li>
</ul>
<p>本次请求一共花了115.16ms（数据求和为114.95ms，推断各阶段间有细微执行时间没有统计到）。</p>
<h2 id="full-request-process">Full Request Process</h2>
<p>现在结合Chrome的DevTools信息，再来更新一下从请求到页面展示的流程，以用户在浏览器中输入www.baidu.com为例，其中Chrome相关内容加粗显示：</p>
<ul>
<li>请求准备部分
<ul>
<li>用户在浏览器中输入www.baidu.com，按下回车</li>
<li><strong>Chrome开始准备请求，如果满足被Queued规则的话放入队列中等待</strong></li>
<li><strong>此时Chrome会分配磁盘的缓存空间为后续缓存操作做准备</strong></li>
<li><strong>队列任务等待结束，开始准备发送请求；非队列任务准备发送请求</strong></li>
<li>Chrome查询是否有可用的磁盘或内存缓存：
<ul>
<li>如有且新鲜，则获取缓存内容，跳过解析和发起请求过程</li>
<li>如果没有缓存，继续按照后续步骤发起请求</li>
</ul>
</li>
</ul>
</li>
<li>域名解析部分
<ul>
<li>浏览器解析URL，获取协议、路径和端口号</li>
<li>浏览器组装一个HTTP请求报文</li>
<li>浏览器进行域名解析，获取主机的IP地址，主要通过：
<ul>
<li>浏览器对域名解析结果的缓存</li>
<li>本机对域名解析结果的缓存</li>
<li>hosts文件</li>
<li>路由器缓存</li>
<li>ISP DNS缓存</li>
<li>DNS递归查询</li>
</ul>
</li>
</ul>
</li>
<li>发起请求部分
<ul>
<li>获取到IP后打开一个socket，与目标建立TCP连接，进行三次握手，细节太多受限篇幅不在此叙述，<strong>花费时间即为Initial Connection中减去SSL相关的部分</strong></li>
<li>如果为HTTPS请求，进行SSL握手，<strong>花费时间为Timing中SSL部分</strong></li>
<li>发送HTTP请求</li>
</ul>
</li>
<li>接收响应部分
<ul>
<li>服务器检查HTTP请求头是否包含缓存验证信息：
<ul>
<li>验证缓存新鲜，返回304</li>
<li>验证不通过，处理请求并准备HTTP相应</li>
</ul>
</li>
<li>HTTP响应通过建立的TCP连接发送给浏览器，首个报文抵达时间即为<strong>Waiting(TTFB)，完整接收时长为Waiting+Content Download时长</strong></li>
<li>浏览器视情况保留TCP连接或进行四次挥手结束连接</li>
<li>浏览器根据响应状态码进行处理</li>
<li>如果响应资源可以缓存，进行缓存</li>
<li>对压缩（如gzip）的响应进行解码</li>
</ul>
</li>
<li>处理响应资源，假设资源为HTML文档（后续过程可能没有严格的先后顺序）：
<ul>
<li>构建DOM树</li>
<li>针对构建过程中遇到的图片、样式、js启动下载</li>
<li>构建CSSOM树</li>
<li>根据DOM树和CSSOM树构建渲染树</li>
<li>JS解析</li>
<li>显示页面</li>
</ul>
</li>
</ul>
<h1 id="ref">Ref</h1>
<p><a href="https://developers.google.com/web/tools/chrome-devtools/network/understanding-resource-timing">Understanding Resource Timing</a></p>
<p><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=12066">chromium.org – Issue: Match Firefox’s per-host connection limit of 15</a></p>
<p><a href="https://developers.google.com/web/fundamentals/primers/service-workers">Service Worker</a></p>
]]></content>
		</item>
		
		<item>
			<title>BTW, I use Arch</title>
			<link>https://jiekun.dev/posts/2019-10-24-btw-i-use-arch/</link>
			<pubDate>Thu, 24 Oct 2019 03:19:30 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-10-24-btw-i-use-arch/</guid>
			<description>rm -rf当然是假的啊，怎么可能失败？
ArchLinux Installation Intro ArchLinux是Linux的一个发行版。
特点  滚动更新 Package管理：pacman 极简安装 高度个性化  缺点  社区相对更小 出问题修复耗费时间 滚动更新带来的不稳定性  Environment CPU.........: Intel(R) Core(TM) i3-4150 CPU @ 3.50GHz MOTHERBOARD.: B85M-DS3H-A Gigabyte Technology Co., Ltd. MEMORY......: 8GB STORAGE.....: 120GB SSD&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; Installation Note 安装过程参照官方文档Installation guide及DistroTube的视频Arch Linux Installation Guide (2019)即可顺利完成。
History Commands # 检查联网 ping www.baidu.com timedatectl set-ntp true # 划分磁盘 cfdisk mkfs.ext4 /dev/sda1 mkswap /dev/sda2 swapon /dev/sda2 # 安装部分必要的包 vim /etc/pacman.d/mirrorlist pacstrap /mnt base linux linux-firmware # 生成fstab分区记录文件 genfstab -U /mnt &amp;gt;&amp;gt; /mnt/etc/fstab # 切换至新系统root arch-chroot /mnt pacman -S vim # 时区和主机设置 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime hwclock --systohc locale-gen vim /etc/locale.</description>
			<content type="html"><![CDATA[<p>rm -rf当然是假的啊，怎么可能失败？</p>
<h1 id="archlinux-installation">ArchLinux Installation</h1>
<h2 id="intro">Intro</h2>
<p>ArchLinux是Linux的一个发行版。</p>
<h3 id="特点">特点</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Rolling_release">滚动更新</a></li>
<li>Package管理：<a href="https://en.wikipedia.org/wiki/Arch_Linux#Pacman">pacman</a></li>
<li>极简安装</li>
<li>高度个性化</li>
</ul>
<h3 id="缺点">缺点</h3>
<ul>
<li>社区相对更小</li>
<li>出问题修复耗费时间</li>
<li>滚动更新带来的不稳定性</li>
</ul>
<h2 id="environment">Environment</h2>
<pre><code>CPU.........: Intel(R) Core(TM) i3-4150 CPU @ 3.50GHz
MOTHERBOARD.: B85M-DS3H-A Gigabyte Technology Co., Ltd.
MEMORY......: 8GB
STORAGE.....: 120GB SSD&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="installation-note">Installation Note</h2>
<p>安装过程参照官方文档<a href="https://wiki.archlinux.org/index.php/Installation_guide">Installation guide</a>及DistroTube的视频<a href="https://www.youtube.com/watch?v=HpskN_jKyhc&amp;t=606s">Arch Linux Installation Guide (2019)</a>即可顺利完成。</p>
<h3 id="history-commands">History Commands</h3>
<pre><code># 检查联网
ping www.baidu.com
timedatectl set-ntp true

# 划分磁盘
cfdisk
mkfs.ext4 /dev/sda1
mkswap /dev/sda2
swapon /dev/sda2

# 安装部分必要的包
vim /etc/pacman.d/mirrorlist
pacstrap /mnt base linux linux-firmware

# 生成fstab分区记录文件
genfstab -U /mnt &gt;&gt; /mnt/etc/fstab

# 切换至新系统root
arch-chroot /mnt

pacman -S vim

# 时区和主机设置
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
hwclock --systohc
locale-gen
vim /etc/locale.conf
vim /etc/hostname
vim /etc/hosts

passwd

# 补充安装网络相关内容
pacman -S net-tools
pacman -S dhcpcd
# 启动dhcpcd
systemctl enable dhcpcd

# 创建普通用户 &amp; sudo权限
useradd -m duck
pacman -S sudo
usermod -aG wheel,audio,video,storage duck
vim /etc/sudoers
passwd duck

# 安装grub 生成引导文件
pacman -S grub
grub-install /dev/sda
grub-mkconfig -o /boot/grub/grub.cfg

exit
boot&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="troubleshooting">Troubleshooting</h3>
<h4 id="legacy-vs-uefi">Legacy vs UEFI</h4>
<p>Legacy BIOS是基于<a href="https://en.wikipedia.org/wiki/Option_ROM">option ROMs</a>的，ROM顾名思义是一些只读的信息，是厂商在设备出厂时写入的，通过读取option ROMs中的信息加载硬件。如果硬件升级后，也需要有对应的options ROMs才能够正常使用。不同厂商提供的信息不一样，没有通用标准，大小为64KB。</p>
<p>UEFI借助将驱动存放至文件系统中而非option ROMs解决这个问题。驱动可以以光盘、闪存等形式存在，由UEFI接口处理这些信息，保证兼容性。</p>
<p>延伸阅读： <a href="https://pediaa.com/difference-between-uefi-and-legacy-boot/">Difference Between UEFI and Legacy Boot</a></p>
<p>本次安装过程中在BIOS设置了使用Legacy模式启动。</p>
<h4 id="分区划分">分区划分</h4>
<p>安装过程中使用了cfdisk代替fdisk进行分区，分区设置如下：</p>
<ul>
<li>创建Primary分区并设置”Bootable”</li>
<li>创建Primary分区，类型设置为swap</li>
</ul>
<h1 id="awesomewm-setup">AwesomeWM Setup</h1>
<h2 id="xorg">Xorg</h2>
<p>Xorg是Linux系统上一个知名的display server。图形化界面（graphical interface）和窗口管理（windows manager）都是基于display server的。因此首先在安装AwesomeWM之前需要有Xorg。</p>
<h2 id="awesome-windows-manager">Awesome Windows Manager</h2>
<p>AwesomeWM顾名思义是个窗口管理工具。</p>
<h2 id="xinit">xinit</h2>
<p>xinit允许用户手动启动一个Xorg display server。通常来说就用用来启动WM或者GI的。</p>
<h2 id="准备工作">准备工作</h2>
<p>基于上述内容，开始配置之前需要安装：</p>
<pre><code>udo pacman -S xorg xorg-xinit awesome&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>当然，除了三件套以外还有一些相关的包，例如字体相关包，awesome默认设置了nano为编辑器，因此需要安装nano，默认设置了xtrem为终端，因此还需要安装xtrem等。</p>
<h2 id="配置">配置</h2>
<p>awesome通过xinit运行，因此要修改xinit的配置文件让它从默认运行的WM（或者其他）改为运行awesome。</p>
<h3 id="xinit配置">xinit配置</h3>
<p>xinit配置在<code>/etc/X11/xinit/xinitrc</code>文件，复制一份到家目录下并更名：</p>
<pre><code>/etc/X11/xinit/xinitrc ~/.xinitrc
mv /etc/X11/xinit/xinitrc /etc/X11/xinit/xinitrc.bak&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这样xinit运行（startx)的时候会读取家目录下的配置。</p>
<p>vim打开.xinitrc有如下内容</p>
<pre><code>#!/bin/sh

userresources=$HOME/.Xresources
usermodmap=$HOME/.Xmodmap
sysresources=/etc/X11/xinit/.Xresources
sysmodmap=/etc/X11/xinit/.Xmodmap

# merge in defaults and keymaps

if [ -f $sysresources ]; then







    xrdb -merge $sysresources

fi

if [ -f $sysmodmap ]; then
    xmodmap $sysmodmap
fi

if [ -f &quot;$userresources&quot; ]; then







    xrdb -merge &quot;$userresources&quot;

fi

if [ -f &quot;$usermodmap&quot; ]; then
    xmodmap &quot;$usermodmap&quot;
fi

# start some nice programs

if [ -d /etc/X11/xinit/xinitrc.d ] ; then
 for f in /etc/X11/xinit/xinitrc.d/?*.sh ; do
  [ -x &quot;$f&quot; ] &amp;&amp; . &quot;$f&quot;
 done
 unset f
fi

xec awesome&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>默认示例配置中最后一段打开了3个不同大小的小窗口，其他内容直接省略，只需要保留<code># start some nice programs</code>后的内容，运行程序修改为awesome：</p>
<pre><code>#!/bin/sh
# start some nice programs

if [ -d /etc/X11/xinit/xinitrc.d ] ; then
 for f in /etc/X11/xinit/xinitrc.d/?*.sh ; do
  [ -x &quot;$f&quot; ] &amp;&amp; . &quot;$f&quot;
 done
 unset f
fi

xec awesome&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>xinit配置完毕，执行startx即可运行配置中的内容。</p>
<h3 id="awesome配置">awesome配置</h3>
<p>awesome配置分为两部分：</p>
<ul>
<li>awesome全局配置</li>
<li>theme配置</li>
</ul>
<h4 id="awesome全局配置">awesome全局配置</h4>
<p>这部分配置控制awesome选择的主题、默认软件（编辑器、浏览器、终端等），是个lua脚本，示例文件在<code>/etc/xdg/awesome/rc.lua</code>，同样在家目录创建一份配置：</p>
<pre><code>mkdir ~/.config
mkdir ~/.config/awesome
 /etc/xdg/awesome/rc.lua ~/.config/awesome/rc.lua&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="theme配置">theme配置</h4>
<p>这部分配置控制具体的主题样式，包括各种图标、热键Mapping、颜色、壁纸、控件等等，通过改动theme配置可以实现高度自定义的awesome界面，示例文件目录在<code>/usr/share/awesome/</code>下，默认有：</p>
<ul>
<li>icons，图标</li>
<li>lib，lua脚本目录</li>
<li>themes，主题文件夹，默认包括几个示例主题<br>
将默认的配置复制到家目录下：</li>
</ul>
<pre><code>usr/share/awesome/* ~/.config/awesome/&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="具体配置及效果示例">具体配置及效果示例</h4>
<p>awesome默认使用xtrem作为终端，没有安装的情况下进入桌面是无法使用终端的。这里改用rxvt-unicode作为终端：</p>
<pre><code># 安装rxvt-unicode
sudo pacman -S rxvt-unicode

# 修改rc.lua
vim ~/.config/awesome/rc.lua&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>搜索关键词terminal并将：</p>
<pre><code>terminal     = &quot;xtrem&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>修改为：</p>
<pre><code>terminal     = &quot;urxvtc&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>awesome默认主题为default，并且提供了几个内置主题，将主题修改为sky：</p>
<pre><code>vim ~/.config/awesome/rc.lua&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>搜索关键词theme并将：</p>
<pre><code>utiful.init(gears.filesystem.get_themes_dir() .. &quot;default/theme.lua&quot;)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>修改为：</p>
<pre><code>utiful.init(&quot;/home/duck/.config/awesome/themes/sky/theme.lua&quot;)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>原代码使用lib中的gears.filesystem.get_themes_dir()方法拿到主题文件夹路径，正确配置之后可以直接修改主题名即可，这里示例使用了绝对路径。</p>
<p>主题默认壁纸在主题文件夹内，修改壁纸为自定义的图片：</p>
<pre><code>vim ~/.config/awesome/themes/sky/theme.lua&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>搜索关键词wallpaper并将：</p>
<pre><code>theme.wallpaper = themes_path .. &quot;sky/sky-background.png&quot;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>修改为：</p>
<pre><code>utiful.init(&quot;/home/duck/.config/awesome/themes/sky/my_background.png&quot;)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>完成之后启动awesomeWM：</p>
<pre><code>tartx&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>即可看到效果。</p>
<h2 id="小结">小结</h2>
<p>awesomeWM可以理解为一个针对键盘操作而设计的窗口管理工具，通过使用awesomeWM可以快速完成各种终端管理，提高工作效率。通过配置awesome的主题可以添加很多控件，如日历、天气等，自定义出专属的生产工具。</p>
<h1 id="linux-booting-process">Linux Booting Process</h1>
<p><img src="../2019/10/001-zhujiekun-Stages-of-Linux-Boot-Process.jpg" alt="">
Linux启动过程可以分为6个阶段</p>
<h2 id="bios">BIOS</h2>
<p>BIOS主要进行系统完整性检查，它会查找和执行对应的boot loader程序，比如在CD-ROM中找boot loader、在硬盘中找boot loader等。当查找到boot loader后，加载boot loader进内存，控制权交至boot loader。</p>
<h2 id="mbr">MBR</h2>
<p>MBR即Master Boot Record，位于bootable磁盘的第一个扇区。MBR大小小于512bytes，由三部分组成：</p>
<ul>
<li>主boot loader信息，在最前面的446bytes中</li>
<li>分区表信息，在随后的64bytes中</li>
<li>MBR校验信息，在最后的2bytes中</li>
</ul>
<p>它包含了GRUB相关信息，简单来说MBR加载和执行GRUB的boot loader。</p>
<h2 id="grub">GRUB</h2>
<p>GRUB即Grand Unified Bootloader，它负责加载和执行内核和文件镜像。如果安装了多个内核的话可以允许用户选择加载的内核，否则按照配置问价加载默认项，配置即之前grub-mkconfig生成的文件：</p>
<pre><code>#
# DO NOT EDIT THIS FILE
#
# It is automatically generated by grub-mkconfig using templates
# from /etc/grub.d and settings from /etc/default/grub
#

### BEGIN /etc/grub.d/00_header ###
insmod part_gpt
insmod part_msdos
if [ -s $prefix/grubenv ]; then
  load_env
fi
if [ &quot;${next_entry}&quot; ] ; then
   set default=&quot;${next_entry}&quot;
   set next_entry=
   save_env next_entry
   set boot_once=true
else
   set default=&quot;0&quot;
fi

if [ x&quot;${feature_menuentry_id}&quot; = xy ]; then
  menuentry_id_option=&quot;--id&quot;
else
  menuentry_id_option=&quot;&quot;
fi

export menuentry_id_option

if [ &quot;${prev_saved_entry}&quot; ]; then
  set saved_entry=&quot;${prev_saved_entry}&quot;
  save_env saved_entry
  set prev_saved_entry=
  save_env prev_saved_entry
  set boot_once=true
fi

function savedefault {
  if [ -z &quot;${boot_once}&quot; ]; then
    saved_entry=&quot;${chosen}&quot;
    save_env saved_entry
  fi
}

function load_video {
  if [ x$feature_all_video_module = xy ]; then
    insmod all_video
  else
    insmod efi_gop
    insmod efi_uga
    insmod ieee1275_fb
    insmod vbe
    insmod vga
    insmod video_bochs
    insmod video_cirrus
  fi
}

if [ x$feature_default_font_path = xy ] ; then
   font=unicode
else
insmod part_msdos
insmod ext2
set root='hd0,msdos1'
if [ x$feature_platform_search_hint = xy ]; then
  search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
else
  search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
fi
    font=&quot;/usr/share/grub/unicode.pf2&quot;
fi

if loadfont $font ; then
  set gfxmode=auto
  load_video
  insmod gfxterm
  set locale_dir=$prefix/locale
  set lang=en_US
  insmod gettext
fi
terminal_input console
terminal_output gfxterm
if [ x$feature_timeout_style = xy ] ; then
  set timeout_style=menu
  set timeout=5
# Fallback normal timeout code in case the timeout_style feature is
# unavailable.
else
  set timeout=5
fi
### END /etc/grub.d/00_header ###

### BEGIN /etc/grub.d/10_linux ###
menuentry 'Arch Linux' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
    load_video
    set gfxpayload=keep
    insmod gzio
    insmod part_msdos
    insmod ext2
    set root='hd0,msdos1'
    if [ x$feature_platform_search_hint = xy ]; then
      search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
    else
      search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
    fi
    echo    'Loading Linux linux ...'
    linux   /boot/vmlinuz-linux root=UUID=0a869b77-d317-4b40-8fb1-ffa44721cce6 rw  loglevel=3 quiet
    echo    'Loading initial ramdisk ...'
    initrd  /boot/initramfs-linux.img
}
submenu 'Advanced options for Arch Linux' $menuentry_id_option 'gnulinux-advanced-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
    menuentry 'Arch Linux, with Linux linux' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-linux-advanced-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
        load_video
        set gfxpayload=keep
        insmod gzio
        insmod part_msdos
        insmod ext2
        set root='hd0,msdos1'
        if [ x$feature_platform_search_hint = xy ]; then
          search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
        else
          search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
        fi
        echo    'Loading Linux linux ...'
        linux   /boot/vmlinuz-linux root=UUID=0a869b77-d317-4b40-8fb1-ffa44721cce6 rw  loglevel=3 quiet
        echo    'Loading initial ramdisk ...'
        initrd  /boot/initramfs-linux.img
    }
    menuentry 'Arch Linux, with Linux linux (fallback initramfs)' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-linux-fallback-0a869b77-d317-4b40-8fb1-ffa44721cce6' {
        load_video
        set gfxpayload=keep
        insmod gzio
        insmod part_msdos
        insmod ext2
        set root='hd0,msdos1'
        if [ x$feature_platform_search_hint = xy ]; then
          search --no-floppy --fs-uuid --set=root --hint-ieee1275='ieee1275//disk@0,msdos1' --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  0a869b77-d317-4b40-8fb1-ffa44721cce6
        else
          search --no-floppy --fs-uuid --set=root 0a869b77-d317-4b40-8fb1-ffa44721cce6
        fi
        echo    'Loading Linux linux ...'
        linux   /boot/vmlinuz-linux root=UUID=0a869b77-d317-4b40-8fb1-ffa44721cce6 rw  loglevel=3 quiet
        echo    'Loading initial ramdisk ...'
        initrd  /boot/initramfs-linux-fallback.img
    }
}

### END /etc/grub.d/10_linux ###

### BEGIN /etc/grub.d/20_linux_xen ###
### END /etc/grub.d/20_linux_xen ###

### BEGIN /etc/grub.d/30_os-prober ###
### END /etc/grub.d/30_os-prober ###

### BEGIN /etc/grub.d/40_custom ###
# This file provides an easy way to add custom menu entries.  Simply type the
# menu entries you want to add after this comment.  Be careful not to change
# the 'exec tail' line above.
### END /etc/grub.d/40_custom ###

### BEGIN /etc/grub.d/41_custom ###
if [ -f  ${config_directory}/custom.cfg ]; then
  source ${config_directory}/custom.cfg
elif [ -z &quot;${config_directory}&quot; -a -f  $prefix/custom.cfg ]; then
  source $prefix/custom.cfg;
fi
### END /etc/grub.d/41_custom ###&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="kernel">Kernel</h2>
<p>内核负责根据grub.cfg中声明的<code>root='hd0,msdos1'</code>挂载文件系统，并且执行<code>/sbin/init</code>的程序。因为init是第一个被Linux内核执行的程序，所以<code>ps aux | grep init</code>的pid为1。</p>
<pre><code>t         1  0.0  0.0 165304 10528 ?        Ss   11:45   0:13 /sbin/init splash&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>grub.cfg中有一行：</p>
<pre><code>initrd  /boot/initramfs-linux.img&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>initrd即初始化RAM Disk，使用initramfs-linux.img镜像，作为临时的root文件系统，直到启动后真正的文件系统挂载。initrd同时还包括了一些必要的驱动，让内核可以获取分区和硬件等信息。</p>
<h2 id="init">Init</h2>
<p>查看/etc/inittab文件来决定Linux运行的Level，具体包括以下7个Level：</p>
<ul>
<li>0 – halt</li>
<li>1 – Single user mode</li>
<li>2 – Multiuser, without NFS</li>
<li>3 – Full multiuser mode</li>
<li>4 – unused</li>
<li>5 – X11</li>
<li>6 – reboot</li>
</ul>
<p>Init根据文件决定默认的initlevel，加载所有相关的程序。</p>
<h2 id="runlevel">Runlevel</h2>
<p>Linux启动时，你会看到各种服务启动，比如“starting sendmail …. OK”，这些都是Runlevel的程序，不同的runlevel在相应的目录中：</p>
<pre><code># Run level ?
 /etc/rc.d/rc?.d/&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在目录下有“S”和“K”开头的程序，S代表startup的时候运行，K代表kill的时候运行。</p>
<h1 id="linux-command-analysis">Linux Command Analysis</h1>
<p>以<code>free</code>命令为例分析执行过程。</p>
<h2 id="free">free</h2>
<p>free命令源码参考<a href="https://github.com/soarpenguin/procps-3.0.5/blob/master/free.c">procps</a>。节选如下：</p>
<pre><code>int main(int argc, char **argv)
{
    int c, flags = 0, unit_set = 0;
    struct commandline_arguments args;

    /*
     * For long options that have no equivalent short option, use a
     * non-character as a pseudo short option, starting with CHAR_MAX + 1.
     */
    enum {
        SI_OPTION = CHAR_MAX + 1,
        KILO_OPTION,
        MEGA_OPTION,
        GIGA_OPTION,
        TERA_OPTION,
        PETA_OPTION,
        TEBI_OPTION,
        PEBI_OPTION,
        HELP_OPTION
    };

    static const struct option longopts[] = {
        {  &quot;bytes&quot;, no_argument,        NULL,  'b'      },
        {  &quot;kilo&quot;,  no_argument,        NULL,  KILO_OPTION  },
        {  &quot;mega&quot;,  no_argument,        NULL,  MEGA_OPTION  },
        {  &quot;giga&quot;,  no_argument,        NULL,  GIGA_OPTION  },
        {  &quot;tera&quot;,  no_argument,        NULL,  TERA_OPTION  },
        {  &quot;peta&quot;,  no_argument,        NULL,  PETA_OPTION  },
        {  &quot;kibi&quot;,  no_argument,        NULL,  'k'      },
        {  &quot;mebi&quot;,  no_argument,        NULL,  'm'      },
        {  &quot;gibi&quot;,  no_argument,        NULL,  'g'      },
        {  &quot;tebi&quot;,  no_argument,        NULL,  TEBI_OPTION  },
        {  &quot;pebi&quot;,  no_argument,        NULL,  PEBI_OPTION  },
        {  &quot;human&quot;, no_argument,        NULL,  'h'      },
        {  &quot;si&quot;,    no_argument,        NULL,  SI_OPTION    },
        {  &quot;lohi&quot;,  no_argument,        NULL,  'l'      },
        {  &quot;total&quot;, no_argument,        NULL,  't'      },
        {  &quot;seconds&quot;,   required_argument,  NULL,  's'      },
        {  &quot;count&quot;, required_argument,  NULL,  'c'      },
        {  &quot;wide&quot;,  no_argument,        NULL,  'w'      },
        {  &quot;help&quot;,  no_argument,        NULL,  HELP_OPTION  },
        {  &quot;version&quot;,   no_argument,        NULL,  'V'      },
        {  NULL,    0,          NULL,  0        }
    };

    /* defaults */
    args.exponent = 0;
    args.repeat_interval = 1000000;
    args.repeat_counter = 0;

#ifdef HAVE_PROGRAM_INVOCATION_NAME
    program_invocation_name = program_invocation_short_name;
#endif
    setlocale (LC_ALL, &quot;&quot;);
    bindtextdomain(PACKAGE, LOCALEDIR);
    textdomain(PACKAGE);
    atexit(close_stdout);

    while ((c = getopt_long(argc, argv, &quot;bkmghltc:ws:V&quot;, longopts, NULL)) != -1)
        switch (c) {
        case 'b':
                check_unit_set(&amp;unit_set);
            args.exponent = 1;
            break;
        case 'k':
                check_unit_set(&amp;unit_set);
            args.exponent = 2;
            break;
        case 'm':
                check_unit_set(&amp;unit_set);
            args.exponent = 3;
            break;
        case 'g':
                check_unit_set(&amp;unit_set);
            args.exponent = 4;
            break;
        case TEBI_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 5;
            break;
        case PEBI_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 6;
            break;
        case KILO_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 2;
            flags |= FREE_SI;
            break;
        case MEGA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 3;
            flags |= FREE_SI;
            break;
        case GIGA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 4;
            flags |= FREE_SI;
            break;
        case TERA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 5;
            flags |= FREE_SI;
            break;
        case PETA_OPTION:
                check_unit_set(&amp;unit_set);
            args.exponent = 6;
            flags |= FREE_SI;
            break;
        case 'h':
            flags |= FREE_HUMANREADABLE;
            break;
        case SI_OPTION:
            flags |= FREE_SI;
            break;
        case 'l':
            flags |= FREE_LOHI;
            break;
        case 't':
            flags |= FREE_TOTAL;
            break;
        case 's':
            flags |= FREE_REPEAT;
            errno = 0;
            args.repeat_interval = (1000000 * strtod_nol_or_err(optarg, &quot;seconds argument failed&quot;));
            if (args.repeat_interval &amp;lt; 1)
                xerrx(EXIT_FAILURE,
                     _(&quot;seconds argument `%s' is not positive number&quot;), optarg);
            break;
        case 'c':
            flags |= FREE_REPEAT;
            flags |= FREE_REPEATCOUNT;
            args.repeat_counter = strtol_or_err(optarg,
                _(&quot;failed to parse count argument&quot;));
            if (args.repeat_counter &amp;lt; 1)
              error(EXIT_FAILURE, ERANGE,
                  _(&quot;failed to parse count argument: '%s'&quot;), optarg);
            break;
        case 'w':
            flags |= FREE_WIDE;
            break;
        case HELP_OPTION:
            usage(stdout);
        case 'V':
            printf(PROCPS_NG_VERSION);
            exit(EXIT_SUCCESS);
        default:
            usage(stderr);
        }

    do {

        meminfo();
        /* Translation Hint: You can use 9 character words in
         * the header, and the words need to be right align to
         * beginning of a number. */
        if (flags &amp; FREE_WIDE) {
            printf(_(&quot;              total        used        free      shared     buffers       cache   available&quot;));
        } else {
            printf(_(&quot;              total        used        free      shared  buff/cache   available&quot;));
        }
        printf(&quot;\n&quot;);
        printf(&quot;%-7s&quot;, _(&quot;Mem:&quot;));
        printf(&quot; %11s&quot;, scale_size(kb_main_total, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_main_used, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_main_free, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_main_shared, flags, args));
        if (flags &amp; FREE_WIDE) {
            printf(&quot; %11s&quot;, scale_size(kb_main_buffers, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_main_cached, flags, args));
        } else {
            printf(&quot; %11s&quot;, scale_size(kb_main_buffers+kb_main_cached, flags, args));
        }
        printf(&quot; %11s&quot;, scale_size(kb_main_available, flags, args));
        printf(&quot;\n&quot;);
        /*
         * Print low vs. high information, if the user requested it.
         * Note we check if low_total == 0: if so, then this kernel
         * does not export the low and high stats. Note we still want
         * to print the high info, even if it is zero.
         */
        if (flags &amp; FREE_LOHI) {
            printf(&quot;%-7s&quot;, _(&quot;Low:&quot;));
            printf(&quot; %11s&quot;, scale_size(kb_low_total, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_low_total - kb_low_free, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_low_free, flags, args));
            printf(&quot;\n&quot;);

            printf(&quot;%-7s&quot;, _(&quot;High:&quot;));
            printf(&quot; %11s&quot;, scale_size(kb_high_total, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_high_total - kb_high_free, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_high_free, flags, args));
            printf(&quot;\n&quot;);
        }

        printf(&quot;%-7s&quot;, _(&quot;Swap:&quot;));
        printf(&quot; %11s&quot;, scale_size(kb_swap_total, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_swap_used, flags, args));
        printf(&quot; %11s&quot;, scale_size(kb_swap_free, flags, args));
        printf(&quot;\n&quot;);

        if (flags &amp; FREE_TOTAL) {
            printf(&quot;%-7s&quot;, _(&quot;Total:&quot;));
            printf(&quot; %11s&quot;, scale_size(kb_main_total + kb_swap_total, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_main_used + kb_swap_used, flags, args));
            printf(&quot; %11s&quot;, scale_size(kb_main_free + kb_swap_free, flags, args));
            printf(&quot;\n&quot;);
        }
        fflush(stdout);
        if (flags &amp; FREE_REPEATCOUNT) {
            args.repeat_counter--;
            if (args.repeat_counter &amp;lt; 1)
                exit(EXIT_SUCCESS);
        }
        if (flags &amp; FREE_REPEAT) {
            printf(&quot;\n&quot;);
            usleep(args.repeat_interval);
        }
    } while ((flags &amp; FREE_REPEAT));

    exit(EXIT_SUCCESS);
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>可以观察到命令主要做了几件事：</p>
<ul>
<li>执行meminfo()方法</li>
<li>根据输入参数，进行格式转换、单位转换等</li>
</ul>
<p>meminfo()方法并不在free.c中，全局查找定位到sysinfo.c文件中：</p>
<pre><code>void meminfo(void){
  char namebuf[32]; /* big enough to hold any row name */
  int linux_version_code = procps_linux_version();
  mem_table_struct findme = { namebuf, NULL};
  mem_table_struct *found;
  char *head;
  char *tail;
  static const mem_table_struct mem_table[] = {
  {&quot;Active&quot;,       &amp;kb_active},       // important
  {&quot;Active(file)&quot;, &amp;kb_active_file},
  {&quot;AnonPages&quot;,    &amp;kb_anon_pages},
  {&quot;Bounce&quot;,       &amp;kb_bounce},
  {&quot;Buffers&quot;,      &amp;kb_main_buffers}, // important
  {&quot;Cached&quot;,       &amp;kb_page_cache},  // important
  {&quot;CommitLimit&quot;,  &amp;kb_commit_limit},
  {&quot;Committed_AS&quot;, &amp;kb_committed_as},
  {&quot;Dirty&quot;,        &amp;kb_dirty},        // kB version of vmstat nr_dirty
  {&quot;HighFree&quot;,     &amp;kb_high_free},
  {&quot;HighTotal&quot;,    &amp;kb_high_total},
  {&quot;Inact_clean&quot;,  &amp;kb_inact_clean},
  {&quot;Inact_dirty&quot;,  &amp;kb_inact_dirty},
  {&quot;Inact_laundry&quot;,&amp;kb_inact_laundry},
  {&quot;Inact_target&quot;, &amp;kb_inact_target},
  {&quot;Inactive&quot;,     &amp;kb_inactive},     // important
  {&quot;Inactive(file)&quot;,&amp;kb_inactive_file},
  {&quot;LowFree&quot;,      &amp;kb_low_free},
  {&quot;LowTotal&quot;,     &amp;kb_low_total},
  {&quot;Mapped&quot;,       &amp;kb_mapped},       // kB version of vmstat nr_mapped
  {&quot;MemAvailable&quot;, &amp;kb_main_available}, // important
  {&quot;MemFree&quot;,      &amp;kb_main_free},    // important
  {&quot;MemTotal&quot;,     &amp;kb_main_total},   // important
  {&quot;NFS_Unstable&quot;, &amp;kb_nfs_unstable},
  {&quot;PageTables&quot;,   &amp;kb_pagetables},   // kB version of vmstat nr_page_table_pages
  {&quot;ReverseMaps&quot;,  &amp;nr_reversemaps},  // same as vmstat nr_page_table_pages
  {&quot;SReclaimable&quot;, &amp;kb_slab_reclaimable}, // &quot;slab reclaimable&quot; (dentry and inode structures)
  {&quot;SUnreclaim&quot;,   &amp;kb_slab_unreclaimable},
  {&quot;Shmem&quot;,        &amp;kb_main_shared},  // kernel 2.6.32 and later
  {&quot;Slab&quot;,         &amp;kb_slab},         // kB version of vmstat nr_slab
  {&quot;SwapCached&quot;,   &amp;kb_swap_cached},
  {&quot;SwapFree&quot;,     &amp;kb_swap_free},    // important
  {&quot;SwapTotal&quot;,    &amp;kb_swap_total},   // important
  {&quot;VmallocChunk&quot;, &amp;kb_vmalloc_chunk},
  {&quot;VmallocTotal&quot;, &amp;kb_vmalloc_total},
  {&quot;VmallocUsed&quot;,  &amp;kb_vmalloc_used},
  {&quot;Writeback&quot;,    &amp;kb_writeback},    // kB version of vmstat nr_writeback
  };
  const int mem_table_count = sizeof(mem_table)/sizeof(mem_table_struct);
  unsigned long watermark_low;
  signed long mem_available, mem_used;

  FILE_TO_BUF(MEMINFO_FILE,meminfo_fd);

  kb_inactive = ~0UL;
  kb_low_total = kb_main_available = 0;

  head = buf;
  for(;;){
    tail = strchr(head, ':');
    if(!tail) break;
    *tail = '\0';
    if(strlen(head) &gt;= sizeof(namebuf)){
      head = tail+1;
      goto nextline;
    }
    strcpy(namebuf,head);
    found = bsearch(&amp;findme, mem_table, mem_table_count,
        sizeof(mem_table_struct), compare_mem_table_structs
    );
    head = tail+1;
    if(!found) goto nextline;
    *(found-&gt;slot) = (unsigned long)strtoull(head,&amp;tail,10);
nextline:
    tail = strchr(head, '\n');
    if(!tail) break;
    head = tail+1;
  }
  if(!kb_low_total){  /* low==main except with large-memory support */
    kb_low_total = kb_main_total;
    kb_low_free  = kb_main_free;
  }
  if(kb_inactive==~0UL){
    kb_inactive = kb_inact_dirty + kb_inact_clean + kb_inact_laundry;
  }
  kb_main_cached = kb_page_cache + kb_slab_reclaimable;
  kb_swap_used = kb_swap_total - kb_swap_free;

  /* if kb_main_available is greater than kb_main_total or our calculation of
     mem_used overflows, that's symptomatic of running within a lxc container
     where such values will be dramatically distorted over those of the host. */
  if (kb_main_available &gt; kb_main_total)
    kb_main_available = kb_main_free;
  mem_used = kb_main_total - kb_main_free - kb_main_cached - kb_main_buffers;
  if (mem_used &amp;lt; 0)
    mem_used = kb_main_total - kb_main_free;
  kb_main_used = (unsigned long)mem_used;

  /* zero? might need fallback for 2.6.27 &amp;lt;= kernel &amp;lt;? 3.14 */
  if (!kb_main_available) {
#ifdef __linux__
    if (linux_version_code &amp;lt; LINUX_VERSION(2, 6, 27))
      kb_main_available = kb_main_free;
    else {
      FILE_TO_BUF(VM_MIN_FREE_FILE, vm_min_free_fd);
      kb_min_free = (unsigned long) strtoull(buf,&amp;tail,10);

      watermark_low = kb_min_free * 5 / 4; /* should be equal to sum of all 'low' fields in /proc/zoneinfo */

      mem_available = (signed long)kb_main_free - watermark_low
      + kb_inactive_file + kb_active_file - MIN((kb_inactive_file + kb_active_file) / 2, watermark_low)
      + kb_slab_reclaimable - MIN(kb_slab_reclaimable / 2, watermark_low);

      if (mem_available &amp;lt; 0) mem_available = 0;
      kb_main_available = (unsigned long)mem_available;
    }
#else
      kb_main_available = kb_main_free;
#endif /* linux */
  }
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>主要进行了：</p>
<ul>
<li>定义数据格式mem_table_struct</li>
<li>执行FILE_TO_BUF(MEMINFO_FILE, meminfo_fd)，这里的MEMINFO_FILE在上文有定义<code>#define MEMINFO_FILE &quot;/proc/meminfo&quot;</code>，meminfo_fd同样有定义为-1</li>
<li>后续主要对stdout内容进行计算，例如<code>mem_used = kb_main_total - kb_main_free - kb_main_cached - kb_main_buffers</code>，以及异常数值处理，例如当上面计算得出的mem_used为负值时，重新以<code>mem_used = kb_main_total - kb_main_free</code>计算</li>
</ul>
<p>FILE_TO_BUF方法具体没有找到定义，在sysinfo.c中有一段相关注释代码如下：</p>
<pre><code>#define FILE_TO_BUF(filename, fd) do{               \
    static int local_n;                     \
    if (fd == -1 &amp;&amp; (fd = open(filename, O_RDONLY)) == -1) {    \
    fputs(BAD_OPEN_MESSAGE, stderr);            \
    fflush(NULL);                       \
    _exit(102);                     \
    }                               \
    lseek(fd, 0L, SEEK_SET);                    \
    if ((local_n = read(fd, buf, sizeof buf - 1)) &amp;lt; 0) {    \
    perror(filename);                   \
    fflush(NULL);                       \
    _exit(103);                     \
    }                               \
    buf[local_n] = '\0';                    \
}while(0)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>可以看到FILE_TO_BUF()主要进行了：</p>
<ul>
<li>fd默认-1，表示未打开</li>
<li>尝试打开对应文件（如/proc/meminfo），赋给fd，成功则fd改变，否则fputs打开失败消息，退出</li>
<li>打开成功，读取fd内容，放入buf中</li>
</ul>
<p>总结free命令从读取/proc/meminfo到显示过程：</p>
<ul>
<li>尝试打开/proc/meminfo，成功则暂存至变量，失败退出</li>
<li>读取暂存的变量，根据定义的数据结构，将各个值放至对应字段</li>
<li>根据读取的数值，计算一些统计值，如已使用内存=总内存-可用内存，并进行对应的异常处理</li>
<li>处理完毕的数据，根据free命令的参数，进行格式转换，如：kb、gb间的转换；根据-h参数决定是否添加单位；根据参数决定字段是否要显示等</li>
<li>输出格式化（类似表格形式）后的内容</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>Redis HyperLogLog及应用尝试</title>
			<link>https://jiekun.dev/posts/2019-10-16-redis-hyperloglog%E5%8F%8A%E5%BA%94%E7%94%A8%E5%B0%9D%E8%AF%95/</link>
			<pubDate>Wed, 16 Oct 2019 05:02:48 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-10-16-redis-hyperloglog%E5%8F%8A%E5%BA%94%E7%94%A8%E5%B0%9D%E8%AF%95/</guid>
			<description>WIP!</description>
			<content type="html"><![CDATA[<p>WIP!</p>
]]></content>
		</item>
		
		<item>
			<title>There is a plan</title>
			<link>https://jiekun.dev/posts/2019-10-08-there-is-a-plan/</link>
			<pubDate>Tue, 08 Oct 2019 07:32:07 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-10-08-there-is-a-plan/</guid>
			<description>国庆长假过完猛然发现假期效率远比周末泡图书馆低，大概是图书馆旅客太多了吧（疯狂找借口乱甩锅）。
未来的几个月非常关键，于是需要确定个Schedule，各个阶段的不同目标要明确清楚，才容易针对性的突破瓶颈。
Dealing with cache system 缓存系统的设计和应用一直是2C项目缓解压力的利器。和以往使用简单的应用层缓存不同，需要开始对分布式系统和应用层之前的缓存进行学习。
Redis Redis在经典的3.0版本（也是目前使用特别广泛的版本）后新增了很多新的特性。以往的学习大多是基于旧版本的，缺乏对新的数据结构，新的功能的了解，因此花1周时间，重点关注Redis的新型数据结构，包括Bitmap、HyperLogLog、BloomFilter、Geo以及一些扩展如实现限流用的Redis-Cell。要求完成1篇以上博客形式的学习笔记。
在大流量的系统中依靠单点的缓存系统很难支撑请求，对于Redis集群的实现之前已经有所了解，第二周的目标是搭建一套Redis集群系统，并且尝试Redis分布式锁RedLock的使用，如轮流抢锁进行Print和Sleep。
HTTP &amp;amp; Nginx HTTP层面的缓存在项目中使用默认配置（目测是没有用上的hhhh），在接下来的一周里面需要丰富HTTP缓存机制的理解，目标是能够手写多种HTTP缓存控制的协商方案流程。
Nginx层面也有一些和HTTP缓存相关的设置，同样在周内了解各个设置的内容，目标是配置Nginx的时候能够不参考文档完成对项目特定内容的缓存控制配置。
Dealing with databases 随着业务的增长，基础数据的数量急剧提升，原有的设计已经有很多地方跟不上新的业务需求。处理大量的数据，需要有对应新的存储方案的设计。
聚焦MySQL的痛点 什么样的数据让数据库撑不住增长压力？由于业务变化，很多业务从之前的周期型统计&amp;amp;展示分析结果逐渐演变成了更有说服力的展示原始的监测数据&amp;amp;分析数据。原始的监控数据，即爬虫抓取的内容，增长量一般会在每日十万、百万，每月数千万，半年内突破亿级。这部分数据既有展示的需要，又要找地方存放，因此需要支持快速取数并且考虑存储成本。
目前，数据一般使用MySQL存放，对于日志型数据，单独开机器存放MySQL的成本较为高，并且也有遇到过磁盘空间不足需要扩容的情况。因此目前需要了解的包括：
 日志型数据的存储，如果是非关系型DB的话了解一下使用方法 数据库扩容方案，分批淘汰方案  总体来说，在这一块应该关注的点：
 MySQL对大数据量，并发要求不高的情况下的方案 非关系型数据库存放日志型数据的方案  在现在的情况下，实际上应该有比MySQL更优秀的成熟的体系去处理这些问题，因为不可能说各种业务数据都用这样的DB来存。希望这个阶段能够接触一些其他的相关知识和新型的存储，深挖MySQL的同时横向扩展知识面，解决数据量持续增长的问题。
本小节目标比较抽象，具体内容和方向还需要调研，因此：
 MySQL处理方案  周期：1周 目标：学习MySQL扩容、分区等可行方案，思考冷热数据如何分批淘汰，完成1篇学习笔记。   新型DB处理方案  周期：1周 目标：了解是否可以用其他DB解决日志型数据的存储，例如ClickHouse、TiDB（未确认，不了解）等。了解他们的基本原理，为什么比MySQL合适，如何实现，完成1篇学习笔记。    Conclusion Schedule
 Redis新型数据类型学习 Redis集群学习和实践 HTTP&amp;amp;Nginx等非应用层缓存学习 MySQL对日志型数据的优化方案 非关系型DB对日志型数据的引用  一共5点，每个内容时限为1周，10月8日起步，DDL为11月5日。评论栏每日打卡，启动！
以上。
嘎。</description>
			<content type="html"><![CDATA[<p>国庆长假过完猛然发现假期效率远比周末泡图书馆低，大概是图书馆旅客太多了吧（疯狂找借口乱甩锅）。</p>
<p>未来的几个月非常关键，于是需要确定个Schedule，各个阶段的不同目标要明确清楚，才容易针对性的突破瓶颈。</p>
<h2 id="dealing-with-cache-system">Dealing with cache system</h2>
<p>缓存系统的设计和应用一直是2C项目缓解压力的利器。和以往使用简单的应用层缓存不同，需要开始对分布式系统和应用层之前的缓存进行学习。</p>
<h3 id="redis">Redis</h3>
<p>Redis在经典的3.0版本（也是目前使用特别广泛的版本）后新增了很多新的特性。以往的学习大多是基于旧版本的，缺乏对新的数据结构，新的功能的了解，因此花1周时间，重点关注Redis的新型数据结构，包括Bitmap、HyperLogLog、BloomFilter、Geo以及一些扩展如实现限流用的Redis-Cell。要求完成1篇以上博客形式的学习笔记。</p>
<p>在大流量的系统中依靠单点的缓存系统很难支撑请求，对于Redis集群的实现之前已经有所了解，第二周的目标是搭建一套Redis集群系统，并且尝试Redis分布式锁RedLock的使用，如轮流抢锁进行Print和Sleep。</p>
<h3 id="http--nginx">HTTP &amp; Nginx</h3>
<p>HTTP层面的缓存在项目中使用默认配置（目测是没有用上的hhhh），在接下来的一周里面需要丰富HTTP缓存机制的理解，目标是能够手写多种HTTP缓存控制的协商方案流程。</p>
<p>Nginx层面也有一些和HTTP缓存相关的设置，同样在周内了解各个设置的内容，目标是配置Nginx的时候能够不参考文档完成对项目特定内容的缓存控制配置。</p>
<h2 id="dealing-with-databases">Dealing with databases</h2>
<p>随着业务的增长，基础数据的数量急剧提升，原有的设计已经有很多地方跟不上新的业务需求。处理大量的数据，需要有对应新的存储方案的设计。</p>
<h3 id="聚焦mysql的痛点">聚焦MySQL的痛点</h3>
<p>什么样的数据让数据库撑不住增长压力？由于业务变化，很多业务从之前的周期型统计&amp;展示分析结果逐渐演变成了更有说服力的展示原始的监测数据&amp;分析数据。原始的监控数据，即爬虫抓取的内容，增长量一般会在每日十万、百万，每月数千万，半年内突破亿级。这部分数据既有展示的需要，又要找地方存放，因此需要支持快速取数并且考虑存储成本。</p>
<p>目前，数据一般使用MySQL存放，对于日志型数据，单独开机器存放MySQL的成本较为高，并且也有遇到过磁盘空间不足需要扩容的情况。因此目前需要了解的包括：</p>
<ul>
<li>日志型数据的存储，如果是非关系型DB的话了解一下使用方法</li>
<li>数据库扩容方案，分批淘汰方案</li>
</ul>
<p>总体来说，在这一块应该关注的点：</p>
<ul>
<li>MySQL对大数据量，并发要求不高的情况下的方案</li>
<li>非关系型数据库存放日志型数据的方案</li>
</ul>
<p>在现在的情况下，实际上应该有比MySQL更优秀的成熟的体系去处理这些问题，因为不可能说各种业务数据都用这样的DB来存。希望这个阶段能够接触一些其他的相关知识和新型的存储，深挖MySQL的同时横向扩展知识面，解决数据量持续增长的问题。</p>
<p>本小节目标比较抽象，具体内容和方向还需要调研，因此：</p>
<ul>
<li>MySQL处理方案
<ul>
<li>周期：1周</li>
<li>目标：学习MySQL扩容、分区等可行方案，思考冷热数据如何分批淘汰，完成1篇学习笔记。</li>
</ul>
</li>
<li>新型DB处理方案
<ul>
<li>周期：1周</li>
<li>目标：了解是否可以用其他DB解决日志型数据的存储，例如ClickHouse、TiDB（未确认，不了解）等。了解他们的基本原理，为什么比MySQL合适，如何实现，完成1篇学习笔记。</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Schedule</p>
<ul>
<li>Redis新型数据类型学习</li>
<li>Redis集群学习和实践</li>
<li>HTTP&amp;Nginx等非应用层缓存学习</li>
<li>MySQL对日志型数据的优化方案</li>
<li>非关系型DB对日志型数据的引用</li>
</ul>
<p>一共5点，每个内容时限为1周，10月8日起步，DDL为11月5日。评论栏每日打卡，启动！</p>
<p>以上。</p>
<p>嘎。</p>
]]></content>
		</item>
		
		<item>
			<title>理解AMQP协议和RabbitMQ的性能和可靠平衡</title>
			<link>https://jiekun.dev/posts/2019-09-26-%E7%90%86%E8%A7%A3amqp%E5%8D%8F%E8%AE%AE%E5%92%8Crabbitmq%E7%9A%84%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%AF%E9%9D%A0%E5%B9%B3%E8%A1%A1/</link>
			<pubDate>Thu, 26 Sep 2019 14:09:28 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-26-%E7%90%86%E8%A7%A3amqp%E5%8D%8F%E8%AE%AE%E5%92%8Crabbitmq%E7%9A%84%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%AF%E9%9D%A0%E5%B9%B3%E8%A1%A1/</guid>
			<description>前言 在之前的博客中，已经使用Pika包实践操作过RabbitMQ了，借用了几个不同的Exchange实现不同功能的生产-消费模式，但是对RabbitMQ的细节还缺乏更进一步的理解。今天从AMQP协议起更仔细地来看一下MQ背后的实现。
AMQP协议 RabbitMQ通过AMQP协议通信，这就类似于HTTP客户端和服务器进行通信一样。
在AMQP中，客户端和服务器之间的通信数据是拆成帧（frame）的结构。
对话启动 需要对话首先要建立连接：
客户端先发送协议头（protocol header）给服务器，服务器收到后，返回Connection.Start给客户端，客户端确认后返回Connection.StartOk给服务器，完成回话启动。
信道 AMQP规范定义了通信的信道，一个AMQP连接可以有多个信道，允许客户端和服务器之间进行多次会话。
AMQP帧结构 上面留意到，建立连接时服务器和客户端的相应都有共同部分Connection，因为AMQP命令是分为类和方法，用点（.）连接。连接时，Connection是使用的类，Start和StartOk是方法。
AMQB的帧由以下组件组成：
 帧类型 信道 帧大小（字节） 帧有效载荷 结束字节标记（0xce）  AMQP的帧有五种类型：
 协议头帧，也就是上面建立连接使用，仅使用一次 方法帧，携带发送或接收的请求或相应 内容头帧，消息的大小和属性 消息体帧，消息的内容 心跳帧，双向均可发送，确保连接两端可用和正常工作  下面来看一下这几种类型的帧如何组成消息。
 除了建立连接以外，AMQP在通信时，首先使用方法帧构建RPC请求所需的类、方法和参数。按照上文的帧结构，现在构造一个帧：  帧类型为方法帧（1） 信道0 有效载荷大小为41 有效载荷为类、方法、参数等   以0xce结尾   方法帧通知对方后，继续构造一个内容头帧，告知对方接下来要发送的消息大小和属性：  帧类型为内容头帧（2） 信道1 有效载荷大小为45 有效载荷为：消息体大小55，被设置的属性为144（内容类型）和200（app_id），被设置的属性的值分别为application/json和Test，timestamp属性为1014206880，投递模式为1   以0xce结尾  注意内容头帧声明的这些属性是在BasicProperty映射表中的。
 内容头帧通知对方后，继续构造一个消息体帧发送具体消息：  帧类型为消息体帧（3） 信道为1 有效载荷大小为55（对应内容头帧中的55） 有效载荷为一段JSON格式的字符串   以0xce结尾  注意AMQP协议是不会理会消息中的内容的，不对消息进行解析，即使知道对方是JSON格式内容。
使用AMQP协议 了解完AMQP协议的格式后，来看一下如何使用AMQP协议。
首先，需要声明一个交换器（Exchange）。交换器在AMQP规范中有自己的类，使用Exchange.Declear命令创建交换器，服务端使用Exchange.DeclearOk进行响应：
然后再创建一个队列（Queue）。同样Queue.Declear和Queue.DeclearOk完成。注意声明队列的时候多次发送同一个Queue.Declear不会有作用，只有第一次Declear会被处理，后续再Declear同样内容无效，Declear同名不同属性队列也无效。
现在我们有交换器和队列，在之前的博客中我们知道，消息是发送给Exchange的，然后Exchange推送至队列中。Exchange和Queue的关系需要进行绑定。使用Queue.Bind和Queue.BindOk命令将Queue绑定至Exchange。</description>
			<content type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>在之前的博客中，已经使用Pika包实践操作过RabbitMQ了，借用了几个不同的Exchange实现不同功能的生产-消费模式，但是对RabbitMQ的细节还缺乏更进一步的理解。今天从AMQP协议起更仔细地来看一下MQ背后的实现。</p>
<h1 id="amqp协议">AMQP协议</h1>
<p>RabbitMQ通过AMQP协议通信，这就类似于HTTP客户端和服务器进行通信一样。<br>
在AMQP中，客户端和服务器之间的通信数据是拆成帧（frame）的结构。</p>
<h5 id="对话启动">对话启动</h5>
<p>需要对话首先要建立连接：</p>
<p><img src="../2019/09/1-1.png" alt="">
客户端先发送协议头（protocol header）给服务器，服务器收到后，返回<code>Connection.Start</code>给客户端，客户端确认后返回<code>Connection.StartOk</code>给服务器，完成回话启动。</p>
<h5 id="信道">信道</h5>
<p>AMQP规范定义了通信的信道，一个AMQP连接可以有多个信道，允许客户端和服务器之间进行多次会话。</p>
<h5 id="amqp帧结构">AMQP帧结构</h5>
<p>上面留意到，建立连接时服务器和客户端的相应都有共同部分<code>Connection</code>，因为AMQP命令是分为类和方法，用点（.）连接。连接时，<code>Connection</code>是使用的类，<code>Start</code>和<code>StartOk</code>是方法。</p>
<p>AMQB的帧由以下组件组成：</p>
<ul>
<li>帧类型</li>
<li>信道</li>
<li>帧大小（字节）</li>
<li>帧有效载荷</li>
<li>结束字节标记（0xce）</li>
</ul>
<p><img src="../2019/09/2.png" alt="">
AMQP的帧有五种类型：</p>
<ul>
<li>协议头帧，也就是上面建立连接使用，仅使用一次</li>
<li>方法帧，携带发送或接收的请求或相应</li>
<li>内容头帧，消息的大小和属性</li>
<li>消息体帧，消息的内容</li>
<li>心跳帧，双向均可发送，确保连接两端可用和正常工作</li>
</ul>
<p>下面来看一下这几种类型的帧如何组成消息。</p>
<ul>
<li>除了建立连接以外，AMQP在通信时，首先使用方法帧构建RPC请求所需的类、方法和参数。按照上文的帧结构，现在构造一个帧：
<ul>
<li>帧类型为方法帧（1）</li>
<li>信道0</li>
<li>有效载荷大小为41</li>
<li>有效载荷为类、方法、参数等</li>
</ul>
</li>
<li>以0xce结尾</li>
</ul>
<p><img src="../2019/09/3.png" alt=""></p>
<ul>
<li>方法帧通知对方后，继续构造一个内容头帧，告知对方接下来要发送的消息大小和属性：
<ul>
<li>帧类型为内容头帧（2）</li>
<li>信道1</li>
<li>有效载荷大小为45</li>
<li>有效载荷为：消息体大小55，被设置的属性为144（内容类型）和200（app_id），被设置的属性的值分别为application/json和Test，timestamp属性为1014206880，投递模式为1</li>
</ul>
</li>
<li>以0xce结尾</li>
</ul>
<p><img src="../2019/09/4.png" alt="">
注意内容头帧声明的这些属性是在BasicProperty映射表中的。</p>
<ul>
<li>内容头帧通知对方后，继续构造一个消息体帧发送具体消息：
<ul>
<li>帧类型为消息体帧（3）</li>
<li>信道为1</li>
<li>有效载荷大小为55（对应内容头帧中的55）</li>
<li>有效载荷为一段JSON格式的字符串</li>
</ul>
</li>
<li>以0xce结尾</li>
</ul>
<p><img src="../2019/09/5.png" alt="">
注意AMQP协议是不会理会消息中的内容的，不对消息进行解析，即使知道对方是JSON格式内容。</p>
<h5 id="使用amqp协议">使用AMQP协议</h5>
<p>了解完AMQP协议的格式后，来看一下如何使用AMQP协议。<br>
首先，需要声明一个交换器（Exchange）。交换器在AMQP规范中有自己的类，使用Exchange.Declear命令创建交换器，服务端使用Exchange.DeclearOk进行响应：</p>
<p><img src="../2019/09/6.png" alt="">
然后再创建一个队列（Queue）。同样Queue.Declear和Queue.DeclearOk完成。注意声明队列的时候多次发送同一个Queue.Declear不会有作用，只有第一次Declear会被处理，后续再Declear同样内容无效，Declear同名不同属性队列也无效。</p>
<p><img src="../2019/09/7.png" alt="">
现在我们有交换器和队列，在之前的博客中我们知道，消息是发送给Exchange的，然后Exchange推送至队列中。Exchange和Queue的关系需要进行绑定。使用Queue.Bind和Queue.BindOk命令将Queue绑定至Exchange。</p>
<p><img src="../2019/09/8.png" alt="">
现在所有准备工作都完成了，我们来发布消息到RabbitMQ。通过上文可知，发送消息需要发送方法帧、内容头帧和（至少一个）消息体帧。其中方法帧在发布消息时应该是对应Basic类的Publish方法。</p>
<p><img src="../2019/09/9.png" alt="">
当RabbitMQ收到消息后，它会尝试将方法帧中的交换器名称和配置交换器的数据库进行匹配。如果配置中不存在交换器，将会自动丢弃该消息。如果希望确保投递消息成功，发布时mandatory标志需要设置为true，或者使用投递确认机制。<br>
RabbitMQ收到的消息将会以FIFO的顺序放入队列，并且放入队列的是消息的引用而不是消息本身，这样可以允许一个消息放入多个队列中。<br>
RabbitMQ可以将这些消息保存在内存中或写入磁盘，取决于Basic.Properties中指定的delivery-mode属性。</p>
<p>再来看一下如何从RabbitMQ中消费消息。<br>
与Basic.Publish类似，首先客户端发送Basic.Consume命令，服务端返回Basic.ConsumeOk，消费者进入活跃状态。然后服务端开始向消费者发送消息，以Basic.Deliver为方法帧，加上内容头和消息体帧发送消息。直到消费者发送Basic.Cancel或者触发一些事件前，服务端都会一直发送消息。</p>
<p><img src="../2019/09/10.png" alt="">
在发送Basic.Consume时，可以设置no_ack=false，这样消费者必须对每条消息发送Basic.Ack进行确认，否则RabbitMQ就会连续发送消息直到Basic.Cancel。</p>
<p><img src="../2019/09/11.png" alt="">
当发送Basic.Ack相应帧的时候，消费者必须在Basic.Deliver方法帧中传递一个投递标签（delivery tag）的参数。</p>
<h1 id="amqp的basicproperties">AMQP的Basic.Properties</h1>
<p>在内容头帧中，有包含很多消息属性，如上文提到的属性144，值为application/json，实际上属性144就是代表content-type。通过这些属性来对消息体进行描述。来看一下Basic.Properties都有哪些属性：</p>
<p><img src="../2019/09/12.png" alt="">
本文不打算一一解释各个属性，它们在需要使用时都可以通过文档查询到。下面选取几个常见的属性简单介绍。</p>
<ul>
<li>expiration，时间戳，超过后消息会被服务器丢弃。</li>
<li>delivery-mode，1表示非持久化消息，2表示持久化消息，性能相关。</li>
<li>header，自定义消息头，值为键值对，通过header属性可以结合header类型的Exchange实现自定义的消息路由。</li>
<li>priority，优先级，如果存在更高优先级的消息，消费者将更早获取到。</li>
</ul>
<p><img src="../2019/09/13.png" alt=""></p>
<h1 id="消息发布的性能权衡">消息发布的性能权衡</h1>
<p>《深入RabbitMQ》中有一幅图简单描述了RabbitMQ实现高性能和可靠投递时的设置组合：</p>
<p><img src="../2019/09/14.png" alt="">
通过结合不同的组合，我们可以从RabbitMQ上榨取最好的性能或者保障更可靠的消息传递。</p>
<p>下面介绍几个实现不同需求的设置。</p>
<h5 id="mandatory">mandatory</h5>
<p>mandatory标志是和Basic.Publish一起传递的参数，告诉RabbitMQ如果消息不可路由，将它通过Basic.Return返回给消费者。</p>
<h5 id="发布者确认替代事务">发布者确认替代事务</h5>
<p>为了确认RabbitMQ收到消息，在发送消息前，发送Confirm.Select命令，等待RabbitMQ返回Confirm.SelectOk以开启投递确认。开启后，对于每条发布的消息，服务器都会返回Basic.Ack响应，或者Baskc.Nack并让发布者决定如何处理。</p>
<p><img src="../2019/09/15.png" alt=""></p>
<h5 id="备用交换器处理无法路由的消息">备用交换器处理无法路由的消息</h5>
<p>声明一个Exchange作为备用交换器，然后在声明<strong>其他</strong>交换器时使用参数<code>alternate-exchange=备用交换器</code>。备用交换器（AE）类型设定为fanout，当消息在Exchange上无法路由时，它将会由AE路由至死信队列。</p>
<p><img src="../2019/09/16.png" alt=""></p>
<h5 id="事务">事务</h5>
<p>在没有确认投递（Confirm.Select）的情况下，事务是确保消息被成功投递的唯一方法。AMQP事务（TX）的使用是：</p>
<ul>
<li>发送TX.Select，相应TX.SelectOk</li>
<li>Basic.Publish</li>
<li>TX.Commit和TX.CommitOk<br>
在Basic.Publish后如果有异常，可以通过TX.Rollback处理。</li>
</ul>
<h5 id="ha队列">HA队列</h5>
<p>HA队列作为RabbitMQ的高可用实现，通过RabbitMQ集群，在创建Queue时设置HA策略，开启HA队列。当消息发布到高可用队列中，该消息会被发送到集群中的每台服务器，一旦消息在任何节点完成消费，那么消息的所有副本将立即从其他节点中删除。</p>
<p><img src="../2019/09/17.png" alt=""></p>
<h5 id="delivery-mode">delivery-mode</h5>
<p>通过设置delivery-mode=2，消息会被持久化到硬盘。持久化会导致性能问题。当消息引用不存在任何队列中，RabbitMQ将从硬盘中删除消息。</p>
<h5 id="rabbitmq回推">RabbitMQ回推</h5>
<p>发布者有可能大量发送消息，如果不进行处理，有可能会拖垮服务。<br>
在旧版本中，发布者发布过快，将会收到一条Channel.Flow让发布者产生阻塞，直到接收到另一条Channel.Flow命令为止。<br>
但是对于不礼貌的发布者而言，无视Channel.Flow命令继续发送仍然会导致问题。RabbitMQ团队使用TCP背压机制来解决这个问题，通过停止接受TCP的低层数据来防止被拖垮。<br>
在内部RabbitMQ有一套信用机制，接收到消息时会扣除一点信用值，完成处理返还信用值。当信用值不足时，当前连接的消息会被跳过直到它有足够的信用值为止。<br>
RabbitMQ还有通知客户端已被阻塞的方法：Connection.Blocked和Connection.Unblocked。</p>
<h1 id="rabbitmq和消费者">RabbitMQ和消费者</h1>
<p>上面聊完发布者和RabbitMQ，现在轮到消费者和RabbitMQ了。</p>
<h5 id="拉取和消费">拉取和消费</h5>
<p>消费者获取消息可以通过Basic.Get和Basic.Consume，下面来比较一下这两者：</p>
<ul>
<li>Basic.Get类似于轮询，如果有消息可消费，返回Basic.GetOk和内容头、消息体；如果没有消息可消费，返回Basic.GetEmpty。</li>
<li>Basic.Consume开启消费者活动状态，RabbitMQ如果有消息即可向消费者进行推送：Basic.Deliver，视情况消费者再返回Basic.Ack。</li>
<li>Basic.Consume的性能比Basic.Get更好，Get的轮询影响吞吐量，并且它不知道什么时候会有新的消息，所以要一直询问。</li>
</ul>
<h5 id="no-ack">no-ack</h5>
<p>消费者发送Basic.Consume的时候，可以带上no-ack标志，表示消费消息不需要进行ack确认，提高性能。<br>
如果不开启no-ack，RabbitMQ会等待消费者发送Basic.Ack确认消息，如果不得到确认，消息将不会被消费掉。</p>
<h5 id="服务质量设置控制消费者预取">服务质量设置控制消费者预取</h5>
<p>如果消息要一条一条确认，那会比较麻烦。通过QoS设置，在确认消息之前，消费者可以预先接收一定数量的消息。<br>
使用QoS的好处就是不用每次都确认消息，通过Basic.Ack设置multiple属性为True，可以让RabbitMQ知道消费者想确认之前未确认的消息。</p>
<h5 id="消费者使用事务">消费者使用事务</h5>
<p>和生产者一样使用TX类，可能会对性能有影响。</p>
<p><img src="../2019/09/18.png" alt=""></p>
<h5 id="拒绝消息">拒绝消息</h5>
<p>Basic.Reject命令告知服务端，消费者无法对投递的消息进行处理。类似的还有RabbitMQ团队扩展的Basic.Nack命令，与Basic.Reject功能类似，但是支持像Basic.Ack一样对多消息进行处理。</p>
<p>死信交换器（DLX）是对AMQP规范的扩展。DLX是用来保存被拒绝的消息。一旦拒绝了一个不重新发送的消息，RabbitMQ将把消息路由到队列的<code>x-dead-letter-exchange</code>参数中指定的交换器。</p>
<p><img src="../2019/09/19.png" alt="">
使用DLX，首先需要声明一个Exchange（图中的x），在声明Queue的时候将Queue的<code>x-dead-letter-exchange</code>指定为x即可。</p>
<h5 id="控制队列">控制队列</h5>
<p>在RabbitMQ可以定义很多不同的队列行为，如：</p>
<ul>
<li>自动销毁自己</li>
<li>只允许一个消费者消费</li>
<li>消息自动过期</li>
<li>保持消息数量有限</li>
<li>将旧消息推出堆栈</li>
</ul>
<p>临时队列<br>
有的时候我们会希望在没有消费者连接队列时，自动删除这个队列。创建自动删除队列非常简单，只需要在Queue.Declear中将<code>auto_delete</code>标志设置为True。</p>
<p>只允许单个消费者<br>
RabbitMQ鼓励多个消费者进行消费，当然它也还是可以支持消费者独占队列的。通过设置<code>exclusive</code>属性为True可以确保只有单个消费者进行消费，队列会在消费者断开连接后自动删除。</p>
<p>自动过期队列<br>
之前有提到过的消息的<code>expiration</code>参数，现在通过设置<code>x-expires</code>参数，可以声明一个自动过期队列。不过需要注意，自动过期队列只有在没有消费者的情况下才会过期，否则只有在发出了Basic.Cancel之后才会自动删除。如果队列在TTL内收到了Basic.Get请求，那么队列的过期设置会无效。</p>
<p>永久队列<br>
如果需要重启后仍可用的队列，需要在声明时设置<code>durable</code>为True。务必要将队列持久化和消息持久化区分开来，相对应的，消息持久化是<code>delivery-mode</code>设置为2。当队列持久化设置之后，需要通过Queue.Delete删除。</p>
<p>队列中的消息自动过期<br>
对于不重要的消息，可以在没被消费的情况下，不需要存在太久。对于队列而言，设置<code>x-message-ttl</code>可以规定队列中的所有消息最大生存时间。</p>
<p>队列最大长度<br>
从RabbitMQ 3.1.0开始，可以指定队列的最大长度，超过最大值时，添加新消息的同时就会删除位于队列最前端的消息，也就是确保队列中为最近新增的n个消息。通过设置<code>x-max-length</code>参数可以实现这个功能。</p>
<p><img src="../2019/09/20.png" alt=""></p>
<h1 id="rabbitmq消息路由模式">RabbitMQ消息路由模式</h1>
<p>消息路由在之前的博客中已经介绍过了，RabbitMQ中主要有几种基本的Exchange：</p>
<ul>
<li>Direct，匹配routing_key</li>
<li>Fanout，广播至所有Queue</li>
<li>Topic，模式匹配routing_key</li>
<li>Headers</li>
</ul>
<p>其中Headers之前的博客是没有使用过的，在这里简略介绍一下。</p>
<p>之前提到过，在Basic.Publish时可以给消息添加各种headers属性，就像HTTP的请求头字段一样。Headers的Exchange通过设定一些header字段，如果消息的header能够匹配Exchange的header，则可以发布到对应的Queue中去。简单来说，就是通过headers来匹配路由的方式。</p>
<h1 id="总结">总结</h1>
<p>本文主要对AMQP协议进行了介绍，同时协议（以及RabbitMQ自行扩展的规范）中的各个设置可能会对MQ的性能和可靠性产生影响，这些内容也从发布者和消费者的角度进行了介绍，以满足不同性能、可靠性要求的业务。</p>
<p>深入了解RabbitMQ，很显然真正的消息队列应用与简单的Radis用作消息队列差异是非常大的，RabbitMQ实现了很多简单队列原生不支持的功能，例如优先级队列、自销毁队列、队列可靠性保障、拉取与消费模式等。在消息队列的场景中，如果有可靠性的要求，应该避免再使用自建的简单队列和造轮子再保障SLA，将对应业务转移至专业的MQ上来。</p>
]]></content>
		</item>
		
		<item>
			<title>Redis分布式锁的实现——RedLock</title>
			<link>https://jiekun.dev/posts/2019-09-21-redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0-redlock/</link>
			<pubDate>Sat, 21 Sep 2019 10:36:07 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-21-redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0-redlock/</guid>
			<description>文章配图是RedLock Python实现的作者optimuspaul的头像。
在分布式应用中经常会存在一些并发的问题，当多个请求想要处理同样的资源时，比如某个操作需要读取资源，根据读取结果进行修改，再写入，若这个步骤没有原子性，多个请求同时进行这样的操作，那就会变得非常混乱。通常来说可以依靠Redis来实现简单的分布式锁机制。
Redis分布式锁SETNX 基于之前的描述，当多个请求需要处理同样的内容时，我们为了确保只有其中一个请求被执行，那么可以借助Redis生成一把锁。并发请求向Redis申请锁，申请成功的人占用本次操作的执行权。因为Redis单线程的特性，一次只处理一个请求，因此后续申请锁的操作都可以被排除。具体代码如下：
t resource_name value ex 5 nx&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 意味着：
 插入一个名为resource_name的键，它的值为value TTL 5秒 只有这个键不存在的情况下才能插入成功  因为nx参数的存在，过期时间内执行相同的操作不会返回1，意味着插入不成功（没申请到锁）。
简易实现的问题 现在来看一下上面的设计有什么问题。
超时 假设现在clinet1拿到了锁，在执行一段时间后超过了设定的ttl，锁过期，client2向Redis执行语句申请锁，因为锁不存在所以client2成功申请到了锁。此时client1仍在继续执行未完成的操作，相当于存在client1和client2共同操作资源的行为。
对于这种问题，当前的锁机制是无法解决的，需要：
 避免在分布式中处理超长的任务 适当延长TTL并在执行完后及时对锁DEL 业务上进行处理 取消TTL，改为由client控制锁的DEL  对于最后一种方案，因为client控制锁的归还（del），如果在执行del命令时发生异常，redis服务器没有接收到，或者client出错，没有执行del，将会造成死锁，因为锁会持续存在，其他client不能够正常获取到锁。
锁被其他线程释放 对于上面的设计，不安全的地方在于，若其他线程执行del resource_name操作，那么看起来可以立刻获取一把新锁，从而达到无视锁机制的效果。
为此，在锁的设计上，value需要设计成一个unique值，在del操作前，业务上需要确认del的键的值是否匹配，若不匹配，应该取消del操作。
因此，简单的分布式锁的使用应该修改为：
t resource_name unique_value px 5000 nx&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; Redis集群分布式锁RedLock 现在继续来考虑一些简易锁的异常问题：
 client1申请到了锁，Redis记录了这把锁 Redis服务发生异常退出 Redis服务恢复，但是丢失数据（假设锁没有及时持久化） client2尝试申请锁，因为Redis没有锁存在，因此申请成功 client1、client2一起操作资源  由于服务的不可靠，简易锁的实现在特殊情况下会失效。为此，Redis作者提供了一种基于Redis集群的分布式锁——RedLock：</description>
			<content type="html"><![CDATA[<p><img src="../2019/09/redlock-py.png%22" alt=""></p>
<p>文章配图是RedLock Python实现的作者<a href="https://github.com/SPSCommerce/redlock-py/commits?author=optimuspaul">optimuspaul</a>的头像。</p>
<p>在分布式应用中经常会存在一些并发的问题，当多个请求想要处理同样的资源时，比如某个操作需要读取资源，根据读取结果进行修改，再写入，若这个步骤没有原子性，多个请求同时进行这样的操作，那就会变得非常混乱。通常来说可以依靠Redis来实现简单的分布式锁机制。</p>
<h2 id="redis分布式锁setnx">Redis分布式锁SETNX</h2>
<p>基于之前的描述，当多个请求需要处理同样的内容时，我们为了确保只有其中一个请求被执行，那么可以借助Redis生成一把锁。并发请求向Redis申请锁，申请成功的人占用本次操作的执行权。因为Redis单线程的特性，一次只处理一个请求，因此后续申请锁的操作都可以被排除。具体代码如下：</p>
<pre><code>t resource_name value ex 5 nx&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>意味着：</p>
<ul>
<li>插入一个名为resource_name的键，它的值为value</li>
<li>TTL 5秒</li>
<li>只有这个键不存在的情况下才能插入成功</li>
</ul>
<p>因为nx参数的存在，过期时间内执行相同的操作不会返回1，意味着插入不成功（没申请到锁）。</p>
<h3 id="简易实现的问题">简易实现的问题</h3>
<p>现在来看一下上面的设计有什么问题。</p>
<h5 id="超时">超时</h5>
<p>假设现在clinet1拿到了锁，在执行一段时间后超过了设定的ttl，锁过期，client2向Redis执行语句申请锁，因为锁不存在所以client2成功申请到了锁。此时client1仍在继续执行未完成的操作，相当于存在client1和client2共同操作资源的行为。</p>
<p>对于这种问题，当前的锁机制是无法解决的，需要：</p>
<ul>
<li>避免在分布式中处理超长的任务</li>
<li>适当延长TTL并在执行完后及时对锁DEL</li>
<li>业务上进行处理</li>
<li>取消TTL，改为由client控制锁的DEL</li>
</ul>
<p>对于最后一种方案，因为client控制锁的归还（del），如果在执行del命令时发生异常，redis服务器没有接收到，或者client出错，没有执行del，将会造成死锁，因为锁会持续存在，其他client不能够正常获取到锁。</p>
<h5 id="锁被其他线程释放">锁被其他线程释放</h5>
<p>对于上面的设计，不安全的地方在于，若其他线程执行<code>del resource_name</code>操作，那么看起来可以立刻获取一把新锁，从而达到无视锁机制的效果。</p>
<p>为此，在锁的设计上，value需要设计成一个unique值，在del操作前，业务上需要确认del的键的值是否匹配，若不匹配，应该取消del操作。</p>
<p>因此，简单的分布式锁的使用应该修改为：</p>
<pre><code>t resource_name unique_value px 5000 nx&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="redis集群分布式锁redlock">Redis集群分布式锁RedLock</h2>
<p>现在继续来考虑一些简易锁的异常问题：</p>
<ul>
<li>client1申请到了锁，Redis记录了这把锁</li>
<li>Redis服务发生异常退出</li>
<li>Redis服务恢复，但是丢失数据（假设锁没有及时持久化）</li>
<li>client2尝试申请锁，因为Redis没有锁存在，因此申请成功</li>
<li>client1、client2一起操作资源</li>
</ul>
<p>由于服务的不可靠，简易锁的实现在特殊情况下会失效。为此，Redis作者提供了一种基于Redis集群的分布式锁——<a href="https://redis.io/topics/distlock">RedLock</a>：</p>
<!-- raw HTML omitted -->
]]></content>
		</item>
		
		<item>
			<title>细数2019年读过的书</title>
			<link>https://jiekun.dev/posts/2019-09-14-%E7%BB%86%E6%95%B02019%E5%B9%B4%E8%AF%BB%E8%BF%87%E7%9A%84%E4%B9%A6/</link>
			<pubDate>Fri, 13 Sep 2019 16:02:46 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-14-%E7%BB%86%E6%95%B02019%E5%B9%B4%E8%AF%BB%E8%BF%87%E7%9A%84%E4%B9%A6/</guid>
			<description>前言 嗯这里说的都是技术相关的书，虽然花里胡哨的沙雕小说也看了几本不过….
DB方向 《Redis开发与运维》 Redis入门书籍，其实17年实习的时候就已经有在使用Redis，不过缺少一些基础的知识，比如知道Redis有5种数据类型但是不知道各自还有多种底层的数据结构实现。这本书相对还算比较浅（orz可能最后面比较难的地方还没看到就跳去另一本书了）所以看起来非常顺畅，能让人对Redis的基础功能都有所了解和掌握使用。
《Redis设计和实现》 略微偏向源码解读的书，分为4部分：
 Redis的数据结构 单机Feature的实现 多机Feature的实现 独立功能的实现  从《Redis开发与运维》了解到zset使用了ziplist和skiplist（实际上是redis mod的zskiplist）还不够，从《Redis设计和实现》进一步了解ziplist和skiplist是什么样的结构，为什么要使用skiplist和dict来实现zset。
书里面各部分的内容基本都给出了对应的源码和注释，当然源码大都是某种数据结构的定义，具体相关的方法还是要到源码里面自己阅读才会有。不过这本书对Redis真的讲得非常详细，如果不用开发Redis，看完这本书基本能掌握Redis所有实践里面需要用到的Feature了。
《深入理解Elasticsearch》 好吧这个书不应该先读的因为并不能看懂在讲的什么东西。反倒是在书里面反复提到了：
《Elasticsearch服务器开发》 应该是Elasticsearch的入门书籍，除了官方文档以外比较可靠的书。具体来说了解了ES的工作原理，包括索引、结构等，当然少不了语法的介绍虽然都跳过了。不过对于想了解ES为什么能实现高速的模糊查询，了解完整的查询过程和数据存储的过程的人应该很实用。书里面也有介绍多机实现的集群方案，虽然读来读去还是搞不懂怎么样去优化大数据量的查询噗。
编程语言 《Fluent Python》 这本啃的是影印版，也就是英文书。非常有意思的一本书，买之前定计划1个月看完结果到手发现根本不可能，除非忍不住。非常厚，啃完了第一部分介绍数据结构然后很后悔没有做读书笔记方便复习orz。第一部分对基本的数据结构有详细的讲解，很多奇怪的特性读完之后就豁然开朗，比如对list generator：
ist1 = [[None] * 5 for _ in range(5)]&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 为什么不能直接：
ist1 = [[None] * 5 ] * 5&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 还简洁易懂不是？（答：不是）
入门Python看完廖雪峰老师的博客基本上该会用的都应该会用了，但是很多东西只会用是不行的，从这本书的学习中很多东西应该认识到必须从“用”转为“改造”才能打造出最适合的Feature。很多时候比如日常业务借助框架简单实现一些功能，如果缺乏对实现的思考，那这个功能其实在后续优化的过程中提升的空间是较为有限的。写的东西如果缺乏理解，一旦出现问题定位起来就会更困难。跟着这本书其实它一路解答疑惑一路也让读者有更多对Python的思考，了解实现才能在开发上更流畅。
CS基础 说到CS基础真的如果非科班的同学没有尽早准备实际上在这块是会非常吃亏的。实习的时候觉得这些协议、架构、设计什么的跟开发有毛线关系，实际上真的会有影响的。很多东西不从源头出发，问题只能解决一半，解决表面。所以虽然时间很紧张但是还是必须要补牢基础知识。
《图解HTTP》 这大概是最简单的HTTP协议介绍的书籍了吧。插图非常多，基本可以当漫画书看。从协议的大纲细到握手细节书里面都有介绍。但是也仅限于“介绍”。当然对于了解一个协议来说是足够用的了。
《HTTP: The Definitive Guide》 可以看作上一本书的进阶，不过没有时间全部读，打印了HTTPS一章书了解了HTTPS的一些在《图解HTTP》里面没有解答或者描述不太透彻的问题。
这本书（好吧其实就一章）看的是英文版，个人一直认为一些较为Official向的东西是不应该参考翻译的因为很多时候翻译并不能准确的express原书的意义（当然一些优秀的翻译是可靠的，但是并不想花时间去了解哪些靠谱哪些不行），而且因为看的内容比较短因此花了几个小时带着词典就把一章吃完了。能够补充《图解》的内容，推荐看完前书之后就接着看这本，差不多的内容可以跳过，把展开介绍的补充积累一下。
《图解TCP/IP》 要摊牌了看这些书其实最初有部分原因还是因为应付面试。不过随着阅读发现原来网络真的可以这么有意思。
和《图解HTTP》一样是本漫画书，而且个人比较关注TCP一节不过书的前半部分介绍网络模型的内容也比较详（长）细。
学TCP可以具体看一下OSI模型和书中TCP/UDP的章节，不过看完之后我又补充看了TCP协议的原文，很多握手细节、握手异常情况一般在书里面是不会展开的，书上写着Client发Hello，Server回OK，然而有各种花里胡哨的Client发错人，发错握手批次等等的情况，不知道就不能算了解TCP了。
所以这本书应该和协议原文搭配食用，效果更佳。
中间件 《深入RabbitMQ》 消息队列肯定是在今年的学习计划之内的，因为不可能什么都靠Redis来玩，事实上Redis是个Cache的角色，它能当消息队列用但是真正遇上的消息队列的场景还是应该由对应的消息队列的实现来完成。
RabbitMQ想要使用可以直接看官网的6章教程，点一下看半天学习不花一分钱，开箱即用的Pika包，各种基本类型的实现代码都有。看完疑问三连：什么是AMQP？什么是Exchange？bind key和route key不是一个东西吗？
这本书名叫“深入”其实感觉还是属于入门类型的，从AMQP入手介绍了协议的基本知识，因为RabbitMQ是基于AMQP协议的，和平时接触最多的HTTP通信有共同点但也有很多不同。可以理解为RabbitMQ基于AMQP协议作了一些实现队列高可用和高性能上的扩展。掌握了AMQP之后很多RabbitMQ的Feature也相对通俗易懂了。</description>
			<content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>嗯这里说的都是技术相关的书，虽然花里胡哨的沙雕小说也看了几本不过….</p>
<h2 id="db方向">DB方向</h2>
<h4 id="redis开发与运维">《Redis开发与运维》</h4>
<p>Redis入门书籍，其实17年实习的时候就已经有在使用Redis，不过缺少一些基础的知识，比如知道Redis有5种数据类型但是不知道各自还有多种底层的数据结构实现。这本书相对还算比较浅（orz可能最后面比较难的地方还没看到就跳去另一本书了）所以看起来非常顺畅，能让人对Redis的基础功能都有所了解和掌握使用。</p>
<h4 id="redis设计和实现">《Redis设计和实现》</h4>
<p>略微偏向源码解读的书，分为4部分：</p>
<ul>
<li>Redis的数据结构</li>
<li>单机Feature的实现</li>
<li>多机Feature的实现</li>
<li>独立功能的实现</li>
</ul>
<p>从《Redis开发与运维》了解到zset使用了ziplist和skiplist（实际上是redis mod的zskiplist）还不够，从《Redis设计和实现》进一步了解ziplist和skiplist是什么样的结构，为什么要使用skiplist和dict来实现zset。</p>
<p>书里面各部分的内容基本都给出了对应的源码和注释，当然源码大都是某种数据结构的定义，具体相关的方法还是要到源码里面自己阅读才会有。不过这本书对Redis真的讲得非常详细，如果不用开发Redis，看完这本书基本能掌握Redis所有实践里面需要用到的Feature了。</p>
<h4 id="深入理解elasticsearch">《深入理解Elasticsearch》</h4>
<p>好吧这个书不应该先读的因为并不能看懂在讲的什么东西。反倒是在书里面反复提到了：</p>
<h4 id="elasticsearch服务器开发">《<strong>Elasticsearch服务器开发</strong>》</h4>
<p>应该是Elasticsearch的入门书籍，除了官方文档以外比较可靠的书。具体来说了解了ES的工作原理，包括索引、结构等，当然少不了语法的介绍虽然都跳过了。不过对于想了解ES为什么能实现高速的模糊查询，了解完整的查询过程和数据存储的过程的人应该很实用。书里面也有介绍多机实现的集群方案，虽然读来读去还是搞不懂怎么样去优化大数据量的查询噗。</p>
<h2 id="编程语言">编程语言</h2>
<h4 id="fluent-python">《Fluent Python》</h4>
<p>这本啃的是影印版，也就是英文书。非常有意思的一本书，买之前定计划1个月看完结果到手发现根本不可能，除非忍不住。非常厚，啃完了第一部分介绍数据结构然后很后悔没有做读书笔记方便复习orz。第一部分对基本的数据结构有详细的讲解，很多奇怪的特性读完之后就豁然开朗，比如对list generator：</p>
<pre><code>ist1 = [[None] * 5 for _ in range(5)]&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>为什么不能直接：</p>
<pre><code>ist1 = [[None] * 5 ] * 5&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>还简洁易懂不是？（答：不是）</p>
<p>入门Python看完廖雪峰老师的博客基本上该会用的都应该会用了，但是很多东西只会用是不行的，从这本书的学习中很多东西应该认识到必须从“用”转为“改造”才能打造出最适合的Feature。很多时候比如日常业务借助框架简单实现一些功能，如果缺乏对实现的思考，那这个功能其实在后续优化的过程中提升的空间是较为有限的。写的东西如果缺乏理解，一旦出现问题定位起来就会更困难。跟着这本书其实它一路解答疑惑一路也让读者有更多对Python的思考，了解实现才能在开发上更流畅。</p>
<h2 id="cs基础">CS基础</h2>
<p>说到CS基础真的如果非科班的同学没有尽早准备实际上在这块是会非常吃亏的。实习的时候觉得这些协议、架构、设计什么的跟开发有毛线关系，实际上真的会有影响的。很多东西不从源头出发，问题只能解决一半，解决表面。所以虽然时间很紧张但是还是必须要补牢基础知识。</p>
<h4 id="图解http">《图解HTTP》</h4>
<p>这大概是最简单的HTTP协议介绍的书籍了吧。插图非常多，基本可以当漫画书看。从协议的大纲细到握手细节书里面都有介绍。但是也仅限于“介绍”。当然对于了解一个协议来说是足够用的了。</p>
<h4 id="http-the-definitive-guide">《HTTP: The Definitive Guide》</h4>
<p>可以看作上一本书的进阶，不过没有时间全部读，打印了HTTPS一章书了解了HTTPS的一些在《图解HTTP》里面没有解答或者描述不太透彻的问题。</p>
<p>这本书（好吧其实就一章）看的是英文版，个人一直认为一些较为Official向的东西是不应该参考翻译的因为很多时候翻译并不能准确的express原书的意义（当然一些优秀的翻译是可靠的，但是并不想花时间去了解哪些靠谱哪些不行），而且因为看的内容比较短因此花了几个小时带着词典就把一章吃完了。能够补充《图解》的内容，推荐看完前书之后就接着看这本，差不多的内容可以跳过，把展开介绍的补充积累一下。</p>
<h4 id="图解tcpip">《图解TCP/IP》</h4>
<p>要摊牌了看这些书其实最初有部分原因还是因为应付面试。不过随着阅读发现原来网络真的可以这么有意思。</p>
<p>和《图解HTTP》一样是本漫画书，而且个人比较关注TCP一节不过书的前半部分介绍网络模型的内容也比较详（长）细。</p>
<p>学TCP可以具体看一下OSI模型和书中TCP/UDP的章节，不过看完之后我又补充看了TCP协议的原文，很多握手细节、握手异常情况一般在书里面是不会展开的，书上写着Client发Hello，Server回OK，然而有各种花里胡哨的Client发错人，发错握手批次等等的情况，不知道就不能算了解TCP了。</p>
<p>所以这本书应该和协议原文搭配食用，效果更佳。</p>
<h2 id="中间件">中间件</h2>
<h4 id="深入rabbitmq">《<strong>深入RabbitMQ</strong>》</h4>
<p>消息队列肯定是在今年的学习计划之内的，因为不可能什么都靠Redis来玩，事实上Redis是个Cache的角色，它能当消息队列用但是真正遇上的消息队列的场景还是应该由对应的消息队列的实现来完成。</p>
<p>RabbitMQ想要使用可以直接看官网的6章教程，点一下看半天学习不花一分钱，开箱即用的Pika包，各种基本类型的实现代码都有。看完疑问三连：什么是AMQP？什么是Exchange？bind key和route key不是一个东西吗？</p>
<p>这本书名叫“深入”其实感觉还是属于入门类型的，从AMQP入手介绍了协议的基本知识，因为RabbitMQ是基于AMQP协议的，和平时接触最多的HTTP通信有共同点但也有很多不同。可以理解为RabbitMQ基于AMQP协议作了一些实现队列高可用和高性能上的扩展。掌握了AMQP之后很多RabbitMQ的Feature也相对通俗易懂了。</p>
]]></content>
		</item>
		
		<item>
			<title>基于Redis的缓存装饰器及缓存预热设计</title>
			<link>https://jiekun.dev/posts/2019-09-08-%E5%9F%BA%E4%BA%8Eredis%E7%9A%84python%E7%BC%93%E5%AD%98%E8%A3%85%E9%A5%B0%E5%99%A8%E5%8F%8A%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD%E8%AE%BE%E8%AE%A1/</link>
			<pubDate>Sun, 08 Sep 2019 05:27:22 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-08-%E5%9F%BA%E4%BA%8Eredis%E7%9A%84python%E7%BC%93%E5%AD%98%E8%A3%85%E9%A5%B0%E5%99%A8%E5%8F%8A%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD%E8%AE%BE%E8%AE%A1/</guid>
			<description>业务背景 业务上使用的是类似MVC的架构，具体而言通过view层控制接口，logic层控制业务逻辑，models模型映射数据库。在logic层，使用了Redis缓存装饰器对满足参数要求的方法执行结果进行缓存，降低复杂逻辑页面、数据量大页面的请求执行耗时。
对于这种使用场景，当缓存失效时，因为缓存使用的位置都是复杂逻辑，再次生成缓存需要数据库层面执行，如果这一步是由用户触发（也就是cache失效后第一位用户请求的时候生成缓存），那对这位用户来说请求时间就会很长甚至504超时。因此，有必要设计缓存的自动预热以及手动预热，前者是为了避免由用户触发生成缓存的长时间等待，后者是为了特殊时候（如数据更新后，缓存还没到期）手动更新缓存。
原有的缓存装饰器 f redis_cache(ttl=None, cache_name=None, **kwargs): &amp;quot;&amp;quot;&amp;quot; Redis缓存装饰器 用于Logics层函数执行结果缓存 全局配置: config/localsettings.py REDIS_ON = True 使用示例和说明： @redis_cache(ttl=3600, cache_name=&amp;quot;&amp;quot;, arg1=1, arg2=20) def sample_method(arg1, arg2, arg3, arg4, arg5) ttl: 缓存失效3600秒 cache_name: 函数功能名 kwargs：参数中对应满足kwargs时进行缓存，示例中当函数参数包含args=1，args2=20时缓存 缓存规则：logic_cache:function_name:参数作为键名进行缓存，示例： logic_cache:sample_method:arg1:1:arg2:20:arg3:rank:arg4:people:arg5:food :param ttl: 过期时间 :param cache_name: 函数功能名 用于清理缓存时显示 方便非技术同时使用 :param kwargs: 命中何种参数时进行缓存 示例 **{&#39;arg1&#39;: 1, &#39;arg2&#39;: 20} :return: 返回函数执行结果 / 缓存结果 &amp;quot;&amp;quot;&amp;quot; def decorator(func): cache_serv = cache @wraps(func) def returned_wrapper(*args, **innerkwargs): try: func_name = func.func_name default_kwargs = kwargs is_cache_target = cache_target_judger(default_kwargs, innerkwargs) # Cache Target if REDIS_ON and is_cache_target: colon = &#39;:&#39; redis_key_prefix_list = [&#39;logic_cache&#39;, func_name] for each in innerkwargs: redis_key_prefix_list.</description>
			<content type="html"><![CDATA[<h2 id="业务背景">业务背景</h2>
<p>业务上使用的是类似MVC的架构，具体而言通过view层控制接口，logic层控制业务逻辑，models模型映射数据库。在logic层，使用了Redis缓存装饰器对满足参数要求的方法执行结果进行缓存，降低复杂逻辑页面、数据量大页面的请求执行耗时。</p>
<p>对于这种使用场景，当缓存失效时，因为缓存使用的位置都是复杂逻辑，再次生成缓存需要数据库层面执行，如果这一步是由用户触发（也就是cache失效后第一位用户请求的时候生成缓存），那对这位用户来说请求时间就会很长甚至504超时。因此，有必要设计缓存的自动预热以及手动预热，前者是为了避免由用户触发生成缓存的长时间等待，后者是为了特殊时候（如数据更新后，缓存还没到期）手动更新缓存。</p>
<h2 id="原有的缓存装饰器">原有的缓存装饰器</h2>
<pre><code>f redis_cache(ttl=None, cache_name=None, **kwargs):
    &quot;&quot;&quot;
    Redis缓存装饰器 用于Logics层函数执行结果缓存
    全局配置: config/localsettings.py REDIS_ON = True
    使用示例和说明：

    @redis_cache(ttl=3600, cache_name=&quot;&quot;, arg1=1, arg2=20)
    def sample_method(arg1, arg2, arg3, arg4, arg5)

    ttl: 缓存失效3600秒
    cache_name: 函数功能名
    kwargs：参数中对应满足kwargs时进行缓存，示例中当函数参数包含args=1，args2=20时缓存
    缓存规则：logic_cache:function_name:参数作为键名进行缓存，示例：
    logic_cache:sample_method:arg1:1:arg2:20:arg3:rank:arg4:people:arg5:food

    :param ttl: 过期时间
    :param cache_name: 函数功能名 用于清理缓存时显示 方便非技术同时使用
    :param kwargs: 命中何种参数时进行缓存 示例 **{'arg1': 1, 'arg2': 20}
    :return: 返回函数执行结果 / 缓存结果
    &quot;&quot;&quot;
    def decorator(func):
        cache_serv = cache

        @wraps(func)
        def returned_wrapper(*args, **innerkwargs):
            try:
                func_name = func.func_name
                default_kwargs = kwargs
                is_cache_target = cache_target_judger(default_kwargs, innerkwargs)
                # Cache Target
                if REDIS_ON and is_cache_target:
                    colon = ':'
                    redis_key_prefix_list = ['logic_cache', func_name]
                    for each in innerkwargs:
                        redis_key_prefix_list.append(each + ':' + str(innerkwargs[each]))
                    redis_key_str = colon.join(redis_key_prefix_list)

                    result = cache_serv.get(redis_key_str)
                    # Cache Exist:
                    if result is not None:
                        print(func_name + ': This is Cache')
                        return result
                    # Cache Not Exist / Force Update
                    else:
                        cache_data = func(*args, **innerkwargs)
                        cache = cache_serv.set(redis_key_str, cache_data, ttl)
                        if cache_name is not None:
                            redis_key_name_prefix_list = ['cache_name', func_name]
                            redis_key_name_str = ':'.join(redis_key_name_prefix_list)
                            cache = cache_serv.set(redis_key_name_str, cache_name, ttl)
                        print(func_name + ': Add to Cache now')
                        return cache_data
                # SQL/ES Target
                else:
                    direct_run_data = func(*args, **innerkwargs)
                    print(func_name + ': Not Cache Target')
                    return direct_run_data
            except Exception as e:
                logging.error(&quot;Redis decorator error: {}&quot;.format(e))
                direct_run_data = func(*args, **innerkwargs)
                print('Error Happened')
                return direct_run_data

        return returned_wrapper

    return decorator


def cache_target_judger(default_kwargs, innerkwargs):
    &quot;&quot;&quot;
    缓存判断 返回Bool值
    判断是否为缓存目标
    :param default_kwargs:
    :param innerkwargs:
    :return:
    &quot;&quot;&quot;
    return all(item in innerkwargs.iteritems() for item in default_kwargs.iteritems())&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>先来说明一下原有缓存的逻辑，其实实现非常简单：</p>
<p>对于如下使用：</p>
<pre><code>@redis_cache(ttl=3600, cache_name='示例功能', arg1=1, arg2=20)
def sample_method(arg1, arg2, arg3, arg4):
        pass

sample_method(arg1=1, arg2=20, arg3='hello', arg4='world')&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="判定缓存目标">判定缓存目标</h4>
<p>在调用sample_method时，传入参数<code>arg1=1, arg2=20, arg3='hello', arg4='world'</code>，也就是<code>returned_wrapper(*args, **innerkwargs)</code>中的innerkwargs，代表方法的参数（字典形式）。<br>
在使用装饰器的时候，装饰器参数ttl, cache_name, 后面的都是kwargs，代表装饰器的参数（字典形式）。</p>
<p>现在将kwargs和innerkwargs比较，如果kwargs是innerkwargs的子集，也就是说innerkwargs满足kwargs的约束，说明这是一个要缓存的目标。以示例说明，redis_cache中kwargs是:<code>{'arg1': 1, 'arg2': 20}</code>，sample_method被捕获到的innerkwargs是<code>{'arg1':1, 'arg2': 20, 'arg3':  'hello', 'arg4': 'world'}</code>。因为满足了kwargs要求的arg1=1和arg2=20，因此这个sample_method的请求是需要被缓存的。</p>
<p>如果在这一步中判断不是要被缓存的那说明Redis中必然不存在这个缓存，则直接执行方法获返回结果即可。</p>
<h4 id="生成缓存键">生成缓存键</h4>
<p>显然，每个不同的函数调用的参数都不一样，我们需要使用当前调用的全部参数作为Redis键名以避免重复。<br>
设计键名为：</p>
<pre><code>前缀 + 方法名 + 方法参数键值对&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>不使用hash是因为前期缺少cache_name注释的情况下无法通过redis键名（如果是hash）判断出这个缓存对应的功能。<br>
这里也会有小问题，如果方法名一样的方法在不同位置有出现的话也可能让键名重复。</p>
<h4 id="获取生成缓存">获取/生成缓存</h4>
<p>有了缓存的键名之后，就可以到Redis中查看这个键是否存在，因此尝试取出这个键：<br>
<code>result = cache_serv.get(redis_key_str)</code></p>
<ul>
<li>如果result不存在，说明缓存不存在，对本次调用需要执行方法，并将结果set进Redis中，并返回执行结果。</li>
<li>如果result存在，说明缓存存在，对本次调用可以返回缓存结果。</li>
</ul>
<h4 id="小结">小结</h4>
<p>通过上述的方法，已经可以实现一个缓存的装饰器，并且控制方法参数级别的缓存判定。</p>
<h2 id="缓存系统改造">缓存系统改造</h2>
<h4 id="允许更新缓存">允许更新缓存</h4>
<p>旧方案的缓存生命周期是从第一次触发生成时刻至缓存过期时刻。对于这种对方法的缓存，要达到预热（更新）的效果，其实只要在判定上作小调整：<br>
在生成了缓存键名之后，原思路是看是否有result，有则取缓存，无则生成缓存。这里只需要改造成：</p>
<ul>
<li>当需要无视规则强制生成缓存的时候，执行函数并生成缓存。</li>
</ul>
<p>这个改动非常简单，在调用方法时，传入一个force_update参数：</p>
<pre><code>@redis_cache(ttl=3600, cache_name='示例功能', arg1=1, arg2=20)
def sample_method(arg1, arg2, arg3, arg4):
        pass

sample_method(arg1=1, arg2=20, arg3='hello', arg4='world', force_update=True)&lt;/code&gt;&lt;/pre&gt;

</code></pre><ul>
<li>这个force_update要在装饰器执行func之前处理，因为<code>sampe_method</code>的定义中没有这个参数，因此当执行func的时候传的参数必须仍然只有前面几个。因此装饰器中加上：</li>
</ul>
<pre><code>force_update = innerkwargs.pop('force_update', False)&lt;/code&gt;&lt;/pre&gt;

</code></pre><ul>
<li>正常调用不会包含这个方法，但是仍然会经过装饰器，因此默认False</li>
<li>使用pop方法保证这个参数不会进入实际执行方法的过程中</li>
</ul>
<p>有了force_update标志之后，对是否需要执行方法并写入缓存的判定就要修改一下：</p>
<ul>
<li>从<code>if result is not None:</code>改为<code>if result is not None and not force_update:</code></li>
</ul>
<p>这样当有force_update的时候也会继续执行方法和写缓存的操作。</p>
<h4 id="缓存定时预热">缓存定时预热</h4>
<p>既然需要实现定时更新，那只要定时执行一下sample_method，并且加上force_update参数强制使它更新就行。</p>
<p>因此是否可以做一个定时脚本：</p>
<pre><code>* */2 * * * python update_cache.py&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>update_cache.py内容如下：</p>
<pre><code>if __name__ == '__main__':
    sample_method1(arg1=1, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method2(arg1=2, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method3(arg1=3, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method4(arg1=4, arg2=2, arg3='hello', arg4='world', force_update=True)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这样就实现了缓存的定时更新</p>
<h4 id="缓存手动预热">缓存手动预热</h4>
<p>思路：手动预热只需要将crontab定时改为（支持）手动触发即可，具体可以设计成一个调用接口。</p>
<p>抱歉，如果是这样设计，这套缓存系统就会面临类似缓存穿透的问题。</p>
<p>缓存穿透，故名思意就是请求不经过缓存，直接打在数据库上执行，在特定期间如果有大量的请求经数据库执行会给数据库造成很大压力。在我们的业务中，使用缓存的地方都是原来较为缓慢的查询，如果让大量请求同时执行SQL的话对MySQL负载时比较高的。</p>
<p>设想如果手动预热做成接口，意味着这个接口对应的sample_method的执行是不经过缓存层的而是直接在数据库执行，如果这个接口同一时间有多人调用的话，就会在SQL同时执行多个复杂查询，影响性能。</p>
<p>因此，为了让缓存手动预热对数据库更加友好，这里需要将预热改造成队列形式。对于这种的业务，不需要保证可靠性，也没有性能要求，因此无需使用MQ，直接借助Redis的LIST类型和lpush+rpop可以做一个非常简单的队列。</p>
<ul>
<li>在手动预热请求的logic层：</li>
</ul>
<pre><code># 要使用集合常量来避免不合法的传参
WARMER_DICT = {
    'sample_method_collection'
}

def submit_warmer(warmer):
    &quot;&quot;&quot;
    :return:
    &quot;&quot;&quot;
    if warmer in WARMER_DICT:
        warmer_key = CACHE_WARMER_KEY
        redis_raw_serv.lpush(warmer_key, warmer)
    return 200, 0, &quot;加入预热队列成功&quot;, {}&lt;/code&gt;&lt;/pre&gt;

</code></pre><ul>
<li>在后台维护一个持续监控队列的进程</li>
</ul>
<pre><code># 同样使用字典来避免不合法的队列元素
CACHE_FUNC = {
    'sample_method_collection': sample_method_collection
}


def sample_method_collection():
    sample_method1(arg1=1, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method2(arg1=2, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method3(arg1=3, arg2=2, arg3='hello', arg4='world', force_update=True)
    sample_method4(arg1=4, arg2=2, arg3='hello', arg4='world', force_update=True)

def warmer_server():
    &quot;&quot;&quot;
    缓存更新后台进程
    不断读取redis中的LIST队列，如有则rpop出任务执行
    :return:
    &quot;&quot;&quot;
    while True:
        cache_warmer_key = CACHE_WARMER_KEY
        try:
            func_name = redis_raw_serv.rpop(cache_warmer_key)
            if func_name not in CACHE_FUNC:
                raise KeyError
            print('Found warmer job %s at %s.' % (func_name, datetime.datetime.now().strftime('%m-%d %H:%M:%S')))
            # 执行一个方法来触发对应（或多个）带force_update参数的方法
            CACHE_FUNC[func_name]()
        except KeyError:
            pass
        print('Interval 5 seconds.')
        time.sleep(5)&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="总结">总结</h2>
<p>新完善的这套缓存方案实现了：</p>
<ul>
<li>方法参数粒度的缓存控制</li>
<li>缓存的自动、手动预热</li>
</ul>
<p>基于这些改造：</p>
<ul>
<li>通过缓存的自动预热，避免了缓存雪崩的问题；</li>
<li>通过缓存手动预热（实际上自动预热也同样）使用队列，避免预热过程中给数据库带来过高负载。</li>
</ul>
<p>Python的装饰器可以应用于MVC的各层，实现接口（View）层面的缓存同样可以使用（粗粒度的控制），但是因为Django中view层的参数为request对象，在使用中需要再进行改造，对request进行解析获取具体参数。</p>
<p>对于方法重名问题，实际上也可以将Redis键改造成<code>前缀:模块名:view层方法名:logic层方法名:参数字典</code>的形式，抽象来说只要能在<code>前缀</code>和<code>参数字典</code>之间能够定位到准确的使用装饰器的位置即可。</p>
<h2 id="持续优化">持续优化</h2>
<h4 id="更简便的缓存预热目标生成">更简便的缓存预热目标生成</h4>
<p>目前对于需要预热的目标方法，都是在crontab脚本中显式执行的，这样每当需要添加一个定期预热的目标方法，都要在脚本内添加代码。<br>
优化方案：额外维护一个动态的预热的目标队列，队列是由第一次生成缓存的时候判断这个方法后续是否需要自动预热，若需要，则加入预热队列中并定期执行，执行的时候又加入下一次预热队列中。这样只需要在缓存装饰器的使用中声明<code>redis_cache(ttl=3600, cache_name='示例', auto_update=True, args1=1, args2=20)</code>即可。</p>
<h4 id="预热参数组合">预热参数组合</h4>
<p>在其他业务有使用到，举例如args1可以为1或2或3， args2可以为20或30，这时候对于方法的缓存预热，需要对参数组合（1，20），（2，20），（3，20）和（1，30），（2，30），（3，30）共计6种。<br>
优化方案：这时候可能需要将面向业务层的缓存装饰器和面向预热的缓存装饰器分离开，因为业务层只对特定一次请求负责，也就是说用户只可能传6种请求的1种，服务只需要将这1种的结果，不管是缓存，还是生成缓存，处理好并返回即可； 对面向预热的装饰器，需要实现支持列表传参，生成参数组合，并逐一执行，调用示例：<br>
<code>redis_cache(ttl=3600, cache_name='示例', args1=[1, 2], args2=[20, 30])</code><br>
在其他业务中，也有实现过组合参数的方法，如：</p>
<pre><code>f param_combination_generator(kwargs):
    &quot;&quot;&quot;
    参数排列组合生成器
    根据dict生成各个key名对应多个可能值的组合情况
    如{'key1':['value1', 'value2'], 'key2':['value3', 'value4']}可以有4种组合
    :param kwargs:
    :return: 返回组合list, 如[((page_num, 1)(sort_type, like_count)), ((page_num, 2)(sort_type, like_count))]
    &quot;&quot;&quot;
    pre_dict = {}
    for k, v in kwargs.iteritems():
        pre_dict[k] = []
        for each_value in v:
            pre_dict[k].append((k, each_value))
    iter_list = []
    for each in pre_dict.values():
        iter_list.append(each)

    param_combination = list(itertools.product(*iter_list))

    return param_combination&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>尽管还需要优化，不过大体思路按照排列组合后的参数对函数逐一放入队列执行应该可以较为友善地实现。当参数排列组合特别多的时候，可能就不太适合缓存的场景，因为cache成本都是非常高昂的，可能需要优化成针对最热点的内容优先缓存的形式。</p>
]]></content>
		</item>
		
		<item>
			<title>学个排序~</title>
			<link>https://jiekun.dev/posts/2019-09-07-%E5%AD%A6%E4%B8%AA%E6%8E%92%E5%BA%8F/</link>
			<pubDate>Sat, 07 Sep 2019 15:49:52 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-09-07-%E5%AD%A6%E4%B8%AA%E6%8E%92%E5%BA%8F/</guid>
			<description>前言 该补充的算法基础还是要补TuT
快排（Quick Sort） 思路总结:
以某个位置为轴，大于轴的数都移动至右侧，小于轴的数都移动到左侧，轴左右侧的新列表递归选取轴和按大小排列
复杂度：
平均：O(nlogn)； 最差：O(n^2)
代码：
f quick_sort(A): quick_sort2(A, 0, len(A)-1) def quick_sort2(A, low, hi): # 递归方法 if hi &amp;gt; low: p = partition(A, low, hi) quick_sort2(A, low, p-1) quick_sort2(A, p+1, hi) def partition(A, low, hi): # 获取轴 # [轴, 小于轴, 小于轴, 小于轴, 大于轴, 大于轴, 大于轴, 大于轴] # [小于轴, 小于轴, 小于轴, 轴, 大于轴, 大于轴, 大于轴, 大于轴] # 返回轴 privot = get_privot(A, low, hi) privot_value = A[privot] A[low], A[privot] = privot_value, A[low] border = low for i in range(low+1, hi+1): if A[i] &amp;amp;lt; privot_value: border += 1 A[i], A[border] = A[border], A[i] A[low], A[border] = A[border], A[low] return border def get_privot(A, low, hi): # 选取一个位置为轴 # 若不选取中间值为轴 最差O(n^2) mid = (hi + low) // 2 s = sorted([A[hi], A[low], A[mid]]) if s[1] == A[hi]: return hi elif s[1] == A[low]: return low else: return mid&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 插入排序（Insertion Sort） 思路：</description>
			<content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>该补充的算法基础还是要补TuT</p>
<h2 id="快排quick-sort">快排（Quick Sort）</h2>
<p>思路总结:</p>
<p>以某个位置为轴，大于轴的数都移动至右侧，小于轴的数都移动到左侧，轴左右侧的新列表递归选取轴和按大小排列</p>
<p><img src="../2019/09/Sorting_quicksort_anim.gif" alt="">
复杂度：</p>
<p>平均：O(nlogn)； 最差：O(n^2)</p>
<p>代码：</p>
<pre><code>f quick_sort(A):
    quick_sort2(A, 0, len(A)-1)

def quick_sort2(A, low, hi):
    # 递归方法
    if hi &gt; low:
        p = partition(A, low, hi)
        quick_sort2(A, low, p-1)
        quick_sort2(A, p+1, hi)

def partition(A, low, hi):
    # 获取轴
    # [轴, 小于轴, 小于轴, 小于轴, 大于轴, 大于轴, 大于轴, 大于轴]
    # [小于轴, 小于轴, 小于轴, 轴, 大于轴, 大于轴, 大于轴, 大于轴]
    # 返回轴
    privot = get_privot(A, low, hi)
    privot_value = A[privot]
    A[low], A[privot] = privot_value, A[low]
    border = low
    for i in range(low+1, hi+1):
        if A[i] &amp;lt; privot_value:
            border += 1
            A[i], A[border] = A[border], A[i]

    A[low], A[border] = A[border], A[low]
    return border

def get_privot(A, low, hi):
    # 选取一个位置为轴
    # 若不选取中间值为轴 最差O(n^2)
    mid = (hi + low) // 2
    s = sorted([A[hi], A[low], A[mid]])
    if s[1] == A[hi]:
        return hi
    elif s[1] == A[low]:
        return low
    else:
        return mid&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="插入排序insertion-sort">插入排序（Insertion Sort）</h2>
<p>思路：</p>
<p>从左往右，拿起一个数，向左侧找它应该插入的位置</p>
<p><img src="../2019/09/Insertion-sort-example-300px.gif" alt="">
复杂度：</p>
<p>O(n^2)</p>
<p>代码：</p>
<pre><code>f insert_sort(A):
    n = len(A)
    for i in range(1, n):
        # 拿起一个元素
        cur_val = A[i]
        k = 0
        # 比它大的都往右挪一格
        for j in range(i-1, -2, -1):
            k = j
            if cur_val &amp;lt; A[j]:
                A[j+1] = A[j]
            else:
                break
        # 挪出来空的一格把该元素放入
        A[k+1] = cur_val&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="选择排序selection-sort">选择排序（Selection Sort）</h2>
<p>思路：</p>
<p>从左往右，找最小值放到最左边</p>
<p><img src="../2019/09/Selection-Sort-Animation.gif" alt="">
复杂度：</p>
<p>O(n^2)</p>
<p>代码：</p>
<pre><code>f select_sort(A):
    n = len(A)
    for i in range(0, n):
        # 找出A[i:end]中的最小值
        min_idx = i
        for j in range(i+1, n):
            if A[j] &amp;lt; A[min_idx]:
                min_idx = j
        # 将这个最小值交换值A[i]的位置
        if min_idx != i:
            A[min_idx], A[i] = A[i], A[min_idx]&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="冒泡排序bubble-sort">冒泡排序（Bubble Sort）</h2>
<p>思路：</p>
<p>从左往右，左侧比右侧大，则交换；一直交换至最右侧，依次排出：第n位为0至n的最大值，第n-1位为0至n-1的最大值</p>
<p><img src="../2019/09/Bubble-sort-example-300px.gif" alt="">
复杂度：</p>
<p>O(n^2)</p>
<p>代码：</p>
<pre><code>f bubble_sort(A):
    n = len(A)
    for i in range(n):
        for j in range(0, n-i-1):
            if A[j] &gt; A[j+1]:
                A[j], A[j+1] = A[j+1], A[j]&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="归并排序merge-sort">归并排序（Merge Sort）</h2>
<p>思路：</p>
<p>将列表分为两份，分别对左侧和右侧进行归并排序，排序完之后比较左侧和右侧第一个的大小，小的先放进结果中，再取下一个较小的放入结果，直至取完所有结果</p>
<p><img src="../2019/09/220px-Merge-sort-example-300px.gif" alt="">
复杂度：</p>
<p>O(nlogn)</p>
<p>代码：</p>
<pre><code>f merge_sort(A):
    merge_sort2(A, 0, len(A)-1)

def merge_sort2(A, first, last):
    if last &gt; first:
        # 拆分为左右两组 分别归并排序
        mid = (first+last) // 2
        merge_sort2(A, first, mid)
        merge_sort2(A, mid+1, last)
        # 合并左右结果
        merge(A, first, mid, last)


def merge(A, first, mid, last):
    left = A[first:mid+1]
    right = A[mid+1:last+1]
    left.append(9999999999)
    right.append(9999999999)
    i = j = 0
    # 依次取左右较小的作为第A[k]值，直至拼接成完整的A[first:last+1]
    for k in range(first, last+1):
        if left[i] &amp;lt;= right[j]:
            A[k] = left[i]
            i += 1
        else:
            A[k] = right[j]
            j += 1&lt;/code&gt;&lt;/pre&gt;
</code></pre>]]></content>
		</item>
		
		<item>
			<title>Redis有序集合的实现&amp;跳跃表源码学习</title>
			<link>https://jiekun.dev/posts/2019-08-31-redis%E4%B8%ADzset%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E7%BB%93%E5%90%88%E6%BA%90%E7%A0%81%E7%9A%84%E8%B7%B3%E8%B7%83%E8%A1%A8%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0/</link>
			<pubDate>Sat, 31 Aug 2019 04:49:01 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-08-31-redis%E4%B8%ADzset%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E7%BB%93%E5%90%88%E6%BA%90%E7%A0%81%E7%9A%84%E8%B7%B3%E8%B7%83%E8%A1%A8%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0/</guid>
			<description>O(1)的skiplist成员查找？ 众所周知Redis中每种基本类型都有2种或以上的底层实现，一般谈到ZSET，我们会说它的实现是基于ziplist和skiplist的，这没有问题：
 当ZSET长度小于设定值（zset-max-ziplist-entries）或成员的长度小于设定值（zset-max-ziplist-value）时会使用ziplist的实现，否则使用skiplist实现  但是当ZSET在使用skiplist实现的时候，它对成员的查找也是O(1)复杂度。根据skiplist的结构，要查找某一个成员必须对各个SkiplistNode进行遍历，因此复杂度为O(n)。所以在ZSET-skiplist的实现中查找成员并不是根据skiplist进行的，而是使用字典（dict）。
先来看一下ZSET的结构源码，Redis5.0.5版本中数据结构的定义在redis/src/server.h中：
typedef struct zset { dict *dict; zskiplist *zsl; } zset;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 可以看到一个ZSET结构使用了一个dict和一个zskiplist（特殊版本的skiplist），具体代码在SkipList小节中再叙述。ZSET的结构可以由下图来标识：
通过这样的结构，当ZSET需要进行成员查询的时候，可以根据dict查询，时间复杂度为O(1)；当ZSET需要进行范围查找的时候，根据skiplist结构可以实现平均O(logn)复杂度的查找。
这两种结构单独使用来实现ZSET是可行的，但是dict在范围型操作的时候需要对字典保存的所有元素进行排序因此需要至少O(nlogn)的时间复杂度和额外O(n)的空间复杂度；在单独使用skiplist根据成员查找分值的时候就由O(1)时间复杂度上升到了O(logn)复杂度。因此Redis中选择同时使用dict和skiplist来实现ZSET类型。
SkipList的实现 下面来具体聊一下SkipList数据结构。
在Redis源码中找到跳跃表的相关定义，就在zset的上面几行，补充一些注释：
/* ZSETs use a specialized version of Skiplists */ # 跳跃表节点（ZSET版） typedef struct zskiplistNode { # 使用sds来存储成员名字 sds ele; # 浮点型分数 double score; # 每个zskiplist节点都带有向前的指针 struct zskiplistNode *backward; # zskiplist分层，每层中包含指向其他zskiplist节点的指针 struct zskiplistLevel { # zskiplist节点指针 struct zskiplistNode *forward; # 本层指向的下个节点离本节点的跨度 unsigned long span; } level[]; } zskiplistNode; # 跳跃表 typedef struct zskiplist { # 分别指向头尾的指针 struct zskiplistNode *header, *tail; # 长度 即跳跃表中包含的节点数目（头节点不算） unsigned long length; # 层数 即跳跃表中各节点层数的最大值（头节点不算） int level; } zskiplist;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; t的结构可以由下图来表示：</description>
			<content type="html"><![CDATA[<h2 id="o1的skiplist成员查找">O(1)的skiplist成员查找？</h2>
<p>众所周知Redis中每种基本类型都有2种或以上的底层实现，一般谈到ZSET，我们会说它的实现是基于ziplist和skiplist的，这没有问题：</p>
<ul>
<li>当ZSET长度小于设定值（zset-max-ziplist-entries）或成员的长度小于设定值（zset-max-ziplist-value）时会使用ziplist的实现，否则使用skiplist实现</li>
</ul>
<p>但是当ZSET在使用skiplist实现的时候，它对成员的查找也是O(1)复杂度。根据skiplist的结构，要查找某一个成员必须对各个SkiplistNode进行遍历，因此复杂度为O(n)。所以在ZSET-skiplist的实现中查找成员并不是根据skiplist进行的，而是使用字典（dict）。</p>
<p>先来看一下ZSET的结构源码，Redis5.0.5版本中数据结构的定义在redis/src/server.h中：</p>
<pre><code>typedef struct zset {
    dict *dict;
    zskiplist *zsl;
} zset;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>可以看到一个ZSET结构使用了一个dict和一个zskiplist（特殊版本的skiplist），具体代码在SkipList小节中再叙述。ZSET的结构可以由下图来标识：</p>
<p><img src="../2019/09/ZSET-skiplist.jpg" alt=""></p>
<p>通过这样的结构，当ZSET需要进行成员查询的时候，可以根据dict查询，时间复杂度为O(1)；当ZSET需要进行范围查找的时候，根据skiplist结构可以实现平均O(logn)复杂度的查找。</p>
<p>这两种结构单独使用来实现ZSET是可行的，但是dict在范围型操作的时候需要对字典保存的所有元素进行排序因此需要至少O(nlogn)的时间复杂度和额外O(n)的空间复杂度；在单独使用skiplist根据成员查找分值的时候就由O(1)时间复杂度上升到了O(logn)复杂度。因此Redis中选择同时使用dict和skiplist来实现ZSET类型。</p>
<h4 id="skiplist的实现">SkipList的实现</h4>
<p>下面来具体聊一下SkipList数据结构。<br>
在Redis源码中找到跳跃表的相关定义，就在zset的上面几行，补充一些注释：</p>
<pre><code>/* ZSETs use a specialized version of Skiplists */
# 跳跃表节点（ZSET版）
typedef struct zskiplistNode {
    # 使用sds来存储成员名字
    sds ele;
    # 浮点型分数
    double score;
    # 每个zskiplist节点都带有向前的指针
    struct zskiplistNode *backward;
    # zskiplist分层，每层中包含指向其他zskiplist节点的指针
    struct zskiplistLevel {
        # zskiplist节点指针
        struct zskiplistNode *forward;
        # 本层指向的下个节点离本节点的跨度
        unsigned long span;
    } level[];
} zskiplistNode;

# 跳跃表
typedef struct zskiplist {
    # 分别指向头尾的指针
    struct zskiplistNode *header, *tail;
    # 长度 即跳跃表中包含的节点数目（头节点不算）
    unsigned long length;
    # 层数 即跳跃表中各节点层数的最大值（头节点不算）
    int level;
} zskiplist;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>t的结构可以由下图来表示：</p>
<p><img src="../2019/09/image-4.png" alt="">
其中：</p>
<ul>
<li>头节点也是zskiplistNode因此也由对应的分数、向前指针、sds，只不过一般不使用，在图中没有表示出来。</li>
<li>skiplist结构中level为5，因为在第三个节点中层数为5。</li>
<li>skiplist结构中length为3，因为一共有头节点（不算在内），o1，o2，o3几个节点。</li>
</ul>
<p>借助ZSET的各种API，来看一下skiplist在实际中是怎么使用的。<br>
下面代码出现在redis/src/t_zset.c中，实现的是zset的插入成员操作：</p>
<pre><code># 输入一个zset的skiplist、新成员的得分和名字
zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) {    
    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;
    unsigned int rank[ZSKIPLIST_MAXLEVEL];
    int i, level;

    serverAssert(!isnan(score));
    x = zsl-&gt;header;

    # 从头遍历跳跃表来查找当前元素应该插入在哪个节点之后
    for (i = zsl-&gt;level-1; i &gt;= 0; i--) {
        /* store rank that is crossed to reach the insert position */
        rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1];
        while (x-&gt;level[i].forward &amp;&amp;
                # 排名是由分数和sds名字共同决定的，同分数下按节点名排序
                (x-&gt;level[i].forward-&gt;score &amp;lt; score ||
                    (x-&gt;level[i].forward-&gt;score == score &amp;&amp;
                    sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &amp;lt; 0)))
        {
            # 注意这一句，说明span是用来便于计算节点排名的
            rank[i] += x-&gt;level[i].span;
            x = x-&gt;level[i].forward;
        }
        update[i] = x;
    }
    /* we assume the element is not already inside, since we allow duplicated
     * scores, reinserting the same element should never happen since the
     * caller of zslInsert() should test in the hash table if the element is
     * already inside or not. */
    level = zslRandomLevel();
    # 判断是否要重写头节点的level值
    if (level &gt; zsl-&gt;level) {
        for (i = zsl-&gt;level; i &amp;lt; level; i++) {
            rank[i] = 0;
            update[i] = zsl-&gt;header;
            update[i]-&gt;level[i].span = zsl-&gt;length;
        }
        zsl-&gt;level = level;
    }
    x = zslCreateNode(level,score,ele);
    for (i = 0; i &amp;lt; level; i++) {
        x-&gt;level[i].forward = update[i]-&gt;level[i].forward;
        update[i]-&gt;level[i].forward = x;

        /* update span covered by update[i] as x is inserted here */
        x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]);
        # span实际就是zset两个成员之间的rank差值
        update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1;
    }

    /* increment span for untouched levels */
    for (i = level; i &amp;lt; zsl-&gt;level; i++) {
        update[i]-&gt;level[i].span++;
    }

    x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0];
    if (x-&gt;level[0].forward)
        x-&gt;level[0].forward-&gt;backward = x;
    else
        zsl-&gt;tail = x;
    zsl-&gt;length++;
    return x;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>可以观察到：</p>
<ul>
<li>跳跃表的不同节点之间由指针和跨度关联</li>
<li>跨度值实际上为这两个节点之间的排名差距，如上图中o1与o3的排名差正是o1指向o3的第4层的跨度值2，也可以等于o1至o2的跨度值1加上o2至o3的跨度值1</li>
<li>排名取决于分数，同分情况下取决于名字</li>
<li>插入节点的时候判断层数是否大于头节点的层数值，是否需要更新</li>
<li>节点的层数是<code>zslRandomLevel()</code>生成的，根据命名每个节点的层数应该是随机的</li>
<li>注释中提到了在新增元素的时候要在哈希表中判断是否为重复，zset是不允许重复的成员出现的（但是可以有同分成员）</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>RabbitMQ入门学习笔记</title>
			<link>https://jiekun.dev/posts/2019-08-18-rabbitmq%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
			<pubDate>Sun, 18 Aug 2019 04:35:28 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-08-18-rabbitmq%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
			<description>RabbitMQ简介 RabbitMQ是个消息中间件。
 Producer：发送消息的程序称为生产者 Queue：消息在RabbitMQ中存储在队列，队列上限由内存和磁盘决定。队列本质上讲就是一个大的消息缓冲区，多个生产者可以发消息到同一个队列，多个消费者可以从同一个队列获取消息。 Consumer：等待接受消息的程序称为消费者  本文目标：
 了解RabbitMQ基础模型 了解RabbitMQ不同的Exchange类型  Hello World 官方教程使用Pika作为RabbitMQ的Python客户端。
send.py:
import pika # 连接本地RabbitMQ connection = pika.BlockingConnection( pika.ConnectionParameters(host=&#39;localhost&#39;)) channel = connection.channel() # 声明要将消息发送至的队列 channel.queue_declare(queue=&#39;hello&#39;) # 指定exchanger, routing_key 发送消息 channel.basic_publish(exchange=&#39;&#39;, routing_key=&#39;hello&#39;, body=&#39;Hello World!&#39;) print(&amp;quot; [x] Sent &#39;Hello World!&#39;&amp;quot;) nnection.close()&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; receive.py
#!/usr/bin/env python import pika connection = pika.BlockingConnection( pika.ConnectionParameters(host=&#39;localhost&#39;)) channel = connection.channel() # 同样声明队列 channel.queue_declare(queue=&#39;hello&#39;) # 接收到消息时执行 def callback(ch, method, properties, body): print(&amp;quot; [x] Received %r&amp;quot; % body) channel.</description>
			<content type="html"><![CDATA[<h2 id="rabbitmq简介">RabbitMQ简介</h2>
<p>RabbitMQ是个消息中间件。</p>
<ul>
<li>Producer：发送消息的程序称为生产者</li>
<li>Queue：消息在RabbitMQ中存储在队列，队列上限由内存和磁盘决定。队列本质上讲就是一个大的消息缓冲区，多个生产者可以发消息到同一个队列，多个消费者可以从同一个队列获取消息。</li>
<li>Consumer：等待接受消息的程序称为消费者</li>
</ul>
<p>本文目标：</p>
<ul>
<li>了解RabbitMQ基础模型</li>
<li>了解RabbitMQ不同的Exchange类型</li>
</ul>
<h2 id="hello-world">Hello World</h2>
<p>官方教程使用<code>Pika</code>作为RabbitMQ的Python客户端。</p>
<p><img src="../2019/09/mq1.jpg" alt="">
send.py:</p>
<pre><code>import pika

# 连接本地RabbitMQ
connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

# 声明要将消息发送至的队列
channel.queue_declare(queue='hello')

# 指定exchanger, routing_key 发送消息
channel.basic_publish(exchange='', routing_key='hello', body='Hello World!')
print(&quot; [x] Sent 'Hello World!'&quot;)
nnection.close()&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>receive.py</p>
<pre><code>#!/usr/bin/env python
import pika

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

# 同样声明队列
channel.queue_declare(queue='hello')

# 接收到消息时执行
def callback(ch, method, properties, body):
    print(&quot; [x] Received %r&quot; % body)


channel.basic_consume(
    queue='hello', on_message_callback=callback, auto_ack=True)

print(' [*] Waiting for messages. To exit press CTRL+C')
hannel.start_consuming()&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="任务队列">任务队列</h2>
<p>借助time.sleep()模拟单个consumer阻塞的情况，让消息分发给多个consumer。</p>
<h4 id="消息分发">消息分发</h4>
<p>RabbitMQ默认采用round-robin的方式对消息进行分发，简而言之，就是消息会平均地分发到各个consumer上。</p>
<h4 id="确认管理">确认管理</h4>
<p>之前的代码consumer对接受到的消息即时进行ACK，因此以但ACK后consumer在处理消息期间出问题，这条消息就永久丢失了。我们可以通过将message acknowledgement在处理完毕后才发送来避免这种情况。但是如果忘记ACK，相关消息就会一直停留在内存中，RabbitMQ不会释放没有ACK的消息。</p>
<h4 id="消息持久化">消息持久化</h4>
<p>为了让服务端的队列消息不丢失，需要声明队列durable=True。但是RabbitMQ不支持对已有的消息队列重新定义。</p>
<h4 id="合理分配">合理分配</h4>
<p>通过声明<code>channel.basic_qos(prefetch_count=1)</code>，使得RabbitMQ知道某个worker一次不能处理多于1条消息，也就是说不要在没有收到前一条ACK的时候发送下一条任务。</p>
<p>task.py:</p>
<pre><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.queue_declare(queue='task_queue', durable=True)

message = ' '.join(sys.argv[1:]) or &quot;Hello World!&quot;
channel.basic_publish(
    exchange='',
    routing_key='task_queue',
    body=message,
    properties=pika.BasicProperties(
        delivery_mode=2,  # make message persistent
    ))
print(&quot; [x] Sent %r&quot; % message)
nnection.close()&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>worker.py:</p>
<pre><code>#!/usr/bin/env python
import pika
import time

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.queue_declare(queue='task_queue', durable=True)
print(' [*] Waiting for messages. To exit press CTRL+C')


def callback(ch, method, properties, body):
    print(&quot; [x] Received %r&quot; % body)
    time.sleep(body.count(b'.'))
    print(&quot; [x] Done&quot;)
    ch.basic_ack(delivery_tag=method.delivery_tag)


channel.basic_qos(prefetch_count=1)
channel.basic_consume(queue='task_queue', on_message_callback=callback)

hannel.start_consuming()&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="发布订阅模式">发布订阅模式</h2>
<p><code>publish/subscrribe</code>模式：多个consumer获取到同一条消息。<br>
官方实现了一套日志订阅系统，一个consumer负责将日志写至磁盘，另一个consumer负责将日志打印在屏幕上，需要用到发布订阅模式使得这些consumer获取到相同的消息。</p>
<h4 id="exchanges">Exchanges</h4>
<p><img src="../2019/09/image.png" alt=""></p>
<p>前面几节介绍过P-&gt;Q-&gt;C的模型，实际上RabbitMQ中P发送的消息并不是直接到Q中的，而是发送到<code>exchange</code>中。exchange负责接收消息，推送消息至相应的Q，它必须清楚消息要推送到多个Q还是分配到多个Q，这些对应的规则在<code>exchange type</code>定义。</p>
<p>通常有几种exchange type：direct，topic，headers和fanout。</p>
<p>在本节要用上的是fanout类型。fanout顾名思义就是广播所有收到的消息到它所知道的队列中。</p>
<p>生产者在发送消息的时候需要声明发送到的exchange的名字和类型。</p>
<p>如果在声明queue的时候使用空字符串，RabbitMQ会选择一个随机的队列名称，比如<code>amq.gen-JzTY20BRgKO-HjmUJj0wLg</code>。<br>
同时，在consumer中指定<code>exclusive=True</code>可以让consumer断开连接后队列被删除。</p>
<p>通过channel.queue_bind方法让consumer告知exchange对应的queue名字，称为binding（绑定）。</p>
<p>完成声明exchange，声明exchange类型，消费者生成随机的断开即删除的Queue，Queue和exchange绑定之后，exchange就可以把每次收到的消息推送到对应的Q中。</p>
<p><img src="../2019/09/image-1.png" alt="">
emit_log.py:</p>
<pre><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='logs', exchange_type='fanout')

message = ' '.join(sys.argv[1:]) or &quot;info: Hello World!&quot;
channel.basic_publish(exchange='logs', routing_key='', body=message)
print(&quot; [x] Sent %r&quot; % message)
nnection.close()&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>receive_logs.py:</p>
<pre><code>#!/usr/bin/env python
import pika

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='logs', exchange_type='fanout')

result = channel.queue_declare(queue='', exclusive=True)
queue_name = result.method.queue

channel.queue_bind(exchange='logs', queue=queue_name)

print(' [*] Waiting for logs. To exit press CTRL+C')

def callback(ch, method, properties, body):
    print(&quot; [x] %r&quot; % body)

channel.basic_consume(
    queue=queue_name, on_message_callback=callback, auto_ack=True)

hannel.start_consuming()&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="路由routing">路由（Routing）</h2>
<p>和上一节略有不同，exchange还是会继续广播消息，但是要让consumer只订阅到特定消息，如重要的报错log。</p>
<p>上一节中我们通过binding将Q和E绑定，这次我们加上额外的参数<code>routing_key</code>：</p>
<pre><code>hannel.queue_bind(exchange=exchange_name,
                   queue=queue_name,
ting_key='black')&lt;/code&gt;&lt;/pre&gt;

</code></pre><p><img src="../2019/09/image-2.png" alt="">
对于<code>fanout</code>来说，这个参数是没有用的因为fanout就是直接将拿到的消息推到各个与exchange绑定了的Q上。<br>
这次改用<code>direct</code>的exchange_type，消息会推到和binding_key和routing_key相同的队列上：</p>
<p>图里可以看到，exchange<code>X</code>有两个queue绑定，其中Q1的rounting_key是orange，Q2是black和green。</p>
<p>P向X推送消息，X按照上一节需要把消息广播到Q1和Q2，但在现在的模型下，P告诉X消息的类型，比如black，X将消息推送至：</p>
<ul>
<li>Q1或者Q2</li>
<li>routing_key是black的<br>
因此Q2收到消息，Q1没有。</li>
</ul>
<p><img src="../2019/09/image-3.png" alt="">
emit_log_direct.py:</p>
<pre><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='direct_logs', exchange_type='direct')

severity = sys.argv[1] if len(sys.argv) &gt; 1 else 'info'
message = ' '.join(sys.argv[2:]) or 'Hello World!'
channel.basic_publish(
    exchange='direct_logs', routing_key=severity, body=message)
print(&quot; [x] Sent %r:%r&quot; % (severity, message))
nnection.close()&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>receive_logs_direct.py:</p>
<pre><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='direct_logs', exchange_type='direct')

result = channel.queue_declare(queue='', exclusive=True)
queue_name = result.method.queue

severities = sys.argv[1:]
if not severities:
    sys.stderr.write(&quot;Usage: %s [info] [warning] [error]\n&quot; % sys.argv[0])
    sys.exit(1)

for severity in severities:
    channel.queue_bind(
        exchange='direct_logs', queue=queue_name, routing_key=severity)

print(' [*] Waiting for logs. To exit press CTRL+C')


def callback(ch, method, properties, body):
    print(&quot; [x] %r:%r&quot; % (method.routing_key, body))


channel.basic_consume(
    queue=queue_name, on_message_callback=callback, auto_ack=True)

hannel.start_consuming()&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="话题topics">话题（Topics）</h2>
<p>上一节中，<code>direct</code>的exchange_type不能按照不同规则匹配，比如animal.chicken，animal.cow，匹配animal.*。</p>
<h4 id="topic-exchange">Topic exchange</h4>
<p>当exchange的类型为topic时，它的routing_key必须为由<code>.</code>分割的单词组成的列表，如<code>quick.orange.rabbit</code>。</p>
<p><code>topic</code>和<code>direct</code>的逻辑类似，消息推送的routing_key必须符合binding_key，但是允许：</p>
<ul>
<li>
<p><code>*</code>可以匹配一个词</p>
</li>
<li>
<p><code>#</code>可以匹配0或多个词</p>
</li>
<li>
<p>一个带有<code>quick.orange.rabbit</code>routing_key的消息会被推到Q1和Q2</p>
</li>
<li>
<p>一个带有<code>lazy.pink.rabbit</code>的消息只会被推到Q2</p>
</li>
<li>
<p>一个带有<code>quick.brown.fox</code>的消息不会被推到Q1或Q2</p>
</li>
<li>
<p>一个带有<code>quqick.orange.male.rabbit</code>的消息不能匹配上任何bindings所以会被丢弃</p>
</li>
</ul>
<p>通过通配符，<code>topic</code>模式也可以实现<code>fanout</code>和<code>direct</code>。</p>
<p>emit_log_topic.py:</p>
<pre><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='topic_logs', exchange_type='topic')

routing_key = sys.argv[1] if len(sys.argv) &gt; 2 else 'anonymous.info'
message = ' '.join(sys.argv[2:]) or 'Hello World!'
channel.basic_publish(
    exchange='topic_logs', routing_key=routing_key, body=message)
print(&quot; [x] Sent %r:%r&quot; % (routing_key, message))
nnection.close()&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>receive_logs_topic.py:</p>
<pre><code>#!/usr/bin/env python
import pika
import sys

connection = pika.BlockingConnection(
    pika.ConnectionParameters(host='localhost'))
channel = connection.channel()

channel.exchange_declare(exchange='topic_logs', exchange_type='topic')

result = channel.queue_declare('', exclusive=True)
queue_name = result.method.queue

binding_keys = sys.argv[1:]
if not binding_keys:
    sys.stderr.write(&quot;Usage: %s [binding_key]...\n&quot; % sys.argv[0])
    sys.exit(1)

for binding_key in binding_keys:
    channel.queue_bind(
        exchange='topic_logs', queue=queue_name, routing_key=binding_key)

print(' [*] Waiting for logs. To exit press CTRL+C')


def callback(ch, method, properties, body):
    print(&quot; [x] %r:%r&quot; % (method.routing_key, body))


channel.basic_consume(
    queue=queue_name, on_message_callback=callback, auto_ack=True)

hannel.start_consuming()&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="总结">总结</h2>
<ul>
<li>RabbitMQ模型：Producer-&gt;Exchange-&gt;Queue-&gt;Consumer</li>
<li>通过消息推送后Consumer的ACK来决定消息是否已经被对方处理，没有ACK的消息需要保留重发</li>
<li>默认的Exchange下消息通过Round Robin来推送到不同的队列，Consumer可以声明自己的QOS让消息在没有收到数量符合的ACK下不再分配给当前Consumer</li>
<li>通过不同的Exchange类型，实现将消息：
<ul>
<li>fanout：广播给所有绑定的Queue</li>
<li>direct：附加对应的routing_key，消息只推送给符合routing_key的Queue</li>
<li>topics：允许routing_key匹配不同的binding_key</li>
</ul>
</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>实现Django Models的数据mock</title>
			<link>https://jiekun.dev/posts/2019-08-03-%E5%AE%9E%E7%8E%B0%E4%B8%80%E5%A5%97%E5%AF%B9django-models%E6%95%B0%E6%8D%AEqueryset%E8%BF%9B%E8%A1%8C%E6%A8%A1%E6%8B%9F%E7%9A%84mock%E6%96%B9%E6%A1%88/</link>
			<pubDate>Sat, 03 Aug 2019 02:46:19 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-08-03-%E5%AE%9E%E7%8E%B0%E4%B8%80%E5%A5%97%E5%AF%B9django-models%E6%95%B0%E6%8D%AEqueryset%E8%BF%9B%E8%A1%8C%E6%A8%A1%E6%8B%9F%E7%9A%84mock%E6%96%B9%E6%A1%88/</guid>
			<description>问题 在开发过程中，整个数据流向为：
爬虫抓取数据-&amp;gt;数据中端进行数据清洗-&amp;gt;入库Web端定义的业务表&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 由于整个流程比较长，而且由于爬虫开发的不稳定性以及数据统计的复杂度，完整的开发往往不能完全异步进行，因为最后面向业务的Web端需要等待清洗入库的数据进行测试。
一般来说，如果Web端需要的业务数据比较简单，开发自测的时候都可以手动生成INSERT等SQL模拟假数据，但是如果业务复杂的时候，往往需要十余个Table联动的数据，手动INSERT比较麻烦，开发效率低。
思考 模拟数据的难处主要有：
 涉及地方多，如10多个表逐一写入对应数据 表与表之间的对应关系，如测试的时候需要从表1取10条数据，从表2取这10条数据对应的一周内各日的数据一共10 * 7条 编写测试SQL费事效率低，缺少开箱即用的数据生成器  为此需要有一款工具：
 根据Django的models字段随机生成数据 支持指定数据内容，如指定数据的id，方便联表查询的时候能够正确JOIN出结果 支持filter、get等常用方法，支持聚合查询 无需写入数据库，返回QuerySet 方便开关，Mock与测试真正数据之间任意切换  实现 将以上问题逐一分析：
随机生成对应类型数据 Django的Models常用的数据类型有：
CharField、IntegerField、DateTimeField、TextField、DecimalField、DateField
其余类型在开发中不常用，因此先实现这几种类型的随机生成器
CharField CharField对应Varchar和Char类型，目标是在有提供选项的时候随机返回选项中的内容，没提供选项的时候随机出0-max_length范围内的字符串，因此采用英文字母进行随机即可。
import string from random import choice, randint def charfield_generator(min_length=0, max_length=20, choices=[]): if not choices: return &#39;&#39;.join(choice(string.ascii_letters) for i in range(randint(min_length, max_length))) else: return choice(choices)&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; IntegerField IntegerField可以对应各类整数类型，包括SmallInt、TinyInt等均可共用同一个生成器通过限制长度来控制返回值。
f integerfield_generator(min_value, max_value, choices=[]): if not choices: return randint(min_value, max_value) else: return choice(choices)&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; TextField TextField在要求不严格的情况下也可以和CharField共用生成器。业务上一般超长的内容会使用TextField，如文章正文。</description>
			<content type="html"><![CDATA[<h1 id="问题">问题</h1>
<p>在开发过程中，整个数据流向为：</p>
<pre><code>爬虫抓取数据-&gt;数据中端进行数据清洗-&gt;入库Web端定义的业务表&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>由于整个流程比较长，而且由于爬虫开发的不稳定性以及数据统计的复杂度，完整的开发往往不能完全异步进行，因为最后面向业务的Web端需要等待清洗入库的数据进行测试。</p>
<p>一般来说，如果Web端需要的业务数据比较简单，开发自测的时候都可以手动生成INSERT等SQL模拟假数据，但是如果业务复杂的时候，往往需要十余个Table联动的数据，手动INSERT比较麻烦，开发效率低。</p>
<h1 id="思考">思考</h1>
<p>模拟数据的难处主要有：</p>
<ul>
<li>涉及地方多，如10多个表逐一写入对应数据</li>
<li>表与表之间的对应关系，如测试的时候需要从表1取10条数据，从表2取这10条数据对应的一周内各日的数据一共10 * 7条</li>
<li>编写测试SQL费事效率低，缺少开箱即用的数据生成器</li>
</ul>
<p>为此需要有一款工具：</p>
<ul>
<li>根据Django的models字段随机生成数据</li>
<li>支持指定数据内容，如指定数据的id，方便联表查询的时候能够正确JOIN出结果</li>
<li>支持filter、get等常用方法，支持聚合查询</li>
<li>无需写入数据库，返回QuerySet</li>
<li>方便开关，Mock与测试真正数据之间任意切换</li>
</ul>
<h1 id="实现">实现</h1>
<p>将以上问题逐一分析：</p>
<h2 id="随机生成对应类型数据">随机生成对应类型数据</h2>
<p>Django的Models常用的数据类型有：<br>
<code>CharField</code>、<code>IntegerField</code>、<code>DateTimeField</code>、<code>TextField</code>、<code>DecimalField</code>、<code>DateField</code><br>
其余类型在开发中不常用，因此先实现这几种类型的随机生成器</p>
<h4 id="charfield">CharField</h4>
<p>CharField对应Varchar和Char类型，目标是在有提供选项的时候随机返回选项中的内容，没提供选项的时候随机出0-max_length范围内的字符串，因此采用英文字母进行随机即可。</p>
<pre><code>import string
from random import choice, randint

def charfield_generator(min_length=0, max_length=20, choices=[]):
    if not choices:
        return ''.join(choice(string.ascii_letters) for i in range(randint(min_length, max_length)))
    else:
        return choice(choices)&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="integerfield">IntegerField</h4>
<p>IntegerField可以对应各类整数类型，包括SmallInt、TinyInt等均可共用同一个生成器通过限制长度来控制返回值。</p>
<pre><code>f integerfield_generator(min_value, max_value, choices=[]):
    if not choices:
        return randint(min_value, max_value)
    else:
        return choice(choices)&lt;/code&gt;&lt;/pre&gt;

</code></pre><h4 id="textfield">TextField</h4>
<p>TextField在要求不严格的情况下也可以和CharField共用生成器。业务上一般超长的内容会使用TextField，如文章正文。</p>
<h4 id="datetimefield">DatetimeField</h4>
<p>DatetimeField生成对应的时间对象，考虑生成一个大于起始时间(start_dt)小于结束时间(end_dt)的datetime对象。</p>
<pre><code>f datetime_generator(start_dt=datetime.now(), end_dt=datetime.now()):
    dt_delta = end_dt - start_dt
    return start_dt + timedelta(seconds=randint(0, 24 * 3600 * dt_delta.days + dt_delta.seconds))&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>简单执行一下看看第一版效果：</p>
<pre><code>for i in range(10):
    print('-------------- GENERATING SET %s -------------- ' % i)
    print(charfield_generator())
    print(integerfield_generator(0, 1000))
    print(datetime_generator(datetime.strptime('2018-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')))
    print('-------------- GENERATED SET %s -------------- ' % i, '\n')&lt;/code&gt;&lt;/pre&gt;

</code></pre><pre><code>GENERATING SET 0 -------------- 
I
196
2018-09-30 13:22:31
-------------- GENERATED SET 0 --------------  

-------------- GENERATING SET 1 -------------- 
XBFGGdpVwmlMMbCT
168
2018-11-16 09:02:16
-------------- GENERATED SET 1 --------------  

-------------- GENERATING SET 2 -------------- 
ZgU
293
2018-12-04 08:44:08
-------------- GENERATED SET 2 --------------  

-------------- GENERATING SET 3 -------------- 
TsUkylUiC
791
2018-10-01 03:48:16
-------------- GENERATED SET 3 --------------  

-------------- GENERATING SET 4 -------------- 
IusHQZsKYFtKi
909
2019-04-22 02:02:27
-------------- GENERATED SET 4 --------------  

-------------- GENERATING SET 5 -------------- 
ScRcj
505
2019-02-21 16:16:51
-------------- GENERATED SET 5 --------------  

-------------- GENERATING SET 6 -------------- 
OLmbMrZImnvaF
500
2018-12-24 22:20:47
-------------- GENERATED SET 6 --------------  

-------------- GENERATING SET 7 -------------- 
rNaRvAYSgxVzwLAe
664
2019-08-01 12:43:00
-------------- GENERATED SET 7 --------------  

-------------- GENERATING SET 8 -------------- 
rtLks
532
2019-03-14 07:38:53
-------------- GENERATED SET 8 --------------  

-------------- GENERATING SET 9 -------------- 
oIDFdOUKs
700
2018-09-21 19:59:06
-------------- GENERATED SET 9 --------------  

[Finished in 0.2s]&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>有了模拟数据之后，需要做几件事：</p>
<ul>
<li>将假数据映射到对应的Models上，实例化成QuerySet，由多个QuerySet组成iterative的QuerySet List</li>
<li>需要支持指定QuerySet List长度，因此可以实现计算页数、分页等操作</li>
</ul>
<pre><code>f model_generator(models, length):
    &quot;&quot;&quot;
    : models Models.model :
    : length int :
    : rtype QuerySet List :
    &quot;&quot;&quot;
    return []&lt;/code&gt;&lt;/pre&gt;

</code></pre><h1 id="最佳实践">最佳实践</h1>
<p>Work in progress!</p>
]]></content>
		</item>
		
		<item>
			<title>Elasticsearch倒排索引原理 数据写入与查询过程</title>
			<link>https://jiekun.dev/posts/2019-07-30-elasticsearch%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86-%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/</link>
			<pubDate>Tue, 30 Jul 2019 09:20:18 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-07-30-elasticsearch%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86-%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B/</guid>
			<description>Elasticsearch在生产中充当的角色 业务上，最早启用Elasticsearch（下称ES）是为了解决模糊查询的问题。具体业务场景为大量抓取回来的短视频内容、热门微博、公众号文章、小红书笔记、信息流新闻文章等，需要支持用户模糊查找，而随着每日新增的内容越来越多，这些信息已经积累到单个媒体数千万近亿的数量，因此依靠MySQL的模糊查询是无法满足性能上的要求，考虑引入对应的搜索引擎来解决，于是就将数据的特定字段迁移至ES以支持快速高效的模糊查询，并将查询得到的ID取回MySQL匹配再将详细内容返回。
Elasticsearch为什么能够支持高效的模糊查询 倒排索引原理 为了支持模糊查询，用户输入关键词之后，需要快速定位到这些词对应的词条，思路与MySQL的LIKE一样，但是MySQL没有实现对应的方案以支持快速定位。ES在这块上略有不同，利用倒排索引（Inverted Index）可以直接获取到文档的ID。下面来简单介绍一下倒排索引的结构。
为了便于理解，介绍的实现与具体实现会有不一致。
现在有以下的数据行：
&amp;lt;th&amp;gt; 书名 &amp;lt;/th&amp;gt; &amp;lt;th&amp;gt; 出版社 &amp;lt;/th&amp;gt;  &amp;lt;td&amp;gt; 高性能MySQL &amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; 电子工业出版社 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; Elasticsearch服务器开发 &amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; 人民邮电出版社 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 深入理解Elasticsearch &amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; 机械工业出版社 &amp;lt;/td&amp;gt;  在写入数据，也就是索引（动词）的过程中：
（1）ES首先会将数据进行分析，如”高性能MySQL”拆分成“高性能”和“MySQL”等词条（tokens），同理，“电子工业出版社”可以被拆分成“电子”、“工业”、“出版社”；
（2) 拆分完毕后添加至对应的倒排索引中：
&amp;lt;th&amp;gt; 对应id &amp;lt;/th&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  （3）这样当Client查询“工业”一词的时候，就可以快速定位到id为1的数据行；
（4）同理对id为2和3的数据分析和索引之后，倒排索引变成：
&amp;lt;th&amp;gt; 对应id &amp;lt;/th&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1, 3 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 1, 2, 3 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 2, 3 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 2 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 2 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 2 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 2 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 3 &amp;lt;/td&amp;gt;  &amp;lt;td&amp;gt; 3 &amp;lt;/td&amp;gt;  (5)举例搜索“工业”一词的时候，就应该定位到id为1和2的行</description>
			<content type="html"><![CDATA[<h1 id="elasticsearch在生产中充当的角色">Elasticsearch在生产中充当的角色</h1>
<p>业务上，最早启用Elasticsearch（下称ES）是为了解决模糊查询的问题。具体业务场景为大量抓取回来的短视频内容、热门微博、公众号文章、小红书笔记、信息流新闻文章等，需要支持用户模糊查找，而随着每日新增的内容越来越多，这些信息已经积累到单个媒体数千万近亿的数量，因此依靠MySQL的模糊查询是无法满足性能上的要求，考虑引入对应的搜索引擎来解决，于是就将数据的特定字段迁移至ES以支持快速高效的模糊查询，并将查询得到的ID取回MySQL匹配再将详细内容返回。</p>
<h1 id="elasticsearch为什么能够支持高效的模糊查询">Elasticsearch为什么能够支持高效的模糊查询</h1>
<h3 id="倒排索引原理">倒排索引原理</h3>
<p>为了支持模糊查询，用户输入关键词之后，需要快速定位到这些词对应的词条，思路与MySQL的LIKE一样，但是MySQL没有实现对应的方案以支持快速定位。ES在这块上略有不同，利用倒排索引（Inverted Index）可以直接获取到文档的ID。下面来简单介绍一下倒排索引的结构。</p>
<p>为了便于理解，介绍的实现与具体实现会有不一致。<br>
现在有以下的数据行：</p>
<!-- raw HTML omitted -->
<pre><code>&lt;th&gt;
  书名
&lt;/th&gt;

&lt;th&gt;
  出版社
&lt;/th&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  高性能MySQL
&lt;/td&gt;

&lt;td&gt;
  电子工业出版社
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  Elasticsearch服务器开发
&lt;/td&gt;

&lt;td&gt;
  人民邮电出版社
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  深入理解Elasticsearch
&lt;/td&gt;

&lt;td&gt;
  机械工业出版社
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<p>在写入数据，也就是索引（动词）的过程中：<br>
（1）ES首先会将数据进行分析，如”高性能MySQL”拆分成“高性能”和“MySQL”等词条（tokens），同理，“电子工业出版社”可以被拆分成“电子”、“工业”、“出版社”；<br>
（2) 拆分完毕后添加至对应的倒排索引中：</p>
<!-- raw HTML omitted -->
<pre><code>&lt;th&gt;
  对应id
&lt;/th&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<p>（3）这样当Client查询“工业”一词的时候，就可以快速定位到id为1的数据行；<br>
（4）同理对id为2和3的数据分析和索引之后，倒排索引变成：</p>
<!-- raw HTML omitted -->
<pre><code>&lt;th&gt;
  对应id
&lt;/th&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1, 3
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  1, 2, 3
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  2, 3
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  2
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  2
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  2
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  2
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  3
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>&lt;td&gt;
  3
&lt;/td&gt;
</code></pre>
<!-- raw HTML omitted -->
<p>(5)举例搜索“工业”一词的时候，就应该定位到id为1和2的行</p>
<p>附上官方文档中的倒排索引势力，格式略有不同但是原理是相近的</p>
<pre><code>Term      Doc_1  Doc_2
-------------------------
Quick   |       |  X
The     |   X   |
brown   |   X   |  X
dog     |   X   |
dogs    |       |  X
fox     |   X   |
foxes   |       |  X
in      |       |  X
jumped  |   X   |
lazy    |   X   |  X
leap    |       |  X
over    |   X   |  X
quick   |   X   |
summer  |       |  X
the     |   X   |
------------------------&lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="倒排索引和分析的具体实现">倒排索引和分析的具体实现</h3>
<p>倒排索引具体实现在官网文档中粗略查询了一下没有具体介绍，估计被埋在了厚厚的文档堆中。根据其他资料显示，倒排索引实现方法多种，主要如BSBI和SPIMI等，参考博客<a href="https://blog.csdn.net/androidlushangderen/article/details/44889677">《倒排索引构建算法BSBI和SPIMI》</a>。</p>
<p>在具体的分析过程中，Elasticsearch会使用多种分析器将文本拆分成用于搜索的词条，然后将这些词条统一化以提高“可搜索性”。具体来讲，分析器应该包含如下功能：<br>
（1）字符过滤器：如去除HTML，字符转换如&amp;转为and<br>
（2）分词器：如遇到空格和标点将文本拆分成词条<br>
（3）Token过滤器：如将大小写统一，增加词条（如jump、leap等同义词）<br>
ES内置有多种可选择的分析器，在业务中我们负责写入数据的同事使用的是针对中文分词的分词器以正确处理中文文本。</p>
<p>经过这些处理之后倒排索引生成，就能实现用于模糊查询的功能了。</p>
<h1 id="elasticsearch数据写入的过程">Elasticsearch数据写入的过程</h1>
<h3 id="预备知识">预备知识</h3>
<p>在ES中，数据结构和MySQL相似但也略有不同，类比来看，ES的存储从上至下可以类比成：<br>
索引（Index）：相当于MySQL中的DB<br>
文档类型（Doc Type）：相当于MySQL的Table<br>
文档（Doc）：相当于MySQL中的一行数据</p>
<p>ES的索引并非可以理解为一整块数据块，由不同的doc构成doc type然后聚集在一起就是index。实际上ES的索引是由一个或多个分片组成的，每个分片包含了文档集的一部分。每个分片又可以又对应的副本。<br>
因此，按照默认配置，ES的每个索引会切分出5个分片，而每个分片又有各自对应的副本，所以一共是10个分片。</p>
<p>分片，具体来说就是Lucene索引，因此可以看作ES的索引是由多个Lucene索引（分片）组成的，这些Lucene索引上包含了部分的doc。</p>
<p>继续细分Lucene索引，ES引入了按段搜索的概念，每个Lucene索引都是由多个段组成的，这些段具体而言就是，自身就是一个倒排索引。每个Lucene索引均包含了一个提交点（Commit Point）和多个段。</p>
<p>一下引入多种概念可能有点让人搞不懂，不要紧，下面借助一些官方的图例来理解一下。</p>
<h3 id="数据如何写入">数据如何写入</h3>
<p><img src="https://img-blog.csdnimg.cn/20190826205731562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="Lucene索引和段"> <!-- raw HTML omitted --></p>
<p>记住官方这张图，图中一个Lucene索引包含了3个段和一个提交点，当新增数据的时候：<br>
（1）新的doc存放至内存缓冲区（In-memory indexing buffer）中，准备被提交(New documents are collected in an in-memory indexing buffer)；<br>
（2）缓冲区的内容提交(Every so often, the buffer is commited)：</p>
<ul>
<li>
<p>一个新的段被写至磁盘中</p>
</li>
<li>
<p>一个新的、包含新段名称的提交点被写至磁盘中</p>
</li>
<li>
<p>所有在文件系统缓存中的待写入的数据被写入（flush）至磁盘，磁盘同步完成</p>
</li>
<li>
<p>A new segment—a supplementary inverted index—is written to disk.</p>
</li>
<li>
<p>A new commit point is written to disk, which includes the name of the new segment.</p>
</li>
<li>
<p>The disk is fsync’ed—all writes waiting in the filesystem cache are flushed to disk, to ensure that they have been physically written.</p>
<p>由于有按段写入缓冲区、写入磁盘的过程存在，ES的新增数据的搜索并不是实时的——近实时搜索。</p>
</li>
</ul>
<h3 id="近实时搜索">近实时搜索</h3>
<p><img src="https://img-blog.csdnimg.cn/20190826210926484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> <!-- raw HTML omitted --></p>
<p>因为需要把对应的段写入之后才能够查询，因此新数据进来的瞬间是无法搜索到的，即使已经按段（意味着倒排索引已经建立好）存在内存中。<br>
提交一个新的段至磁盘需要进行fsync的操作，这是个代价大的操作因此需要在内存缓冲区和磁盘之间增加新的缓冲区，使得在fsync操作之前文档就能够被搜索到。<br>
在Elasticsearch和磁盘之间是文件系统缓存。下图表示段已经从内存缓冲区中同步至文件系统缓存（灰色段），借助缓存，此时文档已经可以被检索到，但是还没有被提交。这个从内存缓冲区至文件系统缓存的过程称为refresh，这是一个写入和打开新段的轻量过程。</p>
<p>我们可以在设置中设置refresh的间隔时间，也可以通过refresh api进行手动refresh使得新增的doc“实时”可见。</p>
<pre><code># 修改my_logs索引的refresh时间间隔
PUT /my_logs
{
  &quot;settings&quot;: {
    &quot;refresh_interval&quot;: &quot;30s&quot; 
  }
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><pre><code># 请求接口对blogs进行refresh操作
POST /blogs/_refresh &lt;/code&gt;&lt;/pre&gt;

</code></pre><h3 id="数据持久化">数据持久化</h3>
<p>既然使用到了内存及文件系统缓存，那么必然有数据丢失的风险。尽管通过refresh实现了近实时搜索，但是还是要时常进行完整commit来确保能从失败中恢复出来。</p>
<p><img src="https://img-blog.csdnimg.cn/20190826211454555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> <!-- raw HTML omitted --> <img src="https://img-blog.csdnimg.cn/20190826211610131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><!-- raw HTML omitted --> <img src="https://img-blog.csdnimg.cn/20190826211636889.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><!-- raw HTML omitted --> <img src="https://img-blog.csdnimg.cn/20190826211955835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><!-- raw HTML omitted --></p>
<p>ES中使用了一个translog，在文档被索引（动词）后，就会被添加到内存缓冲区并且追加到translog：</p>
<p>在refresh操作过后，In-memory buffer区域的段转移到文件缓冲区，也就是灰色段：</p>
<p>随着进程的继续，doc会逐渐积累：</p>
<p>经过一定时间或者translog变大之后，这些translog就会通过fsync提交，现在看到所有的段都是绿色，意味着可搜索、持久化完成。文件缓存系统上的段（灰色）在fsync时会被清空（flush），旧的translog会被删除，创建新的空translog：</p>
<p>同样，flush操作也和refresh类似，有对应API可调用：</p>
<pre><code>POST /blogs/_flush &lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这里引用官方文档对translog的安全性的描述：</p>
<!-- raw HTML omitted -->
<h4 id="translog-有多安全">Translog 有多安全?</h4>
<p>translog 的目的是保证操作不会丢失。这引出了这个问题： Translog 有多安全 ？</p>
<p>在文件被 fsync 到磁盘前，被写入的文件在重启之后就会丢失。默认 translog 是每 5 秒被 fsync 刷新到硬盘， 或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。最终， 基本上，这意味着在整个请求被 fsync 到主分片和复制分片的translog之前，你的客户端不会得到一个 200 OK 响应。</p>
<p>在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小（特别是bulk导入，它在一次请求中平摊了大量文档的开销）。</p>
<p>但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。</p>
<p>这个行为可以通过设置 durability 参数为 async 来启用：</p>
<pre><code>PUT /my_index/_settings
{
    &quot;index.translog.durability&quot;: &quot;async&quot;,
    &quot;index.translog.sync_interval&quot;: &quot;5s&quot;
}&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>这个选项可以针对索引单独设置，并且可以动态进行修改。如果你决定使用异步 translog 的话，你需要 保证 在发生crash时，丢失掉 sync_interval 时间段的数据也无所谓。请在决定前知晓这个特性。</p>
<p>如果你不确定这个行为的后果，最好是使用默认的参数（ “index.translog.durability”: “request” ）来避免数据丢失。</p>
<!-- raw HTML omitted -->
<h3 id="段合并">段合并</h3>
<p><img src="https://img-blog.csdnimg.cn/20190826212541329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> <!-- raw HTML omitted --> <img src="https://img-blog.csdnimg.cn/20190826212551992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JEdWNrMjAxNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><!-- raw HTML omitted --></p>
<p>随着refresh的不断调用，ES中的段会越来越多，太多的段会消耗更多的资源，因为查询是要在各个段中进行检查的，会拖慢查询效率。<br>
ES通过将小段合并至大段来解决这个积累的问题，这个动作是自动的：<br>
（1） 当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。<br>
（2）合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p>
<p>合并之后老的段会被删除，fsync将新的段提交至磁盘</p>
<h1 id="elasticsearch数据查询的过程">Elasticsearch数据查询的过程</h1>
<p>上文已经提过，ES将索引分成不同的分片（Luence索引），再由不同分片中的段（倒排索引）存储具体的数据。为了获取对应的doc，ES需要查询所有分片并且对结果进行合并。</p>
<h3 id="默认的索引过程">默认的索引过程</h3>
<p>ES根据文档的标识符，选择文档应该进入的分片（当然这一步也支持手动指定分片）。默认情况下，通过计算文档的Hash值将文档分配到对应分片上。</p>
<h3 id="取出过程">取出过程</h3>
<p>大多数情况下，为了得到想要的结果，需要查询所有的分片。<br>
我们把请求发送到ES的一个节点，根据请求的搜索类型：<br>
（1）ES首先查询所有节点获得对应符合的文档的标识符+得分（用于排序）<br>
（2）节点根据这些所有的标识符和得分，判断需要取出的对应文档范围（如得分top5的文档），重新构建一个内部请求，再到对应分片上获取这些文档的具体内容。</p>
]]></content>
		</item>
		
		<item>
			<title>Python数据类型——String</title>
			<link>https://jiekun.dev/posts/2019-05-18-python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-string/</link>
			<pubDate>Sat, 18 May 2019 14:23:16 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-05-18-python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-string/</guid>
			<description>又隔了好久好久没有写博客，过完了春节元宵清明五一一大堆节日，今年就没了一半了，所以需要抓紧时间充实一下。立好Flag以后看书一定要随时笔记不然厚厚的书翻起来跟天书一样难找。
前言 其实这是一篇读书笔记，主要是关于Python的几种基础数据类型，包括顺序结构（List、Tuple等）、哈希结构（Dict、Set等）以及文本和Bytes。这些每天都在打交道的类型其实并不像看上去的简单，简单了解一下背后的理论和一些相关的使用技巧有助于平时编码中提高效率和写出（没）优（人）雅（懂）的代码。
原书里面大概很多文字都没（看）什（不）么（懂）用，所以文章尽可能附上相关代码方便理解。
文本与Bytes Python3将Python2的万能的str分成了text类型（Unicode）和bytes类型，反人类的拆分背后隐藏着怎样的秘密？
什么是字符串 字符串就是“字符”的“串”，问题在于什么是“字符”。
两个概念：
 字符的标识，即码位(code point)，是0-1114111的数字构成的，在Unicode中使用4-6个十六进制的数字标示，前缀U+。例如：A-U+0041，€-U+20AC。 代表字符的byte的表示方式取决于具体编码。例如：A-U+0041在UTF-8中编码成单个字节\x41，在UTF-16LE中编码为两个字节\x41\x00。  码位(code points)转字节序(bytes)叫编码，反之叫解码
&#39;你好&#39; &amp;gt;&amp;gt;&amp;gt; b = s.encode(&#39;UTF-8&#39;) # &amp;gt;&amp;gt;&amp;gt; b # 这是个bytes对象 b&#39;\xe4\xbd\xa0\xe5\xa5\xbd&#39; &amp;gt;&amp;gt;&amp;gt; b.decode(&#39;UTF-8&#39;) &#39;你好&#39; &amp;gt;&amp;gt;&amp;gt; b.decode(&#39;UTF-16LE&#39;) &#39;뷤\ue5a0붥&#39; &amp;gt;&amp;gt;&amp;gt; len(s) 2 &amp;gt;&amp;gt;&amp;gt; len(b) 6 &amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 字节 震惊，下面这串东西的[0]和[0:1]的结果竟然不一样？
my_char = bytes(&#39;很好玩的代码&#39;, encoding=&#39;utf_8&#39;) &amp;gt;&amp;gt;&amp;gt; my_char b&#39;\xe5\xbe\x88\xe5\xa5\xbd\xe7\x8e\xa9\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81&#39; &amp;gt;&amp;gt;&amp;gt; my_char[0] 229 &amp;gt;&amp;gt;&amp;gt; my_char[0:1] b&#39;\xe5&#39;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 好吧本来以为是str类型很好玩，其实Python里面的其他顺序类型也是这么做的，指定某个index的时候返回的是对应的元素，[a:b]切片的时候返回的是同类型的序列，只是str类型看起来像是比较奇怪，只返回了值。
1 = [&#39;好&#39;, &#39;玩&#39;, &#39;的&#39;, &#39;代&#39;, &#39;码&#39;] &amp;gt;&amp;gt;&amp;gt; l1[0] &#39;好&#39; &amp;gt;&amp;gt;&amp;gt; l1[0:1] [&#39;好&#39;]&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt; 二进制序列的表示方法有几种，如果不知道什么叫二进制序列的表示方法，请看：</description>
			<content type="html"><![CDATA[<p>又隔了好久好久没有写博客，过完了春节元宵清明五一一大堆节日，今年就没了一半了，所以需要抓紧时间充实一下。立好Flag以后看书一定要随时笔记不然厚厚的书翻起来跟天书一样难找。</p>
<h1 id="前言">前言</h1>
<p>其实这是一篇读书笔记，主要是关于Python的几种基础数据类型，包括顺序结构（List、Tuple等）、哈希结构（Dict、Set等）以及文本和Bytes。这些每天都在打交道的类型其实并不像看上去的简单，简单了解一下背后的理论和一些相关的使用技巧有助于平时编码中提高效率和写出（没）优（人）雅（懂）的代码。<br>
原书里面大概很多文字都没（看）什（不）么（懂）用，所以文章尽可能附上相关代码方便理解。</p>
<h1 id="文本与bytes">文本与Bytes</h1>
<p>Python3将Python2的万能的<code>str</code>分成了<code>text</code>类型（Unicode）和<code>bytes</code>类型，反人类的拆分背后隐藏着怎样的秘密？</p>
<h2 id="什么是字符串">什么是字符串</h2>
<p>字符串就是“字符”的“串”，问题在于什么是“字符”。<br>
两个概念：</p>
<ul>
<li>字符的标识，即<code>码位</code>(code point)，是0-1114111的数字构成的，在Unicode中使用4-6个十六进制的数字标示，前缀U+。例如：A-U+0041，€-U+20AC。</li>
<li>代表字符的byte的表示方式取决于具体编码。例如：A-U+0041在UTF-8中编码成单个字节\x41，在UTF-16LE中编码为两个字节\x41\x00。</li>
</ul>
<p>码位(code points)转字节序(bytes)叫<code>编码</code>，反之叫<code>解码</code></p>
<pre><code>'你好'
&gt;&gt;&gt; b = s.encode('UTF-8') # 
&gt;&gt;&gt; b  # 这是个bytes对象
b'\xe4\xbd\xa0\xe5\xa5\xbd'
&gt;&gt;&gt; b.decode('UTF-8')
'你好'
&gt;&gt;&gt; b.decode('UTF-16LE')
'뷤\ue5a0붥'
&gt;&gt;&gt; len(s)
2
&gt;&gt;&gt; len(b)
6
 &lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="字节">字节</h2>
<p>震惊，下面这串东西的[0]和[0:1]的结果竟然不一样？</p>
<pre><code>my_char = bytes('很好玩的代码', encoding='utf_8')
&gt;&gt;&gt; my_char
b'\xe5\xbe\x88\xe5\xa5\xbd\xe7\x8e\xa9\xe7\x9a\x84\xe4\xbb\xa3\xe7\xa0\x81'
&gt;&gt;&gt; my_char[0]
229
&gt;&gt;&gt; my_char[0:1]
b'\xe5'&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>好吧本来以为是<code>str</code>类型很好玩，其实Python里面的其他顺序类型也是这么做的，指定某个index的时候返回的是对应的元素，[a:b]切片的时候返回的是同类型的序列，只是<code>str</code>类型看起来像是比较奇怪，只返回了值。</p>
<pre><code>1 = ['好', '玩', '的', '代', '码']
&gt;&gt;&gt; l1[0]
'好'
&gt;&gt;&gt; l1[0:1]
['好']&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>二进制序列的表示方法有几种，如果不知道什么叫二进制序列的表示方法，请看：</p>
<pre><code>'cafe咖啡'
&gt;&gt;&gt; s.encode('utf-8')
b'cafe\xe5\x92\x96\xe5\x95\xa1'
&gt;&gt;&gt; s = &quot;&quot;&quot;
... have
... a 
... test
... &quot;&quot;&quot;
&gt;&gt;&gt; s.encode('utf-8')
b'\nhave\na \ntest\n'&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>cafe\xe5\x92\x96\xe5\x95\xa1</p>
<ul>
<li>cafe和原文的cafe完全一致，因此二进制序列可以是ASCII字符本身</li>
<li>换行、回车等和\对应的字节，使用\n、\t等表示</li>
<li>其他字节的值，比如<code>咖啡</code>，使用十六进制转义序列</li>
</ul>
<p>除了少数方法（<code>format</code>、<code>format_map</code>、<code>casefold</code>、<code>isnumeric</code>等）以外，<code>str</code>类型的方法同样支持<code>bytes</code>和<code>bytearray</code>类型。例如<code>endswith</code>、<code>replace</code>等。<code>re</code>模块中的正则表达式也能处理二进制序列。<br>
二进制序列有个类方法是<code>str</code>没有的，<code>fromhex</code>，用于从十六进制数字对构建二进制序列。（大概这东西也没什么用）</p>
<h2 id="struct和memory-views">Struct和Memory Views</h2>
<p><code>struct</code>提供了一些把字节序列(\xe5\x96)转换成不同类型字段组成的元组的方法和逆向方法。<code>struct</code>模块可以处理<code>bytes</code> 、<code>bytearray</code>和<code>memoryview</code>对象。</p>
<pre><code>import struct
&gt;&gt;&gt; fmt = '&amp;lt;3s3sHH'
&gt;&gt;&gt; with open('filter.gif', 'rb') as fp:
...     img = memoryview(fp.read())  # 使用文件创建memoryview对象
...
&gt;&gt;&gt; header = img[:10]  # memoryview切片再创建一个memoryview对象，但是memoryview的切片是共享内存地址的
&gt;&gt;&gt; bytes(header)
b'GIF89a+\x02\xe6\x00'
&gt;&gt;&gt; struct.unpack(fmt, header)  # 按照fmt规则unpack这个memoryview对象，得到一个元组
(b'GIF', b'89a', 555, 230)
&gt;&gt;&gt; del header
 del img&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>虽然搞不懂有什么用不过看起来很厉害就是了。</p>
<h2 id="编码器解码器">编码器/解码器</h2>
<p>这个小节最核心的点就是<strong>不要依赖系统的编码</strong>。因为不同系统的编码不一致，依赖系统编码会导致你的Python代码在不同系统上运行结果不一致。手动指定每次的编码器/解码器可以避免这个问题。</p>
<p>很显然不同的编码器对同一段字符串的编码得到的字节序列差异很大。开头已经说过，代表字符的byte的表示方式取决于具体编码：</p>
<pre><code>for codec in ['utf_8', 'utf_16', 'latin_1']:
...     print(codec, 'This is 同样的文字'.encode(codec), sep='\t')
... 
utf_8    b'This is \xe5\x90\x8c\xe6\xa0\xb7\xe7\x9a\x84\xe6\x96\x87\xe5\xad\x97'  # UTF-8编码结果
utf_16    b'\xff\xfeT\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7h\x84v\x87eW['  # UTF-16编码结果
Traceback (most recent call last):
  File &quot;&amp;lt;stdin&gt;&quot;, line 2, in &amp;lt;module&gt;
UnicodeEncodeError: 'latin-1' codec can't encode characters in position 8-12: ordinal not in range(256)  # Lartin-1不支持中文&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>不支持中文肯定不行，所以有一些处理<code>UnicodeEncodeError</code>的方法，包括将不支持的字符转<strong>跳过</strong>、<strong>替换</strong>。</p>
<pre><code>int(codec, 'This is 同样的文字'.encode('latin_1', errors='ignore'), sep='\t')
latin_1    b'This is '
&gt;&gt;&gt; print(codec, 'This is 同样的文字'.encode('latin_1', errors='replace'), sep='\t')
latin_1    b'This is ?????'
&gt;&gt;&gt; print(codec, 'This is 同样的文字'.encode('latin_1', errors='xmlcharrefreplace'), sep='\t')
latin_1    b'This is &amp;#21516;&amp;#26679;&amp;#30340;&amp;#25991;&amp;#23383;'&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>对应的，如果要将<code>bytes</code>解码，也会有UnicodeDecodeError。</p>
<pre><code>'\xff\xfeT\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7h\x84v\x87eW['
&gt;&gt;&gt; b.decode('utf-8')
Traceback (most recent call last):
  File &quot;&amp;lt;stdin&gt;&quot;, line 1, in &amp;lt;module&gt;
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte  # 解码不了
&gt;&gt;&gt; b.decode('utf-8', errors='replace')
'��T\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7h�v�eW['  # 代替
&gt;&gt;&gt; b.decode('utf-8', errors='ignore')
'T\x00h\x00i\x00s\x00 \x00i\x00s\x00 \x00\x0cT7hveW['  # 忽略&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="使用预期之外的编码抛出syntaxerror">使用预期之外的编码抛出SyntaxError</h2>
<p>文件顶部加上注释</p>
<pre><code># coding: cp1252&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>Python3默认使用UTF-8，GUN/Linux和OS X默认都是UTF-8，Windows则不是，所以可能会报这种反人类的错误。因此，和前面说的一样，不要依赖系统编码，全部手动指定可以让你的脚本正常运行于不同系统。</p>
<h2 id="怎样才能知道一段字节序列的编码">怎样才能知道一段字节序列的编码</h2>
<p>不可能。<br>
不过可以通过某种编码的特定模式来<strong>猜测</strong>（也就是没有100%准确的方案，a.k.a 不可能）对应编码</p>
<h2 id="bom">BOM</h2>
<pre><code>u16_en = 'El Niño'.encode('utf_16')
&gt;&gt;&gt; u16_cn = '有鬼'.encode('utf_16')
&gt;&gt;&gt; u16_en
b'\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00'
&gt;&gt;&gt; u16_cn
b'\xff\xfe\tg&amp;lt;\x9b' &lt;/code&gt;&lt;/pre&gt;

</code></pre><p>奇怪，好像两段没有一个字相同的字符，但经过编码后的字节序列都是以<code>\xff\xfe</code>开头的。没错这就是<code>BOM</code>(byte-order mark)，指明编码时使用小字节序（little-endian byte ordering）。<br>
小字节序中，字母E的位码是U+0045，在字节便宜的第二位和第三位的编码为69和0；而大字节序中是编码顺序是相反的，E的编码为0和69。<br>
因此需要区分开小字节序系统和大字节序系统。因为按照设计,U+FFFE 字符不存在，在小字节序编码中,字节序列 b’\xff\<br>
xfe’ 必定是 ZERO WIDTH NO-BREAK SPACE ,所以编解码器知道该用哪个字节序。</p>
<h2 id="处理文本文件">处理文本文件</h2>
<p>处理文本的原则遵照“Unicode三明治”，就是尽可能早地把输入的字节序列转为字符串，让逻辑层只处理字符串对象。</p>
<pre><code>n('cafe.txt', 'w', encoding='utf_8').write('café')
4
 open('cafe.txt').read()&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>如果在Windows上，最后的输出可能就不是<code>café</code>了，因为首次打开文件的时候指定了UTF-8编码，而再次打开的时候没有指定编码，则会依照系统的默认编码。Linux上默认均为UTF-8，会给人一种代码没有问题的假象，实际上并不是这样的。<br>
另外，如果在open的参数中声明是在二进制模式中读取文件，将会得到一个<code>BufferedReader</code>对象，而正常情况下会得到一个<code>TextIOWrapper</code>对象。</p>
<pre><code>f = open('cafe.txt','rb')
&gt;&gt;&gt; f
&amp;lt;_io.BufferedReader name='cafe.txt'&gt;
&gt;&gt;&gt; f = open('cafe.txt','r')
&gt;&gt;&gt; f
&amp;lt;_io.TextIOWrapper name='cafe.txt' mode='r' encoding='UTF-8'&gt;&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>打开文件时没有指定encoding参数，编码会由<code>locale.getpreferredencoding()</code>指定，类似的还有一个用于编解码文件名的方法<code>sys.getfilesystemencoding()</code>。</p>
<h2 id="字符串对比">字符串对比</h2>
<p>先看一段代码：</p>
<pre><code>1 = 'café'
&gt;&gt;&gt; s2 = 'cafe\u0301'
&gt;&gt;&gt; s1, s2
('café', 'café')
&gt;&gt;&gt; s1 == s2
False
&gt;&gt;&gt; len(s1), len(s2)
(4, 5)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>看到两种表示的<code>café</code>并不相等，因为Python看到的是不同的码位序列。解决办法是将Unicode规范化，使用<code>unicodedata.normalize</code>。<br>
<code>normalize</code>有4种参数: <code>NFC</code>，<code>NFD</code>，<code>NFKC</code>，<code>NFKD</code>。前两个分别对应“使用最少的bytes构成等价字符串”和“把字符串分解成基本字符和单独的组合字符”，也就是类似于<code>café</code>和<code>cafe\u0301</code>两种形式；后两个分别是前两个的“兼容分解”模式，<code>K</code>表示“compatibility”，这样做格式会有所损失，例如<code>1⁄2</code>（这实际上是一个字符，1在上2在下）经过“兼容分解”后会变成<code>1/2</code>（这是3个字符）。<br>
接上面的代码，经过规范化后对比返回<code>True</code>：</p>
<pre><code>from unicodedata import normalize
&gt;&gt;&gt; s1 == normalize('NFC', s2)
True
&gt;&gt;&gt; s2 == normalize('NFD', s1)
True&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="大小写折叠case-fold">大小写折叠(Case Fold)</h2>
<p>字符串的<code>casefold</code>方法将文本变为小写，但是对比<code>lower</code>方法更加暴力</p>
<pre><code>'ß'.casefold()
'ss'  # ß在德语中是“sharp s”
&gt;&gt;&gt; 'ß'.lower()
'ß'&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="规范化总结">规范化总结</h2>
<p>规范化待比较的字符串使用<code>NFC</code>，不区分大小写使用casefold</p>
<h2 id="极端的规范化">极端的“规范化”</h2>
<p>如何将<code>São Paulo</code>规范化成<code>Sao Paulo</code>，尽管这样做会丢失信息？<br>
作者的骚操作，不再展示，可以参考原书4.6.3节。</p>
<h2 id="unicode的文本排序">Unicode的文本排序</h2>
<p>这里有个错误的排序：</p>
<pre><code>fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
&gt;&gt;&gt; sorted(fruits)
['acerola', 'atemoia', 'açaí', 'caju', 'cajá']&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>期望得到的结果是<code>ç</code>按照<code>c</code>排序，<code>á</code>按照<code>a</code>排序：</p>
<pre><code>['açaí', 'acerola', 'atemoia', 'cajá', 'caju']&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>非ASCII文本的标准排序方式是使用<code>locale.strxfrm</code>函数，这个函数的结果跟当前所在区域有关，通过使用<code>locale.setlocale()</code>改变所在区域以达到按照特定区域的习惯排序的效果。</p>
<pre><code>import locale
&gt;&gt;&gt; locale.setlocale(locale.LC_COLLATE, 'zh_CN.UTF-8')
'zh_CN.UTF-8'
&gt;&gt;&gt; fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
&gt;&gt;&gt; sorted(fruits, key=locale.strxfrm)
['açaí', 'acerola', 'atemoia', 'cajá', 'caju']&lt;/code&gt;&lt;/pre&gt;

</code></pre><h2 id="unicode-数据库">Unicode 数据库</h2>
<p>Unicode标准提供了一个完整的数据库，包括码位和字符名称之间的映射、各字符的元数据、字符之间的关系。</p>
]]></content>
		</item>
		
		<item>
			<title>Django单元测试类</title>
			<link>https://jiekun.dev/posts/2019-01-17-django%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%B1%BB/</link>
			<pubDate>Thu, 17 Jan 2019 03:49:11 +0000</pubDate>
			
			<guid>https://jiekun.dev/posts/2019-01-17-django%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%B1%BB/</guid>
			<description>TestCase与TransactionTestCase都是继承自SimpleTestCase，两者主要的区别在于：
 TestCase在测试开始时，判断当前连接的数据库是否支持事务特性，如支持，则开启事务操作；在测试结束时，同样判断是否支持事务特性，如支持，执行事务回滚，然后关闭所有链接。具体setUpClass与tearDownClass方法如下  @classmethod def setUpClass(cls): super(TestCase, cls).setUpClass() if not connections_support_transactions(): # 事务支持判断 return cls.cls_atomics = cls._enter_atomics() # 开启事务，TestCase中测试代码均处于此事务Block中 if cls.fixtures: for db_name in cls._databases_names(include_mirrors=False): try: call_command(&#39;loaddata&#39;, *cls.fixtures, **{ &#39;verbosity&#39;: 0, &#39;commit&#39;: False, &#39;database&#39;: db_name, }) except Exception: cls._rollback_atomics(cls.cls_atomics) raise cls.setUpTestData() @classmethod def tearDownClass(cls): if connections_support_transactions(): # 事务支持判断 cls._rollback_atomics(cls.cls_atomics) # 回滚所有操作 for conn in connections.all(): # 关闭所有链接 conn.close() super(TestCase, cls).tearDownClass()&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;  TransactionTestCase与TestCase不同，在此测试类中并不开启事务块，测试结束时通过进行Fush操作清空数据。此类没有重写SimpleTestCase的setUp和tearDown方法，只修改了_post_teardown等如下：  f _post_teardown(self): &amp;quot;&amp;quot;&amp;quot; * 清空数据库的内容 * 关闭链接 &amp;quot;&amp;quot;&amp;quot; try: self.</description>
			<content type="html"><![CDATA[<p>TestCase与TransactionTestCase都是继承自SimpleTestCase，两者主要的区别在于：</p>
<ul>
<li>TestCase在测试开始时，判断当前连接的数据库是否支持事务特性，如支持，则开启事务操作；在测试结束时，同样判断是否支持事务特性，如支持，执行事务回滚，然后关闭所有链接。具体setUpClass与tearDownClass方法如下</li>
</ul>
<pre><code>@classmethod
    def setUpClass(cls):
        super(TestCase, cls).setUpClass()
        if not connections_support_transactions():  # 事务支持判断
            return
        cls.cls_atomics = cls._enter_atomics()  # 开启事务，TestCase中测试代码均处于此事务Block中

        if cls.fixtures:
            for db_name in cls._databases_names(include_mirrors=False):
                    try:
                        call_command('loaddata', *cls.fixtures, **{
                            'verbosity': 0,
                            'commit': False,
                            'database': db_name,
                        })
                    except Exception:
                        cls._rollback_atomics(cls.cls_atomics)
                        raise
        cls.setUpTestData()


@classmethod
def tearDownClass(cls):
    if connections_support_transactions():  # 事务支持判断
        cls._rollback_atomics(cls.cls_atomics)  # 回滚所有操作
        for conn in connections.all():  # 关闭所有链接
            conn.close()
    super(TestCase, cls).tearDownClass()&lt;/code&gt;&lt;/pre&gt;

</code></pre><ul>
<li>TransactionTestCase与TestCase不同，在此测试类中并不开启事务块，测试结束时通过进行Fush操作清空数据。此类没有重写SimpleTestCase的setUp和tearDown方法，只修改了_post_teardown等如下：</li>
</ul>
<pre><code>f _post_teardown(self):
    &quot;&quot;&quot;
    * 清空数据库的内容
    * 关闭链接
    &quot;&quot;&quot;
    try:
        self._fixture_teardown()
        super(TransactionTestCase, self)._post_teardown()
        if self._should_reload_connections():
            for conn in connections.all():
                conn.close()
    finally:
        if self.available_apps is not None:
            apps.unset_available_apps()
            setting_changed.send(sender=settings._wrapped.__class__,
                                 setting='INSTALLED_APPS',
                                 value=settings.INSTALLED_APPS,
                                 enter=False)


def _fixture_teardown(self):
    for db_name in self._databases_names(include_mirrors=False):
        call_command('flush', verbosity=0, interactive=False,
                     database=db_name, reset_sequences=False,
                     allow_cascade=self.available_apps is not None,
                     inhibit_post_migrate=self.available_apps is not None)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>在事务方面的区别使得：使用TestCase时，如果被测试代码中出现必须在事务块中执行的代码，则会抛出异常，如官方举例的select_for_update()：</p>
<pre><code>SampleTestCase(TestCase):
    def setUp(self):
        Sample.objects.create(**{'field1': 'value1, 'field2': 'value2'})

    def test_difference_testcase(self):
        sample = Sample.objects.select_for_update().filter()
        print(sample)


class SampleTransactionTestCase(TransactionTestCase):
    def setUp(self):
        Sample.objects.create(**{'field1': 'value1, 'field2': 'value2'})

    def test_difference_transactiontestcase(self):
        sample = Sample.objects.select_for_update().filter()
        print(sample)&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>第一个TestCase会抛出异常：</p>
<pre><code>AssertionError: TransactionManagementError not raised&lt;/code&gt;&lt;/pre&gt;

</code></pre><p>第二个TTC会通过测试。</p>
<h2 id="小结">小结</h2>
<ul>
<li>使用TestCase，相当于后续代码都会处于一个外层事务的Block内执行，因此测试者不能测试必须运行在事务Block中的代码 (<em>For instance, you cannot test that a block of code is executing within a transaction, as is required when using select_for_update()</em>)</li>
<li>TestCase中，最终事务需要进行回滚，因此如果在测试代码中进行了conn.close()一类的操作将会引起异常</li>
<li>TransactionTestCase不开启事务，并且通过测试结束时Flush DB的方案来还原干净环境</li>
</ul>
]]></content>
		</item>
		
	</channel>
</rss>
